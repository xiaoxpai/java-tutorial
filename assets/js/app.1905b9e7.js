(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(n){function e(e){for(var a,o,s=e[0],l=e[1],c=e[2],d=0,m=[];d<s.length;d++)o=s[d],Object.prototype.hasOwnProperty.call(r,o)&&r[o]&&m.push(r[o][0]),r[o]=0;for(a in l)Object.prototype.hasOwnProperty.call(l,a)&&(n[a]=l[a]);for(p&&p(e);m.length;)m.shift()();return i.push.apply(i,c||[]),t()}function t(){for(var n,e=0;e<i.length;e++){for(var t=i[e],a=!0,s=1;s<t.length;s++){var l=t[s];0!==r[l]&&(a=!1)}a&&(i.splice(e--,1),n=o(o.s=t[0]))}return n}var a={},r={1:0},i=[];function o(e){if(a[e])return a[e].exports;var t=a[e]={i:e,l:!1,exports:{}};return n[e].call(t.exports,t,t.exports,o),t.l=!0,t.exports}o.e=function(n){var e=[],t=r[n];if(0!==t)if(t)e.push(t[2]);else{var a=new Promise((function(e,a){t=r[n]=[e,a]}));e.push(t[2]=a);var i,s=document.createElement("script");s.charset="utf-8",s.timeout=120,o.nc&&s.setAttribute("nonce",o.nc),s.src=function(n){return o.p+"assets/js/"+({}[n]||n)+"."+{2:"fd3e179e",3:"13829456",4:"6d986bfe",5:"dfc39999",6:"39027bda",7:"3fbeea1c",8:"49ad1637",9:"e7534b6c",10:"4f444ad9",11:"bcba717a",12:"8fe18c68",13:"ac6b35ed",14:"d9be7dd1",15:"658a6d64",16:"0eacd8a6",17:"456002b9",18:"355372f4",19:"ec6f4848",20:"f4728706",21:"07934a6e",22:"04bea09d",23:"bded5cf6",24:"36e55145",25:"af635b06",26:"3eb5129e",27:"76ca98fe",28:"8ccbcac6",29:"ef9e7225",30:"d9cc6dc8",31:"a4970b6b",32:"c1e5ef11",33:"dc8ab04b",34:"27064eb2",35:"e2658c44",36:"5dfe8359",37:"9bed175b",38:"442a0821",39:"ee700231",40:"c70d0291",41:"c2c82a49",42:"d1251607",43:"521ef6e4",44:"66b2dcf2",45:"c588e7c8",46:"a2092b84",47:"e1a8c216",48:"aeba6e1f",49:"3978dfc3",50:"6d98df1d",51:"2bfd5e00",52:"62d88abb",53:"155f15a2",54:"266cf2d7",55:"d1ed211f",56:"cd84ef92",57:"e4428de4",58:"54f14446",59:"b528093b",60:"0b2f58d0",61:"7ec5c991",62:"2241309a",63:"ac4e1e0a",64:"d106193a",65:"b6c04d51",66:"36025271",67:"c231dad8",68:"b1d2c18d",69:"c541140a",70:"50e92823",71:"cfe6e344",72:"82532df7",73:"987e4182",74:"06ab1615",75:"a7709b48",76:"d2a08353",77:"0141ff0a",78:"8d33fcf7",79:"132f7978",80:"be1fa7c9",81:"5f384a58",82:"ac3a3a26",83:"4af5435b",84:"bcb557f7",85:"501d4ca7",86:"facca23f"}[n]+".js"}(n);var l=new Error;i=function(e){s.onerror=s.onload=null,clearTimeout(c);var t=r[n];if(0!==t){if(t){var a=e&&("load"===e.type?"missing":e.type),i=e&&e.target&&e.target.src;l.message="Loading chunk "+n+" failed.\n("+a+": "+i+")",l.name="ChunkLoadError",l.type=a,l.request=i,t[1](l)}r[n]=void 0}};var c=setTimeout((function(){i({type:"timeout",target:s})}),12e4);s.onerror=s.onload=i,document.head.appendChild(s)}return Promise.all(e)},o.m=n,o.c=a,o.d=function(n,e,t){o.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:t})},o.r=function(n){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})},o.t=function(n,e){if(1&e&&(n=o(n)),8&e)return n;if(4&e&&"object"==typeof n&&n&&n.__esModule)return n;var t=Object.create(null);if(o.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:n}),2&e&&"string"!=typeof n)for(var a in n)o.d(t,a,function(e){return n[e]}.bind(null,a));return t},o.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return o.d(e,"a",e),e},o.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},o.p="/java-tutorial/",o.oe=function(n){throw console.error(n),n};var s=window.webpackJsonp=window.webpackJsonp||[],l=s.push.bind(s);s.push=e,s=s.slice();for(var c=0;c<s.length;c++)e(s[c]);var p=l;i.push([100,0]),t()}([function(n,e){n.exports=function(n){return"function"==typeof n}},function(n,e,t){var a=t(25),r=Function.prototype,i=r.bind,o=r.call,s=a&&i.bind(o,o);n.exports=a?function(n){return n&&s(n)}:function(n){return n&&function(){return o.apply(n,arguments)}}},function(n,e){var t=function(n){return n&&n.Math==Math&&n};n.exports=t("object"==typeof globalThis&&globalThis)||t("object"==typeof window&&window)||t("object"==typeof self&&self)||t("object"==typeof global&&global)||function(){return this}()||Function("return this")()},function(n,e){n.exports=function(n){try{return!!n()}catch(n){return!0}}},function(n,e){var t=Array.isArray;n.exports=t},function(n,e,t){var a=t(67),r="object"==typeof self&&self&&self.Object===Object&&self,i=a||r||Function("return this")();n.exports=i},function(n,e,t){"use strict";function a(n,e,t,a,r,i,o,s){var l,c="function"==typeof n?n.options:n;if(e&&(c.render=e,c.staticRenderFns=t,c._compiled=!0),a&&(c.functional=!0),i&&(c._scopeId="data-v-"+i),o?(l=function(n){(n=n||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(n=__VUE_SSR_CONTEXT__),r&&r.call(this,n),n&&n._registeredComponents&&n._registeredComponents.add(o)},c._ssrRegister=l):r&&(l=s?function(){r.call(this,(c.functional?this.parent:this).$root.$options.shadowRoot)}:r),l)if(c.functional){c._injectStyles=l;var p=c.render;c.render=function(n,e){return l.call(e),p(n,e)}}else{var d=c.beforeCreate;c.beforeCreate=d?[].concat(d,l):[l]}return{exports:n,options:c}}t.d(e,"a",(function(){return a}))},function(n,e,t){var a=t(3);n.exports=!a((function(){return 7!=Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(n,e,t){var a=t(1),r=t(45),i=a({}.hasOwnProperty);n.exports=Object.hasOwn||function(n,e){return i(r(n),e)}},function(n,e,t){var a=t(0);n.exports=function(n){return"object"==typeof n?null!==n:a(n)}},function(n,e,t){var a=t(155),r=t(158);n.exports=function(n,e){var t=r(n,e);return a(t)?t:void 0}},function(n,e,t){"use strict";t.d(e,"e",(function(){return a})),t.d(e,"b",(function(){return i})),t.d(e,"j",(function(){return o})),t.d(e,"g",(function(){return l})),t.d(e,"h",(function(){return c})),t.d(e,"i",(function(){return p})),t.d(e,"c",(function(){return d})),t.d(e,"f",(function(){return m})),t.d(e,"l",(function(){return u})),t.d(e,"m",(function(){return h})),t.d(e,"d",(function(){return v})),t.d(e,"k",(function(){return b})),t.d(e,"n",(function(){return f})),t.d(e,"a",(function(){return x}));const a=/#.*$/,r=/\.(md|html)$/,i=/\/$/,o=/^[a-z]+:/i;function s(n){return decodeURI(n).replace(a,"").replace(r,"")}function l(n){return o.test(n)}function c(n){return/^mailto:/.test(n)}function p(n){return/^tel:/.test(n)}function d(n){if(l(n))return n;if(!n)return"404";const e=n.match(a),t=e?e[0]:"",r=s(n);return i.test(r)?n:r+".html"+t}function m(n,e){const t=n.hash,r=function(n){const e=n&&n.match(a);if(e)return e[0]}(e);if(r&&t!==r)return!1;return s(n.path)===s(e)}function u(n,e,t){if(l(e))return{type:"external",path:e};t&&(e=function(n,e,t){const a=n.charAt(0);if("/"===a)return n;if("?"===a||"#"===a)return e+n;const r=e.split("/");t&&r[r.length-1]||r.pop();const i=n.replace(/^\//,"").split("/");for(let n=0;n<i.length;n++){const e=i[n];".."===e?r.pop():"."!==e&&r.push(e)}""!==r[0]&&r.unshift("");return r.join("/")}(e,t));const a=s(e);for(let e=0;e<n.length;e++)if(s(n[e].regularPath)===a)return Object.assign({},n[e],{type:"page",path:d(n[e].path)});return console.error(`[vuepress] No matching page found for sidebar item "${e}"`),{}}function h(n,e,t,a){const{pages:r,themeConfig:i}=t,o=a&&i.locales&&i.locales[a]||i;if("auto"===(n.frontmatter.sidebar||o.sidebar||i.sidebar))return g(n);const s=o.sidebar||i.sidebar;if(s){const{base:t,config:a}=function(n,e){if(Array.isArray(e))return{base:"/",config:e};for(const a in e)if(0===(t=n,/(\.html|\/)$/.test(t)?t:t+"/").indexOf(encodeURI(a)))return{base:a,config:e[a]};var t;return{}}(e,s);return"auto"===a?g(n):a?a.map(n=>function n(e,t,a,r=1){if("string"==typeof e)return u(t,e,a);if(Array.isArray(e))return Object.assign(u(t,e[0],a),{title:e[1]});{r>3&&console.error("[vuepress] detected a too deep nested sidebar group.");const i=e.children||[];return 0===i.length&&e.path?Object.assign(u(t,e.path,a),{title:e.title}):{type:"group",path:e.path,title:e.title,sidebarDepth:e.sidebarDepth,initialOpenGroupIndex:e.initialOpenGroupIndex,children:i.map(e=>n(e,t,a,r+1)),collapsable:!1!==e.collapsable}}}(n,r,t)):[]}return[]}function g(n){const e=v(n.headers||[]);return[{type:"group",collapsable:!1,title:n.title,path:null,children:e.map(e=>({type:"auto",title:e.title,basePath:n.path,path:n.path+"#"+e.slug,children:e.children||[]}))}]}function v(n){let e;return(n=n.map(n=>Object.assign({},n))).forEach(n=>{2===n.level?e=n:e&&(e.children||(e.children=[])).push(n)}),n.filter(n=>2===n.level)}function b(n){return Object.assign(n,{type:n.items&&n.items.length?"links":"link"})}function f(n){return Object.prototype.toString.call(n).match(/\[object (.*?)\]/)[1].toLowerCase()}function y(n){let e=n.frontmatter.date||n.lastUpdated||new Date,t=new Date(e);return"Invalid Date"==t&&e&&(t=new Date(e.replace(/-/g,"/"))),t.getTime()}function x(n,e){return y(e)-y(n)}},function(n,e){n.exports=function(n){return null!=n&&"object"==typeof n}},function(n,e,t){var a=t(14),r=t(140),i=t(141),o=a?a.toStringTag:void 0;n.exports=function(n){return null==n?void 0===n?"[object Undefined]":"[object Null]":o&&o in Object(n)?r(n):i(n)}},function(n,e,t){var a=t(5).Symbol;n.exports=a},function(n,e,t){var a=t(7),r=t(61),i=t(96),o=t(24),s=t(52),l=TypeError,c=Object.defineProperty,p=Object.getOwnPropertyDescriptor;e.f=a?i?function(n,e,t){if(o(n),e=s(e),o(t),"function"==typeof n&&"prototype"===e&&"value"in t&&"writable"in t&&!t.writable){var a=p(n,e);a&&a.writable&&(n[e]=t.value,t={configurable:"configurable"in t?t.configurable:a.configurable,enumerable:"enumerable"in t?t.enumerable:a.enumerable,writable:!1})}return c(n,e,t)}:c:function(n,e,t){if(o(n),e=s(e),o(t),r)try{return c(n,e,t)}catch(n){}if("get"in t||"set"in t)throw l("Accessors not supported");return"value"in t&&(n[e]=t.value),n}},function(n,e,t){var a=t(2),r=t(0),i=function(n){return r(n)?n:void 0};n.exports=function(n,e){return arguments.length<2?i(a[n]):a[n]&&a[n][e]}},function(n,e,t){var a=t(7),r=t(15),i=t(29);n.exports=a?function(n,e,t){return r.f(n,e,i(1,t))}:function(n,e,t){return n[e]=t,n}},function(n,e,t){var a=t(145),r=t(146),i=t(147),o=t(148),s=t(149);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var a=n[e];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=r,l.prototype.get=i,l.prototype.has=o,l.prototype.set=s,n.exports=l},function(n,e,t){var a=t(69);n.exports=function(n,e){for(var t=n.length;t--;)if(a(n[t][0],e))return t;return-1}},function(n,e,t){var a=t(10)(Object,"create");n.exports=a},function(n,e,t){var a=t(167);n.exports=function(n,e){var t=n.__data__;return a(e)?t["string"==typeof e?"string":"hash"]:t.map}},function(n,e,t){var a=t(40);n.exports=function(n){if("string"==typeof n||a(n))return n;var e=n+"";return"0"==e&&1/n==-1/0?"-0":e}},function(n,e,t){var a,r;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(r="function"==typeof(a=function(){var n,e,t={version:"0.2.0"},a=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function r(n,e,t){return n<e?e:n>t?t:n}function i(n){return 100*(-1+n)}t.configure=function(n){var e,t;for(e in n)void 0!==(t=n[e])&&n.hasOwnProperty(e)&&(a[e]=t);return this},t.status=null,t.set=function(n){var e=t.isStarted();n=r(n,a.minimum,1),t.status=1===n?null:n;var l=t.render(!e),c=l.querySelector(a.barSelector),p=a.speed,d=a.easing;return l.offsetWidth,o((function(e){""===a.positionUsing&&(a.positionUsing=t.getPositioningCSS()),s(c,function(n,e,t){var r;return(r="translate3d"===a.positionUsing?{transform:"translate3d("+i(n)+"%,0,0)"}:"translate"===a.positionUsing?{transform:"translate("+i(n)+"%,0)"}:{"margin-left":i(n)+"%"}).transition="all "+e+"ms "+t,r}(n,p,d)),1===n?(s(l,{transition:"none",opacity:1}),l.offsetWidth,setTimeout((function(){s(l,{transition:"all "+p+"ms linear",opacity:0}),setTimeout((function(){t.remove(),e()}),p)}),p)):setTimeout(e,p)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var n=function(){setTimeout((function(){t.status&&(t.trickle(),n())}),a.trickleSpeed)};return a.trickle&&n(),this},t.done=function(n){return n||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(n){var e=t.status;return e?("number"!=typeof n&&(n=(1-e)*r(Math.random()*e,.1,.95)),e=r(e+n,0,.994),t.set(e)):t.start()},t.trickle=function(){return t.inc(Math.random()*a.trickleRate)},n=0,e=0,t.promise=function(a){return a&&"resolved"!==a.state()?(0===e&&t.start(),n++,e++,a.always((function(){0==--e?(n=0,t.done()):t.set((n-e)/n)})),this):this},t.render=function(n){if(t.isRendered())return document.getElementById("nprogress");c(document.documentElement,"nprogress-busy");var e=document.createElement("div");e.id="nprogress",e.innerHTML=a.template;var r,o=e.querySelector(a.barSelector),l=n?"-100":i(t.status||0),p=document.querySelector(a.parent);return s(o,{transition:"all 0 linear",transform:"translate3d("+l+"%,0,0)"}),a.showSpinner||(r=e.querySelector(a.spinnerSelector))&&m(r),p!=document.body&&c(p,"nprogress-custom-parent"),p.appendChild(e),e},t.remove=function(){p(document.documentElement,"nprogress-busy"),p(document.querySelector(a.parent),"nprogress-custom-parent");var n=document.getElementById("nprogress");n&&m(n)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var n=document.body.style,e="WebkitTransform"in n?"Webkit":"MozTransform"in n?"Moz":"msTransform"in n?"ms":"OTransform"in n?"O":"";return e+"Perspective"in n?"translate3d":e+"Transform"in n?"translate":"margin"};var o=function(){var n=[];function e(){var t=n.shift();t&&t(e)}return function(t){n.push(t),1==n.length&&e()}}(),s=function(){var n=["Webkit","O","Moz","ms"],e={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(n,e){return e.toUpperCase()})),e[t]||(e[t]=function(e){var t=document.body.style;if(e in t)return e;for(var a,r=n.length,i=e.charAt(0).toUpperCase()+e.slice(1);r--;)if((a=n[r]+i)in t)return a;return e}(t))}function a(n,e,a){e=t(e),n.style[e]=a}return function(n,e){var t,r,i=arguments;if(2==i.length)for(t in e)void 0!==(r=e[t])&&e.hasOwnProperty(t)&&a(n,t,r);else a(n,i[1],i[2])}}();function l(n,e){return("string"==typeof n?n:d(n)).indexOf(" "+e+" ")>=0}function c(n,e){var t=d(n),a=t+e;l(t,e)||(n.className=a.substring(1))}function p(n,e){var t,a=d(n);l(n,e)&&(t=a.replace(" "+e+" "," "),n.className=t.substring(1,t.length-1))}function d(n){return(" "+(n.className||"")+" ").replace(/\s+/gi," ")}function m(n){n&&n.parentNode&&n.parentNode.removeChild(n)}return t})?a.call(e,t,e,n):a)||(n.exports=r)},function(n,e,t){var a=t(9),r=String,i=TypeError;n.exports=function(n){if(a(n))return n;throw i(r(n)+" is not an object")}},function(n,e,t){var a=t(3);n.exports=!a((function(){var n=function(){}.bind();return"function"!=typeof n||n.hasOwnProperty("prototype")}))},function(n,e,t){var a=t(43),r=t(51);n.exports=function(n){return a(r(n))}},function(n,e,t){var a=t(2),r=t(58),i=t(8),o=t(60),s=t(56),l=t(55),c=r("wks"),p=a.Symbol,d=p&&p.for,m=l?p:p&&p.withoutSetter||o;n.exports=function(n){if(!i(c,n)||!s&&"string"!=typeof c[n]){var e="Symbol."+n;s&&i(p,n)?c[n]=p[n]:c[n]=l&&d?d(e):m(e)}return c[n]}},function(n,e,t){var a=t(25),r=Function.prototype.call;n.exports=a?r.bind(r):function(){return r.apply(r,arguments)}},function(n,e){n.exports=function(n,e){return{enumerable:!(1&n),configurable:!(2&n),writable:!(4&n),value:e}}},function(n,e,t){var a=t(1),r=a({}.toString),i=a("".slice);n.exports=function(n){return i(r(n),8,-1)}},function(n,e,t){var a=t(2),r=t(32),i=a["__core-js_shared__"]||r("__core-js_shared__",{});n.exports=i},function(n,e,t){var a=t(2),r=Object.defineProperty;n.exports=function(n,e){try{r(a,n,{value:e,configurable:!0,writable:!0})}catch(t){a[n]=e}return e}},function(n,e,t){var a=t(139),r=t(12),i=Object.prototype,o=i.hasOwnProperty,s=i.propertyIsEnumerable,l=a(function(){return arguments}())?a:function(n){return r(n)&&o.call(n,"callee")&&!s.call(n,"callee")};n.exports=l},function(n,e,t){var a=t(10)(t(5),"Map");n.exports=a},function(n,e){n.exports=function(n){var e=typeof n;return null!=n&&("object"==e||"function"==e)}},function(n,e,t){var a=t(159),r=t(166),i=t(168),o=t(169),s=t(170);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var a=n[e];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=r,l.prototype.get=i,l.prototype.has=o,l.prototype.set=s,n.exports=l},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n){t[++e]=n})),t}},function(n,e){n.exports=function(n){return"number"==typeof n&&n>-1&&n%1==0&&n<=9007199254740991}},function(n,e,t){var a=t(4),r=t(40),i=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,o=/^\w*$/;n.exports=function(n,e){if(a(n))return!1;var t=typeof n;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=n&&!r(n))||(o.test(n)||!i.test(n)||null!=e&&n in Object(e))}},function(n,e,t){var a=t(13),r=t(12);n.exports=function(n){return"symbol"==typeof n||r(n)&&"[object Symbol]"==a(n)}},function(n,e){n.exports=function(n){return n}},function(n,e,t){var a=t(2),r=t(50).f,i=t(17),o=t(108),s=t(32),l=t(63),c=t(120);n.exports=function(n,e){var t,p,d,m,u,h=n.target,g=n.global,v=n.stat;if(t=g?a:v?a[h]||s(h,{}):(a[h]||{}).prototype)for(p in e){if(m=e[p],d=n.dontCallGetSet?(u=r(t,p))&&u.value:t[p],!c(g?p:h+(v?".":"#")+p,n.forced)&&void 0!==d){if(typeof m==typeof d)continue;l(m,d)}(n.sham||d&&d.sham)&&i(m,"sham",!0),o(t,p,m,n)}}},function(n,e,t){var a=t(1),r=t(3),i=t(30),o=Object,s=a("".split);n.exports=r((function(){return!o("z").propertyIsEnumerable(0)}))?function(n){return"String"==i(n)?s(n,""):o(n)}:o},function(n,e,t){var a=t(0),r=t(106),i=TypeError;n.exports=function(n){if(a(n))return n;throw i(r(n)+" is not a function")}},function(n,e,t){var a=t(51),r=Object;n.exports=function(n){return r(a(n))}},function(n,e){n.exports={}},function(n,e,t){var a=t(118);n.exports=function(n){return a(n.length)}},function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},function(n,e){var t=/^\s+|\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,r=/^0b[01]+$/i,i=/^0o[0-7]+$/i,o=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,l="object"==typeof self&&self&&self.Object===Object&&self,c=s||l||Function("return this")(),p=Object.prototype.toString,d=Math.max,m=Math.min,u=function(){return c.Date.now()};function h(n){var e=typeof n;return!!n&&("object"==e||"function"==e)}function g(n){if("number"==typeof n)return n;if(function(n){return"symbol"==typeof n||function(n){return!!n&&"object"==typeof n}(n)&&"[object Symbol]"==p.call(n)}(n))return NaN;if(h(n)){var e="function"==typeof n.valueOf?n.valueOf():n;n=h(e)?e+"":e}if("string"!=typeof n)return 0===n?n:+n;n=n.replace(t,"");var s=r.test(n);return s||i.test(n)?o(n.slice(2),s?2:8):a.test(n)?NaN:+n}n.exports=function(n,e,t){var a,r,i,o,s,l,c=0,p=!1,v=!1,b=!0;if("function"!=typeof n)throw new TypeError("Expected a function");function f(e){var t=a,i=r;return a=r=void 0,c=e,o=n.apply(i,t)}function y(n){return c=n,s=setTimeout(k,e),p?f(n):o}function x(n){var t=n-l;return void 0===l||t>=e||t<0||v&&n-c>=i}function k(){var n=u();if(x(n))return j(n);s=setTimeout(k,function(n){var t=e-(n-l);return v?m(t,i-(n-c)):t}(n))}function j(n){return s=void 0,b&&a?f(n):(a=r=void 0,o)}function S(){var n=u(),t=x(n);if(a=arguments,r=this,l=n,t){if(void 0===s)return y(l);if(v)return s=setTimeout(k,e),f(l)}return void 0===s&&(s=setTimeout(k,e)),o}return e=g(e)||0,h(t)&&(p=!!t.leading,i=(v="maxWait"in t)?d(g(t.maxWait)||0,e):i,b="trailing"in t?!!t.trailing:b),S.cancel=function(){void 0!==s&&clearTimeout(s),c=0,a=l=r=s=void 0},S.flush=function(){return void 0===s?o:j(u())},S}},function(n,e,t){var a=t(7),r=t(28),i=t(102),o=t(29),s=t(26),l=t(52),c=t(8),p=t(61),d=Object.getOwnPropertyDescriptor;e.f=a?d:function(n,e){if(n=s(n),e=l(e),p)try{return d(n,e)}catch(n){}if(c(n,e))return o(!r(i.f,n,e),n[e])}},function(n,e){var t=TypeError;n.exports=function(n){if(null==n)throw t("Can't call method on "+n);return n}},function(n,e,t){var a=t(103),r=t(53);n.exports=function(n){var e=a(n,"string");return r(e)?e:e+""}},function(n,e,t){var a=t(16),r=t(0),i=t(54),o=t(55),s=Object;n.exports=o?function(n){return"symbol"==typeof n}:function(n){var e=a("Symbol");return r(e)&&i(e.prototype,s(n))}},function(n,e,t){var a=t(1);n.exports=a({}.isPrototypeOf)},function(n,e,t){var a=t(56);n.exports=a&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(n,e,t){var a=t(57),r=t(3);n.exports=!!Object.getOwnPropertySymbols&&!r((function(){var n=Symbol();return!String(n)||!(Object(n)instanceof Symbol)||!Symbol.sham&&a&&a<41}))},function(n,e,t){var a,r,i=t(2),o=t(104),s=i.process,l=i.Deno,c=s&&s.versions||l&&l.version,p=c&&c.v8;p&&(r=(a=p.split("."))[0]>0&&a[0]<4?1:+(a[0]+a[1])),!r&&o&&(!(a=o.match(/Edge\/(\d+)/))||a[1]>=74)&&(a=o.match(/Chrome\/(\d+)/))&&(r=+a[1]),n.exports=r},function(n,e,t){var a=t(59),r=t(31);(n.exports=function(n,e){return r[n]||(r[n]=void 0!==e?e:{})})("versions",[]).push({version:"3.23.3",mode:a?"pure":"global",copyright:"© 2014-2022 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.23.3/LICENSE",source:"https://github.com/zloirock/core-js"})},function(n,e){n.exports=!1},function(n,e,t){var a=t(1),r=0,i=Math.random(),o=a(1..toString);n.exports=function(n){return"Symbol("+(void 0===n?"":n)+")_"+o(++r+i,36)}},function(n,e,t){var a=t(7),r=t(3),i=t(95);n.exports=!a&&!r((function(){return 7!=Object.defineProperty(i("div"),"a",{get:function(){return 7}}).a}))},function(n,e,t){var a=t(1),r=t(0),i=t(31),o=a(Function.toString);r(i.inspectSource)||(i.inspectSource=function(n){return o(n)}),n.exports=i.inspectSource},function(n,e,t){var a=t(8),r=t(113),i=t(50),o=t(15);n.exports=function(n,e,t){for(var s=r(e),l=o.f,c=i.f,p=0;p<s.length;p++){var d=s[p];a(n,d)||t&&a(t,d)||l(n,d,c(e,d))}}},function(n,e,t){var a=t(117);n.exports=function(n){var e=+n;return e!=e||0===e?0:a(e)}},function(n,e,t){var a=t(1),r=t(24),i=t(127);n.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var n,e=!1,t={};try{(n=a(Object.getOwnPropertyDescriptor(Object.prototype,"__proto__").set))(t,[]),e=t instanceof Array}catch(n){}return function(t,a){return r(t),i(a),e?n(t,a):t.__proto__=a,t}}():void 0)},function(n,e){n.exports=function(n,e){for(var t=-1,a=e.length,r=n.length;++t<a;)n[r+t]=e[t];return n}},function(n,e){var t="object"==typeof global&&global&&global.Object===Object&&global;n.exports=t},function(n,e,t){var a=t(18),r=t(150),i=t(151),o=t(152),s=t(153),l=t(154);function c(n){var e=this.__data__=new a(n);this.size=e.size}c.prototype.clear=r,c.prototype.delete=i,c.prototype.get=o,c.prototype.has=s,c.prototype.set=l,n.exports=c},function(n,e){n.exports=function(n,e){return n===e||n!=n&&e!=e}},function(n,e,t){var a=t(13),r=t(35);n.exports=function(n){if(!r(n))return!1;var e=a(n);return"[object Function]"==e||"[object GeneratorFunction]"==e||"[object AsyncFunction]"==e||"[object Proxy]"==e}},function(n,e){var t=Function.prototype.toString;n.exports=function(n){if(null!=n){try{return t.call(n)}catch(n){}try{return n+""}catch(n){}}return""}},function(n,e,t){var a=t(171),r=t(12);n.exports=function n(e,t,i,o,s){return e===t||(null==e||null==t||!r(e)&&!r(t)?e!=e&&t!=t:a(e,t,i,o,n,s))}},function(n,e,t){var a=t(74),r=t(174),i=t(75);n.exports=function(n,e,t,o,s,l){var c=1&t,p=n.length,d=e.length;if(p!=d&&!(c&&d>p))return!1;var m=l.get(n),u=l.get(e);if(m&&u)return m==e&&u==n;var h=-1,g=!0,v=2&t?new a:void 0;for(l.set(n,e),l.set(e,n);++h<p;){var b=n[h],f=e[h];if(o)var y=c?o(f,b,h,e,n,l):o(b,f,h,n,e,l);if(void 0!==y){if(y)continue;g=!1;break}if(v){if(!r(e,(function(n,e){if(!i(v,e)&&(b===n||s(b,n,t,o,l)))return v.push(e)}))){g=!1;break}}else if(b!==f&&!s(b,f,t,o,l)){g=!1;break}}return l.delete(n),l.delete(e),g}},function(n,e,t){var a=t(36),r=t(172),i=t(173);function o(n){var e=-1,t=null==n?0:n.length;for(this.__data__=new a;++e<t;)this.add(n[e])}o.prototype.add=o.prototype.push=r,o.prototype.has=i,n.exports=o},function(n,e){n.exports=function(n,e){return n.has(e)}},function(n,e,t){var a=t(184),r=t(190),i=t(80);n.exports=function(n){return i(n)?a(n):r(n)}},function(n,e,t){(function(n){var a=t(5),r=t(186),i=e&&!e.nodeType&&e,o=i&&"object"==typeof n&&n&&!n.nodeType&&n,s=o&&o.exports===i?a.Buffer:void 0,l=(s?s.isBuffer:void 0)||r;n.exports=l}).call(this,t(48)(n))},function(n,e){var t=/^(?:0|[1-9]\d*)$/;n.exports=function(n,e){var a=typeof n;return!!(e=null==e?9007199254740991:e)&&("number"==a||"symbol"!=a&&t.test(n))&&n>-1&&n%1==0&&n<e}},function(n,e,t){var a=t(187),r=t(188),i=t(189),o=i&&i.isTypedArray,s=o?r(o):a;n.exports=s},function(n,e,t){var a=t(70),r=t(38);n.exports=function(n){return null!=n&&r(n.length)&&!a(n)}},function(n,e,t){var a=t(10)(t(5),"Set");n.exports=a},function(n,e,t){var a=t(35);n.exports=function(n){return n==n&&!a(n)}},function(n,e){n.exports=function(n,e){return function(t){return null!=t&&(t[n]===e&&(void 0!==e||n in Object(t)))}}},function(n,e,t){var a=t(85),r=t(22);n.exports=function(n,e){for(var t=0,i=(e=a(e,n)).length;null!=n&&t<i;)n=n[r(e[t++])];return t&&t==i?n:void 0}},function(n,e,t){var a=t(4),r=t(39),i=t(201),o=t(204);n.exports=function(n,e){return a(n)?n:r(n,e)?[n]:i(o(n))}},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){var a=t(137),r=t(142),i=t(213),o=t(221),s=t(230),l=t(99),c=i((function(n){var e=l(n);return s(e)&&(e=void 0),o(a(n,1,s,!0),r(e,2))}));n.exports=c},function(n,e,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var a=/["'&<>]/;n.exports=function(n){var e,t=""+n,r=a.exec(t);if(!r)return t;var i="",o=0,s=0;for(o=r.index;o<t.length;o++){switch(t.charCodeAt(o)){case 34:e="&quot;";break;case 38:e="&amp;";break;case 39:e="&#39;";break;case 60:e="&lt;";break;case 62:e="&gt;";break;default:continue}s!==o&&(i+=t.substring(s,o)),s=o+1,i+=e}return s!==o?i+t.substring(s,o):i}},function(n,e,t){"use strict";t.r(e);var a={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},r=(t(233),t(6)),i=Object(r.a)(a,(function(){return(0,this._self._c)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"4f1e9d0c",null);e.default=i.exports},function(n,e,t){"use strict";t.r(e);var a={name:"CodeGroup",data:()=>({codeTabs:[],activeCodeTabIndex:-1}),watch:{activeCodeTabIndex(n){this.codeTabs.forEach(n=>{n.elm.classList.remove("theme-code-block__active")}),this.codeTabs[n].elm.classList.add("theme-code-block__active")}},mounted(){this.codeTabs=(this.$slots.default||[]).filter(n=>Boolean(n.componentOptions)).map((n,e)=>(""===n.componentOptions.propsData.active&&(this.activeCodeTabIndex=e),{title:n.componentOptions.propsData.title,elm:n.elm})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab(n){this.activeCodeTabIndex=n}}},r=(t(234),t(6)),i=Object(r.a)(a,(function(){var n=this,e=n._self._c;return e("div",{staticClass:"theme-code-group"},[e("div",{staticClass:"theme-code-group__nav"},[e("ul",{staticClass:"theme-code-group__ul"},n._l(n.codeTabs,(function(t,a){return e("li",{key:t.title,staticClass:"theme-code-group__li"},[e("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":a===n.activeCodeTabIndex},on:{click:function(e){return n.changeCodeTab(a)}}},[n._v("\n            "+n._s(t.title)+"\n          ")])])})),0)]),n._v(" "),n._t("default"),n._v(" "),n.codeTabs.length<1?e("pre",{staticClass:"pre-blank"},[n._v("// Make sure to add code blocks to your code group")]):n._e()],2)}),[],!1,null,"2f5f1757",null);e.default=i.exports},function(n,e){n.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(n,e,t){var a=t(2),r=t(9),i=a.document,o=r(i)&&r(i.createElement);n.exports=function(n){return o?i.createElement(n):{}}},function(n,e,t){var a=t(7),r=t(3);n.exports=a&&r((function(){return 42!=Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(n,e,t){var a=t(58),r=t(60),i=a("keys");n.exports=function(n){return i[n]||(i[n]=r(n))}},function(n,e,t){var a=t(1),r=t(8),i=t(26),o=t(115).indexOf,s=t(46),l=a([].push);n.exports=function(n,e){var t,a=i(n),c=0,p=[];for(t in a)!r(s,t)&&r(a,t)&&l(p,t);for(;e.length>c;)r(a,t=e[c++])&&(~o(p,t)||l(p,t));return p}},function(n,e){n.exports=function(n){var e=null==n?0:n.length;return e?n[e-1]:void 0}},function(n,e,t){n.exports=t(239)},function(n,e,t){"use strict";var a=t(42),r=t(121).left,i=t(122),o=t(57),s=t(123);a({target:"Array",proto:!0,forced:!i("reduce")||!s&&o>79&&o<83},{reduce:function(n){var e=arguments.length;return r(this,n,e,e>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var a={}.propertyIsEnumerable,r=Object.getOwnPropertyDescriptor,i=r&&!a.call({1:2},1);e.f=i?function(n){var e=r(this,n);return!!e&&e.enumerable}:a},function(n,e,t){var a=t(28),r=t(9),i=t(53),o=t(105),s=t(107),l=t(27),c=TypeError,p=l("toPrimitive");n.exports=function(n,e){if(!r(n)||i(n))return n;var t,l=o(n,p);if(l){if(void 0===e&&(e="default"),t=a(l,n,e),!r(t)||i(t))return t;throw c("Can't convert object to primitive value")}return void 0===e&&(e="number"),s(n,e)}},function(n,e,t){var a=t(16);n.exports=a("navigator","userAgent")||""},function(n,e,t){var a=t(44);n.exports=function(n,e){var t=n[e];return null==t?void 0:a(t)}},function(n,e){var t=String;n.exports=function(n){try{return t(n)}catch(n){return"Object"}}},function(n,e,t){var a=t(28),r=t(0),i=t(9),o=TypeError;n.exports=function(n,e){var t,s;if("string"===e&&r(t=n.toString)&&!i(s=a(t,n)))return s;if(r(t=n.valueOf)&&!i(s=a(t,n)))return s;if("string"!==e&&r(t=n.toString)&&!i(s=a(t,n)))return s;throw o("Can't convert object to primitive value")}},function(n,e,t){var a=t(0),r=t(15),i=t(109),o=t(32);n.exports=function(n,e,t,s){s||(s={});var l=s.enumerable,c=void 0!==s.name?s.name:e;if(a(t)&&i(t,c,s),s.global)l?n[e]=t:o(e,t);else{try{s.unsafe?n[e]&&(l=!0):delete n[e]}catch(n){}l?n[e]=t:r.f(n,e,{value:t,enumerable:!1,configurable:!s.nonConfigurable,writable:!s.nonWritable})}return n}},function(n,e,t){var a=t(3),r=t(0),i=t(8),o=t(7),s=t(110).CONFIGURABLE,l=t(62),c=t(111),p=c.enforce,d=c.get,m=Object.defineProperty,u=o&&!a((function(){return 8!==m((function(){}),"length",{value:8}).length})),h=String(String).split("String"),g=n.exports=function(n,e,t){"Symbol("===String(e).slice(0,7)&&(e="["+String(e).replace(/^Symbol\(([^)]*)\)/,"$1")+"]"),t&&t.getter&&(e="get "+e),t&&t.setter&&(e="set "+e),(!i(n,"name")||s&&n.name!==e)&&(o?m(n,"name",{value:e,configurable:!0}):n.name=e),u&&t&&i(t,"arity")&&n.length!==t.arity&&m(n,"length",{value:t.arity});try{t&&i(t,"constructor")&&t.constructor?o&&m(n,"prototype",{writable:!1}):n.prototype&&(n.prototype=void 0)}catch(n){}var a=p(n);return i(a,"source")||(a.source=h.join("string"==typeof e?e:"")),n};Function.prototype.toString=g((function(){return r(this)&&d(this).source||l(this)}),"toString")},function(n,e,t){var a=t(7),r=t(8),i=Function.prototype,o=a&&Object.getOwnPropertyDescriptor,s=r(i,"name"),l=s&&"something"===function(){}.name,c=s&&(!a||a&&o(i,"name").configurable);n.exports={EXISTS:s,PROPER:l,CONFIGURABLE:c}},function(n,e,t){var a,r,i,o=t(112),s=t(2),l=t(1),c=t(9),p=t(17),d=t(8),m=t(31),u=t(97),h=t(46),g=s.TypeError,v=s.WeakMap;if(o||m.state){var b=m.state||(m.state=new v),f=l(b.get),y=l(b.has),x=l(b.set);a=function(n,e){if(y(b,n))throw new g("Object already initialized");return e.facade=n,x(b,n,e),e},r=function(n){return f(b,n)||{}},i=function(n){return y(b,n)}}else{var k=u("state");h[k]=!0,a=function(n,e){if(d(n,k))throw new g("Object already initialized");return e.facade=n,p(n,k,e),e},r=function(n){return d(n,k)?n[k]:{}},i=function(n){return d(n,k)}}n.exports={set:a,get:r,has:i,enforce:function(n){return i(n)?r(n):a(n,{})},getterFor:function(n){return function(e){var t;if(!c(e)||(t=r(e)).type!==n)throw g("Incompatible receiver, "+n+" required");return t}}}},function(n,e,t){var a=t(2),r=t(0),i=t(62),o=a.WeakMap;n.exports=r(o)&&/native code/.test(i(o))},function(n,e,t){var a=t(16),r=t(1),i=t(114),o=t(119),s=t(24),l=r([].concat);n.exports=a("Reflect","ownKeys")||function(n){var e=i.f(s(n)),t=o.f;return t?l(e,t(n)):e}},function(n,e,t){var a=t(98),r=t(94).concat("length","prototype");e.f=Object.getOwnPropertyNames||function(n){return a(n,r)}},function(n,e,t){var a=t(26),r=t(116),i=t(47),o=function(n){return function(e,t,o){var s,l=a(e),c=i(l),p=r(o,c);if(n&&t!=t){for(;c>p;)if((s=l[p++])!=s)return!0}else for(;c>p;p++)if((n||p in l)&&l[p]===t)return n||p||0;return!n&&-1}};n.exports={includes:o(!0),indexOf:o(!1)}},function(n,e,t){var a=t(64),r=Math.max,i=Math.min;n.exports=function(n,e){var t=a(n);return t<0?r(t+e,0):i(t,e)}},function(n,e){var t=Math.ceil,a=Math.floor;n.exports=Math.trunc||function(n){var e=+n;return(e>0?a:t)(e)}},function(n,e,t){var a=t(64),r=Math.min;n.exports=function(n){return n>0?r(a(n),9007199254740991):0}},function(n,e){e.f=Object.getOwnPropertySymbols},function(n,e,t){var a=t(3),r=t(0),i=/#|\.prototype\./,o=function(n,e){var t=l[s(n)];return t==p||t!=c&&(r(e)?a(e):!!e)},s=o.normalize=function(n){return String(n).replace(i,".").toLowerCase()},l=o.data={},c=o.NATIVE="N",p=o.POLYFILL="P";n.exports=o},function(n,e,t){var a=t(44),r=t(45),i=t(43),o=t(47),s=TypeError,l=function(n){return function(e,t,l,c){a(t);var p=r(e),d=i(p),m=o(p),u=n?m-1:0,h=n?-1:1;if(l<2)for(;;){if(u in d){c=d[u],u+=h;break}if(u+=h,n?u<0:m<=u)throw s("Reduce of empty array with no initial value")}for(;n?u>=0:m>u;u+=h)u in d&&(c=t(c,d[u],u,p));return c}};n.exports={left:l(!1),right:l(!0)}},function(n,e,t){"use strict";var a=t(3);n.exports=function(n,e){var t=[][n];return!!t&&a((function(){t.call(null,e||function(){return 1},1)}))}},function(n,e,t){var a=t(30),r=t(2);n.exports="process"==a(r.process)},function(n,e,t){var a=t(42),r=t(2),i=t(125),o=t(126),s=r.WebAssembly,l=7!==Error("e",{cause:7}).cause,c=function(n,e){var t={};t[n]=o(n,e,l),a({global:!0,constructor:!0,arity:1,forced:l},t)},p=function(n,e){if(s&&s[n]){var t={};t[n]=o("WebAssembly."+n,e,l),a({target:"WebAssembly",stat:!0,constructor:!0,arity:1,forced:l},t)}};c("Error",(function(n){return function(e){return i(n,this,arguments)}})),c("EvalError",(function(n){return function(e){return i(n,this,arguments)}})),c("RangeError",(function(n){return function(e){return i(n,this,arguments)}})),c("ReferenceError",(function(n){return function(e){return i(n,this,arguments)}})),c("SyntaxError",(function(n){return function(e){return i(n,this,arguments)}})),c("TypeError",(function(n){return function(e){return i(n,this,arguments)}})),c("URIError",(function(n){return function(e){return i(n,this,arguments)}})),p("CompileError",(function(n){return function(e){return i(n,this,arguments)}})),p("LinkError",(function(n){return function(e){return i(n,this,arguments)}})),p("RuntimeError",(function(n){return function(e){return i(n,this,arguments)}}))},function(n,e,t){var a=t(25),r=Function.prototype,i=r.apply,o=r.call;n.exports="object"==typeof Reflect&&Reflect.apply||(a?o.bind(i):function(){return o.apply(i,arguments)})},function(n,e,t){"use strict";var a=t(16),r=t(8),i=t(17),o=t(54),s=t(65),l=t(63),c=t(128),p=t(129),d=t(130),m=t(134),u=t(135),h=t(136),g=t(7),v=t(59);n.exports=function(n,e,t,b){var f=b?2:1,y=n.split("."),x=y[y.length-1],k=a.apply(null,y);if(k){var j=k.prototype;if(!v&&r(j,"cause")&&delete j.cause,!t)return k;var S=a("Error"),w=e((function(n,e){var t=d(b?e:n,void 0),a=b?new k(n):new k;return void 0!==t&&i(a,"message",t),h&&i(a,"stack",u(a.stack,2)),this&&o(j,this)&&p(a,this,w),arguments.length>f&&m(a,arguments[f]),a}));if(w.prototype=j,"Error"!==x?s?s(w,S):l(w,S,{name:!0}):g&&"stackTraceLimit"in k&&(c(w,k,"stackTraceLimit"),c(w,k,"prepareStackTrace")),l(w,k),!v)try{j.name!==x&&i(j,"name",x),j.constructor=w}catch(n){}return w}}},function(n,e,t){var a=t(0),r=String,i=TypeError;n.exports=function(n){if("object"==typeof n||a(n))return n;throw i("Can't set "+r(n)+" as a prototype")}},function(n,e,t){var a=t(15).f;n.exports=function(n,e,t){t in n||a(n,t,{configurable:!0,get:function(){return e[t]},set:function(n){e[t]=n}})}},function(n,e,t){var a=t(0),r=t(9),i=t(65);n.exports=function(n,e,t){var o,s;return i&&a(o=e.constructor)&&o!==t&&r(s=o.prototype)&&s!==t.prototype&&i(n,s),n}},function(n,e,t){var a=t(131);n.exports=function(n,e){return void 0===n?arguments.length<2?"":e:a(n)}},function(n,e,t){var a=t(132),r=String;n.exports=function(n){if("Symbol"===a(n))throw TypeError("Cannot convert a Symbol value to a string");return r(n)}},function(n,e,t){var a=t(133),r=t(0),i=t(30),o=t(27)("toStringTag"),s=Object,l="Arguments"==i(function(){return arguments}());n.exports=a?i:function(n){var e,t,a;return void 0===n?"Undefined":null===n?"Null":"string"==typeof(t=function(n,e){try{return n[e]}catch(n){}}(e=s(n),o))?t:l?i(e):"Object"==(a=i(e))&&r(e.callee)?"Arguments":a}},function(n,e,t){var a={};a[t(27)("toStringTag")]="z",n.exports="[object z]"===String(a)},function(n,e,t){var a=t(9),r=t(17);n.exports=function(n,e){a(e)&&"cause"in e&&r(n,"cause",e.cause)}},function(n,e,t){var a=t(1),r=Error,i=a("".replace),o=String(r("zxcasd").stack),s=/\n\s*at [^:]*:[^\n]*/,l=s.test(o);n.exports=function(n,e){if(l&&"string"==typeof n&&!r.prepareStackTrace)for(;e--;)n=i(n,s,"");return n}},function(n,e,t){var a=t(3),r=t(29);n.exports=!a((function(){var n=Error("a");return!("stack"in n)||(Object.defineProperty(n,"stack",r(1,7)),7!==n.stack)}))},function(n,e,t){var a=t(66),r=t(138);n.exports=function n(e,t,i,o,s){var l=-1,c=e.length;for(i||(i=r),s||(s=[]);++l<c;){var p=e[l];t>0&&i(p)?t>1?n(p,t-1,i,o,s):a(s,p):o||(s[s.length]=p)}return s}},function(n,e,t){var a=t(14),r=t(33),i=t(4),o=a?a.isConcatSpreadable:void 0;n.exports=function(n){return i(n)||r(n)||!!(o&&n&&n[o])}},function(n,e,t){var a=t(13),r=t(12);n.exports=function(n){return r(n)&&"[object Arguments]"==a(n)}},function(n,e,t){var a=t(14),r=Object.prototype,i=r.hasOwnProperty,o=r.toString,s=a?a.toStringTag:void 0;n.exports=function(n){var e=i.call(n,s),t=n[s];try{n[s]=void 0;var a=!0}catch(n){}var r=o.call(n);return a&&(e?n[s]=t:delete n[s]),r}},function(n,e){var t=Object.prototype.toString;n.exports=function(n){return t.call(n)}},function(n,e,t){var a=t(143),r=t(199),i=t(41),o=t(4),s=t(210);n.exports=function(n){return"function"==typeof n?n:null==n?i:"object"==typeof n?o(n)?r(n[0],n[1]):a(n):s(n)}},function(n,e,t){var a=t(144),r=t(198),i=t(83);n.exports=function(n){var e=r(n);return 1==e.length&&e[0][2]?i(e[0][0],e[0][1]):function(t){return t===n||a(t,n,e)}}},function(n,e,t){var a=t(68),r=t(72);n.exports=function(n,e,t,i){var o=t.length,s=o,l=!i;if(null==n)return!s;for(n=Object(n);o--;){var c=t[o];if(l&&c[2]?c[1]!==n[c[0]]:!(c[0]in n))return!1}for(;++o<s;){var p=(c=t[o])[0],d=n[p],m=c[1];if(l&&c[2]){if(void 0===d&&!(p in n))return!1}else{var u=new a;if(i)var h=i(d,m,p,n,e,u);if(!(void 0===h?r(m,d,3,i,u):h))return!1}}return!0}},function(n,e){n.exports=function(){this.__data__=[],this.size=0}},function(n,e,t){var a=t(19),r=Array.prototype.splice;n.exports=function(n){var e=this.__data__,t=a(e,n);return!(t<0)&&(t==e.length-1?e.pop():r.call(e,t,1),--this.size,!0)}},function(n,e,t){var a=t(19);n.exports=function(n){var e=this.__data__,t=a(e,n);return t<0?void 0:e[t][1]}},function(n,e,t){var a=t(19);n.exports=function(n){return a(this.__data__,n)>-1}},function(n,e,t){var a=t(19);n.exports=function(n,e){var t=this.__data__,r=a(t,n);return r<0?(++this.size,t.push([n,e])):t[r][1]=e,this}},function(n,e,t){var a=t(18);n.exports=function(){this.__data__=new a,this.size=0}},function(n,e){n.exports=function(n){var e=this.__data__,t=e.delete(n);return this.size=e.size,t}},function(n,e){n.exports=function(n){return this.__data__.get(n)}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e,t){var a=t(18),r=t(34),i=t(36);n.exports=function(n,e){var t=this.__data__;if(t instanceof a){var o=t.__data__;if(!r||o.length<199)return o.push([n,e]),this.size=++t.size,this;t=this.__data__=new i(o)}return t.set(n,e),this.size=t.size,this}},function(n,e,t){var a=t(70),r=t(156),i=t(35),o=t(71),s=/^\[object .+?Constructor\]$/,l=Function.prototype,c=Object.prototype,p=l.toString,d=c.hasOwnProperty,m=RegExp("^"+p.call(d).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");n.exports=function(n){return!(!i(n)||r(n))&&(a(n)?m:s).test(o(n))}},function(n,e,t){var a,r=t(157),i=(a=/[^.]+$/.exec(r&&r.keys&&r.keys.IE_PROTO||""))?"Symbol(src)_1."+a:"";n.exports=function(n){return!!i&&i in n}},function(n,e,t){var a=t(5)["__core-js_shared__"];n.exports=a},function(n,e){n.exports=function(n,e){return null==n?void 0:n[e]}},function(n,e,t){var a=t(160),r=t(18),i=t(34);n.exports=function(){this.size=0,this.__data__={hash:new a,map:new(i||r),string:new a}}},function(n,e,t){var a=t(161),r=t(162),i=t(163),o=t(164),s=t(165);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var a=n[e];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=r,l.prototype.get=i,l.prototype.has=o,l.prototype.set=s,n.exports=l},function(n,e,t){var a=t(20);n.exports=function(){this.__data__=a?a(null):{},this.size=0}},function(n,e){n.exports=function(n){var e=this.has(n)&&delete this.__data__[n];return this.size-=e?1:0,e}},function(n,e,t){var a=t(20),r=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;if(a){var t=e[n];return"__lodash_hash_undefined__"===t?void 0:t}return r.call(e,n)?e[n]:void 0}},function(n,e,t){var a=t(20),r=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;return a?void 0!==e[n]:r.call(e,n)}},function(n,e,t){var a=t(20);n.exports=function(n,e){var t=this.__data__;return this.size+=this.has(n)?0:1,t[n]=a&&void 0===e?"__lodash_hash_undefined__":e,this}},function(n,e,t){var a=t(21);n.exports=function(n){var e=a(this,n).delete(n);return this.size-=e?1:0,e}},function(n,e){n.exports=function(n){var e=typeof n;return"string"==e||"number"==e||"symbol"==e||"boolean"==e?"__proto__"!==n:null===n}},function(n,e,t){var a=t(21);n.exports=function(n){return a(this,n).get(n)}},function(n,e,t){var a=t(21);n.exports=function(n){return a(this,n).has(n)}},function(n,e,t){var a=t(21);n.exports=function(n,e){var t=a(this,n),r=t.size;return t.set(n,e),this.size+=t.size==r?0:1,this}},function(n,e,t){var a=t(68),r=t(73),i=t(175),o=t(178),s=t(194),l=t(4),c=t(77),p=t(79),d="[object Object]",m=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,u,h,g){var v=l(n),b=l(e),f=v?"[object Array]":s(n),y=b?"[object Array]":s(e),x=(f="[object Arguments]"==f?d:f)==d,k=(y="[object Arguments]"==y?d:y)==d,j=f==y;if(j&&c(n)){if(!c(e))return!1;v=!0,x=!1}if(j&&!x)return g||(g=new a),v||p(n)?r(n,e,t,u,h,g):i(n,e,f,t,u,h,g);if(!(1&t)){var S=x&&m.call(n,"__wrapped__"),w=k&&m.call(e,"__wrapped__");if(S||w){var T=S?n.value():n,I=w?e.value():e;return g||(g=new a),h(T,I,t,u,g)}}return!!j&&(g||(g=new a),o(n,e,t,u,h,g))}},function(n,e){n.exports=function(n){return this.__data__.set(n,"__lodash_hash_undefined__"),this}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e){n.exports=function(n,e){for(var t=-1,a=null==n?0:n.length;++t<a;)if(e(n[t],t,n))return!0;return!1}},function(n,e,t){var a=t(14),r=t(176),i=t(69),o=t(73),s=t(177),l=t(37),c=a?a.prototype:void 0,p=c?c.valueOf:void 0;n.exports=function(n,e,t,a,c,d,m){switch(t){case"[object DataView]":if(n.byteLength!=e.byteLength||n.byteOffset!=e.byteOffset)return!1;n=n.buffer,e=e.buffer;case"[object ArrayBuffer]":return!(n.byteLength!=e.byteLength||!d(new r(n),new r(e)));case"[object Boolean]":case"[object Date]":case"[object Number]":return i(+n,+e);case"[object Error]":return n.name==e.name&&n.message==e.message;case"[object RegExp]":case"[object String]":return n==e+"";case"[object Map]":var u=s;case"[object Set]":var h=1&a;if(u||(u=l),n.size!=e.size&&!h)return!1;var g=m.get(n);if(g)return g==e;a|=2,m.set(n,e);var v=o(u(n),u(e),a,c,d,m);return m.delete(n),v;case"[object Symbol]":if(p)return p.call(n)==p.call(e)}return!1}},function(n,e,t){var a=t(5).Uint8Array;n.exports=a},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n,a){t[++e]=[a,n]})),t}},function(n,e,t){var a=t(179),r=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,i,o,s){var l=1&t,c=a(n),p=c.length;if(p!=a(e).length&&!l)return!1;for(var d=p;d--;){var m=c[d];if(!(l?m in e:r.call(e,m)))return!1}var u=s.get(n),h=s.get(e);if(u&&h)return u==e&&h==n;var g=!0;s.set(n,e),s.set(e,n);for(var v=l;++d<p;){var b=n[m=c[d]],f=e[m];if(i)var y=l?i(f,b,m,e,n,s):i(b,f,m,n,e,s);if(!(void 0===y?b===f||o(b,f,t,i,s):y)){g=!1;break}v||(v="constructor"==m)}if(g&&!v){var x=n.constructor,k=e.constructor;x==k||!("constructor"in n)||!("constructor"in e)||"function"==typeof x&&x instanceof x&&"function"==typeof k&&k instanceof k||(g=!1)}return s.delete(n),s.delete(e),g}},function(n,e,t){var a=t(180),r=t(181),i=t(76);n.exports=function(n){return a(n,i,r)}},function(n,e,t){var a=t(66),r=t(4);n.exports=function(n,e,t){var i=e(n);return r(n)?i:a(i,t(n))}},function(n,e,t){var a=t(182),r=t(183),i=Object.prototype.propertyIsEnumerable,o=Object.getOwnPropertySymbols,s=o?function(n){return null==n?[]:(n=Object(n),a(o(n),(function(e){return i.call(n,e)})))}:r;n.exports=s},function(n,e){n.exports=function(n,e){for(var t=-1,a=null==n?0:n.length,r=0,i=[];++t<a;){var o=n[t];e(o,t,n)&&(i[r++]=o)}return i}},function(n,e){n.exports=function(){return[]}},function(n,e,t){var a=t(185),r=t(33),i=t(4),o=t(77),s=t(78),l=t(79),c=Object.prototype.hasOwnProperty;n.exports=function(n,e){var t=i(n),p=!t&&r(n),d=!t&&!p&&o(n),m=!t&&!p&&!d&&l(n),u=t||p||d||m,h=u?a(n.length,String):[],g=h.length;for(var v in n)!e&&!c.call(n,v)||u&&("length"==v||d&&("offset"==v||"parent"==v)||m&&("buffer"==v||"byteLength"==v||"byteOffset"==v)||s(v,g))||h.push(v);return h}},function(n,e){n.exports=function(n,e){for(var t=-1,a=Array(n);++t<n;)a[t]=e(t);return a}},function(n,e){n.exports=function(){return!1}},function(n,e,t){var a=t(13),r=t(38),i=t(12),o={};o["[object Float32Array]"]=o["[object Float64Array]"]=o["[object Int8Array]"]=o["[object Int16Array]"]=o["[object Int32Array]"]=o["[object Uint8Array]"]=o["[object Uint8ClampedArray]"]=o["[object Uint16Array]"]=o["[object Uint32Array]"]=!0,o["[object Arguments]"]=o["[object Array]"]=o["[object ArrayBuffer]"]=o["[object Boolean]"]=o["[object DataView]"]=o["[object Date]"]=o["[object Error]"]=o["[object Function]"]=o["[object Map]"]=o["[object Number]"]=o["[object Object]"]=o["[object RegExp]"]=o["[object Set]"]=o["[object String]"]=o["[object WeakMap]"]=!1,n.exports=function(n){return i(n)&&r(n.length)&&!!o[a(n)]}},function(n,e){n.exports=function(n){return function(e){return n(e)}}},function(n,e,t){(function(n){var a=t(67),r=e&&!e.nodeType&&e,i=r&&"object"==typeof n&&n&&!n.nodeType&&n,o=i&&i.exports===r&&a.process,s=function(){try{var n=i&&i.require&&i.require("util").types;return n||o&&o.binding&&o.binding("util")}catch(n){}}();n.exports=s}).call(this,t(48)(n))},function(n,e,t){var a=t(191),r=t(192),i=Object.prototype.hasOwnProperty;n.exports=function(n){if(!a(n))return r(n);var e=[];for(var t in Object(n))i.call(n,t)&&"constructor"!=t&&e.push(t);return e}},function(n,e){var t=Object.prototype;n.exports=function(n){var e=n&&n.constructor;return n===("function"==typeof e&&e.prototype||t)}},function(n,e,t){var a=t(193)(Object.keys,Object);n.exports=a},function(n,e){n.exports=function(n,e){return function(t){return n(e(t))}}},function(n,e,t){var a=t(195),r=t(34),i=t(196),o=t(81),s=t(197),l=t(13),c=t(71),p=c(a),d=c(r),m=c(i),u=c(o),h=c(s),g=l;(a&&"[object DataView]"!=g(new a(new ArrayBuffer(1)))||r&&"[object Map]"!=g(new r)||i&&"[object Promise]"!=g(i.resolve())||o&&"[object Set]"!=g(new o)||s&&"[object WeakMap]"!=g(new s))&&(g=function(n){var e=l(n),t="[object Object]"==e?n.constructor:void 0,a=t?c(t):"";if(a)switch(a){case p:return"[object DataView]";case d:return"[object Map]";case m:return"[object Promise]";case u:return"[object Set]";case h:return"[object WeakMap]"}return e}),n.exports=g},function(n,e,t){var a=t(10)(t(5),"DataView");n.exports=a},function(n,e,t){var a=t(10)(t(5),"Promise");n.exports=a},function(n,e,t){var a=t(10)(t(5),"WeakMap");n.exports=a},function(n,e,t){var a=t(82),r=t(76);n.exports=function(n){for(var e=r(n),t=e.length;t--;){var i=e[t],o=n[i];e[t]=[i,o,a(o)]}return e}},function(n,e,t){var a=t(72),r=t(200),i=t(207),o=t(39),s=t(82),l=t(83),c=t(22);n.exports=function(n,e){return o(n)&&s(e)?l(c(n),e):function(t){var o=r(t,n);return void 0===o&&o===e?i(t,n):a(e,o,3)}}},function(n,e,t){var a=t(84);n.exports=function(n,e,t){var r=null==n?void 0:a(n,e);return void 0===r?t:r}},function(n,e,t){var a=t(202),r=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,i=/\\(\\)?/g,o=a((function(n){var e=[];return 46===n.charCodeAt(0)&&e.push(""),n.replace(r,(function(n,t,a,r){e.push(a?r.replace(i,"$1"):t||n)})),e}));n.exports=o},function(n,e,t){var a=t(203);n.exports=function(n){var e=a(n,(function(n){return 500===t.size&&t.clear(),n})),t=e.cache;return e}},function(n,e,t){var a=t(36);function r(n,e){if("function"!=typeof n||null!=e&&"function"!=typeof e)throw new TypeError("Expected a function");var t=function(){var a=arguments,r=e?e.apply(this,a):a[0],i=t.cache;if(i.has(r))return i.get(r);var o=n.apply(this,a);return t.cache=i.set(r,o)||i,o};return t.cache=new(r.Cache||a),t}r.Cache=a,n.exports=r},function(n,e,t){var a=t(205);n.exports=function(n){return null==n?"":a(n)}},function(n,e,t){var a=t(14),r=t(206),i=t(4),o=t(40),s=a?a.prototype:void 0,l=s?s.toString:void 0;n.exports=function n(e){if("string"==typeof e)return e;if(i(e))return r(e,n)+"";if(o(e))return l?l.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(n,e){n.exports=function(n,e){for(var t=-1,a=null==n?0:n.length,r=Array(a);++t<a;)r[t]=e(n[t],t,n);return r}},function(n,e,t){var a=t(208),r=t(209);n.exports=function(n,e){return null!=n&&r(n,e,a)}},function(n,e){n.exports=function(n,e){return null!=n&&e in Object(n)}},function(n,e,t){var a=t(85),r=t(33),i=t(4),o=t(78),s=t(38),l=t(22);n.exports=function(n,e,t){for(var c=-1,p=(e=a(e,n)).length,d=!1;++c<p;){var m=l(e[c]);if(!(d=null!=n&&t(n,m)))break;n=n[m]}return d||++c!=p?d:!!(p=null==n?0:n.length)&&s(p)&&o(m,p)&&(i(n)||r(n))}},function(n,e,t){var a=t(211),r=t(212),i=t(39),o=t(22);n.exports=function(n){return i(n)?a(o(n)):r(n)}},function(n,e){n.exports=function(n){return function(e){return null==e?void 0:e[n]}}},function(n,e,t){var a=t(84);n.exports=function(n){return function(e){return a(e,n)}}},function(n,e,t){var a=t(41),r=t(214),i=t(216);n.exports=function(n,e){return i(r(n,e,a),n+"")}},function(n,e,t){var a=t(215),r=Math.max;n.exports=function(n,e,t){return e=r(void 0===e?n.length-1:e,0),function(){for(var i=arguments,o=-1,s=r(i.length-e,0),l=Array(s);++o<s;)l[o]=i[e+o];o=-1;for(var c=Array(e+1);++o<e;)c[o]=i[o];return c[e]=t(l),a(n,this,c)}}},function(n,e){n.exports=function(n,e,t){switch(t.length){case 0:return n.call(e);case 1:return n.call(e,t[0]);case 2:return n.call(e,t[0],t[1]);case 3:return n.call(e,t[0],t[1],t[2])}return n.apply(e,t)}},function(n,e,t){var a=t(217),r=t(220)(a);n.exports=r},function(n,e,t){var a=t(218),r=t(219),i=t(41),o=r?function(n,e){return r(n,"toString",{configurable:!0,enumerable:!1,value:a(e),writable:!0})}:i;n.exports=o},function(n,e){n.exports=function(n){return function(){return n}}},function(n,e,t){var a=t(10),r=function(){try{var n=a(Object,"defineProperty");return n({},"",{}),n}catch(n){}}();n.exports=r},function(n,e){var t=Date.now;n.exports=function(n){var e=0,a=0;return function(){var r=t(),i=16-(r-a);if(a=r,i>0){if(++e>=800)return arguments[0]}else e=0;return n.apply(void 0,arguments)}}},function(n,e,t){var a=t(74),r=t(222),i=t(227),o=t(75),s=t(228),l=t(37);n.exports=function(n,e,t){var c=-1,p=r,d=n.length,m=!0,u=[],h=u;if(t)m=!1,p=i;else if(d>=200){var g=e?null:s(n);if(g)return l(g);m=!1,p=o,h=new a}else h=e?[]:u;n:for(;++c<d;){var v=n[c],b=e?e(v):v;if(v=t||0!==v?v:0,m&&b==b){for(var f=h.length;f--;)if(h[f]===b)continue n;e&&h.push(b),u.push(v)}else p(h,b,t)||(h!==u&&h.push(b),u.push(v))}return u}},function(n,e,t){var a=t(223);n.exports=function(n,e){return!!(null==n?0:n.length)&&a(n,e,0)>-1}},function(n,e,t){var a=t(224),r=t(225),i=t(226);n.exports=function(n,e,t){return e==e?i(n,e,t):a(n,r,t)}},function(n,e){n.exports=function(n,e,t,a){for(var r=n.length,i=t+(a?1:-1);a?i--:++i<r;)if(e(n[i],i,n))return i;return-1}},function(n,e){n.exports=function(n){return n!=n}},function(n,e){n.exports=function(n,e,t){for(var a=t-1,r=n.length;++a<r;)if(n[a]===e)return a;return-1}},function(n,e){n.exports=function(n,e,t){for(var a=-1,r=null==n?0:n.length;++a<r;)if(t(e,n[a]))return!0;return!1}},function(n,e,t){var a=t(81),r=t(229),i=t(37),o=a&&1/i(new a([,-0]))[1]==1/0?function(n){return new a(n)}:r;n.exports=o},function(n,e){n.exports=function(){}},function(n,e,t){var a=t(80),r=t(12);n.exports=function(n){return r(n)&&a(n)}},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(86)},function(n,e,t){"use strict";t(87)},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(88)},function(n,e,t){"use strict";t(89)},function(n,e,t){"use strict";t.r(e);
/*!
 * Vue.js v2.7.4
 * (c) 2014-2022 Evan You
 * Released under the MIT License.
 */
var a=Object.freeze({}),r=Array.isArray;function i(n){return null==n}function o(n){return null!=n}function s(n){return!0===n}function l(n){return"string"==typeof n||"number"==typeof n||"symbol"==typeof n||"boolean"==typeof n}function c(n){return"function"==typeof n}function p(n){return null!==n&&"object"==typeof n}var d=Object.prototype.toString;function m(n){return"[object Object]"===d.call(n)}function u(n){return"[object RegExp]"===d.call(n)}function h(n){var e=parseFloat(String(n));return e>=0&&Math.floor(e)===e&&isFinite(n)}function g(n){return o(n)&&"function"==typeof n.then&&"function"==typeof n.catch}function v(n){return null==n?"":Array.isArray(n)||m(n)&&n.toString===d?JSON.stringify(n,null,2):String(n)}function b(n){var e=parseFloat(n);return isNaN(e)?n:e}function f(n,e){for(var t=Object.create(null),a=n.split(","),r=0;r<a.length;r++)t[a[r]]=!0;return e?function(n){return t[n.toLowerCase()]}:function(n){return t[n]}}f("slot,component",!0);var y=f("key,ref,slot,slot-scope,is");function x(n,e){if(n.length){var t=n.indexOf(e);if(t>-1)return n.splice(t,1)}}var k=Object.prototype.hasOwnProperty;function j(n,e){return k.call(n,e)}function S(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var w=/-(\w)/g,T=S((function(n){return n.replace(w,(function(n,e){return e?e.toUpperCase():""}))})),I=S((function(n){return n.charAt(0).toUpperCase()+n.slice(1)})),C=/\B([A-Z])/g,M=S((function(n){return n.replace(C,"-$1").toLowerCase()}));var E=Function.prototype.bind?function(n,e){return n.bind(e)}:function(n,e){function t(t){var a=arguments.length;return a?a>1?n.apply(e,arguments):n.call(e,t):n.call(e)}return t._length=n.length,t};function P(n,e){e=e||0;for(var t=n.length-e,a=new Array(t);t--;)a[t]=n[t+e];return a}function z(n,e){for(var t in e)n[t]=e[t];return n}function A(n){for(var e={},t=0;t<n.length;t++)n[t]&&z(e,n[t]);return e}function q(n,e,t){}var J=function(n,e,t){return!1},L=function(n){return n};function R(n,e){if(n===e)return!0;var t=p(n),a=p(e);if(!t||!a)return!t&&!a&&String(n)===String(e);try{var r=Array.isArray(n),i=Array.isArray(e);if(r&&i)return n.length===e.length&&n.every((function(n,t){return R(n,e[t])}));if(n instanceof Date&&e instanceof Date)return n.getTime()===e.getTime();if(r||i)return!1;var o=Object.keys(n),s=Object.keys(e);return o.length===s.length&&o.every((function(t){return R(n[t],e[t])}))}catch(n){return!1}}function _(n,e){for(var t=0;t<n.length;t++)if(R(n[t],e))return t;return-1}function O(n){var e=!1;return function(){e||(e=!0,n.apply(this,arguments))}}function B(n,e){return n===e?0===n&&1/n!=1/e:n==n||e==e}var D=["component","directive","filter"],H=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch","renderTracked","renderTriggered"],F={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:J,isReservedAttr:J,isUnknownElement:J,getTagNamespace:q,parsePlatformTagName:L,mustUseProp:J,async:!0,_lifecycleHooks:H},N=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function U(n){var e=(n+"").charCodeAt(0);return 36===e||95===e}function $(n,e,t,a){Object.defineProperty(n,e,{value:t,enumerable:!!a,writable:!0,configurable:!0})}var W=new RegExp("[^".concat(N.source,".$_\\d]"));var Q="__proto__"in{},G="undefined"!=typeof window,V=G&&window.navigator.userAgent.toLowerCase(),K=V&&/msie|trident/.test(V),X=V&&V.indexOf("msie 9.0")>0,Z=V&&V.indexOf("edge/")>0;V&&V.indexOf("android");var Y=V&&/iphone|ipad|ipod|ios/.test(V);V&&/chrome\/\d+/.test(V),V&&/phantomjs/.test(V);var nn,en=V&&V.match(/firefox\/(\d+)/),tn={}.watch,an=!1;if(G)try{var rn={};Object.defineProperty(rn,"passive",{get:function(){an=!0}}),window.addEventListener("test-passive",null,rn)}catch(n){}var on=function(){return void 0===nn&&(nn=!G&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),nn},sn=G&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function ln(n){return"function"==typeof n&&/native code/.test(n.toString())}var cn,pn="undefined"!=typeof Symbol&&ln(Symbol)&&"undefined"!=typeof Reflect&&ln(Reflect.ownKeys);cn="undefined"!=typeof Set&&ln(Set)?Set:function(){function n(){this.set=Object.create(null)}return n.prototype.has=function(n){return!0===this.set[n]},n.prototype.add=function(n){this.set[n]=!0},n.prototype.clear=function(){this.set=Object.create(null)},n}();var dn=null;function mn(n){void 0===n&&(n=null),n||dn&&dn._scope.off(),dn=n,n&&n._scope.on()}var un=q,hn=0,gn=function(){function n(){this.id=hn++,this.subs=[]}return n.prototype.addSub=function(n){this.subs.push(n)},n.prototype.removeSub=function(n){x(this.subs,n)},n.prototype.depend=function(e){n.target&&n.target.addDep(this)},n.prototype.notify=function(n){var e=this.subs.slice();for(var t=0,a=e.length;t<a;t++){e[t].update()}},n}();gn.target=null;var vn=[];function bn(n){vn.push(n),gn.target=n}function fn(){vn.pop(),gn.target=vn[vn.length-1]}var yn=function(){function n(n,e,t,a,r,i,o,s){this.tag=n,this.data=e,this.children=t,this.text=a,this.elm=r,this.ns=void 0,this.context=i,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=e&&e.key,this.componentOptions=o,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1}return Object.defineProperty(n.prototype,"child",{get:function(){return this.componentInstance},enumerable:!1,configurable:!0}),n}(),xn=function(n){void 0===n&&(n="");var e=new yn;return e.text=n,e.isComment=!0,e};function kn(n){return new yn(void 0,void 0,void 0,String(n))}function jn(n){var e=new yn(n.tag,n.data,n.children&&n.children.slice(),n.text,n.elm,n.context,n.componentOptions,n.asyncFactory);return e.ns=n.ns,e.isStatic=n.isStatic,e.key=n.key,e.isComment=n.isComment,e.fnContext=n.fnContext,e.fnOptions=n.fnOptions,e.fnScopeId=n.fnScopeId,e.asyncMeta=n.asyncMeta,e.isCloned=!0,e}var Sn=Array.prototype,wn=Object.create(Sn);function Tn(n){return In(n,!0),$(n,"__v_isShallow",!0),n}function In(n,e){if(!Cn(n)){gt(n,e,on());0}}function Cn(n){return!(!n||!n.__v_isReadonly)}["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(n){var e=Sn[n];$(wn,n,(function(){for(var t=[],a=0;a<arguments.length;a++)t[a]=arguments[a];var r,i=e.apply(this,t),o=this.__ob__;switch(n){case"push":case"unshift":r=t;break;case"splice":r=t.slice(2)}return r&&o.observeArray(r),o.dep.notify(),i}))}));function Mn(n){return!(!n||!0!==n.__v_isRef)}function En(n,e,t){Object.defineProperty(n,t,{enumerable:!0,configurable:!0,get:function(){return function(n){return Mn(n)?n.value:n}(e[t])},set:function(n){var a=e[t];Mn(a)&&!Mn(n)?a.value=n:e[t]=n}})}var Pn=new cn;function zn(n){return function n(e,t){var a,i,o=r(e);if(!o&&!p(e)||Object.isFrozen(e)||e instanceof yn)return;if(e.__ob__){var s=e.__ob__.dep.id;if(t.has(s))return;t.add(s)}if(o)for(a=e.length;a--;)n(e[a],t);else for(i=Object.keys(e),a=i.length;a--;)n(e[i[a]],t)}(n,Pn),Pn.clear(),n}var An=S((function(n){var e="&"===n.charAt(0),t="~"===(n=e?n.slice(1):n).charAt(0),a="!"===(n=t?n.slice(1):n).charAt(0);return{name:n=a?n.slice(1):n,once:t,capture:a,passive:e}}));function qn(n,e){function t(){var n=t.fns;if(!r(n))return Ve(n,null,arguments,e,"v-on handler");for(var a=n.slice(),i=0;i<a.length;i++)Ve(a[i],null,arguments,e,"v-on handler")}return t.fns=n,t}function Jn(n,e,t,a,r,o){var l,c,p,d;for(l in n)c=n[l],p=e[l],d=An(l),i(c)||(i(p)?(i(c.fns)&&(c=n[l]=qn(c,o)),s(d.once)&&(c=n[l]=r(d.name,c,d.capture)),t(d.name,c,d.capture,d.passive,d.params)):c!==p&&(p.fns=c,n[l]=p));for(l in e)i(n[l])&&a((d=An(l)).name,e[l],d.capture)}function Ln(n,e,t){var a;n instanceof yn&&(n=n.data.hook||(n.data.hook={}));var r=n[e];function l(){t.apply(this,arguments),x(a.fns,l)}i(r)?a=qn([l]):o(r.fns)&&s(r.merged)?(a=r).fns.push(l):a=qn([r,l]),a.merged=!0,n[e]=a}function Rn(n,e,t,a,r){if(o(e)){if(j(e,t))return n[t]=e[t],r||delete e[t],!0;if(j(e,a))return n[t]=e[a],r||delete e[a],!0}return!1}function _n(n){return l(n)?[kn(n)]:r(n)?function n(e,t){var a,c,p,d,m=[];for(a=0;a<e.length;a++)i(c=e[a])||"boolean"==typeof c||(p=m.length-1,d=m[p],r(c)?c.length>0&&(On((c=n(c,"".concat(t||"","_").concat(a)))[0])&&On(d)&&(m[p]=kn(d.text+c[0].text),c.shift()),m.push.apply(m,c)):l(c)?On(d)?m[p]=kn(d.text+c):""!==c&&m.push(kn(c)):On(c)&&On(d)?m[p]=kn(d.text+c.text):(s(e._isVList)&&o(c.tag)&&i(c.key)&&o(t)&&(c.key="__vlist".concat(t,"_").concat(a,"__")),m.push(c)));return m}(n):void 0}function On(n){return o(n)&&o(n.text)&&!1===n.isComment}function Bn(n,e){if(dn){var t=dn._provided,a=dn.$parent&&dn.$parent._provided;a===t&&(t=dn._provided=Object.create(a)),t[n]=e}else 0}function Dn(n,e){if(n){for(var t=Object.create(null),a=pn?Reflect.ownKeys(n):Object.keys(n),r=0;r<a.length;r++){var i=a[r];if("__ob__"!==i){var o=n[i].from;if(o in e._provided)t[i]=e._provided[o];else if("default"in n[i]){var s=n[i].default;t[i]=c(s)?s.call(e):s}else 0}}return t}}function Hn(n,e){if(!n||!n.length)return{};for(var t={},a=0,r=n.length;a<r;a++){var i=n[a],o=i.data;if(o&&o.attrs&&o.attrs.slot&&delete o.attrs.slot,i.context!==e&&i.fnContext!==e||!o||null==o.slot)(t.default||(t.default=[])).push(i);else{var s=o.slot,l=t[s]||(t[s]=[]);"template"===i.tag?l.push.apply(l,i.children||[]):l.push(i)}}for(var c in t)t[c].every(Fn)&&delete t[c];return t}function Fn(n){return n.isComment&&!n.asyncFactory||" "===n.text}function Nn(n){return n.isComment&&n.asyncFactory}function Un(n,e,t,r){var i,o=Object.keys(t).length>0,s=e?!!e.$stable:!o,l=e&&e.$key;if(e){if(e._normalized)return e._normalized;if(s&&r&&r!==a&&l===r.$key&&!o&&!r.$hasNormal)return r;for(var c in i={},e)e[c]&&"$"!==c[0]&&(i[c]=$n(n,t,c,e[c]))}else i={};for(var p in t)p in i||(i[p]=Wn(t,p));return e&&Object.isExtensible(e)&&(e._normalized=i),$(i,"$stable",s),$(i,"$key",l),$(i,"$hasNormal",o),i}function $n(n,e,t,a){var i=function(){var e=dn;mn(n);var t=arguments.length?a.apply(null,arguments):a({}),i=(t=t&&"object"==typeof t&&!r(t)?[t]:_n(t))&&t[0];return mn(e),t&&(!i||1===t.length&&i.isComment&&!Nn(i))?void 0:t};return a.proxy&&Object.defineProperty(e,t,{get:i,enumerable:!0,configurable:!0}),i}function Wn(n,e){return function(){return n[e]}}function Qn(n,e){var t,a,i,s,l=null;if(r(n)||"string"==typeof n)for(l=new Array(n.length),t=0,a=n.length;t<a;t++)l[t]=e(n[t],t);else if("number"==typeof n)for(l=new Array(n),t=0;t<n;t++)l[t]=e(t+1,t);else if(p(n))if(pn&&n[Symbol.iterator]){l=[];for(var c=n[Symbol.iterator](),d=c.next();!d.done;)l.push(e(d.value,l.length)),d=c.next()}else for(i=Object.keys(n),l=new Array(i.length),t=0,a=i.length;t<a;t++)s=i[t],l[t]=e(n[s],s,t);return o(l)||(l=[]),l._isVList=!0,l}function Gn(n,e,t,a){var r,i=this.$scopedSlots[n];i?(t=t||{},a&&(t=z(z({},a),t)),r=i(t)||(c(e)?e():e)):r=this.$slots[n]||(c(e)?e():e);var o=t&&t.slot;return o?this.$createElement("template",{slot:o},r):r}function Vn(n){return Ct(this.$options,"filters",n,!0)||L}function Kn(n,e){return r(n)?-1===n.indexOf(e):n!==e}function Xn(n,e,t,a,r){var i=F.keyCodes[e]||t;return r&&a&&!F.keyCodes[e]?Kn(r,a):i?Kn(i,n):a?M(a)!==e:void 0===n}function Zn(n,e,t,a,i){if(t)if(p(t)){r(t)&&(t=A(t));var o=void 0,s=function(r){if("class"===r||"style"===r||y(r))o=n;else{var s=n.attrs&&n.attrs.type;o=a||F.mustUseProp(e,s,r)?n.domProps||(n.domProps={}):n.attrs||(n.attrs={})}var l=T(r),c=M(r);l in o||c in o||(o[r]=t[r],i&&((n.on||(n.on={}))["update:".concat(r)]=function(n){t[r]=n}))};for(var l in t)s(l)}else;return n}function Yn(n,e){var t=this._staticTrees||(this._staticTrees=[]),a=t[n];return a&&!e||ee(a=t[n]=this.$options.staticRenderFns[n].call(this._renderProxy,this._c,this),"__static__".concat(n),!1),a}function ne(n,e,t){return ee(n,"__once__".concat(e).concat(t?"_".concat(t):""),!0),n}function ee(n,e,t){if(r(n))for(var a=0;a<n.length;a++)n[a]&&"string"!=typeof n[a]&&te(n[a],"".concat(e,"_").concat(a),t);else te(n,e,t)}function te(n,e,t){n.isStatic=!0,n.key=e,n.isOnce=t}function ae(n,e){if(e)if(m(e)){var t=n.on=n.on?z({},n.on):{};for(var a in e){var r=t[a],i=e[a];t[a]=r?[].concat(r,i):i}}else;return n}function re(n,e,t,a){e=e||{$stable:!t};for(var i=0;i<n.length;i++){var o=n[i];r(o)?re(o,e,t):o&&(o.proxy&&(o.fn.proxy=!0),e[o.key]=o.fn)}return a&&(e.$key=a),e}function ie(n,e){for(var t=0;t<e.length;t+=2){var a=e[t];"string"==typeof a&&a&&(n[e[t]]=e[t+1])}return n}function oe(n,e){return"string"==typeof n?e+n:n}function se(n){n._o=ne,n._n=b,n._s=v,n._l=Qn,n._t=Gn,n._q=R,n._i=_,n._m=Yn,n._f=Vn,n._k=Xn,n._b=Zn,n._v=kn,n._e=xn,n._u=re,n._g=ae,n._d=ie,n._p=oe}function le(n,e,t,i,o){var l,c=this,p=o.options;j(i,"_uid")?(l=Object.create(i))._original=i:(l=i,i=i._original);var d=s(p._compiled),m=!d;this.data=n,this.props=e,this.children=t,this.parent=i,this.listeners=n.on||a,this.injections=Dn(p.inject,i),this.slots=function(){return c.$slots||Un(i,n.scopedSlots,c.$slots=Hn(t,i)),c.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return Un(i,n.scopedSlots,this.slots())}}),d&&(this.$options=p,this.$slots=this.slots(),this.$scopedSlots=Un(i,n.scopedSlots,this.$slots)),p._scopeId?this._c=function(n,e,t,a){var o=ge(l,n,e,t,a,m);return o&&!r(o)&&(o.fnScopeId=p._scopeId,o.fnContext=i),o}:this._c=function(n,e,t,a){return ge(l,n,e,t,a,m)}}function ce(n,e,t,a,r){var i=jn(n);return i.fnContext=t,i.fnOptions=a,e.slot&&((i.data||(i.data={})).slot=e.slot),i}function pe(n,e){for(var t in e)n[T(t)]=e[t]}se(le.prototype);var de={init:function(n,e){if(n.componentInstance&&!n.componentInstance._isDestroyed&&n.data.keepAlive){var t=n;de.prepatch(t,t)}else{(n.componentInstance=function(n,e){var t={_isComponent:!0,_parentVnode:n,parent:e},a=n.data.inlineTemplate;o(a)&&(t.render=a.render,t.staticRenderFns=a.staticRenderFns);return new n.componentOptions.Ctor(t)}(n,Me)).$mount(e?n.elm:void 0,e)}},prepatch:function(n,e){var t=e.componentOptions;!function(n,e,t,r,i){0;var o=r.data.scopedSlots,s=n.$scopedSlots,l=!!(o&&!o.$stable||s!==a&&!s.$stable||o&&n.$scopedSlots.$key!==o.$key||!o&&n.$scopedSlots.$key),c=!!(i||n.$options._renderChildren||l),p=n.$vnode;n.$options._parentVnode=r,n.$vnode=r,n._vnode&&(n._vnode.parent=r);n.$options._renderChildren=i;var d=r.data.attrs||a;n._attrsProxy&&be(n._attrsProxy,d,p.data&&p.data.attrs||a,n)&&(c=!0);if(n.$attrs=d,n.$listeners=t||a,e&&n.$options.props){mt(!1);for(var m=n._props,u=n.$options._propKeys||[],h=0;h<u.length;h++){var g=u[h],v=n.$options.props;m[g]=Mt(g,v,e,n)}mt(!0),n.$options.propsData=e}t=t||a;var b=n.$options._parentListeners;n.$options._parentListeners=t,Ce(n,t,b),c&&(n.$slots=Hn(i,r.context),n.$forceUpdate());0}(e.componentInstance=n.componentInstance,t.propsData,t.listeners,e,t.children)},insert:function(n){var e,t=n.context,a=n.componentInstance;a._isMounted||(a._isMounted=!0,Ae(a,"mounted")),n.data.keepAlive&&(t._isMounted?((e=a)._inactive=!1,Je.push(e)):ze(a,!0))},destroy:function(n){var e=n.componentInstance;e._isDestroyed||(n.data.keepAlive?function n(e,t){if(t&&(e._directInactive=!0,Pe(e)))return;if(!e._inactive){e._inactive=!0;for(var a=0;a<e.$children.length;a++)n(e.$children[a]);Ae(e,"deactivated")}}(e,!0):e.$destroy())}},me=Object.keys(de);function ue(n,e,t,l,c){if(!i(n)){var d=t.$options._base;if(p(n)&&(n=d.extend(n)),"function"==typeof n){var m;if(i(n.cid)&&void 0===(n=function(n,e){if(s(n.error)&&o(n.errorComp))return n.errorComp;if(o(n.resolved))return n.resolved;var t=ke;t&&o(n.owners)&&-1===n.owners.indexOf(t)&&n.owners.push(t);if(s(n.loading)&&o(n.loadingComp))return n.loadingComp;if(t&&!o(n.owners)){var a=n.owners=[t],r=!0,l=null,c=null;t.$on("hook:destroyed",(function(){return x(a,t)}));var d=function(n){for(var e=0,t=a.length;e<t;e++)a[e].$forceUpdate();n&&(a.length=0,null!==l&&(clearTimeout(l),l=null),null!==c&&(clearTimeout(c),c=null))},m=O((function(t){n.resolved=je(t,e),r?a.length=0:d(!0)})),u=O((function(e){o(n.errorComp)&&(n.error=!0,d(!0))})),h=n(m,u);return p(h)&&(g(h)?i(n.resolved)&&h.then(m,u):g(h.component)&&(h.component.then(m,u),o(h.error)&&(n.errorComp=je(h.error,e)),o(h.loading)&&(n.loadingComp=je(h.loading,e),0===h.delay?n.loading=!0:l=setTimeout((function(){l=null,i(n.resolved)&&i(n.error)&&(n.loading=!0,d(!1))}),h.delay||200)),o(h.timeout)&&(c=setTimeout((function(){c=null,i(n.resolved)&&u(null)}),h.timeout)))),r=!1,n.loading?n.loadingComp:n.resolved}}(m=n,d)))return function(n,e,t,a,r){var i=xn();return i.asyncFactory=n,i.asyncMeta={data:e,context:t,children:a,tag:r},i}(m,e,t,l,c);e=e||{},Ft(n),o(e.model)&&function(n,e){var t=n.model&&n.model.prop||"value",a=n.model&&n.model.event||"input";(e.attrs||(e.attrs={}))[t]=e.model.value;var i=e.on||(e.on={}),s=i[a],l=e.model.callback;o(s)?(r(s)?-1===s.indexOf(l):s!==l)&&(i[a]=[l].concat(s)):i[a]=l}(n.options,e);var u=function(n,e,t){var a=e.options.props;if(!i(a)){var r={},s=n.attrs,l=n.props;if(o(s)||o(l))for(var c in a){var p=M(c);Rn(r,l,c,p,!0)||Rn(r,s,c,p,!1)}return r}}(e,n);if(s(n.options.functional))return function(n,e,t,i,s){var l=n.options,c={},p=l.props;if(o(p))for(var d in p)c[d]=Mt(d,p,e||a);else o(t.attrs)&&pe(c,t.attrs),o(t.props)&&pe(c,t.props);var m=new le(t,c,s,i,n),u=l.render.call(null,m._c,m);if(u instanceof yn)return ce(u,t,m.parent,l,m);if(r(u)){for(var h=_n(u)||[],g=new Array(h.length),v=0;v<h.length;v++)g[v]=ce(h[v],t,m.parent,l,m);return g}}(n,u,e,t,l);var h=e.on;if(e.on=e.nativeOn,s(n.options.abstract)){var v=e.slot;e={},v&&(e.slot=v)}!function(n){for(var e=n.hook||(n.hook={}),t=0;t<me.length;t++){var a=me[t],r=e[a],i=de[a];r===i||r&&r._merged||(e[a]=r?he(i,r):i)}}(e);var b=n.options.name||c;return new yn("vue-component-".concat(n.cid).concat(b?"-".concat(b):""),e,void 0,void 0,void 0,t,{Ctor:n,propsData:u,listeners:h,tag:c,children:l},m)}}}function he(n,e){var t=function(t,a){n(t,a),e(t,a)};return t._merged=!0,t}function ge(n,e,t,a,d,m){return(r(t)||l(t))&&(d=a,a=t,t=void 0),s(m)&&(d=2),function(n,e,t,a,l){if(o(t)&&o(t.__ob__))return xn();o(t)&&o(t.is)&&(e=t.is);if(!e)return xn();0;r(a)&&c(a[0])&&((t=t||{}).scopedSlots={default:a[0]},a.length=0);2===l?a=_n(a):1===l&&(a=function(n){for(var e=0;e<n.length;e++)if(r(n[e]))return Array.prototype.concat.apply([],n);return n}(a));var d,m;if("string"==typeof e){var u=void 0;m=n.$vnode&&n.$vnode.ns||F.getTagNamespace(e),d=F.isReservedTag(e)?new yn(F.parsePlatformTagName(e),t,a,void 0,void 0,n):t&&t.pre||!o(u=Ct(n.$options,"components",e))?new yn(e,t,a,void 0,void 0,n):ue(u,t,n,a,e)}else d=ue(e,t,n,a);return r(d)?d:o(d)?(o(m)&&function n(e,t,a){e.ns=t,"foreignObject"===e.tag&&(t=void 0,a=!0);if(o(e.children))for(var r=0,l=e.children.length;r<l;r++){var c=e.children[r];o(c.tag)&&(i(c.ns)||s(a)&&"svg"!==c.tag)&&n(c,t,a)}}(d,m),o(t)&&function(n){p(n.style)&&zn(n.style);p(n.class)&&zn(n.class)}(t),d):xn()}(n,e,t,a,d)}function ve(n){return{get attrs(){return function(n){if(!n._attrsProxy){var e=n._attrsProxy={};$(e,"_v_attr_proxy",!0),be(e,n.$attrs,a,n)}return n._attrsProxy}(n)},get slots(){return function(n){n._slotsProxy||ye(n._slotsProxy={},n.$scopedSlots);return n._slotsProxy}(n)},emit:E(n.$emit,n),expose:function(e){e&&Object.keys(e).forEach((function(t){return En(n,e,t)}))}}}function be(n,e,t,a){var r=!1;for(var i in e)i in n?e[i]!==t[i]&&(r=!0):(r=!0,fe(n,i,a));for(var i in n)i in e||(r=!0,delete n[i]);return r}function fe(n,e,t){Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){return t.$attrs[e]}})}function ye(n,e){for(var t in e)n[t]=e[t];for(var t in n)t in e||delete n[t]}var xe,ke=null;function je(n,e){return(n.__esModule||pn&&"Module"===n[Symbol.toStringTag])&&(n=n.default),p(n)?e.extend(n):n}function Se(n){if(r(n))for(var e=0;e<n.length;e++){var t=n[e];if(o(t)&&(o(t.componentOptions)||Nn(t)))return t}}function we(n,e){xe.$on(n,e)}function Te(n,e){xe.$off(n,e)}function Ie(n,e){var t=xe;return function a(){var r=e.apply(null,arguments);null!==r&&t.$off(n,a)}}function Ce(n,e,t){xe=n,Jn(e,t||{},we,Te,Ie,n),xe=void 0}var Me=null;function Ee(n){var e=Me;return Me=n,function(){Me=e}}function Pe(n){for(;n&&(n=n.$parent);)if(n._inactive)return!0;return!1}function ze(n,e){if(e){if(n._directInactive=!1,Pe(n))return}else if(n._directInactive)return;if(n._inactive||null===n._inactive){n._inactive=!1;for(var t=0;t<n.$children.length;t++)ze(n.$children[t]);Ae(n,"activated")}}function Ae(n,e,t){bn();var a=dn;mn(n);var r=n.$options[e],i="".concat(e," hook");if(r)for(var o=0,s=r.length;o<s;o++)Ve(r[o],n,t||null,n,i);n._hasHookEvent&&n.$emit("hook:"+e),mn(a),fn()}var qe=[],Je=[],Le={},Re=!1,_e=!1,Oe=0;var Be,De=0,He=Date.now;if(G&&!K){var Fe=window.performance;Fe&&"function"==typeof Fe.now&&He()>document.createEvent("Event").timeStamp&&(He=function(){return Fe.now()})}function Ne(){var n,e;for(De=He(),_e=!0,qe.sort((function(n,e){return n.id-e.id})),Oe=0;Oe<qe.length;Oe++)(n=qe[Oe]).before&&n.before(),e=n.id,Le[e]=null,n.run();var t=Je.slice(),a=qe.slice();Oe=qe.length=Je.length=0,Le={},Re=_e=!1,function(n){for(var e=0;e<n.length;e++)n[e]._inactive=!0,ze(n[e],!0)}(t),function(n){var e=n.length;for(;e--;){var t=n[e],a=t.vm;a&&a._watcher===t&&a._isMounted&&!a._isDestroyed&&Ae(a,"updated")}}(a),sn&&F.devtools&&sn.emit("flush")}function Ue(n){var e=n.id;if(null==Le[e]&&(n!==gn.target||!n.noRecurse)){if(Le[e]=!0,_e){for(var t=qe.length-1;t>Oe&&qe[t].id>n.id;)t--;qe.splice(t+1,0,n)}else qe.push(n);Re||(Re=!0,st(Ne))}}var $e=function(){function n(n){void 0===n&&(n=!1),this.active=!0,this.effects=[],this.cleanups=[],!n&&Be&&(this.parent=Be,this.index=(Be.scopes||(Be.scopes=[])).push(this)-1)}return n.prototype.run=function(n){if(this.active){var e=Be;try{return Be=this,n()}finally{Be=e}}else 0},n.prototype.on=function(){Be=this},n.prototype.off=function(){Be=this.parent},n.prototype.stop=function(n){if(this.active){var e=void 0,t=void 0;for(e=0,t=this.effects.length;e<t;e++)this.effects[e].teardown();for(e=0,t=this.cleanups.length;e<t;e++)this.cleanups[e]();if(this.scopes)for(e=0,t=this.scopes.length;e<t;e++)this.scopes[e].stop(!0);if(this.parent&&!n){var a=this.parent.scopes.pop();a&&a!==this&&(this.parent.scopes[this.index]=a,a.index=this.index)}this.active=!1}},n}();var We=0,Qe=function(){function n(n,e,t,a,r){var i,o;i=this,void 0===(o=Be||(n?n._scope:void 0))&&(o=Be),o&&o.active&&o.effects.push(i),(this.vm=n)&&r&&(n._watcher=this),a?(this.deep=!!a.deep,this.user=!!a.user,this.lazy=!!a.lazy,this.sync=!!a.sync,this.before=a.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++We,this.active=!0,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new cn,this.newDepIds=new cn,this.expression="",c(e)?this.getter=e:(this.getter=function(n){if(!W.test(n)){var e=n.split(".");return function(n){for(var t=0;t<e.length;t++){if(!n)return;n=n[e[t]]}return n}}}(e),this.getter||(this.getter=q)),this.value=this.lazy?void 0:this.get()}return n.prototype.get=function(){var n;bn(this);var e=this.vm;try{n=this.getter.call(e,e)}catch(n){if(!this.user)throw n;Ge(n,e,'getter for watcher "'.concat(this.expression,'"'))}finally{this.deep&&zn(n),fn(),this.cleanupDeps()}return n},n.prototype.addDep=function(n){var e=n.id;this.newDepIds.has(e)||(this.newDepIds.add(e),this.newDeps.push(n),this.depIds.has(e)||n.addSub(this))},n.prototype.cleanupDeps=function(){for(var n=this.deps.length;n--;){var e=this.deps[n];this.newDepIds.has(e.id)||e.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},n.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():Ue(this)},n.prototype.run=function(){if(this.active){var n=this.get();if(n!==this.value||p(n)||this.deep){var e=this.value;if(this.value=n,this.user){var t='callback for watcher "'.concat(this.expression,'"');Ve(this.cb,this.vm,[n,e],this.vm,t)}else this.cb.call(this.vm,n,e)}}},n.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},n.prototype.depend=function(){for(var n=this.deps.length;n--;)this.deps[n].depend()},n.prototype.teardown=function(){if(this.vm&&!this.vm._isBeingDestroyed&&x(this.vm._scope.effects,this),this.active){for(var n=this.deps.length;n--;)this.deps[n].removeSub(this);this.active=!1,this.onStop&&this.onStop()}},n}();"".concat("watcher"," callback"),"".concat("watcher"," getter"),"".concat("watcher"," cleanup");function Ge(n,e,t){bn();try{if(e)for(var a=e;a=a.$parent;){var r=a.$options.errorCaptured;if(r)for(var i=0;i<r.length;i++)try{if(!1===r[i].call(a,n,e,t))return}catch(n){Ke(n,a,"errorCaptured hook")}}Ke(n,e,t)}finally{fn()}}function Ve(n,e,t,a,r){var i;try{(i=t?n.apply(e,t):n.call(e))&&!i._isVue&&g(i)&&!i._handled&&(i.catch((function(n){return Ge(n,a,r+" (Promise/async)")})),i._handled=!0)}catch(n){Ge(n,a,r)}return i}function Ke(n,e,t){if(F.errorHandler)try{return F.errorHandler.call(null,n,e,t)}catch(e){e!==n&&Xe(e,null,"config.errorHandler")}Xe(n,e,t)}function Xe(n,e,t){if(!G||"undefined"==typeof console)throw n;console.error(n)}var Ze,Ye=!1,nt=[],et=!1;function tt(){et=!1;var n=nt.slice(0);nt.length=0;for(var e=0;e<n.length;e++)n[e]()}if("undefined"!=typeof Promise&&ln(Promise)){var at=Promise.resolve();Ze=function(){at.then(tt),Y&&setTimeout(q)},Ye=!0}else if(K||"undefined"==typeof MutationObserver||!ln(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())Ze="undefined"!=typeof setImmediate&&ln(setImmediate)?function(){setImmediate(tt)}:function(){setTimeout(tt,0)};else{var rt=1,it=new MutationObserver(tt),ot=document.createTextNode(String(rt));it.observe(ot,{characterData:!0}),Ze=function(){rt=(rt+1)%2,ot.data=String(rt)},Ye=!0}function st(n,e){var t;if(nt.push((function(){if(n)try{n.call(e)}catch(n){Ge(n,e,"nextTick")}else t&&t(e)})),et||(et=!0,Ze()),!n&&"undefined"!=typeof Promise)return new Promise((function(n){t=n}))}function lt(n){return function(e,t){if(void 0===t&&(t=dn),t)return function(n,e,t){var a=n.$options;a[e]=St(a[e],t)}(t,n,e)}}lt("beforeMount"),lt("mounted"),lt("beforeUpdate"),lt("updated"),lt("beforeDestroy"),lt("destroyed"),lt("errorCaptured"),lt("activated"),lt("deactivated"),lt("serverPrefetch"),lt("renderTracked"),lt("renderTriggered");var ct=Object.getOwnPropertyNames(wn),pt={},dt=!0;function mt(n){dt=n}var ut={notify:q,depend:q,addSub:q,removeSub:q},ht=function(){function n(n,e,t){if(void 0===e&&(e=!1),void 0===t&&(t=!1),this.value=n,this.shallow=e,this.mock=t,this.dep=t?ut:new gn,this.vmCount=0,$(n,"__ob__",this),r(n)){if(!t)if(Q)n.__proto__=wn;else for(var a=0,i=ct.length;a<i;a++){$(n,s=ct[a],wn[s])}e||this.observeArray(n)}else{var o=Object.keys(n);for(a=0;a<o.length;a++){var s;vt(n,s=o[a],pt,void 0,e,t)}}}return n.prototype.observeArray=function(n){for(var e=0,t=n.length;e<t;e++)gt(n[e],!1,this.mock)},n}();function gt(n,e,t){var a;if(!(!p(n)||Mn(n)||n instanceof yn))return j(n,"__ob__")&&n.__ob__ instanceof ht?a=n.__ob__:!dt||!t&&on()||!r(n)&&!m(n)||!Object.isExtensible(n)||n.__v_skip||(a=new ht(n,e,t)),a}function vt(n,e,t,a,i,o){var s=new gn,l=Object.getOwnPropertyDescriptor(n,e);if(!l||!1!==l.configurable){var c=l&&l.get,p=l&&l.set;c&&!p||t!==pt&&2!==arguments.length||(t=n[e]);var d=!i&&gt(t,!1,o);return Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){var e=c?c.call(n):t;return gn.target&&(s.depend(),d&&(d.dep.depend(),r(e)&&yt(e))),Mn(e)&&!i?e.value:e},set:function(e){var a=c?c.call(n):t;if(B(a,e)){if(p)p.call(n,e);else{if(c)return;if(Mn(a)&&!Mn(e))return void(a.value=e);t=e}d=!i&&gt(e,!1,o),s.notify()}}}),s}}function bt(n,e,t){if(!Cn(n)){var a=n.__ob__;return r(n)&&h(e)?(n.length=Math.max(n.length,e),n.splice(e,1,t),a&&!a.shallow&&a.mock&&gt(t,!1,!0),t):e in n&&!(e in Object.prototype)?(n[e]=t,t):n._isVue||a&&a.vmCount?t:a?(vt(a.value,e,t,void 0,a.shallow,a.mock),a.dep.notify(),t):(n[e]=t,t)}}function ft(n,e){if(r(n)&&h(e))n.splice(e,1);else{var t=n.__ob__;n._isVue||t&&t.vmCount||Cn(n)||j(n,e)&&(delete n[e],t&&t.dep.notify())}}function yt(n){for(var e=void 0,t=0,a=n.length;t<a;t++)(e=n[t])&&e.__ob__&&e.__ob__.dep.depend(),r(e)&&yt(e)}var xt=F.optionMergeStrategies;function kt(n,e){if(!e)return n;for(var t,a,r,i=pn?Reflect.ownKeys(e):Object.keys(e),o=0;o<i.length;o++)"__ob__"!==(t=i[o])&&(a=n[t],r=e[t],j(n,t)?a!==r&&m(a)&&m(r)&&kt(a,r):bt(n,t,r));return n}function jt(n,e,t){return t?function(){var a=c(e)?e.call(t,t):e,r=c(n)?n.call(t,t):n;return a?kt(a,r):r}:e?n?function(){return kt(c(e)?e.call(this,this):e,c(n)?n.call(this,this):n)}:e:n}function St(n,e){var t=e?n?n.concat(e):r(e)?e:[e]:n;return t?function(n){for(var e=[],t=0;t<n.length;t++)-1===e.indexOf(n[t])&&e.push(n[t]);return e}(t):t}function wt(n,e,t,a){var r=Object.create(n||null);return e?z(r,e):r}xt.data=function(n,e,t){return t?jt(n,e,t):e&&"function"!=typeof e?n:jt(n,e)},H.forEach((function(n){xt[n]=St})),D.forEach((function(n){xt[n+"s"]=wt})),xt.watch=function(n,e,t,a){if(n===tn&&(n=void 0),e===tn&&(e=void 0),!e)return Object.create(n||null);if(!n)return e;var i={};for(var o in z(i,n),e){var s=i[o],l=e[o];s&&!r(s)&&(s=[s]),i[o]=s?s.concat(l):r(l)?l:[l]}return i},xt.props=xt.methods=xt.inject=xt.computed=function(n,e,t,a){if(!n)return e;var r=Object.create(null);return z(r,n),e&&z(r,e),r},xt.provide=jt;var Tt=function(n,e){return void 0===e?n:e};function It(n,e,t){if(c(e)&&(e=e.options),function(n,e){var t=n.props;if(t){var a,i,o={};if(r(t))for(a=t.length;a--;)"string"==typeof(i=t[a])&&(o[T(i)]={type:null});else if(m(t))for(var s in t)i=t[s],o[T(s)]=m(i)?i:{type:i};else 0;n.props=o}}(e),function(n,e){var t=n.inject;if(t){var a=n.inject={};if(r(t))for(var i=0;i<t.length;i++)a[t[i]]={from:t[i]};else if(m(t))for(var o in t){var s=t[o];a[o]=m(s)?z({from:o},s):{from:s}}else 0}}(e),function(n){var e=n.directives;if(e)for(var t in e){var a=e[t];c(a)&&(e[t]={bind:a,update:a})}}(e),!e._base&&(e.extends&&(n=It(n,e.extends,t)),e.mixins))for(var a=0,i=e.mixins.length;a<i;a++)n=It(n,e.mixins[a],t);var o,s={};for(o in n)l(o);for(o in e)j(n,o)||l(o);function l(a){var r=xt[a]||Tt;s[a]=r(n[a],e[a],t,a)}return s}function Ct(n,e,t,a){if("string"==typeof t){var r=n[e];if(j(r,t))return r[t];var i=T(t);if(j(r,i))return r[i];var o=I(i);return j(r,o)?r[o]:r[t]||r[i]||r[o]}}function Mt(n,e,t,a){var r=e[n],i=!j(t,n),o=t[n],s=At(Boolean,r.type);if(s>-1)if(i&&!j(r,"default"))o=!1;else if(""===o||o===M(n)){var l=At(String,r.type);(l<0||s<l)&&(o=!0)}if(void 0===o){o=function(n,e,t){if(!j(e,"default"))return;var a=e.default;0;if(n&&n.$options.propsData&&void 0===n.$options.propsData[t]&&void 0!==n._props[t])return n._props[t];return c(a)&&"Function"!==Pt(e.type)?a.call(n):a}(a,r,n);var p=dt;mt(!0),gt(o),mt(p)}return o}var Et=/^\s*function (\w+)/;function Pt(n){var e=n&&n.toString().match(Et);return e?e[1]:""}function zt(n,e){return Pt(n)===Pt(e)}function At(n,e){if(!r(e))return zt(e,n)?0:-1;for(var t=0,a=e.length;t<a;t++)if(zt(e[t],n))return t;return-1}var qt={enumerable:!0,configurable:!0,get:q,set:q};function Jt(n,e,t){qt.get=function(){return this[e][t]},qt.set=function(n){this[e][t]=n},Object.defineProperty(n,t,qt)}function Lt(n){var e=n.$options;if(e.props&&function(n,e){var t=n.$options.propsData||{},a=n._props=Tn({}),r=n.$options._propKeys=[];n.$parent&&mt(!1);var i=function(i){r.push(i);var o=Mt(i,e,t,n);vt(a,i,o),i in n||Jt(n,"_props",i)};for(var o in e)i(o);mt(!0)}(n,e.props),function(n){var e=n.$options,t=e.setup;if(t){var a=n._setupContext=ve(n);mn(n),bn();var r=Ve(t,null,[n._props||Tn({}),a],n,"setup");if(fn(),mn(),c(r))e.render=r;else if(p(r))if(n._setupState=r,r.__sfc){var i=n._setupProxy={};for(var o in r)"__sfc"!==o&&En(i,r,o)}else for(var o in r)U(o)||En(n,r,o);else 0}}(n),e.methods&&function(n,e){n.$options.props;for(var t in e)n[t]="function"!=typeof e[t]?q:E(e[t],n)}(n,e.methods),e.data)!function(n){var e=n.$options.data;m(e=n._data=c(e)?function(n,e){bn();try{return n.call(e,e)}catch(n){return Ge(n,e,"data()"),{}}finally{fn()}}(e,n):e||{})||(e={});var t=Object.keys(e),a=n.$options.props,r=(n.$options.methods,t.length);for(;r--;){var i=t[r];0,a&&j(a,i)||U(i)||Jt(n,"_data",i)}var o=gt(e);o&&o.vmCount++}(n);else{var t=gt(n._data={});t&&t.vmCount++}e.computed&&function(n,e){var t=n._computedWatchers=Object.create(null),a=on();for(var r in e){var i=e[r],o=c(i)?i:i.get;0,a||(t[r]=new Qe(n,o||q,q,Rt)),r in n||_t(n,r,i)}}(n,e.computed),e.watch&&e.watch!==tn&&function(n,e){for(var t in e){var a=e[t];if(r(a))for(var i=0;i<a.length;i++)Dt(n,t,a[i]);else Dt(n,t,a)}}(n,e.watch)}var Rt={lazy:!0};function _t(n,e,t){var a=!on();c(t)?(qt.get=a?Ot(e):Bt(t),qt.set=q):(qt.get=t.get?a&&!1!==t.cache?Ot(e):Bt(t.get):q,qt.set=t.set||q),Object.defineProperty(n,e,qt)}function Ot(n){return function(){var e=this._computedWatchers&&this._computedWatchers[n];if(e)return e.dirty&&e.evaluate(),gn.target&&e.depend(),e.value}}function Bt(n){return function(){return n.call(this,this)}}function Dt(n,e,t,a){return m(t)&&(a=t,t=t.handler),"string"==typeof t&&(t=n[t]),n.$watch(e,t,a)}var Ht=0;function Ft(n){var e=n.options;if(n.super){var t=Ft(n.super);if(t!==n.superOptions){n.superOptions=t;var a=function(n){var e,t=n.options,a=n.sealedOptions;for(var r in t)t[r]!==a[r]&&(e||(e={}),e[r]=t[r]);return e}(n);a&&z(n.extendOptions,a),(e=n.options=It(t,n.extendOptions)).name&&(e.components[e.name]=n)}}return e}function Nt(n){this._init(n)}function Ut(n){n.cid=0;var e=1;n.extend=function(n){n=n||{};var t=this,a=t.cid,r=n._Ctor||(n._Ctor={});if(r[a])return r[a];var i=n.name||t.options.name;var o=function(n){this._init(n)};return(o.prototype=Object.create(t.prototype)).constructor=o,o.cid=e++,o.options=It(t.options,n),o.super=t,o.options.props&&function(n){var e=n.options.props;for(var t in e)Jt(n.prototype,"_props",t)}(o),o.options.computed&&function(n){var e=n.options.computed;for(var t in e)_t(n.prototype,t,e[t])}(o),o.extend=t.extend,o.mixin=t.mixin,o.use=t.use,D.forEach((function(n){o[n]=t[n]})),i&&(o.options.components[i]=o),o.superOptions=t.options,o.extendOptions=n,o.sealedOptions=z({},o.options),r[a]=o,o}}function $t(n){return n&&(n.Ctor.options.name||n.tag)}function Wt(n,e){return r(n)?n.indexOf(e)>-1:"string"==typeof n?n.split(",").indexOf(e)>-1:!!u(n)&&n.test(e)}function Qt(n,e){var t=n.cache,a=n.keys,r=n._vnode;for(var i in t){var o=t[i];if(o){var s=o.name;s&&!e(s)&&Gt(t,i,a,r)}}}function Gt(n,e,t,a){var r=n[e];!r||a&&r.tag===a.tag||r.componentInstance.$destroy(),n[e]=null,x(t,e)}!function(n){n.prototype._init=function(n){var e=this;e._uid=Ht++,e._isVue=!0,e.__v_skip=!0,e._scope=new $e(!0),n&&n._isComponent?function(n,e){var t=n.$options=Object.create(n.constructor.options),a=e._parentVnode;t.parent=e.parent,t._parentVnode=a;var r=a.componentOptions;t.propsData=r.propsData,t._parentListeners=r.listeners,t._renderChildren=r.children,t._componentTag=r.tag,e.render&&(t.render=e.render,t.staticRenderFns=e.staticRenderFns)}(e,n):e.$options=It(Ft(e.constructor),n||{},e),e._renderProxy=e,e._self=e,function(n){var e=n.$options,t=e.parent;if(t&&!e.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(n)}n.$parent=t,n.$root=t?t.$root:n,n.$children=[],n.$refs={},n._provided=t?t._provided:Object.create(null),n._watcher=null,n._inactive=null,n._directInactive=!1,n._isMounted=!1,n._isDestroyed=!1,n._isBeingDestroyed=!1}(e),function(n){n._events=Object.create(null),n._hasHookEvent=!1;var e=n.$options._parentListeners;e&&Ce(n,e)}(e),function(n){n._vnode=null,n._staticTrees=null;var e=n.$options,t=n.$vnode=e._parentVnode,r=t&&t.context;n.$slots=Hn(e._renderChildren,r),n.$scopedSlots=a,n._c=function(e,t,a,r){return ge(n,e,t,a,r,!1)},n.$createElement=function(e,t,a,r){return ge(n,e,t,a,r,!0)};var i=t&&t.data;vt(n,"$attrs",i&&i.attrs||a,null,!0),vt(n,"$listeners",e._parentListeners||a,null,!0)}(e),Ae(e,"beforeCreate"),function(n){var e=Dn(n.$options.inject,n);e&&(mt(!1),Object.keys(e).forEach((function(t){vt(n,t,e[t])})),mt(!0))}(e),Lt(e),function(n){var e=n.$options.provide;if(e){var t=c(e)?e.call(n):e;if(!p(t))return;var a=pn?Reflect.ownKeys(t):Object.keys(t);mn(n);for(var r=0;r<a.length;r++)Bn(a[r],t[a[r]]);mn()}}(e),Ae(e,"created"),e.$options.el&&e.$mount(e.$options.el)}}(Nt),function(n){var e={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(n.prototype,"$data",e),Object.defineProperty(n.prototype,"$props",t),n.prototype.$set=bt,n.prototype.$delete=ft,n.prototype.$watch=function(n,e,t){if(m(e))return Dt(this,n,e,t);(t=t||{}).user=!0;var a=new Qe(this,n,e,t);if(t.immediate){var r='callback for immediate watcher "'.concat(a.expression,'"');bn(),Ve(e,this,[a.value],this,r),fn()}return function(){a.teardown()}}}(Nt),function(n){var e=/^hook:/;n.prototype.$on=function(n,t){var a=this;if(r(n))for(var i=0,o=n.length;i<o;i++)a.$on(n[i],t);else(a._events[n]||(a._events[n]=[])).push(t),e.test(n)&&(a._hasHookEvent=!0);return a},n.prototype.$once=function(n,e){var t=this;function a(){t.$off(n,a),e.apply(t,arguments)}return a.fn=e,t.$on(n,a),t},n.prototype.$off=function(n,e){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(r(n)){for(var a=0,i=n.length;a<i;a++)t.$off(n[a],e);return t}var o,s=t._events[n];if(!s)return t;if(!e)return t._events[n]=null,t;for(var l=s.length;l--;)if((o=s[l])===e||o.fn===e){s.splice(l,1);break}return t},n.prototype.$emit=function(n){var e=this,t=e._events[n];if(t){t=t.length>1?P(t):t;for(var a=P(arguments,1),r='event handler for "'.concat(n,'"'),i=0,o=t.length;i<o;i++)Ve(t[i],e,a,e,r)}return e}}(Nt),function(n){n.prototype._update=function(n,e){var t=this,a=t.$el,r=t._vnode,i=Ee(t);t._vnode=n,t.$el=r?t.__patch__(r,n):t.__patch__(t.$el,n,e,!1),i(),a&&(a.__vue__=null),t.$el&&(t.$el.__vue__=t),t.$vnode&&t.$parent&&t.$vnode===t.$parent._vnode&&(t.$parent.$el=t.$el)},n.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},n.prototype.$destroy=function(){var n=this;if(!n._isBeingDestroyed){Ae(n,"beforeDestroy"),n._isBeingDestroyed=!0;var e=n.$parent;!e||e._isBeingDestroyed||n.$options.abstract||x(e.$children,n),n._scope.stop(),n._data.__ob__&&n._data.__ob__.vmCount--,n._isDestroyed=!0,n.__patch__(n._vnode,null),Ae(n,"destroyed"),n.$off(),n.$el&&(n.$el.__vue__=null),n.$vnode&&(n.$vnode.parent=null)}}}(Nt),function(n){se(n.prototype),n.prototype.$nextTick=function(n){return st(n,this)},n.prototype._render=function(){var n,e=this,t=e.$options,a=t.render,i=t._parentVnode;i&&(e.$scopedSlots=Un(e.$parent,i.data.scopedSlots,e.$slots,e.$scopedSlots),e._slotsProxy&&ye(e._slotsProxy,e.$scopedSlots)),e.$vnode=i;try{mn(e),ke=e,n=a.call(e._renderProxy,e.$createElement)}catch(t){Ge(t,e,"render"),n=e._vnode}finally{ke=null,mn()}return r(n)&&1===n.length&&(n=n[0]),n instanceof yn||(n=xn()),n.parent=i,n}}(Nt);var Vt=[String,RegExp,Array],Kt={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:Vt,exclude:Vt,max:[String,Number]},methods:{cacheVNode:function(){var n=this.cache,e=this.keys,t=this.vnodeToCache,a=this.keyToCache;if(t){var r=t.tag,i=t.componentInstance,o=t.componentOptions;n[a]={name:$t(o),tag:r,componentInstance:i},e.push(a),this.max&&e.length>parseInt(this.max)&&Gt(n,e[0],e,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var n in this.cache)Gt(this.cache,n,this.keys)},mounted:function(){var n=this;this.cacheVNode(),this.$watch("include",(function(e){Qt(n,(function(n){return Wt(e,n)}))})),this.$watch("exclude",(function(e){Qt(n,(function(n){return!Wt(e,n)}))}))},updated:function(){this.cacheVNode()},render:function(){var n=this.$slots.default,e=Se(n),t=e&&e.componentOptions;if(t){var a=$t(t),r=this.include,i=this.exclude;if(r&&(!a||!Wt(r,a))||i&&a&&Wt(i,a))return e;var o=this.cache,s=this.keys,l=null==e.key?t.Ctor.cid+(t.tag?"::".concat(t.tag):""):e.key;o[l]?(e.componentInstance=o[l].componentInstance,x(s,l),s.push(l)):(this.vnodeToCache=e,this.keyToCache=l),e.data.keepAlive=!0}return e||n&&n[0]}}};!function(n){var e={get:function(){return F}};Object.defineProperty(n,"config",e),n.util={warn:un,extend:z,mergeOptions:It,defineReactive:vt},n.set=bt,n.delete=ft,n.nextTick=st,n.observable=function(n){return gt(n),n},n.options=Object.create(null),D.forEach((function(e){n.options[e+"s"]=Object.create(null)})),n.options._base=n,z(n.options.components,Kt),function(n){n.use=function(n){var e=this._installedPlugins||(this._installedPlugins=[]);if(e.indexOf(n)>-1)return this;var t=P(arguments,1);return t.unshift(this),c(n.install)?n.install.apply(n,t):c(n)&&n.apply(null,t),e.push(n),this}}(n),function(n){n.mixin=function(n){return this.options=It(this.options,n),this}}(n),Ut(n),function(n){D.forEach((function(e){n[e]=function(n,t){return t?("component"===e&&m(t)&&(t.name=t.name||n,t=this.options._base.extend(t)),"directive"===e&&c(t)&&(t={bind:t,update:t}),this.options[e+"s"][n]=t,t):this.options[e+"s"][n]}}))}(n)}(Nt),Object.defineProperty(Nt.prototype,"$isServer",{get:on}),Object.defineProperty(Nt.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Nt,"FunctionalRenderContext",{value:le}),Nt.version="2.7.4";var Xt=f("style,class"),Zt=f("input,textarea,option,select,progress"),Yt=f("contenteditable,draggable,spellcheck"),na=f("events,caret,typing,plaintext-only"),ea=f("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),ta="http://www.w3.org/1999/xlink",aa=function(n){return":"===n.charAt(5)&&"xlink"===n.slice(0,5)},ra=function(n){return aa(n)?n.slice(6,n.length):""},ia=function(n){return null==n||!1===n};function oa(n){for(var e=n.data,t=n,a=n;o(a.componentInstance);)(a=a.componentInstance._vnode)&&a.data&&(e=sa(a.data,e));for(;o(t=t.parent);)t&&t.data&&(e=sa(e,t.data));return function(n,e){if(o(n)||o(e))return la(n,ca(e));return""}(e.staticClass,e.class)}function sa(n,e){return{staticClass:la(n.staticClass,e.staticClass),class:o(n.class)?[n.class,e.class]:e.class}}function la(n,e){return n?e?n+" "+e:n:e||""}function ca(n){return Array.isArray(n)?function(n){for(var e,t="",a=0,r=n.length;a<r;a++)o(e=ca(n[a]))&&""!==e&&(t&&(t+=" "),t+=e);return t}(n):p(n)?function(n){var e="";for(var t in n)n[t]&&(e&&(e+=" "),e+=t);return e}(n):"string"==typeof n?n:""}var pa={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},da=f("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),ma=f("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),ua=function(n){return da(n)||ma(n)};var ha=Object.create(null);var ga=f("text,number,password,search,email,tel,url");var va=Object.freeze({__proto__:null,createElement:function(n,e){var t=document.createElement(n);return"select"!==n||e.data&&e.data.attrs&&void 0!==e.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(n,e){return document.createElementNS(pa[n],e)},createTextNode:function(n){return document.createTextNode(n)},createComment:function(n){return document.createComment(n)},insertBefore:function(n,e,t){n.insertBefore(e,t)},removeChild:function(n,e){n.removeChild(e)},appendChild:function(n,e){n.appendChild(e)},parentNode:function(n){return n.parentNode},nextSibling:function(n){return n.nextSibling},tagName:function(n){return n.tagName},setTextContent:function(n,e){n.textContent=e},setStyleScope:function(n,e){n.setAttribute(e,"")}}),ba={create:function(n,e){fa(e)},update:function(n,e){n.data.ref!==e.data.ref&&(fa(n,!0),fa(e))},destroy:function(n){fa(n,!0)}};function fa(n,e){var t=n.data.ref;if(o(t)){var a=n.context,i=n.componentInstance||n.elm,s=e?null:i,l=e?void 0:i;if(c(t))Ve(t,a,[s],a,"template ref function");else{var p=n.data.refInFor,d="string"==typeof t||"number"==typeof t,m=Mn(t),u=a.$refs;if(d||m)if(p){var h=d?u[t]:t.value;e?r(h)&&x(h,i):r(h)?h.includes(i)||h.push(i):d?(u[t]=[i],ya(a,t,u[t])):t.value=[i]}else if(d){if(e&&u[t]!==i)return;u[t]=l,ya(a,t,s)}else if(m){if(e&&t.value!==i)return;t.value=s}else 0}}}function ya(n,e,t){var a=n._setupState;a&&j(a,e)&&(Mn(a[e])?a[e].value=t:a[e]=t)}var xa=new yn("",{},[]),ka=["create","activate","update","remove","destroy"];function ja(n,e){return n.key===e.key&&n.asyncFactory===e.asyncFactory&&(n.tag===e.tag&&n.isComment===e.isComment&&o(n.data)===o(e.data)&&function(n,e){if("input"!==n.tag)return!0;var t,a=o(t=n.data)&&o(t=t.attrs)&&t.type,r=o(t=e.data)&&o(t=t.attrs)&&t.type;return a===r||ga(a)&&ga(r)}(n,e)||s(n.isAsyncPlaceholder)&&i(e.asyncFactory.error))}function Sa(n,e,t){var a,r,i={};for(a=e;a<=t;++a)o(r=n[a].key)&&(i[r]=a);return i}var wa={create:Ta,update:Ta,destroy:function(n){Ta(n,xa)}};function Ta(n,e){(n.data.directives||e.data.directives)&&function(n,e){var t,a,r,i=n===xa,o=e===xa,s=Ca(n.data.directives,n.context),l=Ca(e.data.directives,e.context),c=[],p=[];for(t in l)a=s[t],r=l[t],a?(r.oldValue=a.value,r.oldArg=a.arg,Ea(r,"update",e,n),r.def&&r.def.componentUpdated&&p.push(r)):(Ea(r,"bind",e,n),r.def&&r.def.inserted&&c.push(r));if(c.length){var d=function(){for(var t=0;t<c.length;t++)Ea(c[t],"inserted",e,n)};i?Ln(e,"insert",d):d()}p.length&&Ln(e,"postpatch",(function(){for(var t=0;t<p.length;t++)Ea(p[t],"componentUpdated",e,n)}));if(!i)for(t in s)l[t]||Ea(s[t],"unbind",n,n,o)}(n,e)}var Ia=Object.create(null);function Ca(n,e){var t,a,r=Object.create(null);if(!n)return r;for(t=0;t<n.length;t++)(a=n[t]).modifiers||(a.modifiers=Ia),r[Ma(a)]=a,e._setupState&&e._setupState.__sfc&&(a.def=a.def||Ct(e,"_setupState","v-"+a.name)),a.def=a.def||Ct(e.$options,"directives",a.name);return r}function Ma(n){return n.rawName||"".concat(n.name,".").concat(Object.keys(n.modifiers||{}).join("."))}function Ea(n,e,t,a,r){var i=n.def&&n.def[e];if(i)try{i(t.elm,n,t,a,r)}catch(a){Ge(a,t.context,"directive ".concat(n.name," ").concat(e," hook"))}}var Pa=[ba,wa];function za(n,e){var t=e.componentOptions;if(!(o(t)&&!1===t.Ctor.options.inheritAttrs||i(n.data.attrs)&&i(e.data.attrs))){var a,r,l=e.elm,c=n.data.attrs||{},p=e.data.attrs||{};for(a in(o(p.__ob__)||s(p._v_attr_proxy))&&(p=e.data.attrs=z({},p)),p)r=p[a],c[a]!==r&&Aa(l,a,r,e.data.pre);for(a in(K||Z)&&p.value!==c.value&&Aa(l,"value",p.value),c)i(p[a])&&(aa(a)?l.removeAttributeNS(ta,ra(a)):Yt(a)||l.removeAttribute(a))}}function Aa(n,e,t,a){a||n.tagName.indexOf("-")>-1?qa(n,e,t):ea(e)?ia(t)?n.removeAttribute(e):(t="allowfullscreen"===e&&"EMBED"===n.tagName?"true":e,n.setAttribute(e,t)):Yt(e)?n.setAttribute(e,function(n,e){return ia(e)||"false"===e?"false":"contenteditable"===n&&na(e)?e:"true"}(e,t)):aa(e)?ia(t)?n.removeAttributeNS(ta,ra(e)):n.setAttributeNS(ta,e,t):qa(n,e,t)}function qa(n,e,t){if(ia(t))n.removeAttribute(e);else{if(K&&!X&&"TEXTAREA"===n.tagName&&"placeholder"===e&&""!==t&&!n.__ieph){var a=function(e){e.stopImmediatePropagation(),n.removeEventListener("input",a)};n.addEventListener("input",a),n.__ieph=!0}n.setAttribute(e,t)}}var Ja={create:za,update:za};function La(n,e){var t=e.elm,a=e.data,r=n.data;if(!(i(a.staticClass)&&i(a.class)&&(i(r)||i(r.staticClass)&&i(r.class)))){var s=oa(e),l=t._transitionClasses;o(l)&&(s=la(s,ca(l))),s!==t._prevClass&&(t.setAttribute("class",s),t._prevClass=s)}}var Ra,_a={create:La,update:La};function Oa(n,e,t){var a=Ra;return function r(){var i=e.apply(null,arguments);null!==i&&Ha(n,r,t,a)}}var Ba=Ye&&!(en&&Number(en[1])<=53);function Da(n,e,t,a){if(Ba){var r=De,i=e;e=i._wrapper=function(n){if(n.target===n.currentTarget||n.timeStamp>=r||n.timeStamp<=0||n.target.ownerDocument!==document)return i.apply(this,arguments)}}Ra.addEventListener(n,e,an?{capture:t,passive:a}:t)}function Ha(n,e,t,a){(a||Ra).removeEventListener(n,e._wrapper||e,t)}function Fa(n,e){if(!i(n.data.on)||!i(e.data.on)){var t=e.data.on||{},a=n.data.on||{};Ra=e.elm||n.elm,function(n){if(o(n.__r)){var e=K?"change":"input";n[e]=[].concat(n.__r,n[e]||[]),delete n.__r}o(n.__c)&&(n.change=[].concat(n.__c,n.change||[]),delete n.__c)}(t),Jn(t,a,Da,Ha,Oa,e.context),Ra=void 0}}var Na,Ua={create:Fa,update:Fa,destroy:function(n){return Fa(n,xa)}};function $a(n,e){if(!i(n.data.domProps)||!i(e.data.domProps)){var t,a,r=e.elm,l=n.data.domProps||{},c=e.data.domProps||{};for(t in(o(c.__ob__)||s(c._v_attr_proxy))&&(c=e.data.domProps=z({},c)),l)t in c||(r[t]="");for(t in c){if(a=c[t],"textContent"===t||"innerHTML"===t){if(e.children&&(e.children.length=0),a===l[t])continue;1===r.childNodes.length&&r.removeChild(r.childNodes[0])}if("value"===t&&"PROGRESS"!==r.tagName){r._value=a;var p=i(a)?"":String(a);Wa(r,p)&&(r.value=p)}else if("innerHTML"===t&&ma(r.tagName)&&i(r.innerHTML)){(Na=Na||document.createElement("div")).innerHTML="<svg>".concat(a,"</svg>");for(var d=Na.firstChild;r.firstChild;)r.removeChild(r.firstChild);for(;d.firstChild;)r.appendChild(d.firstChild)}else if(a!==l[t])try{r[t]=a}catch(n){}}}}function Wa(n,e){return!n.composing&&("OPTION"===n.tagName||function(n,e){var t=!0;try{t=document.activeElement!==n}catch(n){}return t&&n.value!==e}(n,e)||function(n,e){var t=n.value,a=n._vModifiers;if(o(a)){if(a.number)return b(t)!==b(e);if(a.trim)return t.trim()!==e.trim()}return t!==e}(n,e))}var Qa={create:$a,update:$a},Ga=S((function(n){var e={},t=/:(.+)/;return n.split(/;(?![^(]*\))/g).forEach((function(n){if(n){var a=n.split(t);a.length>1&&(e[a[0].trim()]=a[1].trim())}})),e}));function Va(n){var e=Ka(n.style);return n.staticStyle?z(n.staticStyle,e):e}function Ka(n){return Array.isArray(n)?A(n):"string"==typeof n?Ga(n):n}var Xa,Za=/^--/,Ya=/\s*!important$/,nr=function(n,e,t){if(Za.test(e))n.style.setProperty(e,t);else if(Ya.test(t))n.style.setProperty(M(e),t.replace(Ya,""),"important");else{var a=tr(e);if(Array.isArray(t))for(var r=0,i=t.length;r<i;r++)n.style[a]=t[r];else n.style[a]=t}},er=["Webkit","Moz","ms"],tr=S((function(n){if(Xa=Xa||document.createElement("div").style,"filter"!==(n=T(n))&&n in Xa)return n;for(var e=n.charAt(0).toUpperCase()+n.slice(1),t=0;t<er.length;t++){var a=er[t]+e;if(a in Xa)return a}}));function ar(n,e){var t=e.data,a=n.data;if(!(i(t.staticStyle)&&i(t.style)&&i(a.staticStyle)&&i(a.style))){var r,s,l=e.elm,c=a.staticStyle,p=a.normalizedStyle||a.style||{},d=c||p,m=Ka(e.data.style)||{};e.data.normalizedStyle=o(m.__ob__)?z({},m):m;var u=function(n,e){var t,a={};if(e)for(var r=n;r.componentInstance;)(r=r.componentInstance._vnode)&&r.data&&(t=Va(r.data))&&z(a,t);(t=Va(n.data))&&z(a,t);for(var i=n;i=i.parent;)i.data&&(t=Va(i.data))&&z(a,t);return a}(e,!0);for(s in d)i(u[s])&&nr(l,s,"");for(s in u)(r=u[s])!==d[s]&&nr(l,s,null==r?"":r)}}var rr={create:ar,update:ar},ir=/\s+/;function or(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(ir).forEach((function(e){return n.classList.add(e)})):n.classList.add(e);else{var t=" ".concat(n.getAttribute("class")||""," ");t.indexOf(" "+e+" ")<0&&n.setAttribute("class",(t+e).trim())}}function sr(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(ir).forEach((function(e){return n.classList.remove(e)})):n.classList.remove(e),n.classList.length||n.removeAttribute("class");else{for(var t=" ".concat(n.getAttribute("class")||""," "),a=" "+e+" ";t.indexOf(a)>=0;)t=t.replace(a," ");(t=t.trim())?n.setAttribute("class",t):n.removeAttribute("class")}}function lr(n){if(n){if("object"==typeof n){var e={};return!1!==n.css&&z(e,cr(n.name||"v")),z(e,n),e}return"string"==typeof n?cr(n):void 0}}var cr=S((function(n){return{enterClass:"".concat(n,"-enter"),enterToClass:"".concat(n,"-enter-to"),enterActiveClass:"".concat(n,"-enter-active"),leaveClass:"".concat(n,"-leave"),leaveToClass:"".concat(n,"-leave-to"),leaveActiveClass:"".concat(n,"-leave-active")}})),pr=G&&!X,dr="transition",mr="transitionend",ur="animation",hr="animationend";pr&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(dr="WebkitTransition",mr="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(ur="WebkitAnimation",hr="webkitAnimationEnd"));var gr=G?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(n){return n()};function vr(n){gr((function(){gr(n)}))}function br(n,e){var t=n._transitionClasses||(n._transitionClasses=[]);t.indexOf(e)<0&&(t.push(e),or(n,e))}function fr(n,e){n._transitionClasses&&x(n._transitionClasses,e),sr(n,e)}function yr(n,e,t){var a=kr(n,e),r=a.type,i=a.timeout,o=a.propCount;if(!r)return t();var s="transition"===r?mr:hr,l=0,c=function(){n.removeEventListener(s,p),t()},p=function(e){e.target===n&&++l>=o&&c()};setTimeout((function(){l<o&&c()}),i+1),n.addEventListener(s,p)}var xr=/\b(transform|all)(,|$)/;function kr(n,e){var t,a=window.getComputedStyle(n),r=(a[dr+"Delay"]||"").split(", "),i=(a[dr+"Duration"]||"").split(", "),o=jr(r,i),s=(a[ur+"Delay"]||"").split(", "),l=(a[ur+"Duration"]||"").split(", "),c=jr(s,l),p=0,d=0;return"transition"===e?o>0&&(t="transition",p=o,d=i.length):"animation"===e?c>0&&(t="animation",p=c,d=l.length):d=(t=(p=Math.max(o,c))>0?o>c?"transition":"animation":null)?"transition"===t?i.length:l.length:0,{type:t,timeout:p,propCount:d,hasTransform:"transition"===t&&xr.test(a[dr+"Property"])}}function jr(n,e){for(;n.length<e.length;)n=n.concat(n);return Math.max.apply(null,e.map((function(e,t){return Sr(e)+Sr(n[t])})))}function Sr(n){return 1e3*Number(n.slice(0,-1).replace(",","."))}function wr(n,e){var t=n.elm;o(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var a=lr(n.data.transition);if(!i(a)&&!o(t._enterCb)&&1===t.nodeType){for(var r=a.css,s=a.type,l=a.enterClass,d=a.enterToClass,m=a.enterActiveClass,u=a.appearClass,h=a.appearToClass,g=a.appearActiveClass,v=a.beforeEnter,f=a.enter,y=a.afterEnter,x=a.enterCancelled,k=a.beforeAppear,j=a.appear,S=a.afterAppear,w=a.appearCancelled,T=a.duration,I=Me,C=Me.$vnode;C&&C.parent;)I=C.context,C=C.parent;var M=!I._isMounted||!n.isRootInsert;if(!M||j||""===j){var E=M&&u?u:l,P=M&&g?g:m,z=M&&h?h:d,A=M&&k||v,q=M&&c(j)?j:f,J=M&&S||y,L=M&&w||x,R=b(p(T)?T.enter:T);0;var _=!1!==r&&!X,B=Cr(q),D=t._enterCb=O((function(){_&&(fr(t,z),fr(t,P)),D.cancelled?(_&&fr(t,E),L&&L(t)):J&&J(t),t._enterCb=null}));n.data.show||Ln(n,"insert",(function(){var e=t.parentNode,a=e&&e._pending&&e._pending[n.key];a&&a.tag===n.tag&&a.elm._leaveCb&&a.elm._leaveCb(),q&&q(t,D)})),A&&A(t),_&&(br(t,E),br(t,P),vr((function(){fr(t,E),D.cancelled||(br(t,z),B||(Ir(R)?setTimeout(D,R):yr(t,s,D)))}))),n.data.show&&(e&&e(),q&&q(t,D)),_||B||D()}}}function Tr(n,e){var t=n.elm;o(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var a=lr(n.data.transition);if(i(a)||1!==t.nodeType)return e();if(!o(t._leaveCb)){var r=a.css,s=a.type,l=a.leaveClass,c=a.leaveToClass,d=a.leaveActiveClass,m=a.beforeLeave,u=a.leave,h=a.afterLeave,g=a.leaveCancelled,v=a.delayLeave,f=a.duration,y=!1!==r&&!X,x=Cr(u),k=b(p(f)?f.leave:f);0;var j=t._leaveCb=O((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[n.key]=null),y&&(fr(t,c),fr(t,d)),j.cancelled?(y&&fr(t,l),g&&g(t)):(e(),h&&h(t)),t._leaveCb=null}));v?v(S):S()}function S(){j.cancelled||(!n.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[n.key]=n),m&&m(t),y&&(br(t,l),br(t,d),vr((function(){fr(t,l),j.cancelled||(br(t,c),x||(Ir(k)?setTimeout(j,k):yr(t,s,j)))}))),u&&u(t,j),y||x||j())}}function Ir(n){return"number"==typeof n&&!isNaN(n)}function Cr(n){if(i(n))return!1;var e=n.fns;return o(e)?Cr(Array.isArray(e)?e[0]:e):(n._length||n.length)>1}function Mr(n,e){!0!==e.data.show&&wr(e)}var Er=function(n){var e,t,a={},c=n.modules,p=n.nodeOps;for(e=0;e<ka.length;++e)for(a[ka[e]]=[],t=0;t<c.length;++t)o(c[t][ka[e]])&&a[ka[e]].push(c[t][ka[e]]);function d(n){var e=p.parentNode(n);o(e)&&p.removeChild(e,n)}function m(n,e,t,r,i,l,c){if(o(n.elm)&&o(l)&&(n=l[c]=jn(n)),n.isRootInsert=!i,!function(n,e,t,r){var i=n.data;if(o(i)){var l=o(n.componentInstance)&&i.keepAlive;if(o(i=i.hook)&&o(i=i.init)&&i(n,!1),o(n.componentInstance))return u(n,e),h(t,n.elm,r),s(l)&&function(n,e,t,r){var i,s=n;for(;s.componentInstance;)if(s=s.componentInstance._vnode,o(i=s.data)&&o(i=i.transition)){for(i=0;i<a.activate.length;++i)a.activate[i](xa,s);e.push(s);break}h(t,n.elm,r)}(n,e,t,r),!0}}(n,e,t,r)){var d=n.data,m=n.children,v=n.tag;o(v)?(n.elm=n.ns?p.createElementNS(n.ns,v):p.createElement(v,n),y(n),g(n,m,e),o(d)&&b(n,e),h(t,n.elm,r)):s(n.isComment)?(n.elm=p.createComment(n.text),h(t,n.elm,r)):(n.elm=p.createTextNode(n.text),h(t,n.elm,r))}}function u(n,e){o(n.data.pendingInsert)&&(e.push.apply(e,n.data.pendingInsert),n.data.pendingInsert=null),n.elm=n.componentInstance.$el,v(n)?(b(n,e),y(n)):(fa(n),e.push(n))}function h(n,e,t){o(n)&&(o(t)?p.parentNode(t)===n&&p.insertBefore(n,e,t):p.appendChild(n,e))}function g(n,e,t){if(r(e)){0;for(var a=0;a<e.length;++a)m(e[a],t,n.elm,null,!0,e,a)}else l(n.text)&&p.appendChild(n.elm,p.createTextNode(String(n.text)))}function v(n){for(;n.componentInstance;)n=n.componentInstance._vnode;return o(n.tag)}function b(n,t){for(var r=0;r<a.create.length;++r)a.create[r](xa,n);o(e=n.data.hook)&&(o(e.create)&&e.create(xa,n),o(e.insert)&&t.push(n))}function y(n){var e;if(o(e=n.fnScopeId))p.setStyleScope(n.elm,e);else for(var t=n;t;)o(e=t.context)&&o(e=e.$options._scopeId)&&p.setStyleScope(n.elm,e),t=t.parent;o(e=Me)&&e!==n.context&&e!==n.fnContext&&o(e=e.$options._scopeId)&&p.setStyleScope(n.elm,e)}function x(n,e,t,a,r,i){for(;a<=r;++a)m(t[a],i,n,e,!1,t,a)}function k(n){var e,t,r=n.data;if(o(r))for(o(e=r.hook)&&o(e=e.destroy)&&e(n),e=0;e<a.destroy.length;++e)a.destroy[e](n);if(o(e=n.children))for(t=0;t<n.children.length;++t)k(n.children[t])}function j(n,e,t){for(;e<=t;++e){var a=n[e];o(a)&&(o(a.tag)?(S(a),k(a)):d(a.elm))}}function S(n,e){if(o(e)||o(n.data)){var t,r=a.remove.length+1;for(o(e)?e.listeners+=r:e=function(n,e){function t(){0==--t.listeners&&d(n)}return t.listeners=e,t}(n.elm,r),o(t=n.componentInstance)&&o(t=t._vnode)&&o(t.data)&&S(t,e),t=0;t<a.remove.length;++t)a.remove[t](n,e);o(t=n.data.hook)&&o(t=t.remove)?t(n,e):e()}else d(n.elm)}function w(n,e,t,a){for(var r=t;r<a;r++){var i=e[r];if(o(i)&&ja(n,i))return r}}function T(n,e,t,r,l,c){if(n!==e){o(e.elm)&&o(r)&&(e=r[l]=jn(e));var d=e.elm=n.elm;if(s(n.isAsyncPlaceholder))o(e.asyncFactory.resolved)?M(n.elm,e,t):e.isAsyncPlaceholder=!0;else if(s(e.isStatic)&&s(n.isStatic)&&e.key===n.key&&(s(e.isCloned)||s(e.isOnce)))e.componentInstance=n.componentInstance;else{var u,h=e.data;o(h)&&o(u=h.hook)&&o(u=u.prepatch)&&u(n,e);var g=n.children,b=e.children;if(o(h)&&v(e)){for(u=0;u<a.update.length;++u)a.update[u](n,e);o(u=h.hook)&&o(u=u.update)&&u(n,e)}i(e.text)?o(g)&&o(b)?g!==b&&function(n,e,t,a,r){var s,l,c,d=0,u=0,h=e.length-1,g=e[0],v=e[h],b=t.length-1,f=t[0],y=t[b],k=!r;for(0;d<=h&&u<=b;)i(g)?g=e[++d]:i(v)?v=e[--h]:ja(g,f)?(T(g,f,a,t,u),g=e[++d],f=t[++u]):ja(v,y)?(T(v,y,a,t,b),v=e[--h],y=t[--b]):ja(g,y)?(T(g,y,a,t,b),k&&p.insertBefore(n,g.elm,p.nextSibling(v.elm)),g=e[++d],y=t[--b]):ja(v,f)?(T(v,f,a,t,u),k&&p.insertBefore(n,v.elm,g.elm),v=e[--h],f=t[++u]):(i(s)&&(s=Sa(e,d,h)),i(l=o(f.key)?s[f.key]:w(f,e,d,h))?m(f,a,n,g.elm,!1,t,u):ja(c=e[l],f)?(T(c,f,a,t,u),e[l]=void 0,k&&p.insertBefore(n,c.elm,g.elm)):m(f,a,n,g.elm,!1,t,u),f=t[++u]);d>h?x(n,i(t[b+1])?null:t[b+1].elm,t,u,b,a):u>b&&j(e,d,h)}(d,g,b,t,c):o(b)?(o(n.text)&&p.setTextContent(d,""),x(d,null,b,0,b.length-1,t)):o(g)?j(g,0,g.length-1):o(n.text)&&p.setTextContent(d,""):n.text!==e.text&&p.setTextContent(d,e.text),o(h)&&o(u=h.hook)&&o(u=u.postpatch)&&u(n,e)}}}function I(n,e,t){if(s(t)&&o(n.parent))n.parent.data.pendingInsert=e;else for(var a=0;a<e.length;++a)e[a].data.hook.insert(e[a])}var C=f("attrs,class,staticClass,staticStyle,key");function M(n,e,t,a){var r,i=e.tag,l=e.data,c=e.children;if(a=a||l&&l.pre,e.elm=n,s(e.isComment)&&o(e.asyncFactory))return e.isAsyncPlaceholder=!0,!0;if(o(l)&&(o(r=l.hook)&&o(r=r.init)&&r(e,!0),o(r=e.componentInstance)))return u(e,t),!0;if(o(i)){if(o(c))if(n.hasChildNodes())if(o(r=l)&&o(r=r.domProps)&&o(r=r.innerHTML)){if(r!==n.innerHTML)return!1}else{for(var p=!0,d=n.firstChild,m=0;m<c.length;m++){if(!d||!M(d,c[m],t,a)){p=!1;break}d=d.nextSibling}if(!p||d)return!1}else g(e,c,t);if(o(l)){var h=!1;for(var v in l)if(!C(v)){h=!0,b(e,t);break}!h&&l.class&&zn(l.class)}}else n.data!==e.text&&(n.data=e.text);return!0}return function(n,e,t,r){if(!i(e)){var l,c=!1,d=[];if(i(n))c=!0,m(e,d);else{var u=o(n.nodeType);if(!u&&ja(n,e))T(n,e,d,null,null,r);else{if(u){if(1===n.nodeType&&n.hasAttribute("data-server-rendered")&&(n.removeAttribute("data-server-rendered"),t=!0),s(t)&&M(n,e,d))return I(e,d,!0),n;l=n,n=new yn(p.tagName(l).toLowerCase(),{},[],void 0,l)}var h=n.elm,g=p.parentNode(h);if(m(e,d,h._leaveCb?null:g,p.nextSibling(h)),o(e.parent))for(var b=e.parent,f=v(e);b;){for(var y=0;y<a.destroy.length;++y)a.destroy[y](b);if(b.elm=e.elm,f){for(var x=0;x<a.create.length;++x)a.create[x](xa,b);var S=b.data.hook.insert;if(S.merged)for(var w=1;w<S.fns.length;w++)S.fns[w]()}else fa(b);b=b.parent}o(g)?j([n],0,0):o(n.tag)&&k(n)}}return I(e,d,c),e.elm}o(n)&&k(n)}}({nodeOps:va,modules:[Ja,_a,Ua,Qa,rr,G?{create:Mr,activate:Mr,remove:function(n,e){!0!==n.data.show?Tr(n,e):e()}}:{}].concat(Pa)});X&&document.addEventListener("selectionchange",(function(){var n=document.activeElement;n&&n.vmodel&&_r(n,"input")}));var Pr={inserted:function(n,e,t,a){"select"===t.tag?(a.elm&&!a.elm._vOptions?Ln(t,"postpatch",(function(){Pr.componentUpdated(n,e,t)})):zr(n,e,t.context),n._vOptions=[].map.call(n.options,Jr)):("textarea"===t.tag||ga(n.type))&&(n._vModifiers=e.modifiers,e.modifiers.lazy||(n.addEventListener("compositionstart",Lr),n.addEventListener("compositionend",Rr),n.addEventListener("change",Rr),X&&(n.vmodel=!0)))},componentUpdated:function(n,e,t){if("select"===t.tag){zr(n,e,t.context);var a=n._vOptions,r=n._vOptions=[].map.call(n.options,Jr);if(r.some((function(n,e){return!R(n,a[e])})))(n.multiple?e.value.some((function(n){return qr(n,r)})):e.value!==e.oldValue&&qr(e.value,r))&&_r(n,"change")}}};function zr(n,e,t){Ar(n,e,t),(K||Z)&&setTimeout((function(){Ar(n,e,t)}),0)}function Ar(n,e,t){var a=e.value,r=n.multiple;if(!r||Array.isArray(a)){for(var i,o,s=0,l=n.options.length;s<l;s++)if(o=n.options[s],r)i=_(a,Jr(o))>-1,o.selected!==i&&(o.selected=i);else if(R(Jr(o),a))return void(n.selectedIndex!==s&&(n.selectedIndex=s));r||(n.selectedIndex=-1)}}function qr(n,e){return e.every((function(e){return!R(e,n)}))}function Jr(n){return"_value"in n?n._value:n.value}function Lr(n){n.target.composing=!0}function Rr(n){n.target.composing&&(n.target.composing=!1,_r(n.target,"input"))}function _r(n,e){var t=document.createEvent("HTMLEvents");t.initEvent(e,!0,!0),n.dispatchEvent(t)}function Or(n){return!n.componentInstance||n.data&&n.data.transition?n:Or(n.componentInstance._vnode)}var Br={model:Pr,show:{bind:function(n,e,t){var a=e.value,r=(t=Or(t)).data&&t.data.transition,i=n.__vOriginalDisplay="none"===n.style.display?"":n.style.display;a&&r?(t.data.show=!0,wr(t,(function(){n.style.display=i}))):n.style.display=a?i:"none"},update:function(n,e,t){var a=e.value;!a!=!e.oldValue&&((t=Or(t)).data&&t.data.transition?(t.data.show=!0,a?wr(t,(function(){n.style.display=n.__vOriginalDisplay})):Tr(t,(function(){n.style.display="none"}))):n.style.display=a?n.__vOriginalDisplay:"none")},unbind:function(n,e,t,a,r){r||(n.style.display=n.__vOriginalDisplay)}}},Dr={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function Hr(n){var e=n&&n.componentOptions;return e&&e.Ctor.options.abstract?Hr(Se(e.children)):n}function Fr(n){var e={},t=n.$options;for(var a in t.propsData)e[a]=n[a];var r=t._parentListeners;for(var a in r)e[T(a)]=r[a];return e}function Nr(n,e){if(/\d-keep-alive$/.test(e.tag))return n("keep-alive",{props:e.componentOptions.propsData})}var Ur=function(n){return n.tag||Nn(n)},$r=function(n){return"show"===n.name},Wr={name:"transition",props:Dr,abstract:!0,render:function(n){var e=this,t=this.$slots.default;if(t&&(t=t.filter(Ur)).length){0;var a=this.mode;0;var r=t[0];if(function(n){for(;n=n.parent;)if(n.data.transition)return!0}(this.$vnode))return r;var i=Hr(r);if(!i)return r;if(this._leaving)return Nr(n,r);var o="__transition-".concat(this._uid,"-");i.key=null==i.key?i.isComment?o+"comment":o+i.tag:l(i.key)?0===String(i.key).indexOf(o)?i.key:o+i.key:i.key;var s=(i.data||(i.data={})).transition=Fr(this),c=this._vnode,p=Hr(c);if(i.data.directives&&i.data.directives.some($r)&&(i.data.show=!0),p&&p.data&&!function(n,e){return e.key===n.key&&e.tag===n.tag}(i,p)&&!Nn(p)&&(!p.componentInstance||!p.componentInstance._vnode.isComment)){var d=p.data.transition=z({},s);if("out-in"===a)return this._leaving=!0,Ln(d,"afterLeave",(function(){e._leaving=!1,e.$forceUpdate()})),Nr(n,r);if("in-out"===a){if(Nn(i))return c;var m,u=function(){m()};Ln(s,"afterEnter",u),Ln(s,"enterCancelled",u),Ln(d,"delayLeave",(function(n){m=n}))}}return r}}},Qr=z({tag:String,moveClass:String},Dr);function Gr(n){n.elm._moveCb&&n.elm._moveCb(),n.elm._enterCb&&n.elm._enterCb()}function Vr(n){n.data.newPos=n.elm.getBoundingClientRect()}function Kr(n){var e=n.data.pos,t=n.data.newPos,a=e.left-t.left,r=e.top-t.top;if(a||r){n.data.moved=!0;var i=n.elm.style;i.transform=i.WebkitTransform="translate(".concat(a,"px,").concat(r,"px)"),i.transitionDuration="0s"}}delete Qr.mode;var Xr={Transition:Wr,TransitionGroup:{props:Qr,beforeMount:function(){var n=this,e=this._update;this._update=function(t,a){var r=Ee(n);n.__patch__(n._vnode,n.kept,!1,!0),n._vnode=n.kept,r(),e.call(n,t,a)}},render:function(n){for(var e=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),a=this.prevChildren=this.children,r=this.$slots.default||[],i=this.children=[],o=Fr(this),s=0;s<r.length;s++){if((p=r[s]).tag)if(null!=p.key&&0!==String(p.key).indexOf("__vlist"))i.push(p),t[p.key]=p,(p.data||(p.data={})).transition=o;else;}if(a){var l=[],c=[];for(s=0;s<a.length;s++){var p;(p=a[s]).data.transition=o,p.data.pos=p.elm.getBoundingClientRect(),t[p.key]?l.push(p):c.push(p)}this.kept=n(e,null,l),this.removed=c}return n(e,null,i)},updated:function(){var n=this.prevChildren,e=this.moveClass||(this.name||"v")+"-move";n.length&&this.hasMove(n[0].elm,e)&&(n.forEach(Gr),n.forEach(Vr),n.forEach(Kr),this._reflow=document.body.offsetHeight,n.forEach((function(n){if(n.data.moved){var t=n.elm,a=t.style;br(t,e),a.transform=a.WebkitTransform=a.transitionDuration="",t.addEventListener(mr,t._moveCb=function n(a){a&&a.target!==t||a&&!/transform$/.test(a.propertyName)||(t.removeEventListener(mr,n),t._moveCb=null,fr(t,e))})}})))},methods:{hasMove:function(n,e){if(!pr)return!1;if(this._hasMove)return this._hasMove;var t=n.cloneNode();n._transitionClasses&&n._transitionClasses.forEach((function(n){sr(t,n)})),or(t,e),t.style.display="none",this.$el.appendChild(t);var a=kr(t);return this.$el.removeChild(t),this._hasMove=a.hasTransform}}}};function Zr(n,e){for(var t in e)n[t]=e[t];return n}Nt.config.mustUseProp=function(n,e,t){return"value"===t&&Zt(n)&&"button"!==e||"selected"===t&&"option"===n||"checked"===t&&"input"===n||"muted"===t&&"video"===n},Nt.config.isReservedTag=ua,Nt.config.isReservedAttr=Xt,Nt.config.getTagNamespace=function(n){return ma(n)?"svg":"math"===n?"math":void 0},Nt.config.isUnknownElement=function(n){if(!G)return!0;if(ua(n))return!1;if(n=n.toLowerCase(),null!=ha[n])return ha[n];var e=document.createElement(n);return n.indexOf("-")>-1?ha[n]=e.constructor===window.HTMLUnknownElement||e.constructor===window.HTMLElement:ha[n]=/HTMLUnknownElement/.test(e.toString())},z(Nt.options.directives,Br),z(Nt.options.components,Xr),Nt.prototype.__patch__=G?Er:q,Nt.prototype.$mount=function(n,e){return function(n,e,t){var a;n.$el=e,n.$options.render||(n.$options.render=xn),Ae(n,"beforeMount"),a=function(){n._update(n._render(),t)},new Qe(n,a,q,{before:function(){n._isMounted&&!n._isDestroyed&&Ae(n,"beforeUpdate")}},!0),t=!1;var r=n._preWatchers;if(r)for(var i=0;i<r.length;i++)r[i].run();return null==n.$vnode&&(n._isMounted=!0,Ae(n,"mounted")),n}(this,n=n&&G?function(n){if("string"==typeof n){var e=document.querySelector(n);return e||document.createElement("div")}return n}(n):void 0,e)},G&&setTimeout((function(){F.devtools&&sn&&sn.emit("init",Nt)}),0);var Yr=/[!'()*]/g,ni=function(n){return"%"+n.charCodeAt(0).toString(16)},ei=/%2C/g,ti=function(n){return encodeURIComponent(n).replace(Yr,ni).replace(ei,",")};function ai(n){try{return decodeURIComponent(n)}catch(n){0}return n}var ri=function(n){return null==n||"object"==typeof n?n:String(n)};function ii(n){var e={};return(n=n.trim().replace(/^(\?|#|&)/,""))?(n.split("&").forEach((function(n){var t=n.replace(/\+/g," ").split("="),a=ai(t.shift()),r=t.length>0?ai(t.join("=")):null;void 0===e[a]?e[a]=r:Array.isArray(e[a])?e[a].push(r):e[a]=[e[a],r]})),e):e}function oi(n){var e=n?Object.keys(n).map((function(e){var t=n[e];if(void 0===t)return"";if(null===t)return ti(e);if(Array.isArray(t)){var a=[];return t.forEach((function(n){void 0!==n&&(null===n?a.push(ti(e)):a.push(ti(e)+"="+ti(n)))})),a.join("&")}return ti(e)+"="+ti(t)})).filter((function(n){return n.length>0})).join("&"):null;return e?"?"+e:""}var si=/\/?$/;function li(n,e,t,a){var r=a&&a.options.stringifyQuery,i=e.query||{};try{i=ci(i)}catch(n){}var o={name:e.name||n&&n.name,meta:n&&n.meta||{},path:e.path||"/",hash:e.hash||"",query:i,params:e.params||{},fullPath:mi(e,r),matched:n?di(n):[]};return t&&(o.redirectedFrom=mi(t,r)),Object.freeze(o)}function ci(n){if(Array.isArray(n))return n.map(ci);if(n&&"object"==typeof n){var e={};for(var t in n)e[t]=ci(n[t]);return e}return n}var pi=li(null,{path:"/"});function di(n){for(var e=[];n;)e.unshift(n),n=n.parent;return e}function mi(n,e){var t=n.path,a=n.query;void 0===a&&(a={});var r=n.hash;return void 0===r&&(r=""),(t||"/")+(e||oi)(a)+r}function ui(n,e,t){return e===pi?n===e:!!e&&(n.path&&e.path?n.path.replace(si,"")===e.path.replace(si,"")&&(t||n.hash===e.hash&&hi(n.query,e.query)):!(!n.name||!e.name)&&(n.name===e.name&&(t||n.hash===e.hash&&hi(n.query,e.query)&&hi(n.params,e.params))))}function hi(n,e){if(void 0===n&&(n={}),void 0===e&&(e={}),!n||!e)return n===e;var t=Object.keys(n).sort(),a=Object.keys(e).sort();return t.length===a.length&&t.every((function(t,r){var i=n[t];if(a[r]!==t)return!1;var o=e[t];return null==i||null==o?i===o:"object"==typeof i&&"object"==typeof o?hi(i,o):String(i)===String(o)}))}function gi(n){for(var e=0;e<n.matched.length;e++){var t=n.matched[e];for(var a in t.instances){var r=t.instances[a],i=t.enteredCbs[a];if(r&&i){delete t.enteredCbs[a];for(var o=0;o<i.length;o++)r._isBeingDestroyed||i[o](r)}}}}var vi={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(n,e){var t=e.props,a=e.children,r=e.parent,i=e.data;i.routerView=!0;for(var o=r.$createElement,s=t.name,l=r.$route,c=r._routerViewCache||(r._routerViewCache={}),p=0,d=!1;r&&r._routerRoot!==r;){var m=r.$vnode?r.$vnode.data:{};m.routerView&&p++,m.keepAlive&&r._directInactive&&r._inactive&&(d=!0),r=r.$parent}if(i.routerViewDepth=p,d){var u=c[s],h=u&&u.component;return h?(u.configProps&&bi(h,i,u.route,u.configProps),o(h,i,a)):o()}var g=l.matched[p],v=g&&g.components[s];if(!g||!v)return c[s]=null,o();c[s]={component:v},i.registerRouteInstance=function(n,e){var t=g.instances[s];(e&&t!==n||!e&&t===n)&&(g.instances[s]=e)},(i.hook||(i.hook={})).prepatch=function(n,e){g.instances[s]=e.componentInstance},i.hook.init=function(n){n.data.keepAlive&&n.componentInstance&&n.componentInstance!==g.instances[s]&&(g.instances[s]=n.componentInstance),gi(l)};var b=g.props&&g.props[s];return b&&(Zr(c[s],{route:l,configProps:b}),bi(v,i,l,b)),o(v,i,a)}};function bi(n,e,t,a){var r=e.props=function(n,e){switch(typeof e){case"undefined":return;case"object":return e;case"function":return e(n);case"boolean":return e?n.params:void 0;default:0}}(t,a);if(r){r=e.props=Zr({},r);var i=e.attrs=e.attrs||{};for(var o in r)n.props&&o in n.props||(i[o]=r[o],delete r[o])}}function fi(n,e,t){var a=n.charAt(0);if("/"===a)return n;if("?"===a||"#"===a)return e+n;var r=e.split("/");t&&r[r.length-1]||r.pop();for(var i=n.replace(/^\//,"").split("/"),o=0;o<i.length;o++){var s=i[o];".."===s?r.pop():"."!==s&&r.push(s)}return""!==r[0]&&r.unshift(""),r.join("/")}function yi(n){return n.replace(/\/(?:\s*\/)+/g,"/")}var xi=Array.isArray||function(n){return"[object Array]"==Object.prototype.toString.call(n)},ki=Li,ji=Ci,Si=function(n,e){return Ei(Ci(n,e),e)},wi=Ei,Ti=Ji,Ii=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function Ci(n,e){for(var t,a=[],r=0,i=0,o="",s=e&&e.delimiter||"/";null!=(t=Ii.exec(n));){var l=t[0],c=t[1],p=t.index;if(o+=n.slice(i,p),i=p+l.length,c)o+=c[1];else{var d=n[i],m=t[2],u=t[3],h=t[4],g=t[5],v=t[6],b=t[7];o&&(a.push(o),o="");var f=null!=m&&null!=d&&d!==m,y="+"===v||"*"===v,x="?"===v||"*"===v,k=t[2]||s,j=h||g;a.push({name:u||r++,prefix:m||"",delimiter:k,optional:x,repeat:y,partial:f,asterisk:!!b,pattern:j?zi(j):b?".*":"[^"+Pi(k)+"]+?"})}}return i<n.length&&(o+=n.substr(i)),o&&a.push(o),a}function Mi(n){return encodeURI(n).replace(/[\/?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()}))}function Ei(n,e){for(var t=new Array(n.length),a=0;a<n.length;a++)"object"==typeof n[a]&&(t[a]=new RegExp("^(?:"+n[a].pattern+")$",qi(e)));return function(e,a){for(var r="",i=e||{},o=(a||{}).pretty?Mi:encodeURIComponent,s=0;s<n.length;s++){var l=n[s];if("string"!=typeof l){var c,p=i[l.name];if(null==p){if(l.optional){l.partial&&(r+=l.prefix);continue}throw new TypeError('Expected "'+l.name+'" to be defined')}if(xi(p)){if(!l.repeat)throw new TypeError('Expected "'+l.name+'" to not repeat, but received `'+JSON.stringify(p)+"`");if(0===p.length){if(l.optional)continue;throw new TypeError('Expected "'+l.name+'" to not be empty')}for(var d=0;d<p.length;d++){if(c=o(p[d]),!t[s].test(c))throw new TypeError('Expected all "'+l.name+'" to match "'+l.pattern+'", but received `'+JSON.stringify(c)+"`");r+=(0===d?l.prefix:l.delimiter)+c}}else{if(c=l.asterisk?encodeURI(p).replace(/[?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()})):o(p),!t[s].test(c))throw new TypeError('Expected "'+l.name+'" to match "'+l.pattern+'", but received "'+c+'"');r+=l.prefix+c}}else r+=l}return r}}function Pi(n){return n.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function zi(n){return n.replace(/([=!:$\/()])/g,"\\$1")}function Ai(n,e){return n.keys=e,n}function qi(n){return n&&n.sensitive?"":"i"}function Ji(n,e,t){xi(e)||(t=e||t,e=[]);for(var a=(t=t||{}).strict,r=!1!==t.end,i="",o=0;o<n.length;o++){var s=n[o];if("string"==typeof s)i+=Pi(s);else{var l=Pi(s.prefix),c="(?:"+s.pattern+")";e.push(s),s.repeat&&(c+="(?:"+l+c+")*"),i+=c=s.optional?s.partial?l+"("+c+")?":"(?:"+l+"("+c+"))?":l+"("+c+")"}}var p=Pi(t.delimiter||"/"),d=i.slice(-p.length)===p;return a||(i=(d?i.slice(0,-p.length):i)+"(?:"+p+"(?=$))?"),i+=r?"$":a&&d?"":"(?="+p+"|$)",Ai(new RegExp("^"+i,qi(t)),e)}function Li(n,e,t){return xi(e)||(t=e||t,e=[]),t=t||{},n instanceof RegExp?function(n,e){var t=n.source.match(/\((?!\?)/g);if(t)for(var a=0;a<t.length;a++)e.push({name:a,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return Ai(n,e)}(n,e):xi(n)?function(n,e,t){for(var a=[],r=0;r<n.length;r++)a.push(Li(n[r],e,t).source);return Ai(new RegExp("(?:"+a.join("|")+")",qi(t)),e)}(n,e,t):function(n,e,t){return Ji(Ci(n,t),e,t)}(n,e,t)}ki.parse=ji,ki.compile=Si,ki.tokensToFunction=wi,ki.tokensToRegExp=Ti;var Ri=Object.create(null);function _i(n,e,t){e=e||{};try{var a=Ri[n]||(Ri[n]=ki.compile(n));return"string"==typeof e.pathMatch&&(e[0]=e.pathMatch),a(e,{pretty:!0})}catch(n){return""}finally{delete e[0]}}function Oi(n,e,t,a){var r="string"==typeof n?{path:n}:n;if(r._normalized)return r;if(r.name){var i=(r=Zr({},n)).params;return i&&"object"==typeof i&&(r.params=Zr({},i)),r}if(!r.path&&r.params&&e){(r=Zr({},r))._normalized=!0;var o=Zr(Zr({},e.params),r.params);if(e.name)r.name=e.name,r.params=o;else if(e.matched.length){var s=e.matched[e.matched.length-1].path;r.path=_i(s,o,e.path)}else 0;return r}var l=function(n){var e="",t="",a=n.indexOf("#");a>=0&&(e=n.slice(a),n=n.slice(0,a));var r=n.indexOf("?");return r>=0&&(t=n.slice(r+1),n=n.slice(0,r)),{path:n,query:t,hash:e}}(r.path||""),c=e&&e.path||"/",p=l.path?fi(l.path,c,t||r.append):c,d=function(n,e,t){void 0===e&&(e={});var a,r=t||ii;try{a=r(n||"")}catch(n){a={}}for(var i in e){var o=e[i];a[i]=Array.isArray(o)?o.map(ri):ri(o)}return a}(l.query,r.query,a&&a.options.parseQuery),m=r.hash||l.hash;return m&&"#"!==m.charAt(0)&&(m="#"+m),{_normalized:!0,path:p,query:d,hash:m}}var Bi,Di=function(){},Hi={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(n){var e=this,t=this.$router,a=this.$route,r=t.resolve(this.to,a,this.append),i=r.location,o=r.route,s=r.href,l={},c=t.options.linkActiveClass,p=t.options.linkExactActiveClass,d=null==c?"router-link-active":c,m=null==p?"router-link-exact-active":p,u=null==this.activeClass?d:this.activeClass,h=null==this.exactActiveClass?m:this.exactActiveClass,g=o.redirectedFrom?li(null,Oi(o.redirectedFrom),null,t):o;l[h]=ui(a,g,this.exactPath),l[u]=this.exact||this.exactPath?l[h]:function(n,e){return 0===n.path.replace(si,"/").indexOf(e.path.replace(si,"/"))&&(!e.hash||n.hash===e.hash)&&function(n,e){for(var t in e)if(!(t in n))return!1;return!0}(n.query,e.query)}(a,g);var v=l[h]?this.ariaCurrentValue:null,b=function(n){Fi(n)&&(e.replace?t.replace(i,Di):t.push(i,Di))},f={click:Fi};Array.isArray(this.event)?this.event.forEach((function(n){f[n]=b})):f[this.event]=b;var y={class:l},x=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:s,route:o,navigate:b,isActive:l[u],isExactActive:l[h]});if(x){if(1===x.length)return x[0];if(x.length>1||!x.length)return 0===x.length?n():n("span",{},x)}if("a"===this.tag)y.on=f,y.attrs={href:s,"aria-current":v};else{var k=function n(e){var t;if(e)for(var a=0;a<e.length;a++){if("a"===(t=e[a]).tag)return t;if(t.children&&(t=n(t.children)))return t}}(this.$slots.default);if(k){k.isStatic=!1;var j=k.data=Zr({},k.data);for(var S in j.on=j.on||{},j.on){var w=j.on[S];S in f&&(j.on[S]=Array.isArray(w)?w:[w])}for(var T in f)T in j.on?j.on[T].push(f[T]):j.on[T]=b;var I=k.data.attrs=Zr({},k.data.attrs);I.href=s,I["aria-current"]=v}else y.on=f}return n(this.tag,y,this.$slots.default)}};function Fi(n){if(!(n.metaKey||n.altKey||n.ctrlKey||n.shiftKey||n.defaultPrevented||void 0!==n.button&&0!==n.button)){if(n.currentTarget&&n.currentTarget.getAttribute){var e=n.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(e))return}return n.preventDefault&&n.preventDefault(),!0}}var Ni="undefined"!=typeof window;function Ui(n,e,t,a,r){var i=e||[],o=t||Object.create(null),s=a||Object.create(null);n.forEach((function(n){!function n(e,t,a,r,i,o){var s=r.path,l=r.name;0;var c=r.pathToRegexpOptions||{},p=function(n,e,t){t||(n=n.replace(/\/$/,""));if("/"===n[0])return n;if(null==e)return n;return yi(e.path+"/"+n)}(s,i,c.strict);"boolean"==typeof r.caseSensitive&&(c.sensitive=r.caseSensitive);var d={path:p,regex:$i(p,c),components:r.components||{default:r.component},alias:r.alias?"string"==typeof r.alias?[r.alias]:r.alias:[],instances:{},enteredCbs:{},name:l,parent:i,matchAs:o,redirect:r.redirect,beforeEnter:r.beforeEnter,meta:r.meta||{},props:null==r.props?{}:r.components?r.props:{default:r.props}};r.children&&r.children.forEach((function(r){var i=o?yi(o+"/"+r.path):void 0;n(e,t,a,r,d,i)}));t[d.path]||(e.push(d.path),t[d.path]=d);if(void 0!==r.alias)for(var m=Array.isArray(r.alias)?r.alias:[r.alias],u=0;u<m.length;++u){0;var h={path:m[u],children:r.children};n(e,t,a,h,i,d.path||"/")}l&&(a[l]||(a[l]=d))}(i,o,s,n,r)}));for(var l=0,c=i.length;l<c;l++)"*"===i[l]&&(i.push(i.splice(l,1)[0]),c--,l--);return{pathList:i,pathMap:o,nameMap:s}}function $i(n,e){return ki(n,[],e)}function Wi(n,e){var t=Ui(n),a=t.pathList,r=t.pathMap,i=t.nameMap;function o(n,t,o){var s=Oi(n,t,!1,e),c=s.name;if(c){var p=i[c];if(!p)return l(null,s);var d=p.regex.keys.filter((function(n){return!n.optional})).map((function(n){return n.name}));if("object"!=typeof s.params&&(s.params={}),t&&"object"==typeof t.params)for(var m in t.params)!(m in s.params)&&d.indexOf(m)>-1&&(s.params[m]=t.params[m]);return s.path=_i(p.path,s.params),l(p,s,o)}if(s.path){s.params={};for(var u=0;u<a.length;u++){var h=a[u],g=r[h];if(Qi(g.regex,s.path,s.params))return l(g,s,o)}}return l(null,s)}function s(n,t){var a=n.redirect,r="function"==typeof a?a(li(n,t,null,e)):a;if("string"==typeof r&&(r={path:r}),!r||"object"!=typeof r)return l(null,t);var s=r,c=s.name,p=s.path,d=t.query,m=t.hash,u=t.params;if(d=s.hasOwnProperty("query")?s.query:d,m=s.hasOwnProperty("hash")?s.hash:m,u=s.hasOwnProperty("params")?s.params:u,c){i[c];return o({_normalized:!0,name:c,query:d,hash:m,params:u},void 0,t)}if(p){var h=function(n,e){return fi(n,e.parent?e.parent.path:"/",!0)}(p,n);return o({_normalized:!0,path:_i(h,u),query:d,hash:m},void 0,t)}return l(null,t)}function l(n,t,a){return n&&n.redirect?s(n,a||t):n&&n.matchAs?function(n,e,t){var a=o({_normalized:!0,path:_i(t,e.params)});if(a){var r=a.matched,i=r[r.length-1];return e.params=a.params,l(i,e)}return l(null,e)}(0,t,n.matchAs):li(n,t,a,e)}return{match:o,addRoute:function(n,e){var t="object"!=typeof n?i[n]:void 0;Ui([e||n],a,r,i,t),t&&t.alias.length&&Ui(t.alias.map((function(n){return{path:n,children:[e]}})),a,r,i,t)},getRoutes:function(){return a.map((function(n){return r[n]}))},addRoutes:function(n){Ui(n,a,r,i)}}}function Qi(n,e,t){var a=e.match(n);if(!a)return!1;if(!t)return!0;for(var r=1,i=a.length;r<i;++r){var o=n.keys[r-1];o&&(t[o.name||"pathMatch"]="string"==typeof a[r]?ai(a[r]):a[r])}return!0}var Gi=Ni&&window.performance&&window.performance.now?window.performance:Date;function Vi(){return Gi.now().toFixed(3)}var Ki=Vi();function Xi(){return Ki}function Zi(n){return Ki=n}var Yi=Object.create(null);function no(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var n=window.location.protocol+"//"+window.location.host,e=window.location.href.replace(n,""),t=Zr({},window.history.state);return t.key=Xi(),window.history.replaceState(t,"",e),window.addEventListener("popstate",ao),function(){window.removeEventListener("popstate",ao)}}function eo(n,e,t,a){if(n.app){var r=n.options.scrollBehavior;r&&n.app.$nextTick((function(){var i=function(){var n=Xi();if(n)return Yi[n]}(),o=r.call(n,e,t,a?i:null);o&&("function"==typeof o.then?o.then((function(n){lo(n,i)})).catch((function(n){0})):lo(o,i))}))}}function to(){var n=Xi();n&&(Yi[n]={x:window.pageXOffset,y:window.pageYOffset})}function ao(n){to(),n.state&&n.state.key&&Zi(n.state.key)}function ro(n){return oo(n.x)||oo(n.y)}function io(n){return{x:oo(n.x)?n.x:window.pageXOffset,y:oo(n.y)?n.y:window.pageYOffset}}function oo(n){return"number"==typeof n}var so=/^#\d/;function lo(n,e){var t,a="object"==typeof n;if(a&&"string"==typeof n.selector){var r=so.test(n.selector)?document.getElementById(n.selector.slice(1)):document.querySelector(n.selector);if(r){var i=n.offset&&"object"==typeof n.offset?n.offset:{};e=function(n,e){var t=document.documentElement.getBoundingClientRect(),a=n.getBoundingClientRect();return{x:a.left-t.left-e.x,y:a.top-t.top-e.y}}(r,i={x:oo((t=i).x)?t.x:0,y:oo(t.y)?t.y:0})}else ro(n)&&(e=io(n))}else a&&ro(n)&&(e=io(n));e&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:e.x,top:e.y,behavior:n.behavior}):window.scrollTo(e.x,e.y))}var co,po=Ni&&((-1===(co=window.navigator.userAgent).indexOf("Android 2.")&&-1===co.indexOf("Android 4.0")||-1===co.indexOf("Mobile Safari")||-1!==co.indexOf("Chrome")||-1!==co.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function mo(n,e){to();var t=window.history;try{if(e){var a=Zr({},t.state);a.key=Xi(),t.replaceState(a,"",n)}else t.pushState({key:Zi(Vi())},"",n)}catch(t){window.location[e?"replace":"assign"](n)}}function uo(n){mo(n,!0)}function ho(n,e,t){var a=function(r){r>=n.length?t():n[r]?e(n[r],(function(){a(r+1)})):a(r+1)};a(0)}var go={redirected:2,aborted:4,cancelled:8,duplicated:16};function vo(n,e){return fo(n,e,go.redirected,'Redirected when going from "'+n.fullPath+'" to "'+function(n){if("string"==typeof n)return n;if("path"in n)return n.path;var e={};return yo.forEach((function(t){t in n&&(e[t]=n[t])})),JSON.stringify(e,null,2)}(e)+'" via a navigation guard.')}function bo(n,e){return fo(n,e,go.cancelled,'Navigation cancelled from "'+n.fullPath+'" to "'+e.fullPath+'" with a new navigation.')}function fo(n,e,t,a){var r=new Error(a);return r._isRouter=!0,r.from=n,r.to=e,r.type=t,r}var yo=["params","query","hash"];function xo(n){return Object.prototype.toString.call(n).indexOf("Error")>-1}function ko(n,e){return xo(n)&&n._isRouter&&(null==e||n.type===e)}function jo(n){return function(e,t,a){var r=!1,i=0,o=null;So(n,(function(n,e,t,s){if("function"==typeof n&&void 0===n.cid){r=!0,i++;var l,c=Io((function(e){var r;((r=e).__esModule||To&&"Module"===r[Symbol.toStringTag])&&(e=e.default),n.resolved="function"==typeof e?e:Bi.extend(e),t.components[s]=e,--i<=0&&a()})),p=Io((function(n){var e="Failed to resolve async component "+s+": "+n;o||(o=xo(n)?n:new Error(e),a(o))}));try{l=n(c,p)}catch(n){p(n)}if(l)if("function"==typeof l.then)l.then(c,p);else{var d=l.component;d&&"function"==typeof d.then&&d.then(c,p)}}})),r||a()}}function So(n,e){return wo(n.map((function(n){return Object.keys(n.components).map((function(t){return e(n.components[t],n.instances[t],n,t)}))})))}function wo(n){return Array.prototype.concat.apply([],n)}var To="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Io(n){var e=!1;return function(){for(var t=[],a=arguments.length;a--;)t[a]=arguments[a];if(!e)return e=!0,n.apply(this,t)}}var Co=function(n,e){this.router=n,this.base=function(n){if(!n)if(Ni){var e=document.querySelector("base");n=(n=e&&e.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else n="/";"/"!==n.charAt(0)&&(n="/"+n);return n.replace(/\/$/,"")}(e),this.current=pi,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Mo(n,e,t,a){var r=So(n,(function(n,a,r,i){var o=function(n,e){"function"!=typeof n&&(n=Bi.extend(n));return n.options[e]}(n,e);if(o)return Array.isArray(o)?o.map((function(n){return t(n,a,r,i)})):t(o,a,r,i)}));return wo(a?r.reverse():r)}function Eo(n,e){if(e)return function(){return n.apply(e,arguments)}}Co.prototype.listen=function(n){this.cb=n},Co.prototype.onReady=function(n,e){this.ready?n():(this.readyCbs.push(n),e&&this.readyErrorCbs.push(e))},Co.prototype.onError=function(n){this.errorCbs.push(n)},Co.prototype.transitionTo=function(n,e,t){var a,r=this;try{a=this.router.match(n,this.current)}catch(n){throw this.errorCbs.forEach((function(e){e(n)})),n}var i=this.current;this.confirmTransition(a,(function(){r.updateRoute(a),e&&e(a),r.ensureURL(),r.router.afterHooks.forEach((function(n){n&&n(a,i)})),r.ready||(r.ready=!0,r.readyCbs.forEach((function(n){n(a)})))}),(function(n){t&&t(n),n&&!r.ready&&(ko(n,go.redirected)&&i===pi||(r.ready=!0,r.readyErrorCbs.forEach((function(e){e(n)}))))}))},Co.prototype.confirmTransition=function(n,e,t){var a=this,r=this.current;this.pending=n;var i,o,s=function(n){!ko(n)&&xo(n)&&(a.errorCbs.length?a.errorCbs.forEach((function(e){e(n)})):console.error(n)),t&&t(n)},l=n.matched.length-1,c=r.matched.length-1;if(ui(n,r)&&l===c&&n.matched[l]===r.matched[c])return this.ensureURL(),n.hash&&eo(this.router,r,n,!1),s(((o=fo(i=r,n,go.duplicated,'Avoided redundant navigation to current location: "'+i.fullPath+'".')).name="NavigationDuplicated",o));var p=function(n,e){var t,a=Math.max(n.length,e.length);for(t=0;t<a&&n[t]===e[t];t++);return{updated:e.slice(0,t),activated:e.slice(t),deactivated:n.slice(t)}}(this.current.matched,n.matched),d=p.updated,m=p.deactivated,u=p.activated,h=[].concat(function(n){return Mo(n,"beforeRouteLeave",Eo,!0)}(m),this.router.beforeHooks,function(n){return Mo(n,"beforeRouteUpdate",Eo)}(d),u.map((function(n){return n.beforeEnter})),jo(u)),g=function(e,t){if(a.pending!==n)return s(bo(r,n));try{e(n,r,(function(e){!1===e?(a.ensureURL(!0),s(function(n,e){return fo(n,e,go.aborted,'Navigation aborted from "'+n.fullPath+'" to "'+e.fullPath+'" via a navigation guard.')}(r,n))):xo(e)?(a.ensureURL(!0),s(e)):"string"==typeof e||"object"==typeof e&&("string"==typeof e.path||"string"==typeof e.name)?(s(vo(r,n)),"object"==typeof e&&e.replace?a.replace(e):a.push(e)):t(e)}))}catch(n){s(n)}};ho(h,g,(function(){ho(function(n){return Mo(n,"beforeRouteEnter",(function(n,e,t,a){return function(n,e,t){return function(a,r,i){return n(a,r,(function(n){"function"==typeof n&&(e.enteredCbs[t]||(e.enteredCbs[t]=[]),e.enteredCbs[t].push(n)),i(n)}))}}(n,t,a)}))}(u).concat(a.router.resolveHooks),g,(function(){if(a.pending!==n)return s(bo(r,n));a.pending=null,e(n),a.router.app&&a.router.app.$nextTick((function(){gi(n)}))}))}))},Co.prototype.updateRoute=function(n){this.current=n,this.cb&&this.cb(n)},Co.prototype.setupListeners=function(){},Co.prototype.teardown=function(){this.listeners.forEach((function(n){n()})),this.listeners=[],this.current=pi,this.pending=null};var Po=function(n){function e(e,t){n.call(this,e,t),this._startLocation=zo(this.base)}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router,t=e.options.scrollBehavior,a=po&&t;a&&this.listeners.push(no());var r=function(){var t=n.current,r=zo(n.base);n.current===pi&&r===n._startLocation||n.transitionTo(r,(function(n){a&&eo(e,n,t,!0)}))};window.addEventListener("popstate",r),this.listeners.push((function(){window.removeEventListener("popstate",r)}))}},e.prototype.go=function(n){window.history.go(n)},e.prototype.push=function(n,e,t){var a=this,r=this.current;this.transitionTo(n,(function(n){mo(yi(a.base+n.fullPath)),eo(a.router,n,r,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var a=this,r=this.current;this.transitionTo(n,(function(n){uo(yi(a.base+n.fullPath)),eo(a.router,n,r,!1),e&&e(n)}),t)},e.prototype.ensureURL=function(n){if(zo(this.base)!==this.current.fullPath){var e=yi(this.base+this.current.fullPath);n?mo(e):uo(e)}},e.prototype.getCurrentLocation=function(){return zo(this.base)},e}(Co);function zo(n){var e=window.location.pathname,t=e.toLowerCase(),a=n.toLowerCase();return!n||t!==a&&0!==t.indexOf(yi(a+"/"))||(e=e.slice(n.length)),(e||"/")+window.location.search+window.location.hash}var Ao=function(n){function e(e,t,a){n.call(this,e,t),a&&function(n){var e=zo(n);if(!/^\/#/.test(e))return window.location.replace(yi(n+"/#"+e)),!0}(this.base)||qo()}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router.options.scrollBehavior,t=po&&e;t&&this.listeners.push(no());var a=function(){var e=n.current;qo()&&n.transitionTo(Jo(),(function(a){t&&eo(n.router,a,e,!0),po||_o(a.fullPath)}))},r=po?"popstate":"hashchange";window.addEventListener(r,a),this.listeners.push((function(){window.removeEventListener(r,a)}))}},e.prototype.push=function(n,e,t){var a=this,r=this.current;this.transitionTo(n,(function(n){Ro(n.fullPath),eo(a.router,n,r,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var a=this,r=this.current;this.transitionTo(n,(function(n){_o(n.fullPath),eo(a.router,n,r,!1),e&&e(n)}),t)},e.prototype.go=function(n){window.history.go(n)},e.prototype.ensureURL=function(n){var e=this.current.fullPath;Jo()!==e&&(n?Ro(e):_o(e))},e.prototype.getCurrentLocation=function(){return Jo()},e}(Co);function qo(){var n=Jo();return"/"===n.charAt(0)||(_o("/"+n),!1)}function Jo(){var n=window.location.href,e=n.indexOf("#");return e<0?"":n=n.slice(e+1)}function Lo(n){var e=window.location.href,t=e.indexOf("#");return(t>=0?e.slice(0,t):e)+"#"+n}function Ro(n){po?mo(Lo(n)):window.location.hash=n}function _o(n){po?uo(Lo(n)):window.location.replace(Lo(n))}var Oo=function(n){function e(e,t){n.call(this,e,t),this.stack=[],this.index=-1}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.push=function(n,e,t){var a=this;this.transitionTo(n,(function(n){a.stack=a.stack.slice(0,a.index+1).concat(n),a.index++,e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var a=this;this.transitionTo(n,(function(n){a.stack=a.stack.slice(0,a.index).concat(n),e&&e(n)}),t)},e.prototype.go=function(n){var e=this,t=this.index+n;if(!(t<0||t>=this.stack.length)){var a=this.stack[t];this.confirmTransition(a,(function(){var n=e.current;e.index=t,e.updateRoute(a),e.router.afterHooks.forEach((function(e){e&&e(a,n)}))}),(function(n){ko(n,go.duplicated)&&(e.index=t)}))}},e.prototype.getCurrentLocation=function(){var n=this.stack[this.stack.length-1];return n?n.fullPath:"/"},e.prototype.ensureURL=function(){},e}(Co),Bo=function(n){void 0===n&&(n={}),this.app=null,this.apps=[],this.options=n,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Wi(n.routes||[],this);var e=n.mode||"hash";switch(this.fallback="history"===e&&!po&&!1!==n.fallback,this.fallback&&(e="hash"),Ni||(e="abstract"),this.mode=e,e){case"history":this.history=new Po(this,n.base);break;case"hash":this.history=new Ao(this,n.base,this.fallback);break;case"abstract":this.history=new Oo(this,n.base);break;default:0}},Do={currentRoute:{configurable:!0}};function Ho(n,e){return n.push(e),function(){var t=n.indexOf(e);t>-1&&n.splice(t,1)}}Bo.prototype.match=function(n,e,t){return this.matcher.match(n,e,t)},Do.currentRoute.get=function(){return this.history&&this.history.current},Bo.prototype.init=function(n){var e=this;if(this.apps.push(n),n.$once("hook:destroyed",(function(){var t=e.apps.indexOf(n);t>-1&&e.apps.splice(t,1),e.app===n&&(e.app=e.apps[0]||null),e.app||e.history.teardown()})),!this.app){this.app=n;var t=this.history;if(t instanceof Po||t instanceof Ao){var a=function(n){t.setupListeners(),function(n){var a=t.current,r=e.options.scrollBehavior;po&&r&&"fullPath"in n&&eo(e,n,a,!1)}(n)};t.transitionTo(t.getCurrentLocation(),a,a)}t.listen((function(n){e.apps.forEach((function(e){e._route=n}))}))}},Bo.prototype.beforeEach=function(n){return Ho(this.beforeHooks,n)},Bo.prototype.beforeResolve=function(n){return Ho(this.resolveHooks,n)},Bo.prototype.afterEach=function(n){return Ho(this.afterHooks,n)},Bo.prototype.onReady=function(n,e){this.history.onReady(n,e)},Bo.prototype.onError=function(n){this.history.onError(n)},Bo.prototype.push=function(n,e,t){var a=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){a.history.push(n,e,t)}));this.history.push(n,e,t)},Bo.prototype.replace=function(n,e,t){var a=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){a.history.replace(n,e,t)}));this.history.replace(n,e,t)},Bo.prototype.go=function(n){this.history.go(n)},Bo.prototype.back=function(){this.go(-1)},Bo.prototype.forward=function(){this.go(1)},Bo.prototype.getMatchedComponents=function(n){var e=n?n.matched?n:this.resolve(n).route:this.currentRoute;return e?[].concat.apply([],e.matched.map((function(n){return Object.keys(n.components).map((function(e){return n.components[e]}))}))):[]},Bo.prototype.resolve=function(n,e,t){var a=Oi(n,e=e||this.history.current,t,this),r=this.match(a,e),i=r.redirectedFrom||r.fullPath;return{location:a,route:r,href:function(n,e,t){var a="hash"===t?"#"+e:e;return n?yi(n+"/"+a):a}(this.history.base,i,this.mode),normalizedTo:a,resolved:r}},Bo.prototype.getRoutes=function(){return this.matcher.getRoutes()},Bo.prototype.addRoute=function(n,e){this.matcher.addRoute(n,e),this.history.current!==pi&&this.history.transitionTo(this.history.getCurrentLocation())},Bo.prototype.addRoutes=function(n){this.matcher.addRoutes(n),this.history.current!==pi&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(Bo.prototype,Do),Bo.install=function n(e){if(!n.installed||Bi!==e){n.installed=!0,Bi=e;var t=function(n){return void 0!==n},a=function(n,e){var a=n.$options._parentVnode;t(a)&&t(a=a.data)&&t(a=a.registerRouteInstance)&&a(n,e)};e.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),e.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,a(this,this)},destroyed:function(){a(this)}}),Object.defineProperty(e.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(e.prototype,"$route",{get:function(){return this._routerRoot._route}}),e.component("RouterView",vi),e.component("RouterLink",Hi);var r=e.config.optionMergeStrategies;r.beforeRouteEnter=r.beforeRouteLeave=r.beforeRouteUpdate=r.created}},Bo.version="3.5.4",Bo.isNavigationFailure=ko,Bo.NavigationFailureType=go,Bo.START_LOCATION=pi,Ni&&window.Vue&&window.Vue.use(Bo);var Fo=Bo;t(101);t(124);var No={NotFound:()=>Promise.all([t.e(0),t.e(4)]).then(t.bind(null,320)),Layout:()=>Promise.all([t.e(0),t.e(2)]).then(t.bind(null,319))},Uo={"v-4b99dd20":()=>t.e(5).then(t.bind(null,322)),"v-27772cc0":()=>t.e(6).then(t.bind(null,323)),"v-576f0972":()=>t.e(7).then(t.bind(null,324)),"v-62a8b34c":()=>t.e(8).then(t.bind(null,325)),"v-1ee597b8":()=>t.e(9).then(t.bind(null,326)),"v-17a7d10c":()=>t.e(10).then(t.bind(null,327)),"v-75ecbd16":()=>t.e(11).then(t.bind(null,328)),"v-f0e9a0d2":()=>t.e(12).then(t.bind(null,329)),"v-0a24b240":()=>t.e(13).then(t.bind(null,330)),"v-2626d1fc":()=>t.e(14).then(t.bind(null,331)),"v-34fe61e4":()=>t.e(15).then(t.bind(null,332)),"v-00b2ebc6":()=>t.e(16).then(t.bind(null,333)),"v-612590a5":()=>t.e(17).then(t.bind(null,334)),"v-b09ed4f4":()=>t.e(18).then(t.bind(null,335)),"v-08c5e54c":()=>t.e(19).then(t.bind(null,336)),"v-8b222c70":()=>t.e(20).then(t.bind(null,337)),"v-101ee2a2":()=>t.e(21).then(t.bind(null,338)),"v-6441b580":()=>t.e(22).then(t.bind(null,339)),"v-7d156502":()=>t.e(23).then(t.bind(null,340)),"v-ae223d88":()=>t.e(24).then(t.bind(null,341)),"v-d649585e":()=>t.e(25).then(t.bind(null,342)),"v-6589cc90":()=>t.e(26).then(t.bind(null,343)),"v-cba3920e":()=>t.e(27).then(t.bind(null,344)),"v-d7044cd0":()=>t.e(28).then(t.bind(null,345)),"v-09c4ff2e":()=>t.e(29).then(t.bind(null,346)),"v-2040598b":()=>t.e(30).then(t.bind(null,347)),"v-69d50af2":()=>t.e(31).then(t.bind(null,348)),"v-f12e4400":()=>t.e(32).then(t.bind(null,349)),"v-5d502cb7":()=>t.e(33).then(t.bind(null,350)),"v-1a600385":()=>t.e(34).then(t.bind(null,351)),"v-1a493fea":()=>t.e(35).then(t.bind(null,352)),"v-19f95e8b":()=>t.e(36).then(t.bind(null,353)),"v-46ed506a":()=>t.e(37).then(t.bind(null,354)),"v-1f33db24":()=>t.e(38).then(t.bind(null,355)),"v-415dc8b8":()=>t.e(39).then(t.bind(null,356)),"v-4f0d9490":()=>t.e(40).then(t.bind(null,357)),"v-d23f2b76":()=>t.e(41).then(t.bind(null,358)),"v-199c639b":()=>t.e(42).then(t.bind(null,359)),"v-2507e04a":()=>t.e(43).then(t.bind(null,360)),"v-696c277c":()=>t.e(44).then(t.bind(null,361)),"v-783c66c8":()=>t.e(45).then(t.bind(null,362)),"v-eb512f24":()=>t.e(46).then(t.bind(null,363)),"v-a63f00f0":()=>t.e(47).then(t.bind(null,364)),"v-438f9dca":()=>t.e(48).then(t.bind(null,365)),"v-c5441038":()=>t.e(49).then(t.bind(null,366)),"v-f8abeb6c":()=>t.e(50).then(t.bind(null,367)),"v-955934dc":()=>t.e(51).then(t.bind(null,368)),"v-63d503f0":()=>t.e(52).then(t.bind(null,369)),"v-f2154a58":()=>t.e(53).then(t.bind(null,370)),"v-dbf118bc":()=>t.e(54).then(t.bind(null,371)),"v-65004ca6":()=>t.e(55).then(t.bind(null,372)),"v-35c0dec5":()=>t.e(56).then(t.bind(null,373)),"v-066da6f7":()=>t.e(57).then(t.bind(null,374)),"v-aab99b9a":()=>t.e(58).then(t.bind(null,375)),"v-4c05d3a6":()=>t.e(59).then(t.bind(null,376)),"v-ed73b8ba":()=>t.e(60).then(t.bind(null,377)),"v-af4ff908":()=>t.e(61).then(t.bind(null,378)),"v-96ecc776":()=>t.e(62).then(t.bind(null,379)),"v-58178384":()=>t.e(63).then(t.bind(null,380)),"v-7f048411":()=>t.e(64).then(t.bind(null,381)),"v-1fe197ae":()=>t.e(65).then(t.bind(null,382)),"v-31a4aa1d":()=>t.e(66).then(t.bind(null,383)),"v-03cb9ec2":()=>t.e(67).then(t.bind(null,384)),"v-448a2646":()=>t.e(68).then(t.bind(null,385)),"v-6aa69b5a":()=>t.e(69).then(t.bind(null,386)),"v-6140a136":()=>t.e(70).then(t.bind(null,387)),"v-5df11448":()=>t.e(71).then(t.bind(null,388)),"v-f41b300c":()=>t.e(72).then(t.bind(null,389)),"v-2525a60d":()=>t.e(73).then(t.bind(null,390)),"v-fa0cf7f8":()=>t.e(74).then(t.bind(null,391)),"v-47099c49":()=>t.e(75).then(t.bind(null,392)),"v-d302b38c":()=>t.e(76).then(t.bind(null,393)),"v-16f33bda":()=>t.e(77).then(t.bind(null,394)),"v-1f77f9ec":()=>t.e(78).then(t.bind(null,395)),"v-94737480":()=>t.e(79).then(t.bind(null,396)),"v-c4a07c5e":()=>t.e(80).then(t.bind(null,397)),"v-a9382712":()=>t.e(81).then(t.bind(null,398)),"v-9e9dd666":()=>t.e(82).then(t.bind(null,399)),"v-04cda89e":()=>t.e(83).then(t.bind(null,400)),"v-5d493111":()=>t.e(84).then(t.bind(null,401)),"v-26877d31":()=>t.e(85).then(t.bind(null,402)),"v-10d1fe8a":()=>t.e(86).then(t.bind(null,321))};function $o(n){const e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}const Wo=/-(\w)/g,Qo=$o(n=>n.replace(Wo,(n,e)=>e?e.toUpperCase():"")),Go=/\B([A-Z])/g,Vo=$o(n=>n.replace(Go,"-$1").toLowerCase()),Ko=$o(n=>n.charAt(0).toUpperCase()+n.slice(1));function Xo(n,e){if(!e)return;if(n(e))return n(e);return e.includes("-")?n(Ko(Qo(e))):n(Ko(e))||n(Vo(e))}const Zo=Object.assign({},No,Uo),Yo=n=>Zo[n],ns=n=>Uo[n],es=n=>No[n],ts=n=>Nt.component(n);function as(n){return Xo(ns,n)}function rs(n){return Xo(es,n)}function is(n){return Xo(Yo,n)}function os(n){return Xo(ts,n)}function ss(...n){return Promise.all(n.filter(n=>n).map(async n=>{if(!os(n)&&is(n)){const e=await is(n)();Nt.component(n,e.default)}}))}function ls(n,e){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[n]=e)}var cs=t(90),ps=t.n(cs),ds=t(91),ms=t.n(ds),us={created(){if(this.siteMeta=this.$site.headTags.filter(([n])=>"meta"===n).map(([n,e])=>e),this.$ssrContext){const e=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(n=e)?n.map(n=>{let e="<meta";return Object.keys(n).forEach(t=>{e+=` ${t}="${ms()(n[t])}"`}),e+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=gs(this.$canonicalUrl)}var n},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const n=this.getMergedMetaTags();this.currentMetaTags=vs(n,this.currentMetaTags)},getMergedMetaTags(){const n=this.$page.frontmatter.meta||[];return ps()([{name:"description",content:this.$description}],n,this.siteMeta,bs)},updateCanonicalLink(){hs(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",gs(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){vs(null,this.currentMetaTags),hs()}};function hs(){const n=document.querySelector("link[rel='canonical']");n&&n.remove()}function gs(n=""){return n?`<link href="${n}" rel="canonical" />`:""}function vs(n,e){if(e&&[...e].filter(n=>n.parentNode===document.head).forEach(n=>document.head.removeChild(n)),n)return n.map(n=>{const e=document.createElement("meta");return Object.keys(n).forEach(t=>{e.setAttribute(t,n[t])}),document.head.appendChild(e),e})}function bs(n){for(const e of["name","property","itemprop"])if(n.hasOwnProperty(e))return n[e]+e;return JSON.stringify(n)}var fs=t(49),ys={mounted(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(fs)()((function(){this.setActiveHash()}),300),setActiveHash(){const n=[].slice.call(document.querySelectorAll(".sidebar-link")),e=[].slice.call(document.querySelectorAll(".header-anchor")).filter(e=>n.some(n=>n.hash===e.hash)),t=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),a=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),r=window.innerHeight+t;for(let n=0;n<e.length;n++){const i=e[n],o=e[n+1],s=0===n&&0===t||t>=i.parentElement.offsetTop+10&&(!o||t<o.parentElement.offsetTop-10),l=decodeURIComponent(this.$route.hash);if(s&&l!==decodeURIComponent(i.hash)){const t=i;if(r===a)for(let t=n+1;t<e.length;t++)if(l===decodeURIComponent(e[t].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(t.hash),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})}}}},beforeDestroy(){window.removeEventListener("scroll",this.onScroll)}},xs=t(23),ks=t.n(xs),js={mounted(){ks.a.configure({showSpinner:!1}),this.$router.beforeEach((n,e,t)=>{n.path===e.path||Nt.component(n.name)||ks.a.start(),t()}),this.$router.afterEach(()=>{ks.a.done(),this.isSidebarOpen=!1})}};t(231),t(232);class Ss{constructor(){this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}show({text:n="",duration:e=3e3}){let t=document.createElement("div");t.className="message move-in",t.innerHTML=`\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">${n}</div>\n    `,this.containerEl.appendChild(t),e>0&&setTimeout(()=>{this.close(t)},e)}close(n){n.className=n.className.replace("move-in",""),n.className+="move-out",n.addEventListener("animationend",()=>{n.remove()})}}var ws={mounted(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy(){setTimeout(()=>{(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach(n=>{document.querySelectorAll(n).forEach(this.generateCopyButton)})},1e3)},generateCopyButton(n){if(n.classList.contains("codecopy-enabled"))return;const e=document.createElement("i");e.className="code-copy",e.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',e.title="Copy to clipboard",e.addEventListener("click",()=>{this.copyToClipboard(n.innerText)}),n.appendChild(e),n.classList.add("codecopy-enabled")},copyToClipboard(n){const e=document.createElement("textarea");e.value=n,e.setAttribute("readonly",""),e.style.position="absolute",e.style.left="-9999px",document.body.appendChild(e);const t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);e.select(),document.execCommand("copy");(new Ss).show({text:"复制成功",duration:1e3}),document.body.removeChild(e),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}};!function(n,e){void 0===e&&(e={});var t=e.insertAt;if(n&&"undefined"!=typeof document){var a=document.head||document.getElementsByTagName("head")[0],r=document.createElement("style");r.type="text/css","top"===t&&a.firstChild?a.insertBefore(r,a.firstChild):a.appendChild(r),r.styleSheet?r.styleSheet.cssText=n:r.appendChild(document.createTextNode(n))}}("@media (max-width: 1000px) {\n  .vuepress-plugin-demo-block__h_code {\n    display: none;\n  }\n  .vuepress-plugin-demo-block__app {\n    margin-left: auto !important;\n    margin-right: auto !important;\n  }\n}\n.vuepress-plugin-demo-block__wrapper {\n  margin-top: 10px;\n  border: 1px solid #ebebeb;\n  border-radius: 4px;\n  transition: all 0.2s;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display {\n  height: 400px;\n  display: flex;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__app {\n  width: 300px;\n  border: 1px solid #ebebeb;\n  box-shadow: 1px 1px 3px #ebebeb;\n  margin-right: 5px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code {\n  flex: 1;\n  overflow: auto;\n  height: 100%;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code > pre {\n  overflow: visible;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  max-height: 400px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper div {\n  box-sizing: border-box;\n}\n.vuepress-plugin-demo-block__wrapper:hover {\n  box-shadow: 0 0 11px rgba(33, 33, 33, 0.2);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code {\n  overflow: hidden;\n  height: 0;\n  padding: 0 !important;\n  background-color: #282c34;\n  border-radius: 0 !important;\n  transition: height 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code pre {\n  margin: 0 !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  padding: 20px;\n  border-bottom: 1px solid #ebebeb;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer {\n  position: relative;\n  text-align: center;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__codepen {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__expand::before {\n  border-top: none;\n  border-right: 6px solid transparent;\n  border-bottom: 6px solid #ccc;\n  border-left: 6px solid transparent;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__codepen,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand span,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand::before {\n  border-top-color: #3eaf7c !important;\n  border-bottom-color: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover svg {\n  fill: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand-text {\n  transition: all 0.5s;\n  opacity: 0;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:nth-last-child(2) {\n  right: 50px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:last-child {\n  right: 10px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button {\n  border-color: transparent;\n  background-color: transparent;\n  font-size: 14px;\n  color: #3eaf7c;\n  cursor: pointer;\n  outline: none;\n  margin: 0;\n  width: 46px;\n  position: relative;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::before {\n  content: attr(data-tip);\n  white-space: nowrap;\n  position: absolute;\n  top: -30px;\n  left: 50%;\n  color: #eee;\n  line-height: 1;\n  z-index: 1000;\n  border-radius: 4px;\n  padding: 6px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  background-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::after {\n  content: '' !important;\n  display: block;\n  position: absolute;\n  left: 50%;\n  top: -5px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  border: 5px solid transparent;\n  border-top-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button svg {\n  width: 34px;\n  height: 20px;\n  fill: #ccc;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__codepen {\n  position: absolute;\n  top: 10px;\n  transition: all 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand {\n  position: relative;\n  width: 100px;\n  height: 40px;\n  margin: 0;\n  color: #3eaf7c;\n  font-size: 14px;\n  background-color: transparent;\n  border-color: transparent;\n  outline: none;\n  transition: all 0.5s;\n  cursor: pointer;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand::before {\n  content: \"\";\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  width: 0;\n  height: 0;\n  border-top: 6px solid #ccc;\n  border-right: 6px solid transparent;\n  border-left: 6px solid transparent;\n  -webkit-transform: translate(-50%, -50%);\n          transform: translate(-50%, -50%);\n}\n");var Ts={jsLib:[],cssLib:[],jsfiddle:!0,codepen:!0,codepenLayout:"left",codepenJsProcessor:"babel",codepenEditors:"101",horizontal:!1,vue:"https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js",react:"https://cdn.jsdelivr.net/npm/react/umd/react.production.min.js",reactDOM:"https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.production.min.js"},Is={},Cs=function(n){return'<div id="app">\n'.concat(n,"\n</div>")},Ms=function(n){return window.$VUEPRESS_DEMO_BLOCK&&void 0!==window.$VUEPRESS_DEMO_BLOCK[n]?window.$VUEPRESS_DEMO_BLOCK[n]:Ts[n]},Es=function n(e,t,a){var r=document.createElement(e);return t&&Object.keys(t).forEach((function(n){if(n.indexOf("data"))r[n]=t[n];else{var e=n.replace("data","");r.dataset[e]=t[n]}})),a&&a.forEach((function(e){var t=e.tag,a=e.attrs,i=e.children;r.appendChild(n(t,a,i))})),r},Ps=function(n,e,t){var a,r=(a=n.querySelectorAll(".".concat(e)),Array.prototype.slice.call(a));return 1!==r.length||t?r:r[0]},zs=function(n,e){var t,a,r=n.match(/<style>([\s\S]+)<\/style>/),i=n.match(/<template>([\s\S]+)<\/template>/),o=n.match(/<script>([\s\S]+)<\/script>/),s={css:r&&r[1].replace(/^\n|\n$/g,""),html:i&&i[1].replace(/^\n|\n$/g,""),js:o&&o[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};s.htmlTpl=Cs(s.html),s.jsTpl=(t=s.js,a=t.replace(/export\s+default\s*?\{\n*/,"").replace(/\n*\}\s*$/,"").trim(),"new Vue({\n  el: '#app',\n  ".concat(a,"\n})")),s.script=function(n,e){var t=n.split(/export\s+default/),a="(function() {".concat(t[0]," ; return ").concat(t[1],"})()"),r=window.Babel?window.Babel.transform(a,{presets:["es2015"]}).code:a,i=[eval][0](r);return i.template=e,i}(s.js,s.html);var l=Ms("vue");return s.jsLib.unshift(l),s},As=function(n,e){var t,a=n.match(/<style>([\s\S]+)<\/style>/),r=n.match(/<html>([\s\S]+)<\/html>/),i=n.match(/<script>([\s\S]+)<\/script>/),o={css:a&&a[1].replace(/^\n|\n$/g,""),html:r&&r[1].replace(/^\n|\n$/g,""),js:i&&i[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};return o.htmlTpl=o.html,o.jsTpl=o.js,o.script=(t=o.js,window.Babel?window.Babel.transform(t,{presets:["es2015"]}).code:t),o},qs=function(n){return n=n.replace("export default ","").replace(/App\.__style__(\s*)=(\s*)`([\s\S]*)?`/,""),n+='ReactDOM.render(React.createElement(App), document.getElementById("app"))'};function Js(){var n=Ps(document,"vuepress-plugin-demo-block__wrapper",!0);n.length?n.forEach((function(n){if("true"!==n.dataset.created){n.style.display="block";var e=Ps(n,"vuepress-plugin-demo-block__code"),t=Ps(n,"vuepress-plugin-demo-block__display"),a=Ps(n,"vuepress-plugin-demo-block__footer"),r=Ps(t,"vuepress-plugin-demo-block__app"),i=decodeURIComponent(n.dataset.code),o=decodeURIComponent(n.dataset.config),s=decodeURIComponent(n.dataset.type);o=o?JSON.parse(o):{};var l=e.querySelector("div").clientHeight,c="react"===s?function(n,e){var t=(0,window.Babel.transform)(n,{presets:["es2015","react"]}).code,a="(function(exports){var module={};module.exports=exports;".concat(t,";return module.exports.__esModule?module.exports.default:module.exports;})({})"),r=new Function("return ".concat(a))(),i={js:r,css:r.__style__||"",jsLib:e.jsLib||[],cssLib:e.cssLib||[],jsTpl:qs(n),htmlTpl:Cs("")},o=Ms("react"),s=Ms("reactDOM");return i.jsLib.unshift(o,s),i}(i,o):"vanilla"===s?As(i,o):zs(i,o),p=Es("button",{className:"".concat("vuepress-plugin-demo-block__expand")});if(a.appendChild(p),p.addEventListener("click",Ls.bind(null,p,l,e,a)),Ms("jsfiddle")&&a.appendChild(function(n){var e=n.css,t=n.htmlTpl,a=n.jsTpl,r=n.jsLib,i=n.cssLib,o=r.concat(i).concat(Ms("cssLib")).concat(Ms("jsLib")).join(",");return Es("form",{className:"vuepress-plugin-demo-block__jsfiddle",target:"_blank",action:"https://jsfiddle.net/api/post/library/pure/",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"css",value:e}},{tag:"input",attrs:{type:"hidden",name:"html",value:t}},{tag:"input",attrs:{type:"hidden",name:"js",value:a}},{tag:"input",attrs:{type:"hidden",name:"panel_js",value:3}},{tag:"input",attrs:{type:"hidden",name:"wrap",value:1}},{tag:"input",attrs:{type:"hidden",name:"resources",value:o}},{tag:"button",attrs:{type:"submit",className:"vuepress-plugin-demo-block__button",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088289967" class="icon" style="" viewBox="0 0 1170 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1952" xmlns:xlink="http://www.w3.org/1999/xlink" width="228.515625" height="200"><defs><style type="text/css"></style></defs><path d="M1028.571429 441.142857q63.428571 26.285714 102.571428 83.142857T1170.285714 650.857143q0 93.714286-67.428571 160.285714T940 877.714286q-2.285714 0-6.571429-0.285715t-6-0.285714H232q-97.142857-5.714286-164.571429-71.714286T0 645.142857q0-62.857143 31.428571-116t84-84q-6.857143-22.285714-6.857142-46.857143 0-65.714286 46.857142-112t113.714286-46.285714q54.285714 0 98.285714 33.142857 42.857143-88 127.142858-141.714286t186.571428-53.714285q94.857143 0 174.857143 46T982.571429 248.571429t46.571428 172q0 3.428571-0.285714 10.285714t-0.285714 10.285714zM267.428571 593.142857q0 69.714286 48 110.285714t118.857143 40.571429q78.285714 0 137.142857-56.571429-9.142857-11.428571-27.142857-32.285714T519.428571 626.285714q-38.285714 37.142857-82.285714 37.142857-31.428571 0-53.428571-19.142857T361.714286 594.285714q0-30.285714 22-49.714285t52.285714-19.428572q25.142857 0 48.285714 12t41.714286 31.428572 37.142857 42.857142 39.428572 46.857143 44 42.857143 55.428571 31.428572 69.428571 12q69.142857 0 116.857143-40.857143T936 594.857143q0-69.142857-48-109.714286t-118.285714-40.571428q-81.714286 0-137.714286 55.428571l53.142857 61.714286q37.714286-36.571429 81.142857-36.571429 29.714286 0 52.571429 18.857143t22.857143 48q0 32.571429-21.142857 52.285714t-53.714286 19.714286q-24.571429 0-47.142857-12t-41.142857-31.428571-37.428572-42.857143-39.714286-46.857143-44.285714-42.857143-55.142857-31.428571T434.285714 444.571429q-69.714286 0-118.285714 40.285714T267.428571 593.142857z" p-id="1953"></path></svg>',datatip:"JSFiddle"}}])}(c)),Ms("codepen")&&a.appendChild(function(n){var e=n.css,t=n.htmlTpl,a=n.jsTpl,r=n.jsLib,i=n.cssLib,o=JSON.stringify({css:e,html:t,js:a,js_external:r.concat(Ms("jsLib")).join(";"),css_external:i.concat(Ms("cssLib")).join(";"),layout:Ms("codepenLayout"),js_pre_processor:Ms("codepenJsProcessor"),editors:Ms("codepenEditors")});return Es("form",{className:"vuepress-plugin-demo-block__codepen",target:"_blank",action:"https://codepen.io/pen/define",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"data",value:o}},{tag:"button",attrs:{type:"submit",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088271207" class="icon" style="" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1737" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><defs><style type="text/css"></style></defs><path d="M123.428571 668l344.571429 229.714286v-205.142857L277.142857 565.142857z m-35.428571-82.285714l110.285714-73.714286-110.285714-73.714286v147.428572z m468 312l344.571429-229.714286-153.714286-102.857143-190.857143 127.428572v205.142857z m-44-281.714286l155.428571-104-155.428571-104-155.428571 104zM277.142857 458.857143l190.857143-127.428572V126.285714L123.428571 356z m548.571429 53.142857l110.285714 73.714286V438.285714z m-78.857143-53.142857l153.714286-102.857143-344.571429-229.714286v205.142857z m277.142857-102.857143v312q0 23.428571-19.428571 36.571429l-468 312q-12 7.428571-24.571429 7.428571t-24.571429-7.428571L19.428571 704.571429q-19.428571-13.142857-19.428571-36.571429V356q0-23.428571 19.428571-36.571429L487.428571 7.428571q12-7.428571 24.571429-7.428571t24.571429 7.428571l468 312q19.428571 13.142857 19.428571 36.571429z" p-id="1738"></path></svg>',className:"vuepress-plugin-demo-block__button",datatip:"Codepen"}}])}(c)),void 0!==o.horizontal?o.horizontal:Ms("horizontal")){n.classList.add("vuepress-plugin-demo-block__horizontal");var d=e.firstChild.cloneNode(!0);d.classList.add("vuepress-plugin-demo-block__h_code"),t.appendChild(d)}if(c.css&&function(n){if(!Is[n]){var e=Es("style",{innerHTML:n});document.body.appendChild(e),Is[n]=!0}}(c.css),"react"===s)ReactDOM.render(React.createElement(c.js),r);else if("vue"===s){var m=(new(Vue.extend(c.script))).$mount();r.appendChild(m.$el)}else"vanilla"===s&&(r.innerHTML=c.html,new Function("return (function(){".concat(c.script,"})()"))());n.dataset.created="true"}})):setTimeout((function(n){Js()}),300)}function Ls(n,e,t,a){var r="1"!==n.dataset.isExpand;t.style.height=r?"".concat(e,"px"):0,r?a.classList.add("vuepress-plugin-demo-block__show-link"):a.classList.remove("vuepress-plugin-demo-block__show-link"),n.dataset.isExpand=r?"1":"0"}var Rs={mounted:function(){window.$VUEPRESS_DEMO_BLOCK={jsfiddle:!1,codepen:!0,horizontal:!1},Js()},updated:function(){Js()}},_s="auto",Os="zoom-in",Bs="zoom-out",Ds="grab",Hs="move";function Fs(n,e,t){var a=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],r={passive:!1};a?n.addEventListener(e,t,r):n.removeEventListener(e,t,r)}function Ns(n,e){if(n){var t=new Image;t.onload=function(){e&&e(t)},t.src=n}}function Us(n){return n.dataset.original?n.dataset.original:"A"===n.parentNode.tagName?n.parentNode.getAttribute("href"):null}function $s(n,e,t){!function(n){var e=Ws,t=Qs;if(n.transition){var a=n.transition;delete n.transition,n[e]=a}if(n.transform){var r=n.transform;delete n.transform,n[t]=r}}(e);var a=n.style,r={};for(var i in e)t&&(r[i]=a[i]||""),a[i]=e[i];return r}var Ws="transition",Qs="transform",Gs="transform",Vs="transitionend";var Ks=function(){},Xs={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:Ks,onClose:Ks,onGrab:Ks,onMove:Ks,onRelease:Ks,onBeforeOpen:Ks,onBeforeClose:Ks,onBeforeGrab:Ks,onBeforeRelease:Ks,onImageLoading:Ks,onImageLoaded:Ks},Zs={init:function(n){var e,t;e=this,t=n,Object.getOwnPropertyNames(Object.getPrototypeOf(e)).forEach((function(n){e[n]=e[n].bind(t)}))},click:function(n){if(n.preventDefault(),nl(n))return window.open(this.target.srcOriginal||n.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(n.currentTarget)},scroll:function(){var n=document.documentElement||document.body.parentNode||document.body,e=window.pageXOffset||n.scrollLeft,t=window.pageYOffset||n.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:e,y:t});var a=this.lastScrollPosition.x-e,r=this.lastScrollPosition.y-t,i=this.options.scrollThreshold;(Math.abs(r)>=i||Math.abs(a)>=i)&&(this.lastScrollPosition=null,this.close())},keydown:function(n){(function(n){return"Escape"===(n.key||n.code)||27===n.keyCode})(n)&&(this.released?this.close():this.release(this.close))},mousedown:function(n){if(Ys(n)&&!nl(n)){n.preventDefault();var e=n.clientX,t=n.clientY;this.pressTimer=setTimeout(function(){this.grab(e,t)}.bind(this),200)}},mousemove:function(n){this.released||this.move(n.clientX,n.clientY)},mouseup:function(n){Ys(n)&&!nl(n)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(n){n.preventDefault();var e=n.touches[0],t=e.clientX,a=e.clientY;this.pressTimer=setTimeout(function(){this.grab(t,a)}.bind(this),200)},touchmove:function(n){if(!this.released){var e=n.touches[0],t=e.clientX,a=e.clientY;this.move(t,a)}},touchend:function(n){(function(n){n.targetTouches.length})(n)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function Ys(n){return 0===n.button}function nl(n){return n.metaKey||n.ctrlKey}var el={init:function(n){this.el=document.createElement("div"),this.instance=n,this.parent=document.body,$s(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(n.options),Fs(this.el,"click",n.handler.clickOverlay.bind(n))},updateStyle:function(n){$s(this.el,{zIndex:n.zIndex,backgroundColor:n.bgColor,transition:"opacity\n        "+n.transitionDuration+"s\n        "+n.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},tl="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n},al=function(){function n(n,e){for(var t=0;t<e.length;t++){var a=e[t];a.enumerable=a.enumerable||!1,a.configurable=!0,"value"in a&&(a.writable=!0),Object.defineProperty(n,a.key,a)}}return function(e,t,a){return t&&n(e.prototype,t),a&&n(e,a),e}}(),rl=Object.assign||function(n){for(var e=1;e<arguments.length;e++){var t=arguments[e];for(var a in t)Object.prototype.hasOwnProperty.call(t,a)&&(n[a]=t[a])}return n},il={init:function(n,e){this.el=n,this.instance=e,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=Us(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var n=this.instance.options,e=n.zIndex,t=n.enableGrab,a=n.transitionDuration,r=n.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:e+1,cursor:t?Ds:Bs,transition:Gs+"\n        "+a+"s\n        "+r,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=$s(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,$s(this.el,{transform:"none"})},grab:function(n,e,t){var a=ol(),r=a.x-n,i=a.y-e;$s(this.el,{cursor:Hs,transform:"translate3d(\n        "+(this.translate.x+r)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(n,e,t){var a=ol(),r=a.x-n,i=a.y-e;$s(this.el,{transition:Gs,transform:"translate3d(\n        "+(this.translate.x+r)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){$s(this.el,this.styleClose)},restoreOpenStyle:function(){$s(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var n=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var e=this.el.cloneNode(!1);e.setAttribute("src",this.srcOriginal),e.style.position="fixed",e.style.visibility="hidden",n.appendChild(e),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),n.removeChild(e)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var n=ol(),e=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:n.x-e,y:n.y-t}},calculateScale:function(){var n=this.el.dataset,e=n.zoomingHeight,t=n.zoomingWidth,a=this.instance.options,r=a.customSize,i=a.scaleBase;if(!r&&e&&t)return{x:t/this.rect.width,y:e/this.rect.height};if(r&&"object"===(void 0===r?"undefined":tl(r)))return{x:r.width/this.rect.width,y:r.height/this.rect.height};var o=this.rect.width/2,s=this.rect.height/2,l=ol(),c={x:l.x-o,y:l.y-s},p=c.x/o,d=c.y/s,m=i+Math.min(p,d);if(r&&"string"==typeof r){var u=t||this.el.naturalWidth,h=e||this.el.naturalHeight,g=parseFloat(r)*u/(100*this.rect.width),v=parseFloat(r)*h/(100*this.rect.height);if(m>g||m>v)return{x:g,y:v}}return{x:m,y:m}}};function ol(){var n=document.documentElement;return{x:Math.min(n.clientWidth,window.innerWidth)/2,y:Math.min(n.clientHeight,window.innerHeight)/2}}function sl(n,e,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(a){Fs(n,a,e[a],t)}))}var ll=function(){function n(e){!function(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}(this,n),this.target=Object.create(il),this.overlay=Object.create(el),this.handler=Object.create(Zs),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=rl({},Xs,e),this.overlay.init(this),this.handler.init(this)}return al(n,[{key:"listen",value:function(n){if("string"==typeof n)for(var e=document.querySelectorAll(n),t=e.length;t--;)this.listen(e[t]);else"IMG"===n.tagName&&(n.style.cursor=Os,Fs(n,"click",this.handler.click),this.options.preloadImage&&Ns(Us(n)));return this}},{key:"config",value:function(n){return n?(rl(this.options,n),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(n){var e=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var a="string"==typeof n?document.querySelector(n):n;if("IMG"===a.tagName){if(this.options.onBeforeOpen(a),this.target.init(a,this),!this.options.preloadImage){var r=this.target.srcOriginal;null!=r&&(this.options.onImageLoading(a),Ns(r,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),Fs(document,"scroll",this.handler.scroll),Fs(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&Fs(window,"resize",this.handler.resizeWindow);var i=function n(){Fs(a,Vs,n,!1),e.lock=!1,e.target.upgradeSource(),e.options.enableGrab&&sl(document,e.handler,!0),t(a)};return Fs(a,Vs,i),this}}}},{key:"close",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=_s,this.overlay.fadeOut(),this.target.zoomOut(),Fs(document,"scroll",this.handler.scroll,!1),Fs(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&Fs(window,"resize",this.handler.resizeWindow,!1);var a=function a(){Fs(t,Vs,a,!1),n.shown=!1,n.lock=!1,n.target.downgradeSource(),n.options.enableGrab&&sl(document,n.handler,!1),n.target.restoreCloseStyle(),n.overlay.remove(),e(t)};return Fs(t,Vs,a),this}}},{key:"grab",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,a=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var r=this.target.el;this.options.onBeforeGrab(r),this.released=!1,this.target.grab(n,e,t);var i=function n(){Fs(r,Vs,n,!1),a(r)};return Fs(r,Vs,i),this}}},{key:"move",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,a=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=Hs,this.target.move(n,e,t);var r=this.target.el,i=function n(){Fs(r,Vs,n,!1),a(r)};return Fs(r,Vs,i),this}}},{key:"release",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=_s,this.target.restoreOpenStyle();var a=function a(){Fs(t,Vs,a,!1),n.lock=!1,n.released=!0,e(t)};return Fs(t,Vs,a),this}}}]),n}();const cl=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),pl=Number("500");class dl{constructor(){this.instance=new ll(cl)}update(n=".theme-vdoing-content img:not(.no-zoom)"){"undefined"!=typeof window&&this.instance.listen(n)}updateDelay(n=".theme-vdoing-content img:not(.no-zoom)",e=pl){setTimeout(()=>this.update(n),e)}}var ml=[us,ys,js,ws,Rs,{watch:{"$page.path"(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted(){this.$vuepress.zooming=new dl,this.$vuepress.zooming.updateDelay()}}],ul={name:"GlobalLayout",computed:{layout(){const n=this.getLayout();return ls("layout",n),Nt.component(n)}},methods:{getLayout(){if(this.$page.path){const n=this.$page.frontmatter.layout;return n&&(this.$vuepress.getLayoutAsyncComponent(n)||this.$vuepress.getVueComponent(n))?n:"Layout"}return"NotFound"}}},hl=t(6),gl=Object(hl.a)(ul,(function(){return(0,this._self._c)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(n,e,t){switch(e){case"components":n[e]||(n[e]={}),Object.assign(n[e],t);break;case"mixins":n[e]||(n[e]=[]),n[e].push(...t);break;default:throw new Error("Unknown option name.")}}(gl,"mixins",ml);const vl=[{name:"v-4b99dd20",path:"/pages/be093b/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-4b99dd20").then(t)}},{path:"/pages/be093b/index.html",redirect:"/pages/be093b/"},{path:"/02.JavaEE/01.JavaWeb/01.JavaWeb之Servlet指南.html",redirect:"/pages/be093b/"},{name:"v-27772cc0",path:"/pages/6bbb16/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-27772cc0").then(t)}},{path:"/pages/6bbb16/index.html",redirect:"/pages/6bbb16/"},{path:"/02.JavaEE/01.JavaWeb/02.JavaWeb之Jsp指南.html",redirect:"/pages/6bbb16/"},{name:"v-576f0972",path:"/pages/5ecb29/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-576f0972").then(t)}},{path:"/pages/5ecb29/index.html",redirect:"/pages/5ecb29/"},{path:"/02.JavaEE/01.JavaWeb/03.JavaWeb之Filter和Listener.html",redirect:"/pages/5ecb29/"},{name:"v-62a8b34c",path:"/pages/e61883/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-62a8b34c").then(t)}},{path:"/pages/e61883/index.html",redirect:"/pages/e61883/"},{path:"/02.JavaEE/01.JavaWeb/04.JavaWeb之Cookie和Session.html",redirect:"/pages/e61883/"},{name:"v-1ee597b8",path:"/pages/1933b3/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-1ee597b8").then(t)}},{path:"/pages/1933b3/index.html",redirect:"/pages/1933b3/"},{path:"/02.JavaEE/01.JavaWeb/99.JavaWeb面经.html",redirect:"/pages/1933b3/"},{name:"v-17a7d10c",path:"/pages/c1cee9/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-17a7d10c").then(t)}},{path:"/pages/c1cee9/index.html",redirect:"/pages/c1cee9/"},{path:"/02.JavaEE/01.JavaWeb/",redirect:"/pages/c1cee9/"},{name:"v-75ecbd16",path:"/pages/c50d2b/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-75ecbd16").then(t)}},{path:"/pages/c50d2b/index.html",redirect:"/pages/c50d2b/"},{path:"/02.JavaEE/02.服务器/01.Tomcat/01.Tomcat快速入门.html",redirect:"/pages/c50d2b/"},{name:"v-f0e9a0d2",path:"/pages/3c954b/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-f0e9a0d2").then(t)}},{path:"/pages/3c954b/index.html",redirect:"/pages/3c954b/"},{path:"/02.JavaEE/02.服务器/01.Tomcat/02.Tomcat连接器.html",redirect:"/pages/3c954b/"},{name:"v-0a24b240",path:"/pages/2fea08/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-0a24b240").then(t)}},{path:"/pages/2fea08/index.html",redirect:"/pages/2fea08/"},{path:"/02.JavaEE/02.服务器/01.Tomcat/03.Tomcat容器.html",redirect:"/pages/2fea08/"},{name:"v-2626d1fc",path:"/pages/6c22f4/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-2626d1fc").then(t)}},{path:"/pages/6c22f4/index.html",redirect:"/pages/6c22f4/"},{path:"/02.JavaEE/02.服务器/01.Tomcat/04.Tomcat优化.html",redirect:"/pages/6c22f4/"},{name:"v-34fe61e4",path:"/pages/f1bba6/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-34fe61e4").then(t)}},{path:"/pages/f1bba6/index.html",redirect:"/pages/f1bba6/"},{path:"/02.JavaEE/02.服务器/01.Tomcat/05.Tomcat和Jetty.html",redirect:"/pages/f1bba6/"},{name:"v-00b2ebc6",path:"/pages/86288e/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-00b2ebc6").then(t)}},{path:"/pages/86288e/index.html",redirect:"/pages/86288e/"},{path:"/02.JavaEE/02.服务器/01.Tomcat/",redirect:"/pages/86288e/"},{name:"v-612590a5",path:"/pages/9ecdc1/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-612590a5").then(t)}},{path:"/pages/9ecdc1/index.html",redirect:"/pages/9ecdc1/"},{path:"/02.JavaEE/02.服务器/02.Jetty.html",redirect:"/pages/9ecdc1/"},{name:"v-b09ed4f4",path:"/pages/9d17ce/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-b09ed4f4").then(t)}},{path:"/pages/9d17ce/index.html",redirect:"/pages/9d17ce/"},{path:"/02.JavaEE/02.服务器/",redirect:"/pages/9d17ce/"},{name:"v-08c5e54c",path:"/pages/ca58e7/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-08c5e54c").then(t)}},{path:"/pages/ca58e7/index.html",redirect:"/pages/ca58e7/"},{path:"/02.JavaEE/",redirect:"/pages/ca58e7/"},{name:"v-8b222c70",path:"/pages/6b8149/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-8b222c70").then(t)}},{path:"/pages/6b8149/index.html",redirect:"/pages/6b8149/"},{path:"/11.软件/01.构建/01.Maven/01.Maven快速入门.html",redirect:"/pages/6b8149/"},{name:"v-101ee2a2",path:"/pages/f594fa/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-101ee2a2").then(t)}},{path:"/pages/f594fa/index.html",redirect:"/pages/f594fa/"},{path:"/11.软件/01.构建/01.Maven/02.Maven教程之pom.xml详解.html",redirect:"/pages/f594fa/"},{name:"v-6441b580",path:"/pages/d05c38/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-6441b580").then(t)}},{path:"/pages/d05c38/index.html",redirect:"/pages/d05c38/"},{path:"/11.软件/01.构建/01.Maven/03.Maven教程之settings.xml详解.html",redirect:"/pages/d05c38/"},{name:"v-7d156502",path:"/pages/7908f2/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-7d156502").then(t)}},{path:"/pages/7908f2/index.html",redirect:"/pages/7908f2/"},{path:"/11.软件/01.构建/01.Maven/04.Maven实战问题和最佳实践.html",redirect:"/pages/7908f2/"},{name:"v-ae223d88",path:"/pages/2ddf04/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-ae223d88").then(t)}},{path:"/pages/2ddf04/index.html",redirect:"/pages/2ddf04/"},{path:"/11.软件/01.构建/01.Maven/05.Maven教程之发布jar到私服或中央仓库.html",redirect:"/pages/2ddf04/"},{name:"v-d649585e",path:"/pages/149013/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-d649585e").then(t)}},{path:"/pages/149013/index.html",redirect:"/pages/149013/"},{path:"/11.软件/01.构建/01.Maven/06.Maven插件之代码检查.html",redirect:"/pages/149013/"},{name:"v-6589cc90",path:"/pages/14735b/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-6589cc90").then(t)}},{path:"/pages/14735b/index.html",redirect:"/pages/14735b/"},{path:"/11.软件/01.构建/01.Maven/",redirect:"/pages/14735b/"},{name:"v-cba3920e",path:"/pages/e2af3a/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-cba3920e").then(t)}},{path:"/pages/e2af3a/index.html",redirect:"/pages/e2af3a/"},{path:"/11.软件/01.构建/02.Ant.html",redirect:"/pages/e2af3a/"},{name:"v-d7044cd0",path:"/pages/95388e/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-d7044cd0").then(t)}},{path:"/pages/95388e/index.html",redirect:"/pages/95388e/"},{path:"/11.软件/01.构建/",redirect:"/pages/95388e/"},{name:"v-09c4ff2e",path:"/pages/ea83ee/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-09c4ff2e").then(t)}},{path:"/pages/ea83ee/index.html",redirect:"/pages/ea83ee/"},{path:"/11.软件/02.IDE/01.Intellij.html",redirect:"/pages/ea83ee/"},{name:"v-2040598b",path:"/pages/a897a9/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-2040598b").then(t)}},{path:"/pages/a897a9/index.html",redirect:"/pages/a897a9/"},{path:"/11.软件/02.IDE/02.Eclipse.html",redirect:"/pages/a897a9/"},{name:"v-69d50af2",path:"/pages/a537c7/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-69d50af2").then(t)}},{path:"/pages/a537c7/index.html",redirect:"/pages/a537c7/"},{path:"/11.软件/02.IDE/03.VsCode.html",redirect:"/pages/a537c7/"},{name:"v-f12e4400",path:"/pages/2df5ea/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-f12e4400").then(t)}},{path:"/pages/2df5ea/index.html",redirect:"/pages/2df5ea/"},{path:"/11.软件/02.IDE/",redirect:"/pages/2df5ea/"},{name:"v-5d502cb7",path:"/pages/c7c5ec/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-5d502cb7").then(t)}},{path:"/pages/c7c5ec/index.html",redirect:"/pages/c7c5ec/"},{path:"/11.软件/03.监控诊断/01.监控工具对比.html",redirect:"/pages/c7c5ec/"},{name:"v-1a600385",path:"/pages/83e684/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-1a600385").then(t)}},{path:"/pages/83e684/index.html",redirect:"/pages/83e684/"},{path:"/11.软件/03.监控诊断/02.CAT.html",redirect:"/pages/83e684/"},{name:"v-1a493fea",path:"/pages/82c168/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-1a493fea").then(t)}},{path:"/pages/82c168/index.html",redirect:"/pages/82c168/"},{path:"/11.软件/03.监控诊断/03.Zipkin.html",redirect:"/pages/82c168/"},{name:"v-19f95e8b",path:"/pages/d82d3c/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-19f95e8b").then(t)}},{path:"/pages/d82d3c/index.html",redirect:"/pages/d82d3c/"},{path:"/11.软件/03.监控诊断/04.Skywalking.html",redirect:"/pages/d82d3c/"},{name:"v-46ed506a",path:"/pages/b6a542/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-46ed506a").then(t)}},{path:"/pages/b6a542/index.html",redirect:"/pages/b6a542/"},{path:"/11.软件/03.监控诊断/05.Arthas.html",redirect:"/pages/b6a542/"},{name:"v-1f33db24",path:"/pages/2853ec/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-1f33db24").then(t)}},{path:"/pages/2853ec/index.html",redirect:"/pages/2853ec/"},{path:"/11.软件/03.监控诊断/",redirect:"/pages/2853ec/"},{name:"v-415dc8b8",path:"/pages/dab057/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-415dc8b8").then(t)}},{path:"/pages/dab057/index.html",redirect:"/pages/dab057/"},{path:"/11.软件/",redirect:"/pages/dab057/"},{name:"v-4f0d9490",path:"/pages/a14952/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-4f0d9490").then(t)}},{path:"/pages/a14952/index.html",redirect:"/pages/a14952/"},{path:"/12.工具/01.IO/01.JSON序列化.html",redirect:"/pages/a14952/"},{name:"v-d23f2b76",path:"/pages/95f25b/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-d23f2b76").then(t)}},{path:"/pages/95f25b/index.html",redirect:"/pages/95f25b/"},{path:"/12.工具/01.IO/02.二进制序列化.html",redirect:"/pages/95f25b/"},{name:"v-199c639b",path:"/pages/0358e9/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-199c639b").then(t)}},{path:"/pages/0358e9/index.html",redirect:"/pages/0358e9/"},{path:"/12.工具/01.IO/",redirect:"/pages/0358e9/"},{name:"v-2507e04a",path:"/pages/0d31cd/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-2507e04a").then(t)}},{path:"/pages/0d31cd/index.html",redirect:"/pages/0d31cd/"},{path:"/12.工具/02.JavaBean/01.Lombok.html",redirect:"/pages/0d31cd/"},{name:"v-696c277c",path:"/pages/596174/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-696c277c").then(t)}},{path:"/pages/596174/index.html",redirect:"/pages/596174/"},{path:"/12.工具/02.JavaBean/02.Dozer.html",redirect:"/pages/596174/"},{name:"v-783c66c8",path:"/pages/34ec25/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-783c66c8").then(t)}},{path:"/pages/34ec25/index.html",redirect:"/pages/34ec25/"},{path:"/12.工具/03.模板引擎/01.Freemark.html",redirect:"/pages/34ec25/"},{name:"v-eb512f24",path:"/pages/2263fb/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-eb512f24").then(t)}},{path:"/pages/2263fb/index.html",redirect:"/pages/2263fb/"},{path:"/12.工具/03.模板引擎/02.Thymeleaf.html",redirect:"/pages/2263fb/"},{name:"v-a63f00f0",path:"/pages/7ecb81/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-a63f00f0").then(t)}},{path:"/pages/7ecb81/index.html",redirect:"/pages/7ecb81/"},{path:"/12.工具/03.模板引擎/03.Velocity.html",redirect:"/pages/7ecb81/"},{name:"v-438f9dca",path:"/pages/9a5880/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-438f9dca").then(t)}},{path:"/pages/9a5880/index.html",redirect:"/pages/9a5880/"},{path:"/12.工具/03.模板引擎/",redirect:"/pages/9a5880/"},{name:"v-c5441038",path:"/pages/06533c/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-c5441038").then(t)}},{path:"/pages/06533c/index.html",redirect:"/pages/06533c/"},{path:"/12.工具/04.测试/01.Junit.html",redirect:"/pages/06533c/"},{name:"v-f8abeb6c",path:"/pages/ab18ad/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-f8abeb6c").then(t)}},{path:"/pages/ab18ad/index.html",redirect:"/pages/ab18ad/"},{path:"/12.工具/04.测试/02.Mockito.html",redirect:"/pages/ab18ad/"},{name:"v-955934dc",path:"/pages/d99171/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-955934dc").then(t)}},{path:"/pages/d99171/index.html",redirect:"/pages/d99171/"},{path:"/12.工具/04.测试/03.Jmeter.html",redirect:"/pages/d99171/"},{name:"v-63d503f0",path:"/pages/747d3e/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-63d503f0").then(t)}},{path:"/pages/747d3e/index.html",redirect:"/pages/747d3e/"},{path:"/12.工具/04.测试/04.JMH.html",redirect:"/pages/747d3e/"},{name:"v-f2154a58",path:"/pages/337701/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-f2154a58").then(t)}},{path:"/pages/337701/index.html",redirect:"/pages/337701/"},{path:"/12.工具/99.其他/01.Java日志.html",redirect:"/pages/337701/"},{name:"v-dbf118bc",path:"/pages/14e432/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-dbf118bc").then(t)}},{path:"/pages/14e432/index.html",redirect:"/pages/14e432/"},{path:"/12.工具/99.其他/02.Java工具包.html",redirect:"/pages/14e432/"},{name:"v-65004ca6",path:"/pages/ea4914/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-65004ca6").then(t)}},{path:"/pages/ea4914/index.html",redirect:"/pages/ea4914/"},{path:"/12.工具/99.其他/03.Reflections.html",redirect:"/pages/ea4914/"},{name:"v-35c0dec5",path:"/pages/da3f07/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-35c0dec5").then(t)}},{path:"/pages/da3f07/index.html",redirect:"/pages/da3f07/"},{path:"/12.工具/99.其他/04.JavaMail.html",redirect:"/pages/da3f07/"},{name:"v-066da6f7",path:"/pages/c516cc/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-066da6f7").then(t)}},{path:"/pages/c516cc/index.html",redirect:"/pages/c516cc/"},{path:"/12.工具/99.其他/05.Jsoup.html",redirect:"/pages/c516cc/"},{name:"v-aab99b9a",path:"/pages/aa9f61/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-aab99b9a").then(t)}},{path:"/pages/aa9f61/index.html",redirect:"/pages/aa9f61/"},{path:"/12.工具/99.其他/06.Thumbnailator.html",redirect:"/pages/aa9f61/"},{name:"v-4c05d3a6",path:"/pages/cc8ce5/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-4c05d3a6").then(t)}},{path:"/pages/cc8ce5/index.html",redirect:"/pages/cc8ce5/"},{path:"/12.工具/99.其他/07.Zxing.html",redirect:"/pages/cc8ce5/"},{name:"v-ed73b8ba",path:"/pages/4b6820/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-ed73b8ba").then(t)}},{path:"/pages/4b6820/index.html",redirect:"/pages/4b6820/"},{path:"/12.工具/",redirect:"/pages/4b6820/"},{name:"v-af4ff908",path:"/pages/538358/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-af4ff908").then(t)}},{path:"/pages/538358/index.html",redirect:"/pages/538358/"},{path:"/13.框架/11.ORM/01.Mybatis快速入门.html",redirect:"/pages/538358/"},{name:"v-96ecc776",path:"/pages/3f3dba/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-96ecc776").then(t)}},{path:"/pages/3f3dba/index.html",redirect:"/pages/3f3dba/"},{path:"/13.框架/11.ORM/02.Mybatis原理.html",redirect:"/pages/3f3dba/"},{name:"v-58178384",path:"/pages/e873e1/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-58178384").then(t)}},{path:"/pages/e873e1/index.html",redirect:"/pages/e873e1/"},{path:"/13.框架/11.ORM/",redirect:"/pages/e873e1/"},{name:"v-7f048411",path:"/pages/cd25bf/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-7f048411").then(t)}},{path:"/pages/cd25bf/index.html",redirect:"/pages/cd25bf/"},{path:"/13.框架/12.安全/01.Shiro.html",redirect:"/pages/cd25bf/"},{name:"v-1fe197ae",path:"/pages/a6cc5f/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-1fe197ae").then(t)}},{path:"/pages/a6cc5f/index.html",redirect:"/pages/a6cc5f/"},{path:"/13.框架/12.安全/02.SpringSecurity.html",redirect:"/pages/a6cc5f/"},{name:"v-31a4aa1d",path:"/pages/520c52/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-31a4aa1d").then(t)}},{path:"/pages/520c52/index.html",redirect:"/pages/520c52/"},{path:"/13.框架/13.IO/01.Netty.html",redirect:"/pages/520c52/"},{name:"v-03cb9ec2",path:"/pages/e79b77/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-03cb9ec2").then(t)}},{path:"/pages/e79b77/index.html",redirect:"/pages/e79b77/"},{path:"/13.框架/14.微服务/01.Dubbo.html",redirect:"/pages/e79b77/"},{name:"v-448a2646",path:"/pages/fd4995/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-448a2646").then(t)}},{path:"/pages/fd4995/index.html",redirect:"/pages/fd4995/"},{path:"/13.框架/",redirect:"/pages/fd4995/"},{name:"v-6aa69b5a",path:"/pages/5a6cf3/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-6aa69b5a").then(t)}},{path:"/pages/5a6cf3/index.html",redirect:"/pages/5a6cf3/"},{path:"/14.中间件/01.MQ/01.消息队列面试.html",redirect:"/pages/5a6cf3/"},{name:"v-6140a136",path:"/pages/055069/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-6140a136").then(t)}},{path:"/pages/055069/index.html",redirect:"/pages/055069/"},{path:"/14.中间件/01.MQ/02.消息队列基本原理.html",redirect:"/pages/055069/"},{name:"v-5df11448",path:"/pages/f56a96/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-5df11448").then(t)}},{path:"/pages/f56a96/index.html",redirect:"/pages/f56a96/"},{path:"/14.中间件/01.MQ/03.RocketMQ.html",redirect:"/pages/f56a96/"},{name:"v-f41b300c",path:"/pages/3f7c49/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-f41b300c").then(t)}},{path:"/pages/3f7c49/index.html",redirect:"/pages/3f7c49/"},{path:"/14.中间件/01.MQ/04.ActiveMQ.html",redirect:"/pages/3f7c49/"},{name:"v-2525a60d",path:"/pages/fc0b29/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-2525a60d").then(t)}},{path:"/pages/fc0b29/index.html",redirect:"/pages/fc0b29/"},{path:"/14.中间件/01.MQ/",redirect:"/pages/fc0b29/"},{name:"v-fa0cf7f8",path:"/pages/eb30d6/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-fa0cf7f8").then(t)}},{path:"/pages/eb30d6/index.html",redirect:"/pages/eb30d6/"},{path:"/14.中间件/02.缓存/01.缓存面试题.html",redirect:"/pages/eb30d6/"},{name:"v-47099c49",path:"/pages/970fa6/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-47099c49").then(t)}},{path:"/pages/970fa6/index.html",redirect:"/pages/970fa6/"},{path:"/14.中间件/02.缓存/02.Java缓存中间件.html",redirect:"/pages/970fa6/"},{name:"v-d302b38c",path:"/pages/25a710/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-d302b38c").then(t)}},{path:"/pages/25a710/index.html",redirect:"/pages/25a710/"},{path:"/14.中间件/02.缓存/03.Memcached.html",redirect:"/pages/25a710/"},{name:"v-16f33bda",path:"/pages/c4647d/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-16f33bda").then(t)}},{path:"/pages/c4647d/index.html",redirect:"/pages/c4647d/"},{path:"/14.中间件/02.缓存/04.Ehcache.html",redirect:"/pages/c4647d/"},{name:"v-1f77f9ec",path:"/pages/9632fd/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-1f77f9ec").then(t)}},{path:"/pages/9632fd/index.html",redirect:"/pages/9632fd/"},{path:"/14.中间件/02.缓存/05.Java进程内缓存.html",redirect:"/pages/9632fd/"},{name:"v-94737480",path:"/pages/c09100/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-94737480").then(t)}},{path:"/pages/c09100/index.html",redirect:"/pages/c09100/"},{path:"/14.中间件/02.缓存/06.Http缓存.html",redirect:"/pages/c09100/"},{name:"v-c4a07c5e",path:"/pages/71104f/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-c4a07c5e").then(t)}},{path:"/pages/71104f/index.html",redirect:"/pages/71104f/"},{path:"/14.中间件/02.缓存/",redirect:"/pages/71104f/"},{name:"v-a9382712",path:"/pages/f2ebed/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-a9382712").then(t)}},{path:"/pages/f2ebed/index.html",redirect:"/pages/f2ebed/"},{path:"/14.中间件/03.流量控制/01.Hystrix.html",redirect:"/pages/f2ebed/"},{name:"v-9e9dd666",path:"/pages/3cbcff/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-9e9dd666").then(t)}},{path:"/pages/3cbcff/index.html",redirect:"/pages/3cbcff/"},{path:"/14.中间件/",redirect:"/pages/3cbcff/"},{name:"v-04cda89e",path:"/archives/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-04cda89e").then(t)}},{path:"/archives/index.html",redirect:"/archives/"},{path:"/@pages/archivesPage.html",redirect:"/archives/"},{name:"v-5d493111",path:"/categories/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-5d493111").then(t)}},{path:"/categories/index.html",redirect:"/categories/"},{path:"/@pages/categoriesPage.html",redirect:"/categories/"},{name:"v-26877d31",path:"/tags/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-26877d31").then(t)}},{path:"/tags/index.html",redirect:"/tags/"},{path:"/@pages/tagsPage.html",redirect:"/tags/"},{name:"v-10d1fe8a",path:"/",component:gl,beforeEnter:(n,e,t)=>{ss("Layout","v-10d1fe8a").then(t)}},{path:"/index.html",redirect:"/"},{path:"*",component:gl}],bl={title:"JAVA-TUTORIAL",description:"☕ java-tutorial 是一个 Java 教程，汇集一个老司机在 Java 领域的十年积累。",base:"/java-tutorial/",headTags:[["link",{rel:"icon",href:"/java-tutorial/img/favicon.ico"}],["meta",{name:"keywords",content:"vuepress,theme,blog,vdoing"}],["meta",{name:"theme-color",content:"#11a8cd"}]],pages:[{title:"JavaWeb 之 Servlet 指南",frontmatter:{title:"JavaWeb 之 Servlet 指南",categories:["编程","Java","JavaWeb"],tags:["Java","JavaWeb","Servlet"],abbrlink:"2ce8dedd",date:"2020-08-24T19:41:46.000Z",permalink:"/pages/be093b/"},regularPath:"/02.JavaEE/01.JavaWeb/01.JavaWeb%E4%B9%8BServlet%E6%8C%87%E5%8D%97.html",relativePath:"02.JavaEE/01.JavaWeb/01.JavaWeb之Servlet指南.md",key:"v-4b99dd20",path:"/pages/be093b/",headers:[{level:2,title:"JavaWeb 简介",slug:"javaweb-简介",normalizedTitle:"javaweb 简介",charIndex:27},{level:3,title:"Web 应用程序",slug:"web-应用程序",normalizedTitle:"web 应用程序",charIndex:42},{level:3,title:"常见 Web 服务器",slug:"常见-web-服务器",normalizedTitle:"常见 web 服务器",charIndex:369},{level:2,title:"Servlet 简介",slug:"servlet-简介",normalizedTitle:"servlet 简介",charIndex:466},{level:3,title:"什么是 Servlet",slug:"什么是-servlet",normalizedTitle:"什么是 servlet",charIndex:481},{level:3,title:"Servlet 和 CGI 的区别",slug:"servlet-和-cgi-的区别",normalizedTitle:"servlet 和 cgi 的区别",charIndex:773},{level:3,title:"Servlet 版本以及主要特性",slug:"servlet-版本以及主要特性",normalizedTitle:"servlet 版本以及主要特性",charIndex:1e3},{level:3,title:"Servlet 任务",slug:"servlet-任务",normalizedTitle:"servlet 任务",charIndex:1838},{level:3,title:"Servlet 生命周期",slug:"servlet-生命周期",normalizedTitle:"servlet 生命周期",charIndex:2248},{level:2,title:"Servlet API",slug:"servlet-api",normalizedTitle:"servlet api",charIndex:2528},{level:3,title:"Servlet 包",slug:"servlet-包",normalizedTitle:"servlet 包",charIndex:2544},{level:3,title:"Servlet 接口",slug:"servlet-接口",normalizedTitle:"servlet 接口",charIndex:658},{level:4,title:"init() 方法",slug:"init-方法",normalizedTitle:"init() 方法",charIndex:3167},{level:4,title:"service() 方法",slug:"service-方法",normalizedTitle:"service() 方法",charIndex:879},{level:4,title:"doGet() 方法",slug:"doget-方法",normalizedTitle:"doget() 方法",charIndex:4255},{level:4,title:"doPost() 方法",slug:"dopost-方法",normalizedTitle:"dopost() 方法",charIndex:4213},{level:4,title:"destroy() 方法",slug:"destroy-方法",normalizedTitle:"destroy() 方法",charIndex:2465},{level:2,title:"Servlet 和 HTTP 状态码",slug:"servlet-和-http-状态码",normalizedTitle:"servlet 和 http 状态码",charIndex:4975},{level:3,title:"HTTP 状态码",slug:"http-状态码",normalizedTitle:"http 状态码",charIndex:4985},{level:3,title:"设置 HTTP 状态码的方法",slug:"设置-http-状态码的方法",normalizedTitle:"设置 http 状态码的方法",charIndex:5888},{level:3,title:"HTTP 状态码实例",slug:"http-状态码实例",normalizedTitle:"http 状态码实例",charIndex:6372},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:7316}],headersStr:"JavaWeb 简介 Web 应用程序 常见 Web 服务器 Servlet 简介 什么是 Servlet Servlet 和 CGI 的区别 Servlet 版本以及主要特性 Servlet 任务 Servlet 生命周期 Servlet API Servlet 包 Servlet 接口 init() 方法 service() 方法 doGet() 方法 doPost() 方法 destroy() 方法 Servlet 和 HTTP 状态码 HTTP 状态码 设置 HTTP 状态码的方法 HTTP 状态码实例 参考资料",content:'# JavaWeb 之 Servlet 指南\n\n\n# JavaWeb 简介\n\n\n# Web 应用程序\n\nWeb，在英语中 web 即表示网页的意思，它用于表示 Internet 主机上供外界访问的资源。\n\nWeb 应用程序是一种可以通过 Web 访问的应用程序，程序的最大好处是用户很容易访问应用程序，用户只需要有浏览器即可，不需要再安装其他软件。\n\nInternet 上供外界访问的 Web 资源分为：\n\n * 静态 web 资源：指 web 页面中供人们浏览的数据始终是不变。常见静态资源文件：html、css、各种图片类型（jpg、png）\n * 动态 web 资源：指 web 页面中供人们浏览的数据是由程序产生的，不同时间点访问 web 页面看到的内容各不相同。常见动态资源技术：JSP/Servlet、ASP、PHP\n\n\n# 常见 Web 服务器\n\n * Tomcat\n * Jetty\n * Resin\n * Apache\n * Nginx\n * WebSphere\n * WebLogic\n * JBoss\n\n\n# Servlet 简介\n\n\n# 什么是 Servlet\n\nServlet（Server Applet），即小服务程序或服务连接器。Servlet 是 Java 编写的服务器端程序，具有独立于平台和协议的特性，主要功能在于交互式地浏览和生成数据，生成动态 Web 内容。\n\n * 狭义的 Servlet 是指 Java 实现的一个接口。\n * 广义的 Servlet 是指任何实现了这个 Servlet 接口的类。\n\nServlet 运行于支持 Java 的应用服务器中。从原理上讲，Servlet 可以响应任何类型的请求，但绝大多数情况下 Servlet 只用来扩展基于 HTTP 协议的 Web 服务器。\n\n\n# Servlet 和 CGI 的区别\n\nServlet 技术出现之前，Web 主要使用 CGI 技术。它们的区别如下：\n\n * Servlet 是基于 Java 编写的，处于服务器进程中，他能够通过多线程方式运行 service() 方法，一个实例可以服务于多个请求，而且一般不会销毁；\n * CGI(Common Gateway Interface)，即通用网关接口。它会为每个请求产生新的进程，服务完成后销毁，所以效率上低于 Servlet。\n\n\n# Servlet 版本以及主要特性\n\n版本            日期            JAVA EE/JDK 版本       特性\nServlet 4.0   2017 年 10 月   JavaEE 8             HTTP2\nServlet 3.1   2013 年 5 月    JavaEE 7             非阻塞 I/O，HTTP 协议升级机制\nServlet 3.0   2009 年 12 月   JavaEE 6, JavaSE 6   可插拔性，易于开发，异步 Servlet，安全性，文件上传\nServlet 2.5   2005 年 10 月   JavaEE 5, JavaSE 5   依赖 JavaSE 5，支持注解\nServlet 2.4   2003 年 11 月   J2EE 1.4, J2SE 1.3   web.xml 使用 XML Schema\nServlet 2.3   2001 年 8 月    J2EE 1.3, J2SE 1.2   Filter\nServlet 2.2   1999 年 8 月    J2EE 1.2, J2SE 1.2   成为 J2EE 标准\nServlet 2.1   1998 年 11 月   未指定                  First official specification, added RequestDispatcher,\n                                                 ServletContext\nServlet 2.0                 JDK 1.1              Part of Java Servlet Development Kit 2.0\nServlet 1.0   1997 年 6 月                         \n\n\n# Servlet 任务\n\nServlet 执行以下主要任务：\n\n * 读取客户端（浏览器）发送的显式的数据。这包括网页上的 HTML 表单，或者也可以是来自 applet 或自定义的 HTTP 客户端程序的表单。\n * 读取客户端（浏览器）发送的隐式的 HTTP 请求数据。这包括 cookies、媒体类型和浏览器能理解的压缩格式等等。\n * 处理数据并生成结果。这个过程可能需要访问数据库，执行 RMI 或 CORBA 调用，调用 Web 服务，或者直接计算得出对应的响应。\n * 发送显式的数据（即文档）到客户端（浏览器）。该文档的格式可以是多种多样的，包括文本文件（HTML 或 XML）、二进制文件（GIF 图像）、Excel 等。\n * 发送隐式的 HTTP 响应到客户端（浏览器）。这包括告诉浏览器或其他客户端被返回的文档类型（例如 HTML），设置 cookies 和缓存参数，以及其他类似的任务。\n\n\n# Servlet 生命周期\n\n\n\nServlet 生命周期如下：\n\n 1. 加载 - 第一个到达服务器的 HTTP 请求被委派到 Servlet 容器。容器通过类加载器使用 Servlet 类对应的文件加载 servlet；\n 2. 初始化 - Servlet 通过调用 init () 方法进行初始化。\n 3. 服务 - Servlet 调用 service() 方法来处理客户端的请求。\n 4. 销毁 - Servlet 通过调用 destroy() 方法终止（结束）。\n 5. 卸载 - Servlet 是由 JVM 的垃圾回收器进行垃圾回收的。\n\n\n# Servlet API\n\n\n# Servlet 包\n\nJava Servlet 是运行在带有支持 Java Servlet 规范的解释器的 web 服务器上的 Java 类。\n\nServlet 可以使用 javax.servlet 和 javax.servlet.http 包创建，它是 Java 企业版的标准组成部分，Java 企业版是支持大型开发项目的 Java 类库的扩展版本。\n\nJava Servlet 就像任何其他的 Java 类一样已经被创建和编译。在您安装 Servlet 包并把它们添加到您的计算机上的 Classpath 类路径中之后，您就可以通过 JDK 的 Java 编译器或任何其他编译器来编译 Servlet。\n\n\n# Servlet 接口\n\nServlet 接口定义了下面五个方法：\n\npublic interface Servlet {\n    void init(ServletConfig var1) throws ServletException;\n\n    ServletConfig getServletConfig();\n\n    void service(ServletRequest var1, ServletResponse var2) throws ServletException, IOException;\n\n    String getServletInfo();\n\n    void destroy();\n}\n\n\n# init() 方法\n\ninit 方法被设计成只调用一次。它在第一次创建 Servlet 时被调用，在后续每次用户请求时不再调用。因此，它是用于一次性初始化，就像 Applet 的 init 方法一样。\n\nServlet 创建于用户第一次调用对应于该 Servlet 的 URL 时，但是您也可以指定 Servlet 在服务器第一次启动时被加载。\n\n当用户调用一个 Servlet 时，就会创建一个 Servlet 实例，每一个用户请求都会产生一个新的线程，适当的时候移交给 doGet 或 doPost 方法。init() 方法简单地创建或加载一些数据，这些数据将被用于 Servlet 的整个生命周期。\n\ninit 方法的定义如下：\n\npublic void init() throws ServletException {\n  // 初始化代码...\n}\n\n\n# service() 方法\n\nservice() 方法是执行实际任务的核心方法。Servlet 容器（即 Web 服务器）调用 service() 方法来处理来自客户端（浏览器）的请求，并把格式化的响应写回给客户端。\n\nservice() 方法有两个参数：ServletRequest 和 ServletResponse。ServletRequest 用来封装请求信息，ServletResponse 用来封装响应信息，因此本质上这两个类是对通信协议的封装。\n\n每次服务器接收到一个 Servlet 请求时，服务器会产生一个新的线程并调用服务。service() 方法检查 HTTP 请求类型（GET、POST、PUT、DELETE 等），并在适当的时候调用 doGet、doPost、doPut，doDelete 等方法。\n\n下面是该方法的特征：\n\npublic void service(ServletRequest request,\n                    ServletResponse response)\n      throws ServletException, IOException{\n}\n\n\nservice() 方法由容器调用，service 方法在适当的时候调用 doGet、doPost、doPut、doDelete 等方法。所以，您不用对 service() 方法做任何动作，您只需要根据来自客户端的请求类型来重写 doGet() 或 doPost() 即可。\n\ndoGet() 和 doPost() 方法是每次服务请求中最常用的方法。下面是这两种方法的特征。\n\n# doGet() 方法\n\nGET 请求来自于一个 URL 的正常请求，或者来自于一个未指定 METHOD 的 HTML 表单，它由 doGet() 方法处理。\n\npublic void doGet(HttpServletRequest request,\n                  HttpServletResponse response)\n    throws ServletException, IOException {\n    // Servlet 代码\n}\n\n\n# doPost() 方法\n\nPOST 请求来自于一个特别指定了 METHOD 为 POST 的 HTML 表单，它由 doPost() 方法处理。\n\npublic void doPost(HttpServletRequest request,\n                   HttpServletResponse response)\n    throws ServletException, IOException {\n    // Servlet 代码\n}\n\n\n# destroy() 方法\n\ndestroy() 方法只会被调用一次，在 Servlet 生命周期结束时被调用。destroy() 方法可以让您的 Servlet 关闭数据库连接、停止后台线程、把 Cookie 列表或点击计数器写入到磁盘，并执行其他类似的清理活动。\n\n在调用 destroy() 方法之后，servlet 对象被标记为垃圾回收。destroy 方法定义如下所示：\n\n  public void destroy() {\n    // 终止化代码...\n  }\n\n\n\n# Servlet 和 HTTP 状态码\n\ntitle: JavaEE Servlet HTTP 状态码 date: 2017-11-08 categories:\n\n * javaee tags:\n * javaee\n * servlet\n * http\n\n\n# HTTP 状态码\n\nHTTP 请求和 HTTP 响应消息的格式是类似的，结构如下：\n\n * 初始状态行 + 回车换行符（回车+换行）\n * 零个或多个标题行+回车换行符\n * 一个空白行，即回车换行符\n * 一个可选的消息主体，比如文件、查询数据或查询输出\n\n例如，服务器的响应头如下所示：\n\nHTTP/1.1 200 OK\nContent-Type: text/html\nHeader2: ...\n...\nHeaderN: ...\n  (Blank Line)\n<!doctype ...>\n<html>\n<head>...</head>\n<body>\n...\n</body>\n</html>\n\n\n状态行包括 HTTP 版本（在本例中为 HTTP/1.1）、一个状态码（在本例中为 200）和一个对应于状态码的短消息（在本例中为 OK）。\n\n以下是可能从 Web 服务器返回的 HTTP 状态码和相关的信息列表：\n\n * 1**：信息性状态码\n * 2**：成功状态码\n   * 200：请求正常成功\n   * 204：指示请求成功但没有返回新信息\n   * 206：指示服务器已完成对资源的部分 GET 请求\n * 3**：重定向状态码\n   * 301：永久性重定向\n   * 302：临时性重定向\n   * 304：服务器端允许请求访问资源，但未满足条件\n * 4**：客户端错误状态码\n   * 400：请求报文中存在语法错误\n   * 401：发送的请求需要有通过 HTTP 认证的认证信息\n   * 403：对请求资源的访问被服务器拒绝了\n   * 404：服务器上无法找到请求的资源\n * 5**：服务器错误状态码\n   * 500：服务器端在执行请求时发生了错误\n   * 503：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求\n\n\n# 设置 HTTP 状态码的方法\n\n下面的方法可用于在 Servlet 程序中设置 HTTP 状态码。这些方法通过 HttpServletResponse 对象可用。\n\n序号   方法 & 描述\n1    **public void setStatus ( int statusCode\n     )**该方法设置一个任意的状态码。setStatus 方法接受一个\n     int（状态码）作为参数。如果您的反应包含了一个特殊的状态码和文档，请确保在使用 PrintWriter\n     实际返回任何内容之前调用 setStatus。\n2    **public void sendRedirect(String url)**该方法生成一个 302\n     响应，连同一个带有新文档 URL 的 Location 头。\n3    **public void sendError(int code, String\n     message)**该方法发送一个状态码（通常为 404），连同一个在 HTML\n     文档内部自动格式化并发送到客户端的短消息。\n\n\n# HTTP 状态码实例\n\n下面的例子把 407 错误代码发送到客户端浏览器，浏览器会显示 "Need authentication!!!" 消息。\n\n// 导入必需的 java 库\nimport java.io.*;\nimport javax.servlet.*;\nimport javax.servlet.http.*;\nimport java.util.*;\n\n// 扩展 HttpServlet 类\npublic class showError extends HttpServlet {\n\n  // 处理 GET 方法请求的方法\n  public void doGet(HttpServletRequest request,\n                    HttpServletResponse response)\n            throws ServletException, IOException\n  {\n      // 设置错误代码和原因\n      response.sendError(407, "Need authentication!!!" );\n  }\n  // 处理 POST 方法请求的方法\n  public void doPost(HttpServletRequest request,\n                     HttpServletResponse response)\n      throws ServletException, IOException {\n     doGet(request, response);\n  }\n}\n\n\n现在，调用上面的 Servlet 将显示以下结果：\n\nHTTP Status 407 - Need authentication!!!\ntype Status report\nmessage Need authentication!!!\ndescription The client must first authenticate itself with the proxy (Need authentication!!!).\nApache Tomcat/5.5.29\n\n\n\n# 参考资料\n\n * 深入拆解 Tomcat & Jetty\n * Java Web 整合开发王者归来',normalizedContent:'# javaweb 之 servlet 指南\n\n\n# javaweb 简介\n\n\n# web 应用程序\n\nweb，在英语中 web 即表示网页的意思，它用于表示 internet 主机上供外界访问的资源。\n\nweb 应用程序是一种可以通过 web 访问的应用程序，程序的最大好处是用户很容易访问应用程序，用户只需要有浏览器即可，不需要再安装其他软件。\n\ninternet 上供外界访问的 web 资源分为：\n\n * 静态 web 资源：指 web 页面中供人们浏览的数据始终是不变。常见静态资源文件：html、css、各种图片类型（jpg、png）\n * 动态 web 资源：指 web 页面中供人们浏览的数据是由程序产生的，不同时间点访问 web 页面看到的内容各不相同。常见动态资源技术：jsp/servlet、asp、php\n\n\n# 常见 web 服务器\n\n * tomcat\n * jetty\n * resin\n * apache\n * nginx\n * websphere\n * weblogic\n * jboss\n\n\n# servlet 简介\n\n\n# 什么是 servlet\n\nservlet（server applet），即小服务程序或服务连接器。servlet 是 java 编写的服务器端程序，具有独立于平台和协议的特性，主要功能在于交互式地浏览和生成数据，生成动态 web 内容。\n\n * 狭义的 servlet 是指 java 实现的一个接口。\n * 广义的 servlet 是指任何实现了这个 servlet 接口的类。\n\nservlet 运行于支持 java 的应用服务器中。从原理上讲，servlet 可以响应任何类型的请求，但绝大多数情况下 servlet 只用来扩展基于 http 协议的 web 服务器。\n\n\n# servlet 和 cgi 的区别\n\nservlet 技术出现之前，web 主要使用 cgi 技术。它们的区别如下：\n\n * servlet 是基于 java 编写的，处于服务器进程中，他能够通过多线程方式运行 service() 方法，一个实例可以服务于多个请求，而且一般不会销毁；\n * cgi(common gateway interface)，即通用网关接口。它会为每个请求产生新的进程，服务完成后销毁，所以效率上低于 servlet。\n\n\n# servlet 版本以及主要特性\n\n版本            日期            java ee/jdk 版本       特性\nservlet 4.0   2017 年 10 月   javaee 8             http2\nservlet 3.1   2013 年 5 月    javaee 7             非阻塞 i/o，http 协议升级机制\nservlet 3.0   2009 年 12 月   javaee 6, javase 6   可插拔性，易于开发，异步 servlet，安全性，文件上传\nservlet 2.5   2005 年 10 月   javaee 5, javase 5   依赖 javase 5，支持注解\nservlet 2.4   2003 年 11 月   j2ee 1.4, j2se 1.3   web.xml 使用 xml schema\nservlet 2.3   2001 年 8 月    j2ee 1.3, j2se 1.2   filter\nservlet 2.2   1999 年 8 月    j2ee 1.2, j2se 1.2   成为 j2ee 标准\nservlet 2.1   1998 年 11 月   未指定                  first official specification, added requestdispatcher,\n                                                 servletcontext\nservlet 2.0                 jdk 1.1              part of java servlet development kit 2.0\nservlet 1.0   1997 年 6 月                         \n\n\n# servlet 任务\n\nservlet 执行以下主要任务：\n\n * 读取客户端（浏览器）发送的显式的数据。这包括网页上的 html 表单，或者也可以是来自 applet 或自定义的 http 客户端程序的表单。\n * 读取客户端（浏览器）发送的隐式的 http 请求数据。这包括 cookies、媒体类型和浏览器能理解的压缩格式等等。\n * 处理数据并生成结果。这个过程可能需要访问数据库，执行 rmi 或 corba 调用，调用 web 服务，或者直接计算得出对应的响应。\n * 发送显式的数据（即文档）到客户端（浏览器）。该文档的格式可以是多种多样的，包括文本文件（html 或 xml）、二进制文件（gif 图像）、excel 等。\n * 发送隐式的 http 响应到客户端（浏览器）。这包括告诉浏览器或其他客户端被返回的文档类型（例如 html），设置 cookies 和缓存参数，以及其他类似的任务。\n\n\n# servlet 生命周期\n\n\n\nservlet 生命周期如下：\n\n 1. 加载 - 第一个到达服务器的 http 请求被委派到 servlet 容器。容器通过类加载器使用 servlet 类对应的文件加载 servlet；\n 2. 初始化 - servlet 通过调用 init () 方法进行初始化。\n 3. 服务 - servlet 调用 service() 方法来处理客户端的请求。\n 4. 销毁 - servlet 通过调用 destroy() 方法终止（结束）。\n 5. 卸载 - servlet 是由 jvm 的垃圾回收器进行垃圾回收的。\n\n\n# servlet api\n\n\n# servlet 包\n\njava servlet 是运行在带有支持 java servlet 规范的解释器的 web 服务器上的 java 类。\n\nservlet 可以使用 javax.servlet 和 javax.servlet.http 包创建，它是 java 企业版的标准组成部分，java 企业版是支持大型开发项目的 java 类库的扩展版本。\n\njava servlet 就像任何其他的 java 类一样已经被创建和编译。在您安装 servlet 包并把它们添加到您的计算机上的 classpath 类路径中之后，您就可以通过 jdk 的 java 编译器或任何其他编译器来编译 servlet。\n\n\n# servlet 接口\n\nservlet 接口定义了下面五个方法：\n\npublic interface servlet {\n    void init(servletconfig var1) throws servletexception;\n\n    servletconfig getservletconfig();\n\n    void service(servletrequest var1, servletresponse var2) throws servletexception, ioexception;\n\n    string getservletinfo();\n\n    void destroy();\n}\n\n\n# init() 方法\n\ninit 方法被设计成只调用一次。它在第一次创建 servlet 时被调用，在后续每次用户请求时不再调用。因此，它是用于一次性初始化，就像 applet 的 init 方法一样。\n\nservlet 创建于用户第一次调用对应于该 servlet 的 url 时，但是您也可以指定 servlet 在服务器第一次启动时被加载。\n\n当用户调用一个 servlet 时，就会创建一个 servlet 实例，每一个用户请求都会产生一个新的线程，适当的时候移交给 doget 或 dopost 方法。init() 方法简单地创建或加载一些数据，这些数据将被用于 servlet 的整个生命周期。\n\ninit 方法的定义如下：\n\npublic void init() throws servletexception {\n  // 初始化代码...\n}\n\n\n# service() 方法\n\nservice() 方法是执行实际任务的核心方法。servlet 容器（即 web 服务器）调用 service() 方法来处理来自客户端（浏览器）的请求，并把格式化的响应写回给客户端。\n\nservice() 方法有两个参数：servletrequest 和 servletresponse。servletrequest 用来封装请求信息，servletresponse 用来封装响应信息，因此本质上这两个类是对通信协议的封装。\n\n每次服务器接收到一个 servlet 请求时，服务器会产生一个新的线程并调用服务。service() 方法检查 http 请求类型（get、post、put、delete 等），并在适当的时候调用 doget、dopost、doput，dodelete 等方法。\n\n下面是该方法的特征：\n\npublic void service(servletrequest request,\n                    servletresponse response)\n      throws servletexception, ioexception{\n}\n\n\nservice() 方法由容器调用，service 方法在适当的时候调用 doget、dopost、doput、dodelete 等方法。所以，您不用对 service() 方法做任何动作，您只需要根据来自客户端的请求类型来重写 doget() 或 dopost() 即可。\n\ndoget() 和 dopost() 方法是每次服务请求中最常用的方法。下面是这两种方法的特征。\n\n# doget() 方法\n\nget 请求来自于一个 url 的正常请求，或者来自于一个未指定 method 的 html 表单，它由 doget() 方法处理。\n\npublic void doget(httpservletrequest request,\n                  httpservletresponse response)\n    throws servletexception, ioexception {\n    // servlet 代码\n}\n\n\n# dopost() 方法\n\npost 请求来自于一个特别指定了 method 为 post 的 html 表单，它由 dopost() 方法处理。\n\npublic void dopost(httpservletrequest request,\n                   httpservletresponse response)\n    throws servletexception, ioexception {\n    // servlet 代码\n}\n\n\n# destroy() 方法\n\ndestroy() 方法只会被调用一次，在 servlet 生命周期结束时被调用。destroy() 方法可以让您的 servlet 关闭数据库连接、停止后台线程、把 cookie 列表或点击计数器写入到磁盘，并执行其他类似的清理活动。\n\n在调用 destroy() 方法之后，servlet 对象被标记为垃圾回收。destroy 方法定义如下所示：\n\n  public void destroy() {\n    // 终止化代码...\n  }\n\n\n\n# servlet 和 http 状态码\n\ntitle: javaee servlet http 状态码 date: 2017-11-08 categories:\n\n * javaee tags:\n * javaee\n * servlet\n * http\n\n\n# http 状态码\n\nhttp 请求和 http 响应消息的格式是类似的，结构如下：\n\n * 初始状态行 + 回车换行符（回车+换行）\n * 零个或多个标题行+回车换行符\n * 一个空白行，即回车换行符\n * 一个可选的消息主体，比如文件、查询数据或查询输出\n\n例如，服务器的响应头如下所示：\n\nhttp/1.1 200 ok\ncontent-type: text/html\nheader2: ...\n...\nheadern: ...\n  (blank line)\n<!doctype ...>\n<html>\n<head>...</head>\n<body>\n...\n</body>\n</html>\n\n\n状态行包括 http 版本（在本例中为 http/1.1）、一个状态码（在本例中为 200）和一个对应于状态码的短消息（在本例中为 ok）。\n\n以下是可能从 web 服务器返回的 http 状态码和相关的信息列表：\n\n * 1**：信息性状态码\n * 2**：成功状态码\n   * 200：请求正常成功\n   * 204：指示请求成功但没有返回新信息\n   * 206：指示服务器已完成对资源的部分 get 请求\n * 3**：重定向状态码\n   * 301：永久性重定向\n   * 302：临时性重定向\n   * 304：服务器端允许请求访问资源，但未满足条件\n * 4**：客户端错误状态码\n   * 400：请求报文中存在语法错误\n   * 401：发送的请求需要有通过 http 认证的认证信息\n   * 403：对请求资源的访问被服务器拒绝了\n   * 404：服务器上无法找到请求的资源\n * 5**：服务器错误状态码\n   * 500：服务器端在执行请求时发生了错误\n   * 503：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求\n\n\n# 设置 http 状态码的方法\n\n下面的方法可用于在 servlet 程序中设置 http 状态码。这些方法通过 httpservletresponse 对象可用。\n\n序号   方法 & 描述\n1    **public void setstatus ( int statuscode\n     )**该方法设置一个任意的状态码。setstatus 方法接受一个\n     int（状态码）作为参数。如果您的反应包含了一个特殊的状态码和文档，请确保在使用 printwriter\n     实际返回任何内容之前调用 setstatus。\n2    **public void sendredirect(string url)**该方法生成一个 302\n     响应，连同一个带有新文档 url 的 location 头。\n3    **public void senderror(int code, string\n     message)**该方法发送一个状态码（通常为 404），连同一个在 html\n     文档内部自动格式化并发送到客户端的短消息。\n\n\n# http 状态码实例\n\n下面的例子把 407 错误代码发送到客户端浏览器，浏览器会显示 "need authentication!!!" 消息。\n\n// 导入必需的 java 库\nimport java.io.*;\nimport javax.servlet.*;\nimport javax.servlet.http.*;\nimport java.util.*;\n\n// 扩展 httpservlet 类\npublic class showerror extends httpservlet {\n\n  // 处理 get 方法请求的方法\n  public void doget(httpservletrequest request,\n                    httpservletresponse response)\n            throws servletexception, ioexception\n  {\n      // 设置错误代码和原因\n      response.senderror(407, "need authentication!!!" );\n  }\n  // 处理 post 方法请求的方法\n  public void dopost(httpservletrequest request,\n                     httpservletresponse response)\n      throws servletexception, ioexception {\n     doget(request, response);\n  }\n}\n\n\n现在，调用上面的 servlet 将显示以下结果：\n\nhttp status 407 - need authentication!!!\ntype status report\nmessage need authentication!!!\ndescription the client must first authenticate itself with the proxy (need authentication!!!).\napache tomcat/5.5.29\n\n\n\n# 参考资料\n\n * 深入拆解 tomcat & jetty\n * java web 整合开发王者归来',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"JavaWeb 之 Jsp 指南",frontmatter:{title:"JavaWeb 之 Jsp 指南",categories:["编程","Java","JavaWeb"],tags:["Java","JavaWeb","JSP"],abbrlink:"339b3115",date:"2020-02-07T23:04:47.000Z",permalink:"/pages/6bbb16/"},regularPath:"/02.JavaEE/01.JavaWeb/02.JavaWeb%E4%B9%8BJsp%E6%8C%87%E5%8D%97.html",relativePath:"02.JavaEE/01.JavaWeb/02.JavaWeb之Jsp指南.md",key:"v-27772cc0",path:"/pages/6bbb16/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:23},{level:3,title:"什么是 Java Server Pages",slug:"什么是-java-server-pages",normalizedTitle:"什么是 java server pages",charIndex:30},{level:3,title:"为什么使用 JSP",slug:"为什么使用-jsp",normalizedTitle:"为什么使用 jsp",charIndex:361},{level:3,title:"JSP 的优势",slug:"jsp-的优势",normalizedTitle:"jsp 的优势",charIndex:793},{level:2,title:"JSP 工作原理",slug:"jsp-工作原理",normalizedTitle:"jsp 工作原理",charIndex:1141},{level:3,title:"JSP 工作流程",slug:"jsp-工作流程",normalizedTitle:"jsp 工作流程",charIndex:1374},{level:4,title:"工作步骤",slug:"工作步骤",normalizedTitle:"工作步骤",charIndex:1586},{level:3,title:"JSP 生命周期",slug:"jsp-生命周期",normalizedTitle:"jsp 生命周期",charIndex:2292},{level:4,title:"JSP 编译",slug:"jsp-编译",normalizedTitle:"jsp 编译",charIndex:2685},{level:4,title:"JSP 初始化",slug:"jsp-初始化",normalizedTitle:"jsp 初始化",charIndex:2841},{level:4,title:"JSP 执行",slug:"jsp-执行",normalizedTitle:"jsp 执行",charIndex:3050},{level:4,title:"JSP 清理",slug:"jsp-清理",normalizedTitle:"jsp 清理",charIndex:3445},{level:2,title:"语法",slug:"语法",normalizedTitle:"语法",charIndex:3655},{level:3,title:"脚本",slug:"脚本",normalizedTitle:"脚本",charIndex:572},{level:4,title:"中文编码问题",slug:"中文编码问题",normalizedTitle:"中文编码问题",charIndex:4260},{level:3,title:"JSP 声明",slug:"jsp-声明",normalizedTitle:"jsp 声明",charIndex:4739},{level:3,title:"JSP 表达式",slug:"jsp-表达式",normalizedTitle:"jsp 表达式",charIndex:5037},{level:3,title:"JSP 注释",slug:"jsp-注释",normalizedTitle:"jsp 注释",charIndex:5688},{level:3,title:"控制语句",slug:"控制语句",normalizedTitle:"控制语句",charIndex:6333},{level:4,title:"if…else 语句",slug:"if-else-语句",normalizedTitle:"if…else 语句",charIndex:6416},{level:4,title:"switch…case 语句",slug:"switch-case-语句",normalizedTitle:"switch…case 语句",charIndex:6862},{level:4,title:"循环语句",slug:"循环语句",normalizedTitle:"循环语句",charIndex:6405},{level:3,title:"JSP 字面量",slug:"jsp-字面量",normalizedTitle:"jsp 字面量",charIndex:9415},{level:2,title:"指令",slug:"指令",normalizedTitle:"指令",charIndex:9572},{level:3,title:"Page 指令",slug:"page-指令",normalizedTitle:"page 指令",charIndex:9886},{level:4,title:"属性",slug:"属性",normalizedTitle:"属性",charIndex:6293},{level:3,title:"Include 指令",slug:"include-指令",normalizedTitle:"include 指令",charIndex:10725},{level:3,title:"Taglib 指令",slug:"taglib-指令",normalizedTitle:"taglib 指令",charIndex:11015},{level:2,title:"JSP 动作元素",slug:"jsp-动作元素",normalizedTitle:"jsp 动作元素",charIndex:11268},{level:3,title:"常见的属性",slug:"常见的属性",normalizedTitle:"常见的属性",charIndex:12037},{level:3,title:"<jsp:include>",slug:"jsp-include",normalizedTitle:'<a href="jsp:include">jsp:include</a>',charIndex:null},{level:3,title:"<jsp:useBean>",slug:"jsp-usebean",normalizedTitle:'<a href="jsp:usebean">jsp:usebean</a>',charIndex:null},{level:3,title:"<jsp:setProperty>",slug:"jsp-setproperty",normalizedTitle:'<a href="jsp:setproperty">jsp:setproperty</a>',charIndex:null},{level:3,title:"<jsp:getProperty>",slug:"jsp-getproperty",normalizedTitle:'<a href="jsp:getproperty">jsp:getproperty</a>',charIndex:null},{level:3,title:"<jsp:forward>",slug:"jsp-forward",normalizedTitle:'<a href="jsp:forward">jsp:forward</a>',charIndex:null},{level:3,title:"<jsp:plugin>",slug:"jsp-plugin",normalizedTitle:'<a href="jsp:plugin">jsp:plugin</a>',charIndex:null},{level:3,title:"<jsp:element> 、 <jsp:attribute>、<jsp:body>",slug:"jsp-element-、-jsp-attribute-、-jsp-body",normalizedTitle:'<a href="jsp:element">jsp:element</a> 、 <a href="jsp:attribute">jsp:attribute</a>、<a href="jsp:body">jsp:body</a>',charIndex:null},{level:3,title:"<jsp:text>",slug:"jsp-text",normalizedTitle:'<a href="jsp:text">jsp:text</a>',charIndex:null},{level:2,title:"JSP 隐式对象",slug:"jsp-隐式对象",normalizedTitle:"jsp 隐式对象",charIndex:18958},{level:3,title:"request 对象",slug:"request-对象",normalizedTitle:"request 对象",charIndex:19440},{level:3,title:"response 对象",slug:"response-对象",normalizedTitle:"response 对象",charIndex:19611},{level:3,title:"out 对象",slug:"out-对象",normalizedTitle:"out 对象",charIndex:10213},{level:3,title:"session 对象",slug:"session-对象",normalizedTitle:"session 对象",charIndex:20277},{level:3,title:"application 对象",slug:"application-对象",normalizedTitle:"application 对象",charIndex:20401},{level:3,title:"config 对象",slug:"config-对象",normalizedTitle:"config 对象",charIndex:20636},{level:3,title:"pageContext 对象",slug:"pagecontext-对象",normalizedTitle:"pagecontext 对象",charIndex:20911},{level:3,title:"page 对象",slug:"page-对象",normalizedTitle:"page 对象",charIndex:21494},{level:3,title:"exception 对象",slug:"exception-对象",normalizedTitle:"exception 对象",charIndex:21563},{level:2,title:"EL 表达式",slug:"el-表达式",normalizedTitle:"el 表达式",charIndex:10681},{level:3,title:"一个简单的语法",slug:"一个简单的语法",normalizedTitle:"一个简单的语法",charIndex:21843},{level:3,title:"EL 中的基础操作符",slug:"el-中的基础操作符",normalizedTitle:"el 中的基础操作符",charIndex:22724},{level:3,title:"JSP EL 中的函数",slug:"jsp-el-中的函数",normalizedTitle:"jsp el 中的函数",charIndex:23136},{level:3,title:"JSP EL 隐含对象",slug:"jsp-el-隐含对象",normalizedTitle:"jsp el 隐含对象",charIndex:23452},{level:3,title:"pageContext 对象",slug:"pagecontext-对象-2",normalizedTitle:"pagecontext 对象",charIndex:20911},{level:3,title:"Scope 对象",slug:"scope-对象",normalizedTitle:"scope 对象",charIndex:24082},{level:3,title:"param 和 paramValues 对象",slug:"param-和-paramvalues-对象",normalizedTitle:"param 和 paramvalues 对象",charIndex:24244},{level:3,title:"header 和 headerValues 对象",slug:"header-和-headervalues-对象",normalizedTitle:"header 和 headervalues 对象",charIndex:24842},{level:2,title:"JSTL",slug:"jstl",normalizedTitle:"jstl",charIndex:23325},{level:3,title:"JSTL 库安装",slug:"jstl-库安装",normalizedTitle:"jstl 库安装",charIndex:25675},{level:3,title:"核心标签",slug:"核心标签",normalizedTitle:"核心标签",charIndex:25626},{level:3,title:"格式化标签",slug:"格式化标签",normalizedTitle:"格式化标签",charIndex:25634},{level:3,title:"SQL 标签",slug:"sql-标签",normalizedTitle:"sql 标签",charIndex:25549},{level:3,title:"XML 标签",slug:"xml-标签",normalizedTitle:"xml 标签",charIndex:25653},{level:3,title:"JSTL 函数",slug:"jstl-函数",normalizedTitle:"jstl 函数",charIndex:25663},{level:2,title:"Taglib",slug:"taglib",normalizedTitle:"taglib",charIndex:11015},{level:3,title:"JSP 自定义标签",slug:"jsp-自定义标签",normalizedTitle:"jsp 自定义标签",charIndex:30920},{level:3,title:'创建"Hello"标签',slug:"创建-hello-标签",normalizedTitle:"创建&quot;hello&quot;标签",charIndex:null},{level:3,title:"访问标签体",slug:"访问标签体",normalizedTitle:"访问标签体",charIndex:32281},{level:3,title:"自定义标签属性",slug:"自定义标签属性",normalizedTitle:"自定义标签属性",charIndex:33335}],headersStr:'简介 什么是 Java Server Pages 为什么使用 JSP JSP 的优势 JSP 工作原理 JSP 工作流程 工作步骤 JSP 生命周期 JSP 编译 JSP 初始化 JSP 执行 JSP 清理 语法 脚本 中文编码问题 JSP 声明 JSP 表达式 JSP 注释 控制语句 if…else 语句 switch…case 语句 循环语句 JSP 字面量 指令 Page 指令 属性 Include 指令 Taglib 指令 JSP 动作元素 常见的属性 <jsp:include> <jsp:useBean> <jsp:setProperty> <jsp:getProperty> <jsp:forward> <jsp:plugin> <jsp:element> 、 <jsp:attribute>、<jsp:body> <jsp:text> JSP 隐式对象 request 对象 response 对象 out 对象 session 对象 application 对象 config 对象 pageContext 对象 page 对象 exception 对象 EL 表达式 一个简单的语法 EL 中的基础操作符 JSP EL 中的函数 JSP EL 隐含对象 pageContext 对象 Scope 对象 param 和 paramValues 对象 header 和 headerValues 对象 JSTL JSTL 库安装 核心标签 格式化标签 SQL 标签 XML 标签 JSTL 函数 Taglib JSP 自定义标签 创建"Hello"标签 访问标签体 自定义标签属性',content:'# JavaWeb 之 Jsp 指南\n\n\n# 简介\n\n\n# 什么是 Java Server Pages\n\nJSP全称Java Server Pages，是一种动态网页开发技术。\n\n它使用 JSP 标签在 HTML 网页中插入 Java 代码。标签通常以<%开头以%>结束。\n\nJSP 是一种 Java servlet，主要用于实现 Java web 应用程序的用户界面部分。网页开发者们通过结合 HTML 代码、XHTML 代码、XML 元素以及嵌入 JSP 操作和命令来编写 JSP。\n\nJSP 通过网页表单获取用户输入数据、访问数据库及其他数据源，然后动态地创建网页。\n\nJSP 标签有多种功能，比如访问数据库、记录用户选择信息、访问 JavaBeans 组件等，还可以在不同的网页中传递控制信息和共享信息。\n\n\n# 为什么使用 JSP\n\nJSP 也是一种 Servlet，因此 JSP 能够完成 Servlet 能完成的任何工作。\n\nJSP 程序与 CGI 程序有着相似的功能，但和 CGI 程序相比，JSP 程序有如下优势：\n\n * 性能更加优越，因为 JSP 可以直接在 HTML 网页中动态嵌入元素而不需要单独引用 CGI 文件。\n * 服务器调用的是已经编译好的 JSP 文件，而不像 CGI/Perl 那样必须先载入解释器和目标脚本。\n * JSP 基于 Java Servlets API，因此，JSP 拥有各种强大的企业级 Java API，包括 JDBC，JNDI，EJB，JAXP 等等。\n * JSP 页面可以与处理业务逻辑的 servlets 一起使用，这种模式被 Java servlet 模板引擎所支持。\n\n最后，JSP 是 Java EE 不可或缺的一部分，是一个完整的企业级应用平台。这意味着 JSP 可以用最简单的方式来实现最复杂的应用。\n\n\n# JSP 的优势\n\n以下列出了使用 JSP 带来的其他好处：\n\n * 与 ASP 相比：JSP 有两大优势。首先，动态部分用 Java 编写，而不是 VB 或其他 MS 专用语言，所以更加强大与易用。第二点就是 JSP 易于移植到非 MS 平台上。\n * 与纯 Servlets 相比：JSP 可以很方便的编写或者修改 HTML 网页而不用去面对大量的 println 语句。\n * 与 SSI 相比：SSI 无法使用表单数据、无法进行数据库链接。\n * 与 JavaScript 相比：虽然 JavaScript 可以在客户端动态生成 HTML，但是很难与服务器交互，因此不能提供复杂的服务，比如访问数据库和图像处理等等。\n * 与静态 HTML 相比：静态 HTML 不包含动态信息。\n\n\n# JSP 工作原理\n\nJSP 是一种 Servlet，但工作方式和 Servlet 有所差别。\n\nServlet 是先将源代码编译为 class 文件后部署到服务器下的，先编译后部署。\n\nJsp 是先将源代码部署到服务器再编译，先部署后编译。\n\nJsp 会在客户端第一次请求 Jsp 文件时被编译为 HttpJspPage 类（Servlet 的一个子类）。该类会被服务器临时存放在服务器工作目录里。所以，第一次请求 Jsp 后，访问速度会变快就是这个道理。\n\n\n# JSP 工作流程\n\n网络服务器需要一个 JSP 引擎，也就是一个容器来处理 JSP 页面。容器负责截获对 JSP 页面的请求。本教程使用内嵌 JSP 容器的 Apache 来支持 JSP 开发。\n\nJSP 容器与 Web 服务器协同合作，为 JSP 的正常运行提供必要的运行环境和其他服务，并且能够正确识别专属于 JSP 网页的特殊元素。\n\n下图显示了 JSP 容器和 JSP 文件在 Web 应用中所处的位置。\n\n\n\n# 工作步骤\n\n以下步骤表明了 Web 服务器是如何使用 JSP 来创建网页的：\n\n * 就像其他普通的网页一样，您的浏览器发送一个 HTTP 请求给服务器。\n * Web 服务器识别出这是一个对 JSP 网页的请求，并且将该请求传递给 JSP 引擎。通过使用 URL 或者.jsp 文件来完成。\n * JSP 引擎从磁盘中载入 JSP 文件，然后将它们转化为 servlet。这种转化只是简单地将所有模板文本改用 println()语句，并且将所有的 JSP 元素转化成 Java 代码。\n * JSP 引擎将 servlet 编译成可执行类，并且将原始请求传递给 servlet 引擎。\n * Web 服务器的某组件将会调用 servlet 引擎，然后载入并执行 servlet 类。在执行过程中，servlet 产生 HTML 格式的输出并将其内嵌于 HTTP response 中上交给 Web 服务器。\n * Web 服务器以静态 HTML 网页的形式将 HTTP response 返回到您的浏览器中。\n * 最终，Web 浏览器处理 HTTP response 中动态产生的 HTML 网页，就好像在处理静态网页一样。\n\n以上提及到的步骤可以用下图来表示：\n\n一般情况下，JSP 引擎会检查 JSP 文件对应的 servlet 是否已经存在，并且检查 JSP 文件的修改日期是否早于 servlet。如果 JSP 文件的修改日期早于对应的 servlet，那么容器就可以确定 JSP 文件没有被修改过并且 servlet 有效。这使得整个流程与其他脚本语言（比如 PHP）相比要高效快捷一些。\n\n\n# JSP 生命周期\n\n理解 JSP 底层功能的关键就是去理解它们所遵守的生命周期。\n\nJSP 生命周期就是从创建到销毁的整个过程，类似于 servlet 生命周期，区别在于 JSP 生命周期还包括将 JSP 文件编译成 servlet。\n\n以下是 JSP 生命周期中所走过的几个阶段：\n\n * **编译阶段：**servlet 容器编译 servlet 源文件，生成 servlet 类\n * **初始化阶段：**加载与 JSP 对应的 servlet 类，创建其实例，并调用它的初始化方法\n * **执行阶段：**调用与 JSP 对应的 servlet 实例的服务方法\n * **销毁阶段：**调用与 JSP 对应的 servlet 实例的销毁方法，然后销毁 servlet 实例\n\n很明显，JSP 生命周期的四个主要阶段和 servlet 生命周期非常相似，下面给出图示：\n\n\n\n# JSP 编译\n\n当浏览器请求 JSP 页面时，JSP 引擎会首先去检查是否需要编译这个文件。如果这个文件没有被编译过，或者在上次编译后被更改过，则编译这个 JSP 文件。\n\n编译的过程包括三个步骤：\n\n * 解析 JSP 文件。\n * 将 JSP 文件转为 servlet。\n * 编译 servlet。\n\n# JSP 初始化\n\n容器载入 JSP 文件后，它会在为请求提供任何服务前调用 jspInit()方法。如果您需要执行自定义的 JSP 初始化任务，复写 jspInit()方法就行了，就像下面这样：\n\npublic void jspInit(){\n  // 初始化代码\n}\n\n\n一般来讲程序只初始化一次，servlet 也是如此。通常情况下您可以在 jspInit()方法中初始化数据库连接、打开文件和创建查询表。\n\n# JSP 执行\n\n这一阶段描述了 JSP 生命周期中一切与请求相关的交互行为，直到被销毁。\n\n当 JSP 网页完成初始化后，JSP 引擎将会调用 _jspService() 方法。\n\n_jspService() 方法需要一个 HttpServletRequest 对象和一个 HttpServletResponse 对象作为它的参数，就像下面这样：\n\nvoid _jspService(HttpServletRequest request,\n                 HttpServletResponse response) {\n   // 服务端处理代码\n}\n\n\n_jspService() 方法在每个 request 中被调用一次并且负责产生与之相对应的 response，并且它还负责产生所有 7 个 HTTP 方法的回应，比如 GET、POST、DELETE 等等。\n\n# JSP 清理\n\nJSP 生命周期的销毁阶段描述了当一个 JSP 网页从容器中被移除时所发生的一切。\n\njspDestroy()方法在 JSP 中等价于 servlet 中的销毁方法。当您需要执行任何清理工作时复写 jspDestroy()方法，比如释放数据库连接或者关闭文件夹等等。\n\njspDestroy()方法的格式如下：\n\npublic void jspDestroy() {\n   // 清理代码\n}\n\n\n\n# 语法\n\n\n# 脚本\n\n脚本程序可以包含任意量的 Java 语句、变量、方法或表达式，只要它们在脚本语言中是有效的。\n\n脚本程序的语法格式：\n\n<% 代码片段 %>\n\n\n或者，您也可以编写与其等价的 XML 语句，就像下面这样：\n\n<jsp:scriptlet>\n  代码片段\n</jsp:scriptlet>\n\n\n任何文本、HTML 标签、JSP 元素必须写在脚本程序的外面。\n\n下面给出一个示例，同时也是本教程的第一个 JSP 示例：\n\n<html>\n  <head>\n    <title>Hello World</title>\n  </head>\n  <body>\n    Hello World!<br />\n    <% out.println("Your IP address is " + request.getRemoteAddr()); %>\n  </body>\n</html>\n\n\n**注意：**请确保 Apache Tomcat 已经安装在 C:\\apache-tomcat-7.0.2 目录下并且运行环境已经正确设置。\n\n将以上代码保存在 hello.jsp 中，然后将它放置在 C:\\apache-tomcat-7.0.2\\webapps\\ROOT 目录下，打开浏览器并在地址栏中输入 http://localhost:8080/hello.jsp 。运行后得到以下结果：\n\n\n\n# 中文编码问题\n\n如果我们要在页面正常显示中文，我们需要在 JSP 文件头部添加以下代码：<>\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%>\n\n\n接下来我们将以上程序修改为：\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%>\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    Hello World!<br />\n    <% out.println("你的 IP 地址 " + request.getRemoteAddr()); %>\n  </body>\n</html>\n\n\n这样中文就可以正常显示了。\n\n\n# JSP 声明\n\n一个声明语句可以声明一个或多个变量、方法，供后面的 Java 代码使用。在 JSP 文件中，您必须先声明这些变量和方法然后才能使用它们。\n\nJSP 声明的语法格式：\n\n<%! declaration; [ declaration; ]+ ... %>\n\n\n或者，您也可以编写与其等价的 XML 语句，就像下面这样：\n\n<jsp:declaration>\n  代码片段\n</jsp:declaration>\n\n\n程序示例：\n\n<%! int i = 0; %> <%! int a, b, c; %> <%! Circle a = new Circle(2.0); %>\n\n\n\n# JSP 表达式\n\n一个 JSP 表达式中包含的脚本语言表达式，先被转化成 String，然后插入到表达式出现的地方。\n\n由于表达式的值会被转化成 String，所以您可以在一个文本行中使用表达式而不用去管它是否是 HTML 标签。\n\n表达式元素中可以包含任何符合 Java 语言规范的表达式，但是不能使用分号来结束表达式。\n\nJSP 表达式的语法格式：\n\n<%= 表达式 %>\n\n\n同样，您也可以编写与之等价的 XML 语句：\n\n<jsp:expression>\n  表达式\n</jsp:expression>\n\n\n程序示例：\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%>\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <p>\n      今天的日期是: <%= (new java.util.Date()).toLocaleString()%>\n    </p>\n  </body>\n</html>\n\n\n运行后得到以下结果：\n\n今天的日期是: 2016-6-25 13:40:07\n\n\n----------------------------------------\n\n\n# JSP 注释\n\nJSP 注释主要有两个作用：为代码作注释以及将某段代码注释掉。\n\nJSP 注释的语法格式：\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%>\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>JSP注释示例</title>\n  </head>\n  <body>\n    <%-- 该部分注释在网页中不会被显示--%>\n    <p>\n      今天的日期是: <%= (new java.util.Date()).toLocaleString()%>\n    </p>\n  </body>\n</html>\n\n\n运行后得到以下结果：\n\n今天的日期是: 2016-6-25 13:41:26\n\n\n不同情况下使用注释的语法规则：\n\n语法             描述\n<%-- 注释 --%>   JSP 注释，注释内容不会被发送至浏览器甚至不会被编译\n\x3c!-- 注释 --\x3e    HTML 注释，通过浏览器查看网页源代码时可以看见注释内容\n<%             代表静态 <%常量\n%>             代表静态 %> 常量\n\'              在属性中使用的单引号\n"              在属性中使用的双引号\n\n\n# 控制语句\n\nJSP 提供对 Java 语言的全面支持。您可以在 JSP 程序中使用 Java API 甚至建立 Java 代码块，包括判断语句和循环语句等等。\n\n# if…else 语句\n\nIf…else块，请看下面这个例子：\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%> <%! int day = 1; %>\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>02.JSP语法 - if...else示例</title>\n  </head>\n  <body>\n    <h3>IF...ELSE 实例</h3>\n    <% if (day == 1 | day == 7) { %>\n    <p>今天是周末</p>\n    <% } else { %>\n    <p>今天不是周末</p>\n    <% } %>\n  </body>\n</html>\n\n\n运行后得到以下结果：\n\nIF...ELSE 实例\n今天不是周末\n\n\n# switch…case 语句\n\n现在来看看 switch…case 块，与 if…else 块有很大的不同，它使用 out.println()，并且整个都装在脚本程序的标签中，就像下面这样：\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%> <%! int day = 3; %>\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>02.JSP语法 - switch...case示例</title>\n  </head>\n  <body>\n    <h3>Sswitch...case示例</h3>\n    <% switch(day) { case 0: out.println("星期天"); break; case 1:\n    out.println("星期一"); break; case 2: out.println("星期二"); break; case 3:\n    out.println("星期三"); break; case 4: out.println("星期四"); break; case 5:\n    out.println("星期五"); break; default: out.println("星期六"); } %>\n  </body>\n</html>\n\n\n浏览器访问，运行后得出以下结果：\n\nSWITCH...CASE 实例\n\n星期三\n\n\n# 循环语句\n\n在 JSP 程序中可以使用 Java 的三个基本循环类型：for，while，和 do…while。\n\n让我们来看看 for 循环的例子，以下输出的不同字体大小的"菜鸟教程"：\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%> <%! int fontSize; %>\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <h3>For 循环实例</h3>\n    <%for ( fontSize = 1; fontSize <= 3; fontSize++){ %>\n    <font color="green" size="<%= fontSize %>">\n      菜鸟教程 </font\n    ><br />\n    <%}%>\n  </body>\n</html>\n\n\n运行后得到以下结果：\n\n\n\n将上例改用 while 循环来写：\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%> <%! int fontSize; %>\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <h3>While 循环实例</h3>\n    <%while ( fontSize <= 3){ %>\n    <font color="green" size="<%= fontSize %>">\n      菜鸟教程 </font\n    ><br />\n    <%fontSize++;%> <%}%>\n  </body>\n</html>\n\n\n浏览器访问，输出结果为（fontSize 初始化为 0，所以多输出了一行）：\n\n\n\nJSP 运算符\n\nJSP 支持所有 Java 逻辑和算术运算符。\n\n下表罗列出了 JSP 常见运算符，优先级从高到底：\n\n类别      操作符                                   结合性\n后缀      () [] . (点运算符)                        左到右\n一元      ++ - - ! ~                            右到左\n可乘性     * / %                                 左到右\n可加性     + -                                   左到右\n移位      >> >>> <<                             左到右\n关系      > >= < <=                             左到右\n相等/不等   == !=                                 左到右\n位与      &                                     左到右\n位异或     ^                                     左到右\n位或      |                                     左到右\n逻辑与     &&                                    左到右\n逻辑或     | |                                   左到右\n条件判断    ?:                                    右到左\n赋值      = += -= \\*= /= %= >>= <<= &= ^= | =   右到左\n逗号      ,                                     左到右\n\n\n# JSP 字面量\n\nJSP 语言定义了以下几个字面量：\n\n * 布尔值(boolean)：true 和 false;\n * 整型(int)：与 Java 中的一样;\n * 浮点型(float)：与 Java 中的一样;\n * 字符串(string)：以单引号或双引号开始和结束;\n * Null：null。\n\n\n# 指令\n\nJSP 指令用来设置整个 JSP 页面相关的属性，如网页的编码方式和脚本语言。\n\nJSP 指令以开<%@开始，以%>结束。\n\nJSP 指令语法格式如下：\n\n<%@ directive attribute="value" %>\n\n\n指令可以有很多个属性，它们以键值对的形式存在，并用逗号隔开。\n\nJSP 中的三种指令标签：\n\n指令                   描述\n<%@ page ... %>      定义网页依赖属性，比如脚本语言、error 页面、缓存需求等等\n<%@ include ... %>   包含其他文件\n<%@ taglib ... %>    引入标签库的定义，可以是自定义标签\n\n\n# Page 指令\n\nPage 指令为容器提供当前页面的使用说明。一个 JSP 页面可以包含多个page指令。\n\nPage 指令的语法格式：\n\n<%@ page attribute="value" %>\n\n\n等价的 XML 格式：\n\n<jsp:directive.page attribute="value" />\n\n\n例：\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8" %>\n\n\n# 属性\n\n下表列出与 Page 指令相关的属性：\n\n属性                   描述\nbuffer               指定 out 对象使用缓冲区的大小\nautoFlush            控制 out 对象的 缓存区\ncontentType          指定当前 JSP 页面的 MIME 类型和字符编码\nerrorPage            指定当 JSP 页面发生异常时需要转向的错误处理页面\nisErrorPage          指定当前页面是否可以作为另一个 JSP 页面的错误处理页面\nextends              指定 servlet 从哪一个类继承\nimport               导入要使用的 Java 类\ninfo                 定义 JSP 页面的描述信息\nisThreadSafe         指定对 JSP 页面的访问是否为线程安全\nlanguage             定义 JSP 页面所用的脚本语言，默认是 Java\nsession              指定 JSP 页面是否使用 session\nisELIgnored          指定是否执行 EL 表达式\nisScriptingEnabled   确定脚本元素能否被使用\n\n\n# Include 指令\n\nJSP 可以通过include指令来包含其他文件。\n\n被包含的文件可以是 JSP 文件、HTML 文件或文本文件。包含的文件就好像是该 JSP 文件的一部分，会被同时编译执行。\n\nInclude 指令的语法格式如下：\n\n<%@ include file="文件相对 url 地址" %>\n\n\ninclude 指令中的文件名实际上是一个相对的 URL 地址。\n\n如果您没有给文件关联一个路径，JSP 编译器默认在当前路径下寻找。\n\n等价的 XML 语法：\n\n<jsp:directive.include file="文件相对 url 地址" />\n\n\n\n# Taglib 指令\n\nJSP 允许用户自定义标签，一个自定义标签库就是自定义标签的集合。\n\ntaglib指令引入一个自定义标签集合的定义，包括库路径、自定义标签。\n\ntaglib指令的语法：\n\n<%@ taglib uri="uri" prefix="prefixOfTag" %>\n\n\nuri 属性确定标签库的位置，prefix 属性指定标签库的前缀。\n\n等价的 XML 语法：\n\n<jsp:directive.taglib uri="uri" prefix="prefixOfTag" />\n\n\n\n# JSP 动作元素\n\nJSP 动作元素是一组 JSP 内置的标签，只需要书写很少的标记代码就能使用 JSP 提供的丰富功能。JSP 动作元素是对常用的 JSP 功能的抽象与封装，包括两种，自定义 JSP 动作元素与标准 JSP 动作元素。\n\n与 JSP 指令元素不同的是，JSP 动作元素在请求处理阶段起作用。JSP 动作元素是用 XML 语法写成的。\n\n利用 JSP 动作可以动态地插入文件、重用 JavaBean 组件、把用户重定向到另外的页面、为 Java 插件生成 HTML 代码。\n\n动作元素只有一种语法，它符合 XML 标准：\n\n<jsp:action_name attribute="value" />\n\n\n动作元素基本上都是预定义的函数，JSP 规范定义了一系列的标准动作，它用 JSP 作为前缀，可用的标准动作元素如下：\n\n语法                描述\njsp:include       在页面被请求的时候引入一个文件。\njsp:useBean       寻找或者实例化一个 JavaBean。\njsp:setProperty   设置 JavaBean 的属性。\njsp:getProperty   输出某个 JavaBean 的属性。\njsp:forward       把请求转到一个新的页面。\njsp:plugin        根据浏览器类型为 Java 插件生成 OBJECT 或 EMBED 标记。\njsp:element       定义动态 XML 元素\njsp:attribute     设置动态定义的 XML 元素属性。\njsp:body          设置动态定义的 XML 元素内容。\njsp:text          在 JSP 页面和文档中使用写入文本的模板\n\n\n# 常见的属性\n\n所有的动作要素都有两个属性：id 属性和 scope 属性。\n\n * **id 属性：**id 属性是动作元素的唯一标识，可以在 JSP 页面中引用。动作元素创建的 id 值可以通过 PageContext 来调用。\n * **scope 属性：**该属性用于识别动作元素的生命周期。 id 属性和 scope 属性有直接关系，scope 属性定义了相关联 id 对象的寿命。 scope 属性有四个可能的值： (a) page, (b)request, (c)session, 和 (d) application。\n\n\n# <jsp:include>\n\n<jsp:include> 用来包含静态和动态的文件。该动作把指定文件插入正在生成的页面。\n\n如果被包含的文件为 JSP 程序，则会先执行 JSP 程序，再将执行结果包含进来。\n\n语法格式如下：\n\n<jsp:include page="相对 URL 地址" flush="true" />\n\n\n前面已经介绍过 include 指令，它是在 JSP 文件被转换成 Servlet 的时候引入文件，而这里的 jsp:include 动作不同，插入文件的时间是在页面被请求的时候。\n\n以下是 include 动作相关的属性列表。\n\n属性      描述\npage    包含在页面中的相对 URL 地址。\nflush   布尔属性，定义在包含资源前是否刷新缓存区。\n\n示例：\n\n以下我们定义了两个文件 date.jsp 和 main.jsp，代码如下所示：\n\ndate.jsp 文件代码：\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%>\n<p>\n  今天的日期是: <%= (new java.util.Date())%>\n</p>\n\n\nmain.jsp 文件代码：\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%>\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <h2>include 动作实例</h2>\n    <jsp:include page="date.jsp" flush="true" />\n  </body>\n</html>\n\n\n现在将以上两个文件放在服务器的根目录下，访问 main.jsp 文件。显示结果如下：\n\ninclude 动作实例\n\n今天的日期是: 2016-6-25 14:08:17\n\n\n\n# <jsp:useBean>\n\njsp:useBean 动作用来加载一个将在 JSP 页面中使用的 JavaBean。\n\n这个功能非常有用，因为它使得我们可以发挥 Java 组件复用的优势。\n\njsp:useBean 动作最简单的语法为：\n\n<jsp:useBean id="name" class="package.class" />\n\n\n在类载入后，我们既可以通过 jsp:setProperty 和 jsp:getProperty 动作来修改和检索 bean 的属性。\n\n以下是 useBean 动作相关的属性列表。\n\n属性         描述\nclass      指定 Bean 的完整包名。\ntype       指定将引用该对象变量的类型。\nbeanName   通过 java.beans.Beans 的 instantiate() 方法指定 Bean 的名字。\n\n在给出具体实例前，让我们先来看下 jsp:setProperty 和 jsp:getProperty 动作元素：\n\n\n# <jsp:setProperty>\n\njsp:setProperty 用来设置已经实例化的 Bean 对象的属性，有两种用法。首先，你可以在 jsp:useBean 元素的外面（后面）使用 jsp:setProperty，如下所示：\n\n<jsp:useBean id="myName" ... />\n...\n<jsp:setProperty name="myName" property="someProperty" .../>\n\n\n此时，不管 jsp:useBean 是找到了一个现有的 Bean，还是新创建了一个 Bean 实例，jsp:setProperty 都会执行。第二种用法是把 jsp:setProperty 放入 jsp:useBean 元素的内部，如下所示：\n\n<jsp:useBean id="myName" ... >\n...\n   <jsp:setProperty name="myName" property="someProperty" .../>\n</jsp:useBean>\n\n\n此时，jsp:setProperty 只有在新建 Bean 实例时才会执行，如果是使用现有实例则不执行 jsp:setProperty。\n\njsp:setProperty 动作有下面四个属性,如下表：\n\n属性         描述\nname       name 属性是必需的。它表示要设置属性的是哪个 Bean。\nproperty   property 属性是必需的。它表示要设置哪个属性。有一个特殊用法：如果 property\n           的值是"*"，表示所有名字和 Bean 属性名字匹配的请求参数都将被传递给相应的属性 set 方法。\nvalue      value 属性是可选的。该属性用来指定 Bean 属性的值。字符串数据会在目标类中通过标准的 valueOf\n           方法自动转换成数字、boolean、Boolean、\n           byte、Byte、char、Character。例如，boolean 和 Boolean\n           类型的属性值（比如"true"）通过 Boolean.valueOf 转换，int 和 Integer\n           类型的属性值（比如"42"）通过 Integer.valueOf 转换。 　　 value 和 param\n           不能同时使用，但可以使用其中任意一个。\nparam      param 是可选的。它指定用哪个请求参数作为 Bean 属性的值。如果当前请求没有参数，则什么事情也不做，系统不会把\n           null 传递给 Bean 属性的 set 方法。因此，你可以让 Bean\n           自己提供默认属性值，只有当请求参数明确指定了新值时才修改默认属性值。\n\n\n# <jsp:getProperty>\n\njsp:getProperty 动作提取指定 Bean 属性的值，转换成字符串，然后输出。语法格式如下：\n\n<jsp:useBean id="myName" ... />\n...\n<jsp:getProperty name="myName" property="someProperty" .../>\n\n\n下表是与 getProperty 相关联的属性：\n\n属性         描述\nname       要检索的 Bean 属性名称。Bean 必须已定义。\nproperty   表示要提取 Bean 属性的值\n\n实例\n\n以下实例我们使用了 Bean:\n\npackage com.runoob.main;\n\npublic class TestBean {\n   private String message = "菜鸟教程";\n\n   public String getMessage() {\n      return(message);\n   }\n   public void setMessage(String message) {\n      this.message = message;\n   }\n}\n\n\n编译以上实例文件 TestBean.java ：\n\n$ javac TestBean.java\n\n\n编译完成后会在当前目录下生成一个 TestBean.class 文件， 将该文件拷贝至当前 JSP 项目的 WebContent/WEB-INF/classes/com/runoob/main 下( com/runoob/main 包路径，没有需要手动创建)。\n\n下面是一个 Eclipse 中目录结构图：\n\n\n\n下面是一个很简单的例子，它的功能是装载一个 Bean，然后设置/读取它的 message 属性。\n\n现在让我们在 main.jsp 文件中调用该 Bean:\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%>\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <h2>Jsp 使用 JavaBean 实例</h2>\n    <jsp:useBean id="test" class="com.runoob.main.TestBean" />\n\n    <jsp:setProperty name="test" property="message" value="菜鸟教程..." />\n\n    <p>输出信息....</p>\n\n    <jsp:getProperty name="test" property="message" />\n  </body>\n</html>\n\n\n浏览器访问，执行以上文件，输出如下所示：\n\n\n\n\n# <jsp:forward>\n\njsp:forward 动作把请求转到另外的页面。jsp:forward 标记只有一个属性 page。语法格式如下所示：\n\n<jsp:forward page="相对 URL 地址" />\n\n\n以下是 forward 相关联的属性：\n\n属性     描述\npage   page 属性包含的是一个相对 URL。page 的值既可以直接给出，也可以在请求的时候动态计算，可以是一个 JSP\n       页面或者一个 Java Servlet.\n\n实例\n\n以下实例我们使用了两个文件，分别是： date.jsp 和 main.jsp。\n\ndate.jsp 文件代码如下：\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%>\n<p>\n  今天的日期是: <%= (new java.util.Date()).toLocaleString()%>\n</p>\n\n\nmain.jsp 文件代码：\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%>\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <h2>forward 动作实例</h2>\n    <jsp:forward page="date.jsp" />\n  </body>\n</html>\n\n\n现在将以上两个文件放在服务器的根目录下，访问 main.jsp 文件。显示结果如下：\n\n今天的日期是: 2016-6-25 14:37:25\n\n\n\n# <jsp:plugin>\n\njsp:plugin 动作用来根据浏览器的类型，插入通过 Java 插件 运行 Java Applet 所必需的 OBJECT 或 EMBED 元素。\n\n如果需要的插件不存在，它会下载插件，然后执行 Java 组件。 Java 组件可以是一个 applet 或一个 JavaBean。\n\nplugin 动作有多个对应 HTML 元素的属性用于格式化 Java 组件。param 元素可用于向 Applet 或 Bean 传递参数。\n\n以下是使用 plugin 动作元素的典型实例:\n\n<jsp:plugin type="applet" codebase="dirname" code="MyApplet.class"\n                           width="60" height="80">\n   <jsp:param name="fontcolor" value="red" />\n   <jsp:param name="background" value="black" />\n\n   <jsp:fallback>\n      Unable to initialize Java Plugin\n   </jsp:fallback>\n\n</jsp:plugin>\n\n\n如果你有兴趣可以尝试使用 applet 来测试 jsp:plugin 动作元素，<fallback> 元素是一个新元素，在组件出现故障的错误是发送给用户错误信息。\n\n\n# <jsp:element> 、 <jsp:attribute>、<jsp:body>\n\n<jsp:element> 、 <jsp:attribute>、<jsp:body> 动作元素动态定义 XML 元素。动态是非常重要的，这就意味着 XML 元素在编译时是动态生成的而非静态。\n\n以下实例动态定义了 XML 元素：\n\n<%@ page language="java" contentType="text/html; charset=UTF-8"\npageEncoding="UTF-8"%>\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <jsp:element name="xmlElement">\n      <jsp:attribute name="xmlElementAttr">\n        属性值\n      </jsp:attribute>\n      <jsp:body>\n        XML 元素的主体\n      </jsp:body>\n    </jsp:element>\n  </body>\n</html>\n\n\n浏览器访问以下页面，输出结果如下所示：\n\n\n\n\n# <jsp:text>\n\njsp:text动作元素允许在 JSP 页面和文档中使用写入文本的模板，语法格式如下：\n\n<jsp:text>模板数据</jsp:text>\n\n\n以上文本模板不能包含其他元素，只能只能包含文本和 EL 表达式（注：EL 表达式将在后续章节中介绍）。请注意，在 XML 文件中，您不能使用表达式如 ${whatever > 0}，因为>符号是非法的。 你可以使用 ${whatever gt 0}表达式或者嵌入在一个 CDATA 部分的值。\n\n<jsp:text><![CDATA[<br>]]></jsp:text>\n\n\n如果你需要在 XHTML 中声明 DOCTYPE,必须使用到 <jsp:text> 动作元素，实例如下：\n\n<jsp:text><![CDATA[<!DOCTYPE html\nPUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"\n"DTD/xhtml1-strict.dtd">]]>\n</jsp:text>\n<head><title>jsp:text action</title></head>\n<body>\n\n<books><book><jsp:text>\n    Welcome to JSP Programming\n</jsp:text></book></books>\n\n</body>\n</html>\n\n\n你可以对以上实例尝试使用jsp:text及不使用该动作元素执行结果的区别。\n\n\n# JSP 隐式对象\n\nJSP 隐式对象是 JSP 容器为每个页面提供的 Java 对象，开发者可以直接使用它们而不用显式声明。JSP 隐式对象也被称为预定义变量。\n\nJSP 所支持的九大隐式对象：\n\n对象            描述\nrequest       HttpServletRequest类的实例\nresponse      HttpServletResponse类的实例\nout           PrintWriter类的实例，用于把结果输出至网页上\nsession       HttpSession类的实例\napplication   ServletContext类的实例，与应用上下文有关\nconfig        ServletConfig类的实例\npageContext   PageContext类的实例，提供对 JSP 页面所有对象以及命名空间的访问\npage          类似于 Java 类中的 this 关键字\nException     Exception类的对象，代表发生错误的 JSP 页面中对应的异常对象\n\n\n# request 对象\n\nrequest对象是javax.servlet.http.HttpServletRequest 类的实例。\n\n每当客户端请求一个 JSP 页面时，JSP 引擎就会制造一个新的request对象来代表这个请求。\n\nrequest对象提供了一系列方法来获取 HTTP 头信息，cookies，HTTP 方法等等。\n\n\n# response 对象\n\nresponse对象是javax.servlet.http.HttpServletResponse类的实例。\n\n当服务器创建request对象时会同时创建用于响应这个客户端的response对象。\n\nresponse对象也定义了处理 HTTP 头模块的接口。通过这个对象，开发者们可以添加新的 cookies，时间戳，HTTP 状态码等等。\n\n\n# out 对象\n\nout对象是javax.servlet.jsp.JspWriter类的实例，用来在response对象中写入内容。\n\n最初的JspWriter类对象根据页面是否有缓存来进行不同的实例化操作。可以在page指令中使用buffered=\'false\'属性来轻松关闭缓存。\n\nJspWriter类包含了大部分java.io.PrintWriter类中的方法。不过，JspWriter新增了一些专为处理缓存而设计的方法。还有就是，JspWriter类会抛出IOExceptions异常，而PrintWriter不会。\n\n下表列出了我们将会用来输出boolean，char，int，double，String，object等类型数据的重要方法：\n\n方法                         描述\nout.print(dataType dt)     输出 Type 类型的值\nout.println(dataType dt)   输出 Type 类型的值然后换行\nout.flush()                刷新输出流\n\n\n# session 对象\n\nsession对象是javax.servlet.http.HttpSession类的实例。和 Java Servlets 中的session对象有一样的行为。\n\nsession对象用来跟踪在各个客户端请求间的会话。\n\n\n# application 对象\n\napplication对象直接包装了 servlet 的ServletContext类的对象，是javax.servlet.ServletContext类的实例。\n\n这个对象在 JSP 页面的整个生命周期中都代表着这个 JSP 页面。这个对象在 JSP 页面初始化时被创建，随着jspDestroy()方法的调用而被移除。\n\n通过向application中添加属性，则所有组成您 web 应用的 JSP 文件都能访问到这些属性。\n\n\n# config 对象\n\nconfig对象是javax.servlet.ServletConfig类的实例，直接包装了 servlet 的ServletConfig类的对象。\n\n这个对象允许开发者访问 Servlet 或者 JSP 引擎的初始化参数，比如文件路径等。\n\n以下是 config 对象的使用方法，不是很重要，所以不常用：\n\nconfig.getServletName();\n\n\n它返回包含在<servlet-name>元素中的 servlet 名字，注意，<servlet-name>元素在WEB-INF\\web.xml文件中定义。\n\n\n# pageContext 对象\n\npageContext对象是javax.servlet.jsp.PageContext类的实例，用来代表整个 JSP 页面。\n\n这个对象主要用来访问页面信息，同时过滤掉大部分实现细节。\n\n这个对象存储了request对象和response对象的引用。application对象，config对象，session对象，out对象可以通过访问这个对象的属性来导出。\n\npageContext对象也包含了传给 JSP 页面的指令信息，包括缓存信息，ErrorPage URL,页面 scope 等。\n\nPageContext类定义了一些字段，包括 PAGE_SCOPE，REQUEST_SCOPE，SESSION_SCOPE， APPLICATION_SCOPE。它也提供了 40 余种方法，有一半继承自javax.servlet.jsp.JspContext 类。\n\n其中一个重要的方法就是removeArribute()，它可接受一个或两个参数。比如，pageContext.removeArribute("attrName")移除四个 scope 中相关属性，但是下面这种方法只移除特定 scope 中的相关属性：\n\npageContext.removeAttribute("attrName", PAGE_SCOPE);\n\n\n\n# page 对象\n\n这个对象就是页面实例的引用。它可以被看做是整个 JSP 页面的代表。\n\npage对象就是this对象的同义词。\n\n\n# exception 对象\n\nexception对象包装了从先前页面中抛出的异常信息。它通常被用来产生对出错条件的适当响应。\n\n\n# EL 表达式\n\nEL 表达式是用${}括起来的脚本，用来更方便地读取对象。EL 表达式写在 JSP 的 HTML 代码中，而不能写在<%与%>引起的 JSP 脚本中。\n\nJSP 表达式语言（EL）使得访问存储在 JavaBean 中的数据变得非常简单。JSP EL 既可以用来创建算术表达式也可以用来创建逻辑表达式。在 JSP EL 表达式内可以使用整型数，浮点数，字符串，常量 true、false，还有 null。\n\n\n# 一个简单的语法\n\n典型的，当您需要在 JSP 标签中指定一个属性值时，只需要简单地使用字符串即可：\n\n<jsp:setProperty name="box" property="perimeter" value="100" />\n\n\nJSP EL 允许您指定一个表达式来表示属性值。一个简单的表达式语法如下：\n\n${expr}\n\n\n其中，expr 指的是表达式。在 JSP EL 中通用的操作符是"."和"[]"。这两个操作符允许您通过内嵌的 JSP 对象访问各种各样的 JavaBean 属性。\n\n举例来说，上面的 <jsp:setProperty> 标签可以使用表达式语言改写成如下形式：\n\n<jsp:setProperty\n  name="box"\n  property="perimeter"\n  value="${2*box.width+2*box.height}"\n/>\n\n\n当 JSP 编译器在属性中见到"${}"格式后，它会产生代码来计算这个表达式，并且产生一个替代品来代替表达式的值。\n\n您也可以在标签的模板文本中使用表达式语言。比如 <jsp:text> 标签简单地将其主体中的文本插入到 JSP 输出中：\n\n<jsp:text>\n  <h1>Hello JSP!</h1>\n</jsp:text>\n\n\n现在，在jsp:text标签主体中使用表达式，就像这样：\n\n<jsp:text>\n  Box Perimeter is: ${2*box.width + 2*box.height}\n</jsp:text>\n\n\n在 EL 表达式中可以使用圆括号来组织子表达式。比如 ${(1 + 2) _ 3} 等于 9，但是 ${1 + (2 _ 3)} 等于 7。\n\n想要停用对 EL 表达式的评估的话，需要使用 page 指令将 isELIgnored 属性值设为 true：\n\n<%@ page isELIgnored ="true|false" %>\n\n\n这样，EL 表达式就会被忽略。若设为 false，则容器将会计算 EL 表达式。\n\n\n# EL 中的基础操作符\n\nEL 表达式支持大部分 Java 所提供的算术和逻辑操作符：\n\n操作符         描述\n.           访问一个 Bean 属性或者一个映射条目\n[]          访问一个数组或者链表的元素\n( )         组织一个子表达式以改变优先级\n+           加\n-           减或负\n*           乘\n/ or div    除\n% or mod    取模\n== or eq    测试是否相等\n!= or ne    测试是否不等\n< or lt     测试是否小于\n> or gt     测试是否大于\n<= or le    测试是否小于等于\n>= or ge    测试是否大于等于\n&& or and   测试逻辑与\n|| or or    测试逻辑或\n! or not    测试取反\nempty       测试是否空值\n\n\n# JSP EL 中的函数\n\nJSP EL 允许您在表达式中使用函数。这些函数必须被定义在自定义标签库中。函数的使用语法如下：\n\n${ns:func(param1, param2, ...)}\n\n\nns 指的是命名空间（namespace），func 指的是函数的名称，param1 指的是第一个参数，param2 指的是第二个参数，以此类推。比如，有函数 fn:length，在 JSTL 库中定义，可以像下面这样来获取一个字符串的长度：\n\n${fn:length("Get my length")}\n\n\n要使用任何标签库中的函数，您需要将这些库安装在服务器中，然后使用 <taglib> 标签在 JSP 文件中包含这些库。\n\n\n# JSP EL 隐含对象\n\nJSP EL 支持下表列出的隐含对象：\n\n隐含对象               描述\npageScope          page 作用域\nrequestScope       request 作用域\nsessionScope       session 作用域\napplicationScope   application 作用域\nparam              Request 对象的参数，字符串\nparamValues        Request 对象的参数，字符串集合\nheader             HTTP 信息头，字符串\nheaderValues       HTTP 信息头，字符串集合\ninitParam          上下文初始化参数\ncookie             Cookie 值\npageContext        当前页面的 pageContext\n\n您可以在表达式中使用这些对象，就像使用变量一样。接下来会给出几个例子来更好的理解这个概念。\n\n\n# pageContext 对象\n\npageContext 对象是 JSP 中 pageContext 对象的引用。通过 pageContext 对象，您可以访问 request 对象。比如，访问 request 对象传入的查询字符串，就像这样：\n\n${pageContext.request.queryString}\n\n\n\n# Scope 对象\n\npageScope，requestScope，sessionScope，applicationScope 变量用来访问存储在各个作用域层次的变量。\n\n举例来说，如果您需要显式访问在 applicationScope 层的 box 变量，可以这样来访问：applicationScope.box。\n\n\n# param 和 paramValues 对象\n\nparam 和 paramValues 对象用来访问参数值，通过使用 request.getParameter 方法和 request.getParameterValues 方法。\n\n举例来说，访问一个名为 order 的参数，可以这样使用表达式：${param.order}，或者${param["order"]}。\n\n接下来的例子表明了如何访问 request 中的 username 参数：\n\n<%@ page import="java.io.*,java.util.*" %> <% String title = "Accessing Request\nParam"; %>\n<html>\n  <head>\n    <title><% out.print(title); %></title>\n  </head>\n  <body>\n    <center>\n      <h1><% out.print(title); %></h1>\n    </center>\n    <div align="center">\n      <p>${param["username"]}</p>\n    </div>\n  </body>\n</html>\n\n\nparam 对象返回单一的字符串，而 paramValues 对象则返回一个字符串数组。\n\n\n# header 和 headerValues 对象\n\nheader 和 headerValues 对象用来访问信息头，通过使用 request.getHeader 方法和 request.getHeaders 方法。\n\n举例来说，要访问一个名为 user-agent 的信息头，可以这样使用表达式：${header.user-agent}，或者 ${header["user-agent"]}。\n\n接下来的例子表明了如何访问 user-agent 信息头：\n\n<%@ page import="java.io.*,java.util.*" %> <% String title = "User Agent\nExample"; %>\n<html>\n  <head>\n    <title><% out.print(title); %></title>\n  </head>\n  <body>\n    <center>\n      <h1><% out.print(title); %></h1>\n    </center>\n    <div align="center">\n      <p>${header["user-agent"]}</p>\n    </div>\n  </body>\n</html>\n\n\n运行结果如下：\n\n\n\nheader 对象返回单一值，而 headerValues 则返回一个字符串数组。\n\n\n# JSTL\n\nJSP 标准标签库（JSTL）是一个 JSP 标签集合，它封装了 JSP 应用的通用核心功能。\n\nJSTL 支持通用的、结构化的任务，比如迭代，条件判断，XML 文档操作，国际化标签，SQL 标签。 除了这些，它还提供了一个框架来使用集成 JSTL 的自定义标签。\n\n根据 JSTL 标签所提供的功能，可以将其分为 5 个类别。\n\n * 核心标签\n * 格式化标签\n * SQL 标签\n * XML 标签\n * JSTL 函数\n\n\n# JSTL 库安装\n\nApache Tomcat 安装 JSTL 库步骤如下：\n\n从 Apache 的标准标签库中下载的二进包(jakarta-taglibs-standard-current.zip)。\n\n * 官方下载地址：http://archive.apache.org/dist/jakarta/taglibs/standard/binaries/\n * 本站下载地址：jakarta-taglibs-standard-1.1.2.zip\n\n下载 jakarta-taglibs-standard-1.1.2.zip 包并解压，将 jakarta-taglibs-standard-1.1.2/lib/ 下的两个 jar 文件：standard.jar 和 jstl.jar 文件拷贝到 /WEB-INF/lib/ 下。\n\n将 tld 下的需要引入的 tld 文件复制到 WEB-INF 目录下。\n\n接下来我们在 web.xml 文件中添加以下配置：\n\n<?xml version="1.0" encoding="UTF-8"?>\n<web-app\n  version="2.4"\n  xmlns="http://java.sun.com/xml/ns/j2ee"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://java.sun.com/xml/ns/j2ee\n        http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd"\n>\n  <jsp-config>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/fmt</taglib-uri>\n      <taglib-location>/WEB-INF/fmt.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/fmt-rt</taglib-uri>\n      <taglib-location>/WEB-INF/fmt-rt.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/core</taglib-uri>\n      <taglib-location>/WEB-INF/c.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/core-rt</taglib-uri>\n      <taglib-location>/WEB-INF/c-rt.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/sql</taglib-uri>\n      <taglib-location>/WEB-INF/sql.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/sql-rt</taglib-uri>\n      <taglib-location>/WEB-INF/sql-rt.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/x</taglib-uri>\n      <taglib-location>/WEB-INF/x.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/x-rt</taglib-uri>\n      <taglib-location>/WEB-INF/x-rt.tld</taglib-location>\n    </taglib>\n  </jsp-config>\n</web-app>\n\n\n使用任何库，你必须在每个 JSP 文件中的头部包含 标签。\n\n\n# 核心标签\n\n核心标签是最常用的 JSTL 标签。引用核心标签库的语法如下：\n\n<%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %>\n\n\n标签              描述\n<c:out>         用于在 JSP 中显示数据，就像<%= ... >\n<c:set>         用于保存数据\n<c:remove>      用于删除数据\n<c:catch>       用来处理产生错误的异常状况，并且将错误信息储存起来\n<c:if>          与我们在一般程序中用的 if 一样\n<c:choose>      本身只当做<c:when>和<c:otherwise>的父标签\n<c:when>        <c:choose>的子标签，用来判断条件是否成立\n<c:otherwise>   <c:choose>的子标签，接在<c:when>标签后，当<c:when>标签判断为 false 时被执行\n<c:import>      检索一个绝对或相对 URL，然后将其内容暴露给页面\n<c:forEach>     基础迭代标签，接受多种集合类型\n<c:forTokens>   根据指定的分隔符来分隔内容并迭代输出\n<c:param>       用来给包含或重定向的页面传递参数\n<c:redirect>    重定向至一个新的 URL.\n<c:url>         使用可选的查询参数来创造一个 URL\n\n\n# 格式化标签\n\nJSTL 格式化标签用来格式化并输出文本、日期、时间、数字。引用格式化标签库的语法如下：\n\n<%@ taglib prefix="fmt" uri="http://java.sun.com/jsp/jstl/fmt" %>\n\n\n标签                      描述\n<fmt:formatNumber>      使用指定的格式或精度格式化数字\n<fmt:parseNumber>       解析一个代表着数字，货币或百分比的字符串\n<fmt:formatDate>        使用指定的风格或模式格式化日期和时间\n<fmt:parseDate>         解析一个代表着日期或时间的字符串\n<fmt:bundle>            绑定资源\n<fmt:setLocale>         指定地区\n<fmt:setBundle>         绑定资源\n<fmt:timeZone>          指定时区\n<fmt:setTimeZone>       指定时区\n<fmt:message>           显示资源配置文件信息\n<fmt:requestEncoding>   设置 request 的字符编码\n\n\n# SQL 标签\n\nJSTL SQL 标签库提供了与关系型数据库（Oracle，MySQL，SQL Server 等等）进行交互的标签。引用 SQL 标签库的语法如下：\n\n<%@ taglib prefix="sql" uri="http://java.sun.com/jsp/jstl/sql" %>\n\n\n标签                    描述\n<sql:setDataSource>   指定数据源\n<sql:query>           运行 SQL 查询语句\n<sql:update>          运行 SQL 更新语句\n<sql:param>           将 SQL 语句中的参数设为指定值\n<sql:dateParam>       将 SQL 语句中的日期参数设为指定的 java.util.Date 对象值\n<sql:transaction>     在共享数据库连接中提供嵌套的数据库行为元素，将所有语句以一个事务的形式来运行\n\n\n# XML 标签\n\nJSTL XML 标签库提供了创建和操作 XML 文档的标签。引用 XML 标签库的语法如下：\n\n<%@ taglib prefix="x" uri="http://java.sun.com/jsp/jstl/xml" %>\n\n\n在使用 xml 标签前，你必须将 XML 和 XPath 的相关包拷贝至你的 <Tomcat 安装目录>\\lib 下:\n\n * XercesImpl.jar\n   \n   下载地址： http://www.apache.org/dist/xerces/j/\n\n * xalan.jar\n   \n   下载地址： http://xml.apache.org/xalan-j/index.html\n\n标签              描述\n<x:out>         与<%= ... >,类似，不过只用于 XPath 表达式\n<x:parse>       解析 XML 数据\n<x:set>         设置 XPath 表达式\n<x:if>          判断 XPath 表达式，若为真，则执行本体中的内容，否则跳过本体\n<x:forEach>     迭代 XML 文档中的节点\n<x:choose>      <x:when>和<x:otherwise>的父标签\n<x:when>        <x:choose>的子标签，用来进行条件判断\n<x:otherwise>   <x:choose>的子标签，当<x:when>判断为 false 时被执行\n<x:transform>   将 XSL 转换应用在 XML 文档中\n<x:param>       与<x:transform>共同使用，用于设置 XSL 样式表\n\n\n# JSTL 函数\n\nJSTL 包含一系列标准函数，大部分是通用的字符串处理函数。引用 JSTL 函数库的语法如下：\n\n<%@ taglib prefix="fn" uri="http://java.sun.com/jsp/jstl/functions" %>\n\n\n函数                        描述\nfn:contains()             测试输入的字符串是否包含指定的子串\nfn:containsIgnoreCase()   测试输入的字符串是否包含指定的子串，大小写不敏感\nfn:endsWith()             测试输入的字符串是否以指定的后缀结尾\nfn:escapeXml()            跳过可以作为 XML 标记的字符\nfn:indexOf()              返回指定字符串在输入字符串中出现的位置\nfn:join()                 将数组中的元素合成一个字符串然后输出\nfn:length()               返回字符串长度\nfn:replace()              将输入字符串中指定的位置替换为指定的字符串然后返回\nfn:split()                将字符串用指定的分隔符分隔然后组成一个子字符串数组并返回\nfn:startsWith()           测试输入字符串是否以指定的前缀开始\nfn:substring()            返回字符串的子集\nfn:substringAfter()       返回字符串在指定子串之后的子集\nfn:substringBefore()      返回字符串在指定子串之前的子集\nfn:toLowerCase()          将字符串中的字符转为小写\nfn:toUpperCase()          将字符串中的字符转为大写\nfn:trim()                 移除首尾的空白符\n\n\n# Taglib\n\n\n# JSP 自定义标签\n\n自定义标签是用户定义的 JSP 语言元素。当 JSP 页面包含一个自定义标签时将被转化为 servlet，标签转化为对被 称为 tag handler 的对象的操作，即当 servlet 执行时 Web container 调用那些操作。\n\nJSP 标签扩展可以让你创建新的标签并且可以直接插入到一个 JSP 页面。 JSP 2.0 规范中引入 Simple Tag Handlers 来编写这些自定义标记。\n\n你可以继承 SimpleTagSupport 类并重写的 doTag()方法来开发一个最简单的自定义标签。\n\n\n# 创建"Hello"标签\n\n接下来，我们想创建一个自定义标签叫作ex:Hello，标签格式为：\n\n<ex:Hello />\n\n\n要创建自定义的 JSP 标签，你首先必须创建处理标签的 Java 类。所以，让我们创建一个 HelloTag 类，如下所示：\n\npackage com.runoob; import javax.servlet.jsp.tagext.*; import\njavax.servlet.jsp.*; import java.io.*; public class HelloTag extends\nSimpleTagSupport { public void doTag() throws JspException, IOException {\nJspWriter out = getJspContext().getOut(); out.println("Hello Custom Tag!"); } }\n\n\n以下代码重写了 doTag()方法，方法中使用了 getJspContext()方法来获取当前的 JspContext 对象，并将"Hello Custom Tag!"传递给 JspWriter 对象。\n\n编译以上类，并将其复制到环境变量 CLASSPATH 目录中。最后创建如下标签库：<Tomcat安装目录>webapps\\ROOT\\WEB-INF\\custom.tld。\n\n<taglib>\n  <tlib-version>1.0</tlib-version>\n  <jsp-version>2.0</jsp-version>\n  <short-name>Example TLD</short-name>\n  <tag>\n    <name>Hello</name>\n    <tag-class>com.runoob.HelloTag</tag-class>\n    <body-content>empty</body-content>\n  </tag>\n</taglib>\n\n\n接下来，我们就可以在 JSP 文件中使用 Hello 标签：\n\n<%@ taglib prefix="ex" uri="WEB-INF/custom.tld"%>\n<html>\n  <head>\n    <title>A sample custom tag</title>\n  </head>\n  <body>\n    <ex:Hello />\n  </body>\n</html>\n\n\n以上程序输出结果为：\n\nHello Custom Tag!\n\n\n\n# 访问标签体\n\n你可以像标准标签库一样在标签中包含消息内容。如我们要在我们自定义的 Hello 中包含内容，格式如下：\n\n<ex:Hello>\n  This is message body\n</ex:Hello>\n\n\n我们可以修改标签处理类文件，代码如下：\n\npackage com.runoob;\n\nimport javax.servlet.jsp.tagext.*;\nimport javax.servlet.jsp.*;\nimport java.io.*;\n\npublic class HelloTag extends SimpleTagSupport {\n\n   StringWriter sw = new StringWriter();\n   public void doTag()\n      throws JspException, IOException\n    {\n       getJspBody().invoke(sw);\n       getJspContext().getOut().println(sw.toString());\n    }\n\n}\n\n\n接下来我们需要修改 TLD 文件，如下所示：\n\n<taglib>\n  <tlib-version>1.0</tlib-version>\n  <jsp-version>2.0</jsp-version>\n  <short-name>Example TLD with Body</short-name>\n  <tag>\n    <name>Hello</name>\n    <tag-class>com.runoob.HelloTag</tag-class>\n    <body-content>scriptless</body-content>\n  </tag>\n</taglib>\n\n\n现在我们可以在 JSP 使用修改后的标签，如下所示:\n\n<%@ taglib prefix="ex" uri="WEB-INF/custom.tld"%>\n<html>\n  <head>\n    <title>A sample custom tag</title>\n  </head>\n  <body>\n    <ex:Hello>\n      This is message body\n    </ex:Hello>\n  </body>\n</html>\n\n\n以上程序输出结果如下所示：\n\nThis is message body\n\n\n\n# 自定义标签属性\n\n你可以在自定义标准中设置各种属性，要接收属性，值自定义标签类必须实现 setter 方法， JavaBean 中的 setter 方法如下所示：\n\npackage com.runoob;\n\nimport javax.servlet.jsp.tagext.*;\nimport javax.servlet.jsp.*;\nimport java.io.*;\n\npublic class HelloTag extends SimpleTagSupport {\n\n   private String message;\n\n   public void setMessage(String msg) {\n      this.message = msg;\n   }\n\n   StringWriter sw = new StringWriter();\n\n   public void doTag()\n      throws JspException, IOException\n    {\n       if (message != null) {\n          /* 从属性中使用消息 */\n          JspWriter out = getJspContext().getOut();\n          out.println( message );\n       }\n       else {\n          /* 从内容体中使用消息 */\n          getJspBody().invoke(sw);\n          getJspContext().getOut().println(sw.toString());\n       }\n   }\n\n}\n\n\n属性的名称是"message"，所以 setter 方法是的 setMessage()。现在让我们在 TLD 文件中使用的元素添加此属性：\n\n<taglib>\n  <tlib-version>1.0</tlib-version>\n  <jsp-version>2.0</jsp-version>\n  <short-name>Example TLD with Body</short-name>\n  <tag>\n    <name>Hello</name>\n    <tag-class>com.runoob.HelloTag</tag-class>\n    <body-content>scriptless</body-content>\n    <attribute>\n      <name>message</name>\n    </attribute>\n  </tag>\n</taglib>\n\n\n现在我们就可以在 JSP 文件中使用 message 属性了，如下所示：\n\n<%@ taglib prefix="ex" uri="WEB-INF/custom.tld"%>\n<html>\n  <head>\n    <title>A sample custom tag</title>\n  </head>\n  <body>\n    <ex:Hello message="This is custom tag" />\n  </body>\n</html>\n\n\n以上实例数据输出结果为：\n\nThis is custom tag\n\n\n你还可以包含以下属性：\n\n属性            描述\nname          定义属性的名称。每个标签的是属性名称必须是唯一的。\nrequired      指定属性是否是必须的或者可选的,如果设置为 false 为可选。\nrtexprvalue   声明在运行表达式时，标签属性是否有效。\ntype          定义该属性的 Java 类类型 。默认指定为 String\ndescription   描述信息\nfragment      如果声明了该属性,属性值将被视为一个 JspFragment。\n\n以下是指定相关的属性实例：\n\n.....\n<attribute>\n  <name>attribute_name</name>\n  <required>false</required>\n  <type>java.util.Date</type>\n  <fragment>false</fragment>\n</attribute>\n.....\n\n\n如果你使用了两个属性，修改 TLD 文件，如下所示：\n\n.....\n<attribute>\n  <name>attribute_name1</name>\n  <required>false</required>\n  <type>java.util.Boolean</type>\n  <fragment>false</fragment>\n</attribute>\n<attribute>\n  <name>attribute_name2</name>\n  <required>true</required>\n  <type>java.util.Date</type>\n</attribute>\n.....\n',normalizedContent:'# javaweb 之 jsp 指南\n\n\n# 简介\n\n\n# 什么是 java server pages\n\njsp全称java server pages，是一种动态网页开发技术。\n\n它使用 jsp 标签在 html 网页中插入 java 代码。标签通常以<%开头以%>结束。\n\njsp 是一种 java servlet，主要用于实现 java web 应用程序的用户界面部分。网页开发者们通过结合 html 代码、xhtml 代码、xml 元素以及嵌入 jsp 操作和命令来编写 jsp。\n\njsp 通过网页表单获取用户输入数据、访问数据库及其他数据源，然后动态地创建网页。\n\njsp 标签有多种功能，比如访问数据库、记录用户选择信息、访问 javabeans 组件等，还可以在不同的网页中传递控制信息和共享信息。\n\n\n# 为什么使用 jsp\n\njsp 也是一种 servlet，因此 jsp 能够完成 servlet 能完成的任何工作。\n\njsp 程序与 cgi 程序有着相似的功能，但和 cgi 程序相比，jsp 程序有如下优势：\n\n * 性能更加优越，因为 jsp 可以直接在 html 网页中动态嵌入元素而不需要单独引用 cgi 文件。\n * 服务器调用的是已经编译好的 jsp 文件，而不像 cgi/perl 那样必须先载入解释器和目标脚本。\n * jsp 基于 java servlets api，因此，jsp 拥有各种强大的企业级 java api，包括 jdbc，jndi，ejb，jaxp 等等。\n * jsp 页面可以与处理业务逻辑的 servlets 一起使用，这种模式被 java servlet 模板引擎所支持。\n\n最后，jsp 是 java ee 不可或缺的一部分，是一个完整的企业级应用平台。这意味着 jsp 可以用最简单的方式来实现最复杂的应用。\n\n\n# jsp 的优势\n\n以下列出了使用 jsp 带来的其他好处：\n\n * 与 asp 相比：jsp 有两大优势。首先，动态部分用 java 编写，而不是 vb 或其他 ms 专用语言，所以更加强大与易用。第二点就是 jsp 易于移植到非 ms 平台上。\n * 与纯 servlets 相比：jsp 可以很方便的编写或者修改 html 网页而不用去面对大量的 println 语句。\n * 与 ssi 相比：ssi 无法使用表单数据、无法进行数据库链接。\n * 与 javascript 相比：虽然 javascript 可以在客户端动态生成 html，但是很难与服务器交互，因此不能提供复杂的服务，比如访问数据库和图像处理等等。\n * 与静态 html 相比：静态 html 不包含动态信息。\n\n\n# jsp 工作原理\n\njsp 是一种 servlet，但工作方式和 servlet 有所差别。\n\nservlet 是先将源代码编译为 class 文件后部署到服务器下的，先编译后部署。\n\njsp 是先将源代码部署到服务器再编译，先部署后编译。\n\njsp 会在客户端第一次请求 jsp 文件时被编译为 httpjsppage 类（servlet 的一个子类）。该类会被服务器临时存放在服务器工作目录里。所以，第一次请求 jsp 后，访问速度会变快就是这个道理。\n\n\n# jsp 工作流程\n\n网络服务器需要一个 jsp 引擎，也就是一个容器来处理 jsp 页面。容器负责截获对 jsp 页面的请求。本教程使用内嵌 jsp 容器的 apache 来支持 jsp 开发。\n\njsp 容器与 web 服务器协同合作，为 jsp 的正常运行提供必要的运行环境和其他服务，并且能够正确识别专属于 jsp 网页的特殊元素。\n\n下图显示了 jsp 容器和 jsp 文件在 web 应用中所处的位置。\n\n\n\n# 工作步骤\n\n以下步骤表明了 web 服务器是如何使用 jsp 来创建网页的：\n\n * 就像其他普通的网页一样，您的浏览器发送一个 http 请求给服务器。\n * web 服务器识别出这是一个对 jsp 网页的请求，并且将该请求传递给 jsp 引擎。通过使用 url 或者.jsp 文件来完成。\n * jsp 引擎从磁盘中载入 jsp 文件，然后将它们转化为 servlet。这种转化只是简单地将所有模板文本改用 println()语句，并且将所有的 jsp 元素转化成 java 代码。\n * jsp 引擎将 servlet 编译成可执行类，并且将原始请求传递给 servlet 引擎。\n * web 服务器的某组件将会调用 servlet 引擎，然后载入并执行 servlet 类。在执行过程中，servlet 产生 html 格式的输出并将其内嵌于 http response 中上交给 web 服务器。\n * web 服务器以静态 html 网页的形式将 http response 返回到您的浏览器中。\n * 最终，web 浏览器处理 http response 中动态产生的 html 网页，就好像在处理静态网页一样。\n\n以上提及到的步骤可以用下图来表示：\n\n一般情况下，jsp 引擎会检查 jsp 文件对应的 servlet 是否已经存在，并且检查 jsp 文件的修改日期是否早于 servlet。如果 jsp 文件的修改日期早于对应的 servlet，那么容器就可以确定 jsp 文件没有被修改过并且 servlet 有效。这使得整个流程与其他脚本语言（比如 php）相比要高效快捷一些。\n\n\n# jsp 生命周期\n\n理解 jsp 底层功能的关键就是去理解它们所遵守的生命周期。\n\njsp 生命周期就是从创建到销毁的整个过程，类似于 servlet 生命周期，区别在于 jsp 生命周期还包括将 jsp 文件编译成 servlet。\n\n以下是 jsp 生命周期中所走过的几个阶段：\n\n * **编译阶段：**servlet 容器编译 servlet 源文件，生成 servlet 类\n * **初始化阶段：**加载与 jsp 对应的 servlet 类，创建其实例，并调用它的初始化方法\n * **执行阶段：**调用与 jsp 对应的 servlet 实例的服务方法\n * **销毁阶段：**调用与 jsp 对应的 servlet 实例的销毁方法，然后销毁 servlet 实例\n\n很明显，jsp 生命周期的四个主要阶段和 servlet 生命周期非常相似，下面给出图示：\n\n\n\n# jsp 编译\n\n当浏览器请求 jsp 页面时，jsp 引擎会首先去检查是否需要编译这个文件。如果这个文件没有被编译过，或者在上次编译后被更改过，则编译这个 jsp 文件。\n\n编译的过程包括三个步骤：\n\n * 解析 jsp 文件。\n * 将 jsp 文件转为 servlet。\n * 编译 servlet。\n\n# jsp 初始化\n\n容器载入 jsp 文件后，它会在为请求提供任何服务前调用 jspinit()方法。如果您需要执行自定义的 jsp 初始化任务，复写 jspinit()方法就行了，就像下面这样：\n\npublic void jspinit(){\n  // 初始化代码\n}\n\n\n一般来讲程序只初始化一次，servlet 也是如此。通常情况下您可以在 jspinit()方法中初始化数据库连接、打开文件和创建查询表。\n\n# jsp 执行\n\n这一阶段描述了 jsp 生命周期中一切与请求相关的交互行为，直到被销毁。\n\n当 jsp 网页完成初始化后，jsp 引擎将会调用 _jspservice() 方法。\n\n_jspservice() 方法需要一个 httpservletrequest 对象和一个 httpservletresponse 对象作为它的参数，就像下面这样：\n\nvoid _jspservice(httpservletrequest request,\n                 httpservletresponse response) {\n   // 服务端处理代码\n}\n\n\n_jspservice() 方法在每个 request 中被调用一次并且负责产生与之相对应的 response，并且它还负责产生所有 7 个 http 方法的回应，比如 get、post、delete 等等。\n\n# jsp 清理\n\njsp 生命周期的销毁阶段描述了当一个 jsp 网页从容器中被移除时所发生的一切。\n\njspdestroy()方法在 jsp 中等价于 servlet 中的销毁方法。当您需要执行任何清理工作时复写 jspdestroy()方法，比如释放数据库连接或者关闭文件夹等等。\n\njspdestroy()方法的格式如下：\n\npublic void jspdestroy() {\n   // 清理代码\n}\n\n\n\n# 语法\n\n\n# 脚本\n\n脚本程序可以包含任意量的 java 语句、变量、方法或表达式，只要它们在脚本语言中是有效的。\n\n脚本程序的语法格式：\n\n<% 代码片段 %>\n\n\n或者，您也可以编写与其等价的 xml 语句，就像下面这样：\n\n<jsp:scriptlet>\n  代码片段\n</jsp:scriptlet>\n\n\n任何文本、html 标签、jsp 元素必须写在脚本程序的外面。\n\n下面给出一个示例，同时也是本教程的第一个 jsp 示例：\n\n<html>\n  <head>\n    <title>hello world</title>\n  </head>\n  <body>\n    hello world!<br />\n    <% out.println("your ip address is " + request.getremoteaddr()); %>\n  </body>\n</html>\n\n\n**注意：**请确保 apache tomcat 已经安装在 c:\\apache-tomcat-7.0.2 目录下并且运行环境已经正确设置。\n\n将以上代码保存在 hello.jsp 中，然后将它放置在 c:\\apache-tomcat-7.0.2\\webapps\\root 目录下，打开浏览器并在地址栏中输入 http://localhost:8080/hello.jsp 。运行后得到以下结果：\n\n\n\n# 中文编码问题\n\n如果我们要在页面正常显示中文，我们需要在 jsp 文件头部添加以下代码：<>\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%>\n\n\n接下来我们将以上程序修改为：\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%>\n<!doctype html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    hello world!<br />\n    <% out.println("你的 ip 地址 " + request.getremoteaddr()); %>\n  </body>\n</html>\n\n\n这样中文就可以正常显示了。\n\n\n# jsp 声明\n\n一个声明语句可以声明一个或多个变量、方法，供后面的 java 代码使用。在 jsp 文件中，您必须先声明这些变量和方法然后才能使用它们。\n\njsp 声明的语法格式：\n\n<%! declaration; [ declaration; ]+ ... %>\n\n\n或者，您也可以编写与其等价的 xml 语句，就像下面这样：\n\n<jsp:declaration>\n  代码片段\n</jsp:declaration>\n\n\n程序示例：\n\n<%! int i = 0; %> <%! int a, b, c; %> <%! circle a = new circle(2.0); %>\n\n\n\n# jsp 表达式\n\n一个 jsp 表达式中包含的脚本语言表达式，先被转化成 string，然后插入到表达式出现的地方。\n\n由于表达式的值会被转化成 string，所以您可以在一个文本行中使用表达式而不用去管它是否是 html 标签。\n\n表达式元素中可以包含任何符合 java 语言规范的表达式，但是不能使用分号来结束表达式。\n\njsp 表达式的语法格式：\n\n<%= 表达式 %>\n\n\n同样，您也可以编写与之等价的 xml 语句：\n\n<jsp:expression>\n  表达式\n</jsp:expression>\n\n\n程序示例：\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%>\n<!doctype html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <p>\n      今天的日期是: <%= (new java.util.date()).tolocalestring()%>\n    </p>\n  </body>\n</html>\n\n\n运行后得到以下结果：\n\n今天的日期是: 2016-6-25 13:40:07\n\n\n----------------------------------------\n\n\n# jsp 注释\n\njsp 注释主要有两个作用：为代码作注释以及将某段代码注释掉。\n\njsp 注释的语法格式：\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%>\n<!doctype html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>jsp注释示例</title>\n  </head>\n  <body>\n    <%-- 该部分注释在网页中不会被显示--%>\n    <p>\n      今天的日期是: <%= (new java.util.date()).tolocalestring()%>\n    </p>\n  </body>\n</html>\n\n\n运行后得到以下结果：\n\n今天的日期是: 2016-6-25 13:41:26\n\n\n不同情况下使用注释的语法规则：\n\n语法             描述\n<%-- 注释 --%>   jsp 注释，注释内容不会被发送至浏览器甚至不会被编译\n\x3c!-- 注释 --\x3e    html 注释，通过浏览器查看网页源代码时可以看见注释内容\n<%             代表静态 <%常量\n%>             代表静态 %> 常量\n\'              在属性中使用的单引号\n"              在属性中使用的双引号\n\n\n# 控制语句\n\njsp 提供对 java 语言的全面支持。您可以在 jsp 程序中使用 java api 甚至建立 java 代码块，包括判断语句和循环语句等等。\n\n# if…else 语句\n\nif…else块，请看下面这个例子：\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%> <%! int day = 1; %>\n<!doctype html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>02.jsp语法 - if...else示例</title>\n  </head>\n  <body>\n    <h3>if...else 实例</h3>\n    <% if (day == 1 | day == 7) { %>\n    <p>今天是周末</p>\n    <% } else { %>\n    <p>今天不是周末</p>\n    <% } %>\n  </body>\n</html>\n\n\n运行后得到以下结果：\n\nif...else 实例\n今天不是周末\n\n\n# switch…case 语句\n\n现在来看看 switch…case 块，与 if…else 块有很大的不同，它使用 out.println()，并且整个都装在脚本程序的标签中，就像下面这样：\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%> <%! int day = 3; %>\n<!doctype html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>02.jsp语法 - switch...case示例</title>\n  </head>\n  <body>\n    <h3>sswitch...case示例</h3>\n    <% switch(day) { case 0: out.println("星期天"); break; case 1:\n    out.println("星期一"); break; case 2: out.println("星期二"); break; case 3:\n    out.println("星期三"); break; case 4: out.println("星期四"); break; case 5:\n    out.println("星期五"); break; default: out.println("星期六"); } %>\n  </body>\n</html>\n\n\n浏览器访问，运行后得出以下结果：\n\nswitch...case 实例\n\n星期三\n\n\n# 循环语句\n\n在 jsp 程序中可以使用 java 的三个基本循环类型：for，while，和 do…while。\n\n让我们来看看 for 循环的例子，以下输出的不同字体大小的"菜鸟教程"：\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%> <%! int fontsize; %>\n<!doctype html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <h3>for 循环实例</h3>\n    <%for ( fontsize = 1; fontsize <= 3; fontsize++){ %>\n    <font color="green" size="<%= fontsize %>">\n      菜鸟教程 </font\n    ><br />\n    <%}%>\n  </body>\n</html>\n\n\n运行后得到以下结果：\n\n\n\n将上例改用 while 循环来写：\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%> <%! int fontsize; %>\n<!doctype html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <h3>while 循环实例</h3>\n    <%while ( fontsize <= 3){ %>\n    <font color="green" size="<%= fontsize %>">\n      菜鸟教程 </font\n    ><br />\n    <%fontsize++;%> <%}%>\n  </body>\n</html>\n\n\n浏览器访问，输出结果为（fontsize 初始化为 0，所以多输出了一行）：\n\n\n\njsp 运算符\n\njsp 支持所有 java 逻辑和算术运算符。\n\n下表罗列出了 jsp 常见运算符，优先级从高到底：\n\n类别      操作符                                   结合性\n后缀      () [] . (点运算符)                        左到右\n一元      ++ - - ! ~                            右到左\n可乘性     * / %                                 左到右\n可加性     + -                                   左到右\n移位      >> >>> <<                             左到右\n关系      > >= < <=                             左到右\n相等/不等   == !=                                 左到右\n位与      &                                     左到右\n位异或     ^                                     左到右\n位或      |                                     左到右\n逻辑与     &&                                    左到右\n逻辑或     | |                                   左到右\n条件判断    ?:                                    右到左\n赋值      = += -= \\*= /= %= >>= <<= &= ^= | =   右到左\n逗号      ,                                     左到右\n\n\n# jsp 字面量\n\njsp 语言定义了以下几个字面量：\n\n * 布尔值(boolean)：true 和 false;\n * 整型(int)：与 java 中的一样;\n * 浮点型(float)：与 java 中的一样;\n * 字符串(string)：以单引号或双引号开始和结束;\n * null：null。\n\n\n# 指令\n\njsp 指令用来设置整个 jsp 页面相关的属性，如网页的编码方式和脚本语言。\n\njsp 指令以开<%@开始，以%>结束。\n\njsp 指令语法格式如下：\n\n<%@ directive attribute="value" %>\n\n\n指令可以有很多个属性，它们以键值对的形式存在，并用逗号隔开。\n\njsp 中的三种指令标签：\n\n指令                   描述\n<%@ page ... %>      定义网页依赖属性，比如脚本语言、error 页面、缓存需求等等\n<%@ include ... %>   包含其他文件\n<%@ taglib ... %>    引入标签库的定义，可以是自定义标签\n\n\n# page 指令\n\npage 指令为容器提供当前页面的使用说明。一个 jsp 页面可以包含多个page指令。\n\npage 指令的语法格式：\n\n<%@ page attribute="value" %>\n\n\n等价的 xml 格式：\n\n<jsp:directive.page attribute="value" />\n\n\n例：\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8" %>\n\n\n# 属性\n\n下表列出与 page 指令相关的属性：\n\n属性                   描述\nbuffer               指定 out 对象使用缓冲区的大小\nautoflush            控制 out 对象的 缓存区\ncontenttype          指定当前 jsp 页面的 mime 类型和字符编码\nerrorpage            指定当 jsp 页面发生异常时需要转向的错误处理页面\niserrorpage          指定当前页面是否可以作为另一个 jsp 页面的错误处理页面\nextends              指定 servlet 从哪一个类继承\nimport               导入要使用的 java 类\ninfo                 定义 jsp 页面的描述信息\nisthreadsafe         指定对 jsp 页面的访问是否为线程安全\nlanguage             定义 jsp 页面所用的脚本语言，默认是 java\nsession              指定 jsp 页面是否使用 session\niselignored          指定是否执行 el 表达式\nisscriptingenabled   确定脚本元素能否被使用\n\n\n# include 指令\n\njsp 可以通过include指令来包含其他文件。\n\n被包含的文件可以是 jsp 文件、html 文件或文本文件。包含的文件就好像是该 jsp 文件的一部分，会被同时编译执行。\n\ninclude 指令的语法格式如下：\n\n<%@ include file="文件相对 url 地址" %>\n\n\ninclude 指令中的文件名实际上是一个相对的 url 地址。\n\n如果您没有给文件关联一个路径，jsp 编译器默认在当前路径下寻找。\n\n等价的 xml 语法：\n\n<jsp:directive.include file="文件相对 url 地址" />\n\n\n\n# taglib 指令\n\njsp 允许用户自定义标签，一个自定义标签库就是自定义标签的集合。\n\ntaglib指令引入一个自定义标签集合的定义，包括库路径、自定义标签。\n\ntaglib指令的语法：\n\n<%@ taglib uri="uri" prefix="prefixoftag" %>\n\n\nuri 属性确定标签库的位置，prefix 属性指定标签库的前缀。\n\n等价的 xml 语法：\n\n<jsp:directive.taglib uri="uri" prefix="prefixoftag" />\n\n\n\n# jsp 动作元素\n\njsp 动作元素是一组 jsp 内置的标签，只需要书写很少的标记代码就能使用 jsp 提供的丰富功能。jsp 动作元素是对常用的 jsp 功能的抽象与封装，包括两种，自定义 jsp 动作元素与标准 jsp 动作元素。\n\n与 jsp 指令元素不同的是，jsp 动作元素在请求处理阶段起作用。jsp 动作元素是用 xml 语法写成的。\n\n利用 jsp 动作可以动态地插入文件、重用 javabean 组件、把用户重定向到另外的页面、为 java 插件生成 html 代码。\n\n动作元素只有一种语法，它符合 xml 标准：\n\n<jsp:action_name attribute="value" />\n\n\n动作元素基本上都是预定义的函数，jsp 规范定义了一系列的标准动作，它用 jsp 作为前缀，可用的标准动作元素如下：\n\n语法                描述\njsp:include       在页面被请求的时候引入一个文件。\njsp:usebean       寻找或者实例化一个 javabean。\njsp:setproperty   设置 javabean 的属性。\njsp:getproperty   输出某个 javabean 的属性。\njsp:forward       把请求转到一个新的页面。\njsp:plugin        根据浏览器类型为 java 插件生成 object 或 embed 标记。\njsp:element       定义动态 xml 元素\njsp:attribute     设置动态定义的 xml 元素属性。\njsp:body          设置动态定义的 xml 元素内容。\njsp:text          在 jsp 页面和文档中使用写入文本的模板\n\n\n# 常见的属性\n\n所有的动作要素都有两个属性：id 属性和 scope 属性。\n\n * **id 属性：**id 属性是动作元素的唯一标识，可以在 jsp 页面中引用。动作元素创建的 id 值可以通过 pagecontext 来调用。\n * **scope 属性：**该属性用于识别动作元素的生命周期。 id 属性和 scope 属性有直接关系，scope 属性定义了相关联 id 对象的寿命。 scope 属性有四个可能的值： (a) page, (b)request, (c)session, 和 (d) application。\n\n\n# <jsp:include>\n\n<jsp:include> 用来包含静态和动态的文件。该动作把指定文件插入正在生成的页面。\n\n如果被包含的文件为 jsp 程序，则会先执行 jsp 程序，再将执行结果包含进来。\n\n语法格式如下：\n\n<jsp:include page="相对 url 地址" flush="true" />\n\n\n前面已经介绍过 include 指令，它是在 jsp 文件被转换成 servlet 的时候引入文件，而这里的 jsp:include 动作不同，插入文件的时间是在页面被请求的时候。\n\n以下是 include 动作相关的属性列表。\n\n属性      描述\npage    包含在页面中的相对 url 地址。\nflush   布尔属性，定义在包含资源前是否刷新缓存区。\n\n示例：\n\n以下我们定义了两个文件 date.jsp 和 main.jsp，代码如下所示：\n\ndate.jsp 文件代码：\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%>\n<p>\n  今天的日期是: <%= (new java.util.date())%>\n</p>\n\n\nmain.jsp 文件代码：\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%>\n<!doctype html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <h2>include 动作实例</h2>\n    <jsp:include page="date.jsp" flush="true" />\n  </body>\n</html>\n\n\n现在将以上两个文件放在服务器的根目录下，访问 main.jsp 文件。显示结果如下：\n\ninclude 动作实例\n\n今天的日期是: 2016-6-25 14:08:17\n\n\n\n# <jsp:usebean>\n\njsp:usebean 动作用来加载一个将在 jsp 页面中使用的 javabean。\n\n这个功能非常有用，因为它使得我们可以发挥 java 组件复用的优势。\n\njsp:usebean 动作最简单的语法为：\n\n<jsp:usebean id="name" class="package.class" />\n\n\n在类载入后，我们既可以通过 jsp:setproperty 和 jsp:getproperty 动作来修改和检索 bean 的属性。\n\n以下是 usebean 动作相关的属性列表。\n\n属性         描述\nclass      指定 bean 的完整包名。\ntype       指定将引用该对象变量的类型。\nbeanname   通过 java.beans.beans 的 instantiate() 方法指定 bean 的名字。\n\n在给出具体实例前，让我们先来看下 jsp:setproperty 和 jsp:getproperty 动作元素：\n\n\n# <jsp:setproperty>\n\njsp:setproperty 用来设置已经实例化的 bean 对象的属性，有两种用法。首先，你可以在 jsp:usebean 元素的外面（后面）使用 jsp:setproperty，如下所示：\n\n<jsp:usebean id="myname" ... />\n...\n<jsp:setproperty name="myname" property="someproperty" .../>\n\n\n此时，不管 jsp:usebean 是找到了一个现有的 bean，还是新创建了一个 bean 实例，jsp:setproperty 都会执行。第二种用法是把 jsp:setproperty 放入 jsp:usebean 元素的内部，如下所示：\n\n<jsp:usebean id="myname" ... >\n...\n   <jsp:setproperty name="myname" property="someproperty" .../>\n</jsp:usebean>\n\n\n此时，jsp:setproperty 只有在新建 bean 实例时才会执行，如果是使用现有实例则不执行 jsp:setproperty。\n\njsp:setproperty 动作有下面四个属性,如下表：\n\n属性         描述\nname       name 属性是必需的。它表示要设置属性的是哪个 bean。\nproperty   property 属性是必需的。它表示要设置哪个属性。有一个特殊用法：如果 property\n           的值是"*"，表示所有名字和 bean 属性名字匹配的请求参数都将被传递给相应的属性 set 方法。\nvalue      value 属性是可选的。该属性用来指定 bean 属性的值。字符串数据会在目标类中通过标准的 valueof\n           方法自动转换成数字、boolean、boolean、\n           byte、byte、char、character。例如，boolean 和 boolean\n           类型的属性值（比如"true"）通过 boolean.valueof 转换，int 和 integer\n           类型的属性值（比如"42"）通过 integer.valueof 转换。 　　 value 和 param\n           不能同时使用，但可以使用其中任意一个。\nparam      param 是可选的。它指定用哪个请求参数作为 bean 属性的值。如果当前请求没有参数，则什么事情也不做，系统不会把\n           null 传递给 bean 属性的 set 方法。因此，你可以让 bean\n           自己提供默认属性值，只有当请求参数明确指定了新值时才修改默认属性值。\n\n\n# <jsp:getproperty>\n\njsp:getproperty 动作提取指定 bean 属性的值，转换成字符串，然后输出。语法格式如下：\n\n<jsp:usebean id="myname" ... />\n...\n<jsp:getproperty name="myname" property="someproperty" .../>\n\n\n下表是与 getproperty 相关联的属性：\n\n属性         描述\nname       要检索的 bean 属性名称。bean 必须已定义。\nproperty   表示要提取 bean 属性的值\n\n实例\n\n以下实例我们使用了 bean:\n\npackage com.runoob.main;\n\npublic class testbean {\n   private string message = "菜鸟教程";\n\n   public string getmessage() {\n      return(message);\n   }\n   public void setmessage(string message) {\n      this.message = message;\n   }\n}\n\n\n编译以上实例文件 testbean.java ：\n\n$ javac testbean.java\n\n\n编译完成后会在当前目录下生成一个 testbean.class 文件， 将该文件拷贝至当前 jsp 项目的 webcontent/web-inf/classes/com/runoob/main 下( com/runoob/main 包路径，没有需要手动创建)。\n\n下面是一个 eclipse 中目录结构图：\n\n\n\n下面是一个很简单的例子，它的功能是装载一个 bean，然后设置/读取它的 message 属性。\n\n现在让我们在 main.jsp 文件中调用该 bean:\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%>\n<!doctype html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <h2>jsp 使用 javabean 实例</h2>\n    <jsp:usebean id="test" class="com.runoob.main.testbean" />\n\n    <jsp:setproperty name="test" property="message" value="菜鸟教程..." />\n\n    <p>输出信息....</p>\n\n    <jsp:getproperty name="test" property="message" />\n  </body>\n</html>\n\n\n浏览器访问，执行以上文件，输出如下所示：\n\n\n\n\n# <jsp:forward>\n\njsp:forward 动作把请求转到另外的页面。jsp:forward 标记只有一个属性 page。语法格式如下所示：\n\n<jsp:forward page="相对 url 地址" />\n\n\n以下是 forward 相关联的属性：\n\n属性     描述\npage   page 属性包含的是一个相对 url。page 的值既可以直接给出，也可以在请求的时候动态计算，可以是一个 jsp\n       页面或者一个 java servlet.\n\n实例\n\n以下实例我们使用了两个文件，分别是： date.jsp 和 main.jsp。\n\ndate.jsp 文件代码如下：\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%>\n<p>\n  今天的日期是: <%= (new java.util.date()).tolocalestring()%>\n</p>\n\n\nmain.jsp 文件代码：\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%>\n<!doctype html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <h2>forward 动作实例</h2>\n    <jsp:forward page="date.jsp" />\n  </body>\n</html>\n\n\n现在将以上两个文件放在服务器的根目录下，访问 main.jsp 文件。显示结果如下：\n\n今天的日期是: 2016-6-25 14:37:25\n\n\n\n# <jsp:plugin>\n\njsp:plugin 动作用来根据浏览器的类型，插入通过 java 插件 运行 java applet 所必需的 object 或 embed 元素。\n\n如果需要的插件不存在，它会下载插件，然后执行 java 组件。 java 组件可以是一个 applet 或一个 javabean。\n\nplugin 动作有多个对应 html 元素的属性用于格式化 java 组件。param 元素可用于向 applet 或 bean 传递参数。\n\n以下是使用 plugin 动作元素的典型实例:\n\n<jsp:plugin type="applet" codebase="dirname" code="myapplet.class"\n                           width="60" height="80">\n   <jsp:param name="fontcolor" value="red" />\n   <jsp:param name="background" value="black" />\n\n   <jsp:fallback>\n      unable to initialize java plugin\n   </jsp:fallback>\n\n</jsp:plugin>\n\n\n如果你有兴趣可以尝试使用 applet 来测试 jsp:plugin 动作元素，<fallback> 元素是一个新元素，在组件出现故障的错误是发送给用户错误信息。\n\n\n# <jsp:element> 、 <jsp:attribute>、<jsp:body>\n\n<jsp:element> 、 <jsp:attribute>、<jsp:body> 动作元素动态定义 xml 元素。动态是非常重要的，这就意味着 xml 元素在编译时是动态生成的而非静态。\n\n以下实例动态定义了 xml 元素：\n\n<%@ page language="java" contenttype="text/html; charset=utf-8"\npageencoding="utf-8"%>\n<!doctype html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>菜鸟教程(runoob.com)</title>\n  </head>\n  <body>\n    <jsp:element name="xmlelement">\n      <jsp:attribute name="xmlelementattr">\n        属性值\n      </jsp:attribute>\n      <jsp:body>\n        xml 元素的主体\n      </jsp:body>\n    </jsp:element>\n  </body>\n</html>\n\n\n浏览器访问以下页面，输出结果如下所示：\n\n\n\n\n# <jsp:text>\n\njsp:text动作元素允许在 jsp 页面和文档中使用写入文本的模板，语法格式如下：\n\n<jsp:text>模板数据</jsp:text>\n\n\n以上文本模板不能包含其他元素，只能只能包含文本和 el 表达式（注：el 表达式将在后续章节中介绍）。请注意，在 xml 文件中，您不能使用表达式如 ${whatever > 0}，因为>符号是非法的。 你可以使用 ${whatever gt 0}表达式或者嵌入在一个 cdata 部分的值。\n\n<jsp:text><![cdata[<br>]]></jsp:text>\n\n\n如果你需要在 xhtml 中声明 doctype,必须使用到 <jsp:text> 动作元素，实例如下：\n\n<jsp:text><![cdata[<!doctype html\npublic "-//w3c//dtd xhtml 1.0 strict//en"\n"dtd/xhtml1-strict.dtd">]]>\n</jsp:text>\n<head><title>jsp:text action</title></head>\n<body>\n\n<books><book><jsp:text>\n    welcome to jsp programming\n</jsp:text></book></books>\n\n</body>\n</html>\n\n\n你可以对以上实例尝试使用jsp:text及不使用该动作元素执行结果的区别。\n\n\n# jsp 隐式对象\n\njsp 隐式对象是 jsp 容器为每个页面提供的 java 对象，开发者可以直接使用它们而不用显式声明。jsp 隐式对象也被称为预定义变量。\n\njsp 所支持的九大隐式对象：\n\n对象            描述\nrequest       httpservletrequest类的实例\nresponse      httpservletresponse类的实例\nout           printwriter类的实例，用于把结果输出至网页上\nsession       httpsession类的实例\napplication   servletcontext类的实例，与应用上下文有关\nconfig        servletconfig类的实例\npagecontext   pagecontext类的实例，提供对 jsp 页面所有对象以及命名空间的访问\npage          类似于 java 类中的 this 关键字\nexception     exception类的对象，代表发生错误的 jsp 页面中对应的异常对象\n\n\n# request 对象\n\nrequest对象是javax.servlet.http.httpservletrequest 类的实例。\n\n每当客户端请求一个 jsp 页面时，jsp 引擎就会制造一个新的request对象来代表这个请求。\n\nrequest对象提供了一系列方法来获取 http 头信息，cookies，http 方法等等。\n\n\n# response 对象\n\nresponse对象是javax.servlet.http.httpservletresponse类的实例。\n\n当服务器创建request对象时会同时创建用于响应这个客户端的response对象。\n\nresponse对象也定义了处理 http 头模块的接口。通过这个对象，开发者们可以添加新的 cookies，时间戳，http 状态码等等。\n\n\n# out 对象\n\nout对象是javax.servlet.jsp.jspwriter类的实例，用来在response对象中写入内容。\n\n最初的jspwriter类对象根据页面是否有缓存来进行不同的实例化操作。可以在page指令中使用buffered=\'false\'属性来轻松关闭缓存。\n\njspwriter类包含了大部分java.io.printwriter类中的方法。不过，jspwriter新增了一些专为处理缓存而设计的方法。还有就是，jspwriter类会抛出ioexceptions异常，而printwriter不会。\n\n下表列出了我们将会用来输出boolean，char，int，double，string，object等类型数据的重要方法：\n\n方法                         描述\nout.print(datatype dt)     输出 type 类型的值\nout.println(datatype dt)   输出 type 类型的值然后换行\nout.flush()                刷新输出流\n\n\n# session 对象\n\nsession对象是javax.servlet.http.httpsession类的实例。和 java servlets 中的session对象有一样的行为。\n\nsession对象用来跟踪在各个客户端请求间的会话。\n\n\n# application 对象\n\napplication对象直接包装了 servlet 的servletcontext类的对象，是javax.servlet.servletcontext类的实例。\n\n这个对象在 jsp 页面的整个生命周期中都代表着这个 jsp 页面。这个对象在 jsp 页面初始化时被创建，随着jspdestroy()方法的调用而被移除。\n\n通过向application中添加属性，则所有组成您 web 应用的 jsp 文件都能访问到这些属性。\n\n\n# config 对象\n\nconfig对象是javax.servlet.servletconfig类的实例，直接包装了 servlet 的servletconfig类的对象。\n\n这个对象允许开发者访问 servlet 或者 jsp 引擎的初始化参数，比如文件路径等。\n\n以下是 config 对象的使用方法，不是很重要，所以不常用：\n\nconfig.getservletname();\n\n\n它返回包含在<servlet-name>元素中的 servlet 名字，注意，<servlet-name>元素在web-inf\\web.xml文件中定义。\n\n\n# pagecontext 对象\n\npagecontext对象是javax.servlet.jsp.pagecontext类的实例，用来代表整个 jsp 页面。\n\n这个对象主要用来访问页面信息，同时过滤掉大部分实现细节。\n\n这个对象存储了request对象和response对象的引用。application对象，config对象，session对象，out对象可以通过访问这个对象的属性来导出。\n\npagecontext对象也包含了传给 jsp 页面的指令信息，包括缓存信息，errorpage url,页面 scope 等。\n\npagecontext类定义了一些字段，包括 page_scope，request_scope，session_scope， application_scope。它也提供了 40 余种方法，有一半继承自javax.servlet.jsp.jspcontext 类。\n\n其中一个重要的方法就是removearribute()，它可接受一个或两个参数。比如，pagecontext.removearribute("attrname")移除四个 scope 中相关属性，但是下面这种方法只移除特定 scope 中的相关属性：\n\npagecontext.removeattribute("attrname", page_scope);\n\n\n\n# page 对象\n\n这个对象就是页面实例的引用。它可以被看做是整个 jsp 页面的代表。\n\npage对象就是this对象的同义词。\n\n\n# exception 对象\n\nexception对象包装了从先前页面中抛出的异常信息。它通常被用来产生对出错条件的适当响应。\n\n\n# el 表达式\n\nel 表达式是用${}括起来的脚本，用来更方便地读取对象。el 表达式写在 jsp 的 html 代码中，而不能写在<%与%>引起的 jsp 脚本中。\n\njsp 表达式语言（el）使得访问存储在 javabean 中的数据变得非常简单。jsp el 既可以用来创建算术表达式也可以用来创建逻辑表达式。在 jsp el 表达式内可以使用整型数，浮点数，字符串，常量 true、false，还有 null。\n\n\n# 一个简单的语法\n\n典型的，当您需要在 jsp 标签中指定一个属性值时，只需要简单地使用字符串即可：\n\n<jsp:setproperty name="box" property="perimeter" value="100" />\n\n\njsp el 允许您指定一个表达式来表示属性值。一个简单的表达式语法如下：\n\n${expr}\n\n\n其中，expr 指的是表达式。在 jsp el 中通用的操作符是"."和"[]"。这两个操作符允许您通过内嵌的 jsp 对象访问各种各样的 javabean 属性。\n\n举例来说，上面的 <jsp:setproperty> 标签可以使用表达式语言改写成如下形式：\n\n<jsp:setproperty\n  name="box"\n  property="perimeter"\n  value="${2*box.width+2*box.height}"\n/>\n\n\n当 jsp 编译器在属性中见到"${}"格式后，它会产生代码来计算这个表达式，并且产生一个替代品来代替表达式的值。\n\n您也可以在标签的模板文本中使用表达式语言。比如 <jsp:text> 标签简单地将其主体中的文本插入到 jsp 输出中：\n\n<jsp:text>\n  <h1>hello jsp!</h1>\n</jsp:text>\n\n\n现在，在jsp:text标签主体中使用表达式，就像这样：\n\n<jsp:text>\n  box perimeter is: ${2*box.width + 2*box.height}\n</jsp:text>\n\n\n在 el 表达式中可以使用圆括号来组织子表达式。比如 ${(1 + 2) _ 3} 等于 9，但是 ${1 + (2 _ 3)} 等于 7。\n\n想要停用对 el 表达式的评估的话，需要使用 page 指令将 iselignored 属性值设为 true：\n\n<%@ page iselignored ="true|false" %>\n\n\n这样，el 表达式就会被忽略。若设为 false，则容器将会计算 el 表达式。\n\n\n# el 中的基础操作符\n\nel 表达式支持大部分 java 所提供的算术和逻辑操作符：\n\n操作符         描述\n.           访问一个 bean 属性或者一个映射条目\n[]          访问一个数组或者链表的元素\n( )         组织一个子表达式以改变优先级\n+           加\n-           减或负\n*           乘\n/ or div    除\n% or mod    取模\n== or eq    测试是否相等\n!= or ne    测试是否不等\n< or lt     测试是否小于\n> or gt     测试是否大于\n<= or le    测试是否小于等于\n>= or ge    测试是否大于等于\n&& or and   测试逻辑与\n|| or or    测试逻辑或\n! or not    测试取反\nempty       测试是否空值\n\n\n# jsp el 中的函数\n\njsp el 允许您在表达式中使用函数。这些函数必须被定义在自定义标签库中。函数的使用语法如下：\n\n${ns:func(param1, param2, ...)}\n\n\nns 指的是命名空间（namespace），func 指的是函数的名称，param1 指的是第一个参数，param2 指的是第二个参数，以此类推。比如，有函数 fn:length，在 jstl 库中定义，可以像下面这样来获取一个字符串的长度：\n\n${fn:length("get my length")}\n\n\n要使用任何标签库中的函数，您需要将这些库安装在服务器中，然后使用 <taglib> 标签在 jsp 文件中包含这些库。\n\n\n# jsp el 隐含对象\n\njsp el 支持下表列出的隐含对象：\n\n隐含对象               描述\npagescope          page 作用域\nrequestscope       request 作用域\nsessionscope       session 作用域\napplicationscope   application 作用域\nparam              request 对象的参数，字符串\nparamvalues        request 对象的参数，字符串集合\nheader             http 信息头，字符串\nheadervalues       http 信息头，字符串集合\ninitparam          上下文初始化参数\ncookie             cookie 值\npagecontext        当前页面的 pagecontext\n\n您可以在表达式中使用这些对象，就像使用变量一样。接下来会给出几个例子来更好的理解这个概念。\n\n\n# pagecontext 对象\n\npagecontext 对象是 jsp 中 pagecontext 对象的引用。通过 pagecontext 对象，您可以访问 request 对象。比如，访问 request 对象传入的查询字符串，就像这样：\n\n${pagecontext.request.querystring}\n\n\n\n# scope 对象\n\npagescope，requestscope，sessionscope，applicationscope 变量用来访问存储在各个作用域层次的变量。\n\n举例来说，如果您需要显式访问在 applicationscope 层的 box 变量，可以这样来访问：applicationscope.box。\n\n\n# param 和 paramvalues 对象\n\nparam 和 paramvalues 对象用来访问参数值，通过使用 request.getparameter 方法和 request.getparametervalues 方法。\n\n举例来说，访问一个名为 order 的参数，可以这样使用表达式：${param.order}，或者${param["order"]}。\n\n接下来的例子表明了如何访问 request 中的 username 参数：\n\n<%@ page import="java.io.*,java.util.*" %> <% string title = "accessing request\nparam"; %>\n<html>\n  <head>\n    <title><% out.print(title); %></title>\n  </head>\n  <body>\n    <center>\n      <h1><% out.print(title); %></h1>\n    </center>\n    <div align="center">\n      <p>${param["username"]}</p>\n    </div>\n  </body>\n</html>\n\n\nparam 对象返回单一的字符串，而 paramvalues 对象则返回一个字符串数组。\n\n\n# header 和 headervalues 对象\n\nheader 和 headervalues 对象用来访问信息头，通过使用 request.getheader 方法和 request.getheaders 方法。\n\n举例来说，要访问一个名为 user-agent 的信息头，可以这样使用表达式：${header.user-agent}，或者 ${header["user-agent"]}。\n\n接下来的例子表明了如何访问 user-agent 信息头：\n\n<%@ page import="java.io.*,java.util.*" %> <% string title = "user agent\nexample"; %>\n<html>\n  <head>\n    <title><% out.print(title); %></title>\n  </head>\n  <body>\n    <center>\n      <h1><% out.print(title); %></h1>\n    </center>\n    <div align="center">\n      <p>${header["user-agent"]}</p>\n    </div>\n  </body>\n</html>\n\n\n运行结果如下：\n\n\n\nheader 对象返回单一值，而 headervalues 则返回一个字符串数组。\n\n\n# jstl\n\njsp 标准标签库（jstl）是一个 jsp 标签集合，它封装了 jsp 应用的通用核心功能。\n\njstl 支持通用的、结构化的任务，比如迭代，条件判断，xml 文档操作，国际化标签，sql 标签。 除了这些，它还提供了一个框架来使用集成 jstl 的自定义标签。\n\n根据 jstl 标签所提供的功能，可以将其分为 5 个类别。\n\n * 核心标签\n * 格式化标签\n * sql 标签\n * xml 标签\n * jstl 函数\n\n\n# jstl 库安装\n\napache tomcat 安装 jstl 库步骤如下：\n\n从 apache 的标准标签库中下载的二进包(jakarta-taglibs-standard-current.zip)。\n\n * 官方下载地址：http://archive.apache.org/dist/jakarta/taglibs/standard/binaries/\n * 本站下载地址：jakarta-taglibs-standard-1.1.2.zip\n\n下载 jakarta-taglibs-standard-1.1.2.zip 包并解压，将 jakarta-taglibs-standard-1.1.2/lib/ 下的两个 jar 文件：standard.jar 和 jstl.jar 文件拷贝到 /web-inf/lib/ 下。\n\n将 tld 下的需要引入的 tld 文件复制到 web-inf 目录下。\n\n接下来我们在 web.xml 文件中添加以下配置：\n\n<?xml version="1.0" encoding="utf-8"?>\n<web-app\n  version="2.4"\n  xmlns="http://java.sun.com/xml/ns/j2ee"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://java.sun.com/xml/ns/j2ee\n        http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd"\n>\n  <jsp-config>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/fmt</taglib-uri>\n      <taglib-location>/web-inf/fmt.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/fmt-rt</taglib-uri>\n      <taglib-location>/web-inf/fmt-rt.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/core</taglib-uri>\n      <taglib-location>/web-inf/c.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/core-rt</taglib-uri>\n      <taglib-location>/web-inf/c-rt.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/sql</taglib-uri>\n      <taglib-location>/web-inf/sql.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/sql-rt</taglib-uri>\n      <taglib-location>/web-inf/sql-rt.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/x</taglib-uri>\n      <taglib-location>/web-inf/x.tld</taglib-location>\n    </taglib>\n    <taglib>\n      <taglib-uri>http://java.sun.com/jsp/jstl/x-rt</taglib-uri>\n      <taglib-location>/web-inf/x-rt.tld</taglib-location>\n    </taglib>\n  </jsp-config>\n</web-app>\n\n\n使用任何库，你必须在每个 jsp 文件中的头部包含 标签。\n\n\n# 核心标签\n\n核心标签是最常用的 jstl 标签。引用核心标签库的语法如下：\n\n<%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %>\n\n\n标签              描述\n<c:out>         用于在 jsp 中显示数据，就像<%= ... >\n<c:set>         用于保存数据\n<c:remove>      用于删除数据\n<c:catch>       用来处理产生错误的异常状况，并且将错误信息储存起来\n<c:if>          与我们在一般程序中用的 if 一样\n<c:choose>      本身只当做<c:when>和<c:otherwise>的父标签\n<c:when>        <c:choose>的子标签，用来判断条件是否成立\n<c:otherwise>   <c:choose>的子标签，接在<c:when>标签后，当<c:when>标签判断为 false 时被执行\n<c:import>      检索一个绝对或相对 url，然后将其内容暴露给页面\n<c:foreach>     基础迭代标签，接受多种集合类型\n<c:fortokens>   根据指定的分隔符来分隔内容并迭代输出\n<c:param>       用来给包含或重定向的页面传递参数\n<c:redirect>    重定向至一个新的 url.\n<c:url>         使用可选的查询参数来创造一个 url\n\n\n# 格式化标签\n\njstl 格式化标签用来格式化并输出文本、日期、时间、数字。引用格式化标签库的语法如下：\n\n<%@ taglib prefix="fmt" uri="http://java.sun.com/jsp/jstl/fmt" %>\n\n\n标签                      描述\n<fmt:formatnumber>      使用指定的格式或精度格式化数字\n<fmt:parsenumber>       解析一个代表着数字，货币或百分比的字符串\n<fmt:formatdate>        使用指定的风格或模式格式化日期和时间\n<fmt:parsedate>         解析一个代表着日期或时间的字符串\n<fmt:bundle>            绑定资源\n<fmt:setlocale>         指定地区\n<fmt:setbundle>         绑定资源\n<fmt:timezone>          指定时区\n<fmt:settimezone>       指定时区\n<fmt:message>           显示资源配置文件信息\n<fmt:requestencoding>   设置 request 的字符编码\n\n\n# sql 标签\n\njstl sql 标签库提供了与关系型数据库（oracle，mysql，sql server 等等）进行交互的标签。引用 sql 标签库的语法如下：\n\n<%@ taglib prefix="sql" uri="http://java.sun.com/jsp/jstl/sql" %>\n\n\n标签                    描述\n<sql:setdatasource>   指定数据源\n<sql:query>           运行 sql 查询语句\n<sql:update>          运行 sql 更新语句\n<sql:param>           将 sql 语句中的参数设为指定值\n<sql:dateparam>       将 sql 语句中的日期参数设为指定的 java.util.date 对象值\n<sql:transaction>     在共享数据库连接中提供嵌套的数据库行为元素，将所有语句以一个事务的形式来运行\n\n\n# xml 标签\n\njstl xml 标签库提供了创建和操作 xml 文档的标签。引用 xml 标签库的语法如下：\n\n<%@ taglib prefix="x" uri="http://java.sun.com/jsp/jstl/xml" %>\n\n\n在使用 xml 标签前，你必须将 xml 和 xpath 的相关包拷贝至你的 <tomcat 安装目录>\\lib 下:\n\n * xercesimpl.jar\n   \n   下载地址： http://www.apache.org/dist/xerces/j/\n\n * xalan.jar\n   \n   下载地址： http://xml.apache.org/xalan-j/index.html\n\n标签              描述\n<x:out>         与<%= ... >,类似，不过只用于 xpath 表达式\n<x:parse>       解析 xml 数据\n<x:set>         设置 xpath 表达式\n<x:if>          判断 xpath 表达式，若为真，则执行本体中的内容，否则跳过本体\n<x:foreach>     迭代 xml 文档中的节点\n<x:choose>      <x:when>和<x:otherwise>的父标签\n<x:when>        <x:choose>的子标签，用来进行条件判断\n<x:otherwise>   <x:choose>的子标签，当<x:when>判断为 false 时被执行\n<x:transform>   将 xsl 转换应用在 xml 文档中\n<x:param>       与<x:transform>共同使用，用于设置 xsl 样式表\n\n\n# jstl 函数\n\njstl 包含一系列标准函数，大部分是通用的字符串处理函数。引用 jstl 函数库的语法如下：\n\n<%@ taglib prefix="fn" uri="http://java.sun.com/jsp/jstl/functions" %>\n\n\n函数                        描述\nfn:contains()             测试输入的字符串是否包含指定的子串\nfn:containsignorecase()   测试输入的字符串是否包含指定的子串，大小写不敏感\nfn:endswith()             测试输入的字符串是否以指定的后缀结尾\nfn:escapexml()            跳过可以作为 xml 标记的字符\nfn:indexof()              返回指定字符串在输入字符串中出现的位置\nfn:join()                 将数组中的元素合成一个字符串然后输出\nfn:length()               返回字符串长度\nfn:replace()              将输入字符串中指定的位置替换为指定的字符串然后返回\nfn:split()                将字符串用指定的分隔符分隔然后组成一个子字符串数组并返回\nfn:startswith()           测试输入字符串是否以指定的前缀开始\nfn:substring()            返回字符串的子集\nfn:substringafter()       返回字符串在指定子串之后的子集\nfn:substringbefore()      返回字符串在指定子串之前的子集\nfn:tolowercase()          将字符串中的字符转为小写\nfn:touppercase()          将字符串中的字符转为大写\nfn:trim()                 移除首尾的空白符\n\n\n# taglib\n\n\n# jsp 自定义标签\n\n自定义标签是用户定义的 jsp 语言元素。当 jsp 页面包含一个自定义标签时将被转化为 servlet，标签转化为对被 称为 tag handler 的对象的操作，即当 servlet 执行时 web container 调用那些操作。\n\njsp 标签扩展可以让你创建新的标签并且可以直接插入到一个 jsp 页面。 jsp 2.0 规范中引入 simple tag handlers 来编写这些自定义标记。\n\n你可以继承 simpletagsupport 类并重写的 dotag()方法来开发一个最简单的自定义标签。\n\n\n# 创建"hello"标签\n\n接下来，我们想创建一个自定义标签叫作ex:hello，标签格式为：\n\n<ex:hello />\n\n\n要创建自定义的 jsp 标签，你首先必须创建处理标签的 java 类。所以，让我们创建一个 hellotag 类，如下所示：\n\npackage com.runoob; import javax.servlet.jsp.tagext.*; import\njavax.servlet.jsp.*; import java.io.*; public class hellotag extends\nsimpletagsupport { public void dotag() throws jspexception, ioexception {\njspwriter out = getjspcontext().getout(); out.println("hello custom tag!"); } }\n\n\n以下代码重写了 dotag()方法，方法中使用了 getjspcontext()方法来获取当前的 jspcontext 对象，并将"hello custom tag!"传递给 jspwriter 对象。\n\n编译以上类，并将其复制到环境变量 classpath 目录中。最后创建如下标签库：<tomcat安装目录>webapps\\root\\web-inf\\custom.tld。\n\n<taglib>\n  <tlib-version>1.0</tlib-version>\n  <jsp-version>2.0</jsp-version>\n  <short-name>example tld</short-name>\n  <tag>\n    <name>hello</name>\n    <tag-class>com.runoob.hellotag</tag-class>\n    <body-content>empty</body-content>\n  </tag>\n</taglib>\n\n\n接下来，我们就可以在 jsp 文件中使用 hello 标签：\n\n<%@ taglib prefix="ex" uri="web-inf/custom.tld"%>\n<html>\n  <head>\n    <title>a sample custom tag</title>\n  </head>\n  <body>\n    <ex:hello />\n  </body>\n</html>\n\n\n以上程序输出结果为：\n\nhello custom tag!\n\n\n\n# 访问标签体\n\n你可以像标准标签库一样在标签中包含消息内容。如我们要在我们自定义的 hello 中包含内容，格式如下：\n\n<ex:hello>\n  this is message body\n</ex:hello>\n\n\n我们可以修改标签处理类文件，代码如下：\n\npackage com.runoob;\n\nimport javax.servlet.jsp.tagext.*;\nimport javax.servlet.jsp.*;\nimport java.io.*;\n\npublic class hellotag extends simpletagsupport {\n\n   stringwriter sw = new stringwriter();\n   public void dotag()\n      throws jspexception, ioexception\n    {\n       getjspbody().invoke(sw);\n       getjspcontext().getout().println(sw.tostring());\n    }\n\n}\n\n\n接下来我们需要修改 tld 文件，如下所示：\n\n<taglib>\n  <tlib-version>1.0</tlib-version>\n  <jsp-version>2.0</jsp-version>\n  <short-name>example tld with body</short-name>\n  <tag>\n    <name>hello</name>\n    <tag-class>com.runoob.hellotag</tag-class>\n    <body-content>scriptless</body-content>\n  </tag>\n</taglib>\n\n\n现在我们可以在 jsp 使用修改后的标签，如下所示:\n\n<%@ taglib prefix="ex" uri="web-inf/custom.tld"%>\n<html>\n  <head>\n    <title>a sample custom tag</title>\n  </head>\n  <body>\n    <ex:hello>\n      this is message body\n    </ex:hello>\n  </body>\n</html>\n\n\n以上程序输出结果如下所示：\n\nthis is message body\n\n\n\n# 自定义标签属性\n\n你可以在自定义标准中设置各种属性，要接收属性，值自定义标签类必须实现 setter 方法， javabean 中的 setter 方法如下所示：\n\npackage com.runoob;\n\nimport javax.servlet.jsp.tagext.*;\nimport javax.servlet.jsp.*;\nimport java.io.*;\n\npublic class hellotag extends simpletagsupport {\n\n   private string message;\n\n   public void setmessage(string msg) {\n      this.message = msg;\n   }\n\n   stringwriter sw = new stringwriter();\n\n   public void dotag()\n      throws jspexception, ioexception\n    {\n       if (message != null) {\n          /* 从属性中使用消息 */\n          jspwriter out = getjspcontext().getout();\n          out.println( message );\n       }\n       else {\n          /* 从内容体中使用消息 */\n          getjspbody().invoke(sw);\n          getjspcontext().getout().println(sw.tostring());\n       }\n   }\n\n}\n\n\n属性的名称是"message"，所以 setter 方法是的 setmessage()。现在让我们在 tld 文件中使用的元素添加此属性：\n\n<taglib>\n  <tlib-version>1.0</tlib-version>\n  <jsp-version>2.0</jsp-version>\n  <short-name>example tld with body</short-name>\n  <tag>\n    <name>hello</name>\n    <tag-class>com.runoob.hellotag</tag-class>\n    <body-content>scriptless</body-content>\n    <attribute>\n      <name>message</name>\n    </attribute>\n  </tag>\n</taglib>\n\n\n现在我们就可以在 jsp 文件中使用 message 属性了，如下所示：\n\n<%@ taglib prefix="ex" uri="web-inf/custom.tld"%>\n<html>\n  <head>\n    <title>a sample custom tag</title>\n  </head>\n  <body>\n    <ex:hello message="this is custom tag" />\n  </body>\n</html>\n\n\n以上实例数据输出结果为：\n\nthis is custom tag\n\n\n你还可以包含以下属性：\n\n属性            描述\nname          定义属性的名称。每个标签的是属性名称必须是唯一的。\nrequired      指定属性是否是必须的或者可选的,如果设置为 false 为可选。\nrtexprvalue   声明在运行表达式时，标签属性是否有效。\ntype          定义该属性的 java 类类型 。默认指定为 string\ndescription   描述信息\nfragment      如果声明了该属性,属性值将被视为一个 jspfragment。\n\n以下是指定相关的属性实例：\n\n.....\n<attribute>\n  <name>attribute_name</name>\n  <required>false</required>\n  <type>java.util.date</type>\n  <fragment>false</fragment>\n</attribute>\n.....\n\n\n如果你使用了两个属性，修改 tld 文件，如下所示：\n\n.....\n<attribute>\n  <name>attribute_name1</name>\n  <required>false</required>\n  <type>java.util.boolean</type>\n  <fragment>false</fragment>\n</attribute>\n<attribute>\n  <name>attribute_name2</name>\n  <required>true</required>\n  <type>java.util.date</type>\n</attribute>\n.....\n',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"JavaWeb 之 Filter 和 Listener",frontmatter:{title:"JavaWeb 之 Filter 和 Listener",categories:["编程","Java","JavaWeb"],tags:["Java","JavaWeb","Filter","Listener"],abbrlink:"9eb5517a",date:"2020-08-24T19:41:46.000Z",permalink:"/pages/5ecb29/"},regularPath:"/02.JavaEE/01.JavaWeb/03.JavaWeb%E4%B9%8BFilter%E5%92%8CListener.html",relativePath:"02.JavaEE/01.JavaWeb/03.JavaWeb之Filter和Listener.md",key:"v-576f0972",path:"/pages/5ecb29/",headers:[{level:2,title:"Filter",slug:"filter",normalizedTitle:"filter",charIndex:12},{level:3,title:"过滤器方法",slug:"过滤器方法",normalizedTitle:"过滤器方法",charIndex:483},{level:3,title:"过滤器配置",slug:"过滤器配置",normalizedTitle:"过滤器配置",charIndex:1350},{level:2,title:"Listener",slug:"listener",normalizedTitle:"listener",charIndex:21},{level:3,title:"监听器的分类",slug:"监听器的分类",normalizedTitle:"监听器的分类",charIndex:2207},{level:3,title:"监听对象的创建和销毁",slug:"监听对象的创建和销毁",normalizedTitle:"监听对象的创建和销毁",charIndex:2439},{level:4,title:"HttpSessionListener",slug:"httpsessionlistener",normalizedTitle:"httpsessionlistener",charIndex:2453},{level:4,title:"ServletContextListener",slug:"servletcontextlistener",normalizedTitle:"servletcontextlistener",charIndex:2652},{level:4,title:"ServletRequestListener",slug:"servletrequestlistener",normalizedTitle:"servletrequestlistener",charIndex:3072},{level:3,title:"监听对象的属性变化",slug:"监听对象的属性变化",normalizedTitle:"监听对象的属性变化",charIndex:3390},{level:4,title:"attributeAdded 方法",slug:"attributeadded-方法",normalizedTitle:"attributeadded 方法",charIndex:3676},{level:4,title:"attributeRemoved 方法",slug:"attributeremoved-方法",normalizedTitle:"attributeremoved 方法",charIndex:4011},{level:4,title:"attributeReplaced 方法",slug:"attributereplaced-方法",normalizedTitle:"attributereplaced 方法",charIndex:4298},{level:3,title:"监听 Session 内的对象",slug:"监听-session-内的对象",normalizedTitle:"监听 session 内的对象",charIndex:4594},{level:4,title:"HttpSessionBindingListener",slug:"httpsessionbindinglistener",normalizedTitle:"httpsessionbindinglistener",charIndex:4828},{level:4,title:"HttpSessionActivationListener",slug:"httpsessionactivationlistener",normalizedTitle:"httpsessionactivationlistener",charIndex:4856},{level:2,title:"Filter 和 Listener",slug:"filter-和-listener",normalizedTitle:"filter 和 listener",charIndex:12},{level:2,title:"示例代码",slug:"示例代码",normalizedTitle:"示例代码",charIndex:5846},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:5896}],headersStr:"Filter 过滤器方法 过滤器配置 Listener 监听器的分类 监听对象的创建和销毁 HttpSessionListener ServletContextListener ServletRequestListener 监听对象的属性变化 attributeAdded 方法 attributeRemoved 方法 attributeReplaced 方法 监听 Session 内的对象 HttpSessionBindingListener HttpSessionActivationListener Filter 和 Listener 示例代码 参考资料",content:'# JavaWeb 之 Filter 和 Listener\n\n引入了 Servlet 规范后，你不需要关心 Socket 网络通信、不需要关心 HTTP 协议，也不需要关心你的业务类是如何被实例化和调用的，因为这些都被 Servlet 规范标准化了，你只要关心怎么实现的你的业务逻辑。这对于程序员来说是件好事，但也有不方便的一面。所谓规范就是说大家都要遵守，就会千篇一律，但是如果这个规范不能满足你的业务的个性化需求，就有问题了，因此设计一个规范或者一个中间件，要充分考虑到可扩展性。Servlet 规范提供了两种扩展机制：Filter和Listener。\n\n\n# Filter\n\nFilter 是过滤器，这个接口允许你对请求和响应做一些统一的定制化处理。\n\nFilter 提供了过滤链（Filter Chain）的概念，一个过滤链包括多个 Filter。客户端请求 request 在抵达 Servlet 之前会经过过滤链的所有 Filter，服务器响应 response 从 Servlet 抵达客户端浏览器之前也会经过过滤链的所有 FIlter。\n\n\n\n\n# 过滤器方法\n\nFilter 接口有三个方法：\n\n * init：初始化 Filter\n * destroy：销毁 Filter\n * doFilter：将请求传给下个 Filter 或 Servlet\n\ninit 和 destroy 方法只会被调用一次；doFilter 每次有客户端请求都会被调用一次。\n\npublic interface Filter {\n\n\t/**\n\t * web 程序启动时调用此方法, 用于初始化该 Filter\n\t * @param config\n\t *            可以从该参数中获取初始化参数以及ServletContext信息等\n\t * @throws ServletException\n\t */\n\tpublic void init(FilterConfig config) throws ServletException;\n\n\t/**\n\t * 客户请求服务器时会经过\n\t *\n\t * @param request\n\t *            客户请求\n\t * @param response\n\t *            服务器响应\n\t * @param chain\n\t *            过滤链, 通过 chain.doFilter(request, response) 将请求传给下个 Filter 或\n\t *            Servlet\n\t * @throws ServletException\n\t * @throws IOException\n\t */\n\tpublic void doFilter(ServletRequest request, ServletResponse response,\n\t\t\tFilterChain chain) throws ServletException, IOException;\n\n\t/**\n\t * web 程序关闭时调用此方法, 用于销毁一些资源\n\t */\n\tpublic void destroy();\n\n}\n\n\n\n# 过滤器配置\n\nFilter 需要配置在 web.xml 中才能生效。一个 Filter 需要配置 <filter> 与 <filter-mapping> 标签。\n\n * <filter> 配置 Filter 名称，实现类以及初始化参数。\n * <filter-mapping> 配置什么规则下使用该 Filter。\n * <filter> 的 filterName 与 <filter-mapping> 的 filterName 必须匹配。\n * <url-pattern> 配置 URL 的规则，可以配置多个，可以使用通配符（*）。\n * <dispatcher> 配置到达 Servlet 的方式，有 4 种取值：REQUEST、FORWARD、INCLUDE、ERROR。可以同时配置多个 <dispatcher>。如果没有配置任何 <dispatcher>，默认为 REQUEST。\n   * REQUEST - 表示仅当直接请求 Servlet 时才生效。\n   * FORWARD - 表示仅当某 Servlet 通过 FORWARD 到该 Servlet 时才生效。\n   * INCLUDE - JSP 中可以通过 <jsp:include> 请求某 Servlet。仅在这种情况表有效。\n   * ERROR - JSP 中可以通过 <%@ page errorPage="error.jsp" %> 指定错误处理页面。仅在这种情况表有效。\n\n\n# Listener\n\n监听器（Listener）用于监听 web 应用程序中的ServletContext, HttpSession和 ServletRequest等域对象的创建与销毁事件，以及监听这些域对象中的属性发生修改的事件。\n\n使用 Listener 不需要关注该类事件时怎样触发或者怎么调用相应的 Listener，只要记住该类事件触发时一定会调用相应的 Listener，遵循 Servlet 规范的服务器会自动完成相应工作。\n\n\n# 监听器的分类\n\n在 Servlet 规范中定义了多种类型的监听器，它们用于监听的事件源分别为ServletContext，HttpSession和ServletRequest这三个域对象 Servlet 规范针对这三个对象上的操作，又把多种类型的监听器划分为三种类型：\n\n 1. 监听域对象自身的创建和销毁的事件监听器。\n 2. 监听域对象中的属性的增加和删除的事件监听器。\n 3. 监听绑定到 HttpSession 域中的某个对象的状态的事件监听器。\n\n\n# 监听对象的创建和销毁\n\n# HttpSessionListener\n\nHttpSessionListener 接口用于监听 HttpSession 对象的创建和销毁。\n\n * 创建一个 Session 时，激发 sessionCreated (HttpSessionEvent se) 方法\n * 销毁一个 Session 时，激发 sessionDestroyed (HttpSessionEvent se) 方法。\n\n# ServletContextListener\n\nServletContextListener 接口用于监听 ServletContext 对象的创建和销毁事件。\n\n实现了 ServletContextListener 接口的类都可以对 ServletContext 对象的创建和销毁进行监听。\n\n * 当 ServletContext 对象被创建时，激发 contextInitialized (ServletContextEvent sce) 方法。\n * 当 ServletContext 对象被销毁时，激发 contextDestroyed(ServletContextEvent sce) 方法。\n\nServletContext 域对象创建和销毁时机：\n\n * 创建：服务器启动针对每一个 Web 应用创建 ServletContext\n * 销毁：服务器关闭前先关闭代表每一个 web 应用的 ServletContext\n\n# ServletRequestListener\n\nServletRequestListener 接口用于监听 ServletRequest 对象的创建和销毁。\n\n * Request 对象被创建时，监听器的 requestInitialized(ServletRequestEvent sre) 方法将会被调用\n * Request 对象被销毁时，监听器的 requestDestroyed(ServletRequestEvent sre) 方法将会被调用\n\nServletRequest 域对象创建和销毁时机：\n\n * 创建：用户每一次访问都会创建 request 对象\n * 销毁：当前访问结束，request 对象就会销毁\n\n\n# 监听对象的属性变化\n\n域对象中属性的变更的事件监听器就是用来监听 ServletContext、HttpSession、HttpServletRequest 这三个对象中的属性变更信息事件的监听器。 这三个监听器接口分别是 ServletContextAttributeListener、HttpSessionAttributeListener 和 ServletRequestAttributeListener，这三个接口中都定义了三个方法来处理被监听对象中的属性的增加，删除和替换的事件，同一个事件在这三个接口中对应的方法名称完全相同，只是接受的参数类型不同。\n\n# attributeAdded 方法\n\n当向被监听对象中增加一个属性时，web 容器就调用事件监听器的 attributeAdded 方法进行响应，这个方法接收一个事件类型的参数，监听器可以通过这个参数来获得正在增加属性的域对象和被保存到域中的属性对象 各个域属性监听器中的完整语法定义为：\n\npublic void attributeAdded(ServletContextAttributeEvent scae)\npublic void attributeReplaced(HttpSessionBindingEvent hsbe)\npublic void attributeRmoved(ServletRequestAttributeEvent srae)\n\n\n# attributeRemoved 方法\n\n当删除被监听对象中的一个属性时，web 容器调用事件监听器的 attributeRemoved 方法进行响应 各个域属性监听器中的完整语法定义为：\n\npublic void attributeRemoved(ServletContextAttributeEvent scae)\npublic void attributeRemoved(HttpSessionBindingEvent hsbe)\npublic void attributeRemoved(ServletRequestAttributeEvent srae)\n\n\n# attributeReplaced 方法\n\n当监听器的域对象中的某个属性被替换时，web 容器调用事件监听器的 attributeReplaced 方法进行响应 各个域属性监听器中的完整语法定义为：\n\npublic void attributeReplaced(ServletContextAttributeEvent scae)\npublic void attributeReplaced(HttpSessionBindingEvent hsbe)\npublic void attributeReplaced(ServletRequestAttributeEvent srae)\n\n\n\n# 监听 Session 内的对象\n\n保存在 Session 域中的对象可以有多种状态：\n\n * 绑定（session.setAttribute("bean",Object)）到 Session 中；\n * 从 Session 域中解除绑定（session.removeAttribute("bean")）；\n * 随 Session 对象持久化到一个存储设备中；\n * 随 Session 对象从一个存储设备中恢复。\n\nServlet 规范中定义了两个特殊的监听器接口 HttpSessionBindingListener 和HttpSessionActivationListener 来帮助 JavaBean 对象了解自己在 Session 域中的这些状态。\n\n实现这两个接口的类不需要 web.xml 文件中进行注册。\n\n# HttpSessionBindingListener\n\nHttpSessionBindingListener 接口的 JavaBean 对象可以感知自己被绑定或解绑定到 Session 中的事件。\n\n * 当对象被绑定到 HttpSession 对象中时，web 服务器调用该对象的 valueBound(HttpSessionBindingEvent event) 方法。\n * 当对象从 HttpSession 对象中解除绑定时，web 服务器调用该对象的 valueUnbound(HttpSessionBindingEvent event) 方法。\n\n# HttpSessionActivationListener\n\n实现了 HttpSessionActivationListener 接口的 JavaBean 对象可以感知自己被活化(反序列化)和钝化(序列化)的事件。\n\n * 当绑定到 HttpSession 对象中的 JavaBean 对象将要随 HttpSession 对象被序列化之前，web 服务器调用该 JavaBean 对象的 sessionWillPassivate(HttpSessionEvent event) 方法。这样 JavaBean 对象就可以知道自己将要和 HttpSession 对象一起被序列化到硬盘中.\n * 当绑定到 HttpSession 对象中的 JavaBean 对象将要随 HttpSession 对象被反序列化之后，web 服务器调用该 JavaBean 对象的 sessionDidActive(HttpSessionEvent event) 方法。这样 JavaBean 对象就可以知道自己将要和 HttpSession 对象一起被反序列化回到内存中\n\n\n# Filter 和 Listener\n\nFilter 和 Listener 的本质区别：\n\n * Filter 是干预过程的，它是过程的一部分，是基于过程行为的。\n * Listener 是基于状态的，任何行为改变同一个状态，触发的事件是一致的。\n\n\n# 示例代码\n\n * Filter 的示例源码：源码\n * Listener 的示例源码：源码\n\n\n# 参考资料\n\n * 深入拆解 Tomcat & Jetty\n * Java Web 整合开发王者归来',normalizedContent:'# javaweb 之 filter 和 listener\n\n引入了 servlet 规范后，你不需要关心 socket 网络通信、不需要关心 http 协议，也不需要关心你的业务类是如何被实例化和调用的，因为这些都被 servlet 规范标准化了，你只要关心怎么实现的你的业务逻辑。这对于程序员来说是件好事，但也有不方便的一面。所谓规范就是说大家都要遵守，就会千篇一律，但是如果这个规范不能满足你的业务的个性化需求，就有问题了，因此设计一个规范或者一个中间件，要充分考虑到可扩展性。servlet 规范提供了两种扩展机制：filter和listener。\n\n\n# filter\n\nfilter 是过滤器，这个接口允许你对请求和响应做一些统一的定制化处理。\n\nfilter 提供了过滤链（filter chain）的概念，一个过滤链包括多个 filter。客户端请求 request 在抵达 servlet 之前会经过过滤链的所有 filter，服务器响应 response 从 servlet 抵达客户端浏览器之前也会经过过滤链的所有 filter。\n\n\n\n\n# 过滤器方法\n\nfilter 接口有三个方法：\n\n * init：初始化 filter\n * destroy：销毁 filter\n * dofilter：将请求传给下个 filter 或 servlet\n\ninit 和 destroy 方法只会被调用一次；dofilter 每次有客户端请求都会被调用一次。\n\npublic interface filter {\n\n\t/**\n\t * web 程序启动时调用此方法, 用于初始化该 filter\n\t * @param config\n\t *            可以从该参数中获取初始化参数以及servletcontext信息等\n\t * @throws servletexception\n\t */\n\tpublic void init(filterconfig config) throws servletexception;\n\n\t/**\n\t * 客户请求服务器时会经过\n\t *\n\t * @param request\n\t *            客户请求\n\t * @param response\n\t *            服务器响应\n\t * @param chain\n\t *            过滤链, 通过 chain.dofilter(request, response) 将请求传给下个 filter 或\n\t *            servlet\n\t * @throws servletexception\n\t * @throws ioexception\n\t */\n\tpublic void dofilter(servletrequest request, servletresponse response,\n\t\t\tfilterchain chain) throws servletexception, ioexception;\n\n\t/**\n\t * web 程序关闭时调用此方法, 用于销毁一些资源\n\t */\n\tpublic void destroy();\n\n}\n\n\n\n# 过滤器配置\n\nfilter 需要配置在 web.xml 中才能生效。一个 filter 需要配置 <filter> 与 <filter-mapping> 标签。\n\n * <filter> 配置 filter 名称，实现类以及初始化参数。\n * <filter-mapping> 配置什么规则下使用该 filter。\n * <filter> 的 filtername 与 <filter-mapping> 的 filtername 必须匹配。\n * <url-pattern> 配置 url 的规则，可以配置多个，可以使用通配符（*）。\n * <dispatcher> 配置到达 servlet 的方式，有 4 种取值：request、forward、include、error。可以同时配置多个 <dispatcher>。如果没有配置任何 <dispatcher>，默认为 request。\n   * request - 表示仅当直接请求 servlet 时才生效。\n   * forward - 表示仅当某 servlet 通过 forward 到该 servlet 时才生效。\n   * include - jsp 中可以通过 <jsp:include> 请求某 servlet。仅在这种情况表有效。\n   * error - jsp 中可以通过 <%@ page errorpage="error.jsp" %> 指定错误处理页面。仅在这种情况表有效。\n\n\n# listener\n\n监听器（listener）用于监听 web 应用程序中的servletcontext, httpsession和 servletrequest等域对象的创建与销毁事件，以及监听这些域对象中的属性发生修改的事件。\n\n使用 listener 不需要关注该类事件时怎样触发或者怎么调用相应的 listener，只要记住该类事件触发时一定会调用相应的 listener，遵循 servlet 规范的服务器会自动完成相应工作。\n\n\n# 监听器的分类\n\n在 servlet 规范中定义了多种类型的监听器，它们用于监听的事件源分别为servletcontext，httpsession和servletrequest这三个域对象 servlet 规范针对这三个对象上的操作，又把多种类型的监听器划分为三种类型：\n\n 1. 监听域对象自身的创建和销毁的事件监听器。\n 2. 监听域对象中的属性的增加和删除的事件监听器。\n 3. 监听绑定到 httpsession 域中的某个对象的状态的事件监听器。\n\n\n# 监听对象的创建和销毁\n\n# httpsessionlistener\n\nhttpsessionlistener 接口用于监听 httpsession 对象的创建和销毁。\n\n * 创建一个 session 时，激发 sessioncreated (httpsessionevent se) 方法\n * 销毁一个 session 时，激发 sessiondestroyed (httpsessionevent se) 方法。\n\n# servletcontextlistener\n\nservletcontextlistener 接口用于监听 servletcontext 对象的创建和销毁事件。\n\n实现了 servletcontextlistener 接口的类都可以对 servletcontext 对象的创建和销毁进行监听。\n\n * 当 servletcontext 对象被创建时，激发 contextinitialized (servletcontextevent sce) 方法。\n * 当 servletcontext 对象被销毁时，激发 contextdestroyed(servletcontextevent sce) 方法。\n\nservletcontext 域对象创建和销毁时机：\n\n * 创建：服务器启动针对每一个 web 应用创建 servletcontext\n * 销毁：服务器关闭前先关闭代表每一个 web 应用的 servletcontext\n\n# servletrequestlistener\n\nservletrequestlistener 接口用于监听 servletrequest 对象的创建和销毁。\n\n * request 对象被创建时，监听器的 requestinitialized(servletrequestevent sre) 方法将会被调用\n * request 对象被销毁时，监听器的 requestdestroyed(servletrequestevent sre) 方法将会被调用\n\nservletrequest 域对象创建和销毁时机：\n\n * 创建：用户每一次访问都会创建 request 对象\n * 销毁：当前访问结束，request 对象就会销毁\n\n\n# 监听对象的属性变化\n\n域对象中属性的变更的事件监听器就是用来监听 servletcontext、httpsession、httpservletrequest 这三个对象中的属性变更信息事件的监听器。 这三个监听器接口分别是 servletcontextattributelistener、httpsessionattributelistener 和 servletrequestattributelistener，这三个接口中都定义了三个方法来处理被监听对象中的属性的增加，删除和替换的事件，同一个事件在这三个接口中对应的方法名称完全相同，只是接受的参数类型不同。\n\n# attributeadded 方法\n\n当向被监听对象中增加一个属性时，web 容器就调用事件监听器的 attributeadded 方法进行响应，这个方法接收一个事件类型的参数，监听器可以通过这个参数来获得正在增加属性的域对象和被保存到域中的属性对象 各个域属性监听器中的完整语法定义为：\n\npublic void attributeadded(servletcontextattributeevent scae)\npublic void attributereplaced(httpsessionbindingevent hsbe)\npublic void attributermoved(servletrequestattributeevent srae)\n\n\n# attributeremoved 方法\n\n当删除被监听对象中的一个属性时，web 容器调用事件监听器的 attributeremoved 方法进行响应 各个域属性监听器中的完整语法定义为：\n\npublic void attributeremoved(servletcontextattributeevent scae)\npublic void attributeremoved(httpsessionbindingevent hsbe)\npublic void attributeremoved(servletrequestattributeevent srae)\n\n\n# attributereplaced 方法\n\n当监听器的域对象中的某个属性被替换时，web 容器调用事件监听器的 attributereplaced 方法进行响应 各个域属性监听器中的完整语法定义为：\n\npublic void attributereplaced(servletcontextattributeevent scae)\npublic void attributereplaced(httpsessionbindingevent hsbe)\npublic void attributereplaced(servletrequestattributeevent srae)\n\n\n\n# 监听 session 内的对象\n\n保存在 session 域中的对象可以有多种状态：\n\n * 绑定（session.setattribute("bean",object)）到 session 中；\n * 从 session 域中解除绑定（session.removeattribute("bean")）；\n * 随 session 对象持久化到一个存储设备中；\n * 随 session 对象从一个存储设备中恢复。\n\nservlet 规范中定义了两个特殊的监听器接口 httpsessionbindinglistener 和httpsessionactivationlistener 来帮助 javabean 对象了解自己在 session 域中的这些状态。\n\n实现这两个接口的类不需要 web.xml 文件中进行注册。\n\n# httpsessionbindinglistener\n\nhttpsessionbindinglistener 接口的 javabean 对象可以感知自己被绑定或解绑定到 session 中的事件。\n\n * 当对象被绑定到 httpsession 对象中时，web 服务器调用该对象的 valuebound(httpsessionbindingevent event) 方法。\n * 当对象从 httpsession 对象中解除绑定时，web 服务器调用该对象的 valueunbound(httpsessionbindingevent event) 方法。\n\n# httpsessionactivationlistener\n\n实现了 httpsessionactivationlistener 接口的 javabean 对象可以感知自己被活化(反序列化)和钝化(序列化)的事件。\n\n * 当绑定到 httpsession 对象中的 javabean 对象将要随 httpsession 对象被序列化之前，web 服务器调用该 javabean 对象的 sessionwillpassivate(httpsessionevent event) 方法。这样 javabean 对象就可以知道自己将要和 httpsession 对象一起被序列化到硬盘中.\n * 当绑定到 httpsession 对象中的 javabean 对象将要随 httpsession 对象被反序列化之后，web 服务器调用该 javabean 对象的 sessiondidactive(httpsessionevent event) 方法。这样 javabean 对象就可以知道自己将要和 httpsession 对象一起被反序列化回到内存中\n\n\n# filter 和 listener\n\nfilter 和 listener 的本质区别：\n\n * filter 是干预过程的，它是过程的一部分，是基于过程行为的。\n * listener 是基于状态的，任何行为改变同一个状态，触发的事件是一致的。\n\n\n# 示例代码\n\n * filter 的示例源码：源码\n * listener 的示例源码：源码\n\n\n# 参考资料\n\n * 深入拆解 tomcat & jetty\n * java web 整合开发王者归来',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"JavaWeb 之 Cookie 和 Session",frontmatter:{title:"JavaWeb 之 Cookie 和 Session",categories:["编程","Java","JavaWeb"],tags:["Java","JavaWeb","Cookie","Session"],abbrlink:"bb93a37b",date:"2020-08-24T19:41:46.000Z",permalink:"/pages/e61883/"},regularPath:"/02.JavaEE/01.JavaWeb/04.JavaWeb%E4%B9%8BCookie%E5%92%8CSession.html",relativePath:"02.JavaEE/01.JavaWeb/04.JavaWeb之Cookie和Session.md",key:"v-62a8b34c",path:"/pages/e61883/",headers:[{level:2,title:"Cookie",slug:"cookie",normalizedTitle:"cookie",charIndex:12},{level:3,title:"Cookie 是什么",slug:"cookie-是什么",normalizedTitle:"cookie 是什么",charIndex:143},{level:3,title:"Cookie 剖析",slug:"cookie-剖析",normalizedTitle:"cookie 剖析",charIndex:483},{level:3,title:"Cookie 类中的方法",slug:"cookie-类中的方法",normalizedTitle:"cookie 类中的方法",charIndex:1288},{level:3,title:"Cookie 的有效期",slug:"cookie-的有效期",normalizedTitle:"cookie 的有效期",charIndex:2432},{level:3,title:"Cookie 的域名",slug:"cookie-的域名",normalizedTitle:"cookie 的域名",charIndex:2632},{level:3,title:"Cookie 的路径",slug:"cookie-的路径",normalizedTitle:"cookie 的路径",charIndex:991},{level:3,title:"Cookie 的安全属性",slug:"cookie-的安全属性",normalizedTitle:"cookie 的安全属性",charIndex:3014},{level:3,title:"Cookie 实例",slug:"cookie-实例",normalizedTitle:"cookie 实例",charIndex:3254},{level:4,title:"添加 Cookie",slug:"添加-cookie",normalizedTitle:"添加 cookie",charIndex:3267},{level:4,title:"显示 Cookie",slug:"显示-cookie",normalizedTitle:"显示 cookie",charIndex:6148},{level:4,title:"删除 Cookie",slug:"删除-cookie",normalizedTitle:"删除 cookie",charIndex:8707},{level:2,title:"Session",slug:"session",normalizedTitle:"session",charIndex:21},{level:3,title:"Session 是什么",slug:"session-是什么",normalizedTitle:"session 是什么",charIndex:11262},{level:3,title:"Session 类中的方法",slug:"session-类中的方法",normalizedTitle:"session 类中的方法",charIndex:11473},{level:3,title:"Session 的有效期",slug:"session-的有效期",normalizedTitle:"session 的有效期",charIndex:12772},{level:3,title:"Session 对浏览器的要求",slug:"session-对浏览器的要求",normalizedTitle:"session 对浏览器的要求",charIndex:13121},{level:3,title:"URL 地址重写",slug:"url-地址重写",normalizedTitle:"url 地址重写",charIndex:13375},{level:3,title:"Session 中禁用 Cookie",slug:"session-中禁用-cookie",normalizedTitle:"session 中禁用 cookie",charIndex:13563},{level:3,title:"Session 实例",slug:"session-实例",normalizedTitle:"session 实例",charIndex:13763},{level:4,title:"Session 跟踪",slug:"session-跟踪",normalizedTitle:"session 跟踪",charIndex:13777},{level:4,title:"删除 Session 会话数据",slug:"删除-session-会话数据",normalizedTitle:"删除 session 会话数据",charIndex:16954},{level:2,title:"Cookie vs Session",slug:"cookie-vs-session",normalizedTitle:"cookie vs session",charIndex:17664},{level:3,title:"存取方式",slug:"存取方式",normalizedTitle:"存取方式",charIndex:17686},{level:3,title:"隐私安全",slug:"隐私安全",normalizedTitle:"隐私安全",charIndex:2726},{level:3,title:"有效期",slug:"有效期",normalizedTitle:"有效期",charIndex:2440},{level:3,title:"服务器的开销",slug:"服务器的开销",normalizedTitle:"服务器的开销",charIndex:18160},{level:3,title:"浏览器的支持",slug:"浏览器的支持",normalizedTitle:"浏览器的支持",charIndex:379},{level:3,title:"跨域名",slug:"跨域名",normalizedTitle:"跨域名",charIndex:2655}],headersStr:"Cookie Cookie 是什么 Cookie 剖析 Cookie 类中的方法 Cookie 的有效期 Cookie 的域名 Cookie 的路径 Cookie 的安全属性 Cookie 实例 添加 Cookie 显示 Cookie 删除 Cookie Session Session 是什么 Session 类中的方法 Session 的有效期 Session 对浏览器的要求 URL 地址重写 Session 中禁用 Cookie Session 实例 Session 跟踪 删除 Session 会话数据 Cookie vs Session 存取方式 隐私安全 有效期 服务器的开销 浏览器的支持 跨域名",content:'# JavaWeb 之 Cookie 和 Session\n\n\n# Cookie\n\n由于 Http 是一种无状态的协议，服务器单从网络连接上无从知道客户身份。\n\n会话跟踪是 Web 程序中常用的技术，用来跟踪用户的整个会话。常用会话跟踪技术是 Cookie 与 Session。\n\n\n# Cookie 是什么\n\nCookie 实际上是存储在客户端上的文本信息，并保留了各种跟踪的信息。\n\nCookie 工作步骤：\n\n 1. 客户端请求服务器，如果服务器需要记录该用户的状态，就是用 response 向客户端浏览器颁发一个 Cookie。\n 2. 客户端浏览器会把 Cookie 保存下来。\n 3. 当浏览器再请求该网站时，浏览器把该请求的网址连同 Cookie 一同提交给服务器。服务器检查该 Cookie，以此来辨认用户状态。\n\n注：Cookie 功能需要浏览器的支持，如果浏览器不支持 Cookie 或者 Cookie 禁用了，Cookie 功能就会失效。\n\nJava 中把 Cookie 封装成了javax.servlet.http.Cookie类。\n\n\n# Cookie 剖析\n\nCookies 通常设置在 HTTP 头信息中（虽然 JavaScript 也可以直接在浏览器上设置一个 Cookie）。\n\n设置 Cookie 的 Servlet 会发送如下的头信息：\n\nHTTP/1.1 200 OK\nDate: Fri, 04 Feb 2000 21:03:38 GMT\nServer: Apache/1.3.9 (UNIX) PHP/4.0b3\nSet-Cookie: name=xyz; expires=Friday, 04-Feb-07 22:03:38 GMT;\n                 path=/; domain=w3cschool.cc\nConnection: close\nContent-Type: text/html\n\n\n正如您所看到的，Set-Cookie 头包含了一个名称值对、一个 GMT 日期、一个路径和一个域。名称和值会被 URL 编码。expires 字段是一个指令，告诉浏览器在给定的时间和日期之后"忘记"该 Cookie。\n\n如果浏览器被配置为存储 Cookies，它将会保留此信息直到到期日期。如果用户的浏览器指向任何匹配该 Cookie 的路径和域的页面，它会重新发送 Cookie 到服务器。浏览器的头信息可能如下所示：\n\nGET / HTTP/1.0\nConnection: Keep-Alive\nUser-Agent: Mozilla/4.6 (X11; I; Linux 2.2.6-15apmac ppc)\nHost: zink.demon.co.uk:1126\nAccept: image/gif, */*\nAccept-Encoding: gzip\nAccept-Language: en\nAccept-Charset: iso-8859-1,*,utf-8\nCookie: name=xyz\n\n\n\n# Cookie 类中的方法\n\n方法                                       功能\npublic void setDomain(String pattern)    该方法设置 cookie 适用的域。\npublic String getDomain()                该方法获取 cookie 适用的域。\npublic void setMaxAge(int expiry)        该方法设置 cookie 过期的时间（以秒为单位）。如果不这样设置，cookie 只会在当前 session\n                                         会话中持续有效。\npublic int getMaxAge()                   该方法返回 cookie 的最大生存周期（以秒为单位），默认情况下，-1 表示 cookie\n                                         将持续下去，直到浏览器关闭。\npublic String getName()                  该方法返回 cookie 的名称。名称在创建后不能改变。\npublic void setValue(String newValue)    该方法设置与 cookie 关联的值。\npublic String getValue()                 该方法获取与 cookie 关联的值。\npublic void setPath(String uri)          该方法设置 cookie 适用的路径。如果您不指定路径，与当前页面相同目录下的（包括子目录下的）所有 URL 都会返回\n                                         cookie。\npublic String getPath()                  该方法获取 cookie 适用的路径。\npublic void setSecure(boolean flag)      该方法设置布尔值，向浏览器指示，只会在 HTTPS 和 SSL 等安全协议中传输此类 Cookie。\npublic void setComment(String purpose)   该方法规定了描述 cookie 目的的注释。该注释在浏览器向用户呈现 cookie 时非常有用。\npublic String getComment()               该方法返回了描述 cookie 目的的注释，如果 cookie 没有注释则返回 null。\n\n\n# Cookie 的有效期\n\nCookie的maxAge决定着 Cookie 的有效期，单位为秒。\n\n如果 maxAge 为 0，则表示删除该 Cookie；\n\n如果为负数，表示该 Cookie 仅在本浏览器中以及本窗口打开的子窗口内有效，关闭窗口后该 Cookie 即失效。\n\nCookie 中提供getMaxAge()和setMaxAge(int expiry)方法来读写maxAge属性。\n\n\n# Cookie 的域名\n\nCookie 是不可以跨域名的。域名 www.google.com 颁发的 Cookie 不会被提交到域名 www.baidu.com 去。这是由 Cookie 的隐私安全机制决定的。隐私安全机制能够禁止网站非法获取其他网站的 Cookie。\n\n正常情况下，同一个一级域名的两个二级域名之间也不能互相使用 Cookie。如果想让某域名下的子域名也可以使用该 Cookie，需要设置 Cookie 的 domain 参数。\n\nJava 中使用setDomain(Stringdomain)和getDomain()方法来设置、获取 domain。\n\n\n# Cookie 的路径\n\nPath 属性决定允许访问 Cookie 的路径。\n\nJava 中使用setPath(Stringuri)和getPath()方法来设置、获取 path。\n\n\n# Cookie 的安全属性\n\nHTTP 协议不仅是无状态的，而且是不安全的。\n\n使用 HTTP 协议的数据不经过任何加密就直接在网络上传播，有被截获的可能。如果不希望 Cookie 在 HTTP 等非安全协议中传输，可以设置 Cookie 的 secure 属性为 true。浏览器只会在 HTTPS 和 SSL 等安全协议中传输此类 Cookie。\n\nJava 中使用setSecure(booleanflag)和getSecure ()方法来设置、获取 Secure。\n\n\n# Cookie 实例\n\n# 添加 Cookie\n\n通过 Servlet 添加 Cookies 包括三个步骤：\n\n 1. 创建一个 Cookie 对象：您可以调用带有 cookie 名称和 cookie 值的 Cookie 构造函数，cookie 名称和 cookie 值都是字符串。\n\n 2. 设置最大生存周期：您可以使用 setMaxAge 方法来指定 cookie 能够保持有效的时间（以秒为单位）。\n\n 3. 发送 Cookie 到 HTTP 响应头：您可以使用 response.addCookie 来添加 HTTP 响应头中的 Cookies。\n\nAddCookies.java\n\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.net.URLEncoder;\n\nimport javax.servlet.ServletException;\nimport javax.servlet.annotation.WebServlet;\nimport javax.servlet.http.Cookie;\nimport javax.servlet.http.HttpServlet;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\n\n@WebServlet("/servlet/AddCookies")\npublic class AddCookies extends HttpServlet {\n    private static final long serialVersionUID = 1L;\n\n    /**\n     * @see HttpServlet#HttpServlet()\n     */\n    public AddCookies() {\n        super();\n    }\n\n    /**\n     * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response)\n     */\n    public void doGet(HttpServletRequest request, HttpServletResponse response)\n                    throws ServletException, IOException {\n        // 为名字和姓氏创建 Cookie\n        Cookie name = new Cookie("name", URLEncoder.encode(request.getParameter("name"), "UTF-8")); // 中文转码\n        Cookie url = new Cookie("url", request.getParameter("url"));\n\n        // 为两个 Cookie 设置过期日期为 24 小时后\n        name.setMaxAge(60 * 60 * 24);\n        url.setMaxAge(60 * 60 * 24);\n\n        // 在响应头中添加两个 Cookie\n        response.addCookie(name);\n        response.addCookie(url);\n\n        // 设置响应内容类型\n        response.setContentType("text/html;charset=UTF-8");\n\n        PrintWriter out = response.getWriter();\n        String title = "设置 Cookie 实例";\n        String docType = "<!DOCTYPE html>\\n";\n        out.println(docType + "<html>\\n" + "<head><title>" + title + "</title></head>\\n"\n                        + "<body bgcolor=\\"#f0f0f0\\">\\n" + "<h1 align=\\"center\\">" + title\n                        + "</h1>\\n" + "<ul>\\n" + "  <li><b>站点名：</b>：" + request.getParameter("name")\n                        + "\\n</li>" + "  <li><b>站点 URL：</b>：" + request.getParameter("url")\n                        + "\\n</li>" + "</ul>\\n" + "</body></html>");\n    }\n\n    /**\n     * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response)\n     */\n    protected void doPost(HttpServletRequest request, HttpServletResponse response)\n                    throws ServletException, IOException {\n        doGet(request, response);\n    }\n\n}\n\n\naddCookies.jsp\n\n<%@ page language="java" pageEncoding="UTF-8" %>\n<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">\n<html>\n<head>\n  <meta charset="utf-8">\n  <title>添加Cookie</title>\n</head>\n<body>\n<form action=/servlet/AddCookies method="GET">\n  站点名 ：<input type="text" name="name">\n  <br/>\n  站点 URL：<input type="text" name="url"/><br>\n  <input type="submit" value="提交"/>\n</form>\n</body>\n</html>\n\n\n# 显示 Cookie\n\n要读取 Cookies，您需要通过调用 HttpServletRequest 的 getCookies() 方法创建一个 javax.servlet.http.Cookie 对象的数组。然后循环遍历数组，并使用 getName() 和 getValue() 方法来访问每个 cookie 和关联的值。\n\nReadCookies.java\n\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.net.URLDecoder;\n\nimport javax.servlet.ServletException;\nimport javax.servlet.annotation.WebServlet;\nimport javax.servlet.http.Cookie;\nimport javax.servlet.http.HttpServlet;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\n\n@WebServlet("/servlet/ReadCookies")\npublic class ReadCookies extends HttpServlet {\n    private static final long serialVersionUID = 1L;\n\n    /**\n     * @see HttpServlet#HttpServlet()\n     */\n    public ReadCookies() {\n        super();\n    }\n\n    /**\n     * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response)\n     */\n    public void doGet(HttpServletRequest request, HttpServletResponse response)\n                    throws ServletException, IOException {\n        Cookie cookie = null;\n        Cookie[] cookies = null;\n        // 获取与该域相关的 Cookie 的数组\n        cookies = request.getCookies();\n\n        // 设置响应内容类型\n        response.setContentType("text/html;charset=UTF-8");\n\n        PrintWriter out = response.getWriter();\n        String title = "Delete Cookie Example";\n        String docType = "<!DOCTYPE html>\\n";\n        out.println(docType + "<html>\\n" + "<head><title>" + title + "</title></head>\\n"\n                        + "<body bgcolor=\\"#f0f0f0\\">\\n");\n        if (cookies != null) {\n            out.println("<h2>Cookie 名称和值</h2>");\n            for (int i = 0; i < cookies.length; i++) {\n                cookie = cookies[i];\n                if ((cookie.getName()).compareTo("name") == 0) {\n                    cookie.setMaxAge(0);\n                    response.addCookie(cookie);\n                    out.print("已删除的 cookie：" + cookie.getName() + "<br/>");\n                }\n                out.print("名称：" + cookie.getName() + "，");\n                out.print("值：" + URLDecoder.decode(cookie.getValue(), "utf-8") + " <br/>");\n            }\n        } else {\n            out.println("<h2 class=\\"tutheader\\">No Cookie founds</h2>");\n        }\n        out.println("</body>");\n        out.println("</html>");\n    }\n\n    /**\n     * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response)\n     */\n    protected void doPost(HttpServletRequest request, HttpServletResponse response)\n                    throws ServletException, IOException {\n        doGet(request, response);\n    }\n\n}\n\n\n# 删除 Cookie\n\nJava 中并没有提供直接删除 Cookie 的方法，如果想要删除一个 Cookie，直接将这个 Cookie 的有效期设为 0 就可以了。步骤如下：\n\n 1. 读取一个现有的 cookie，并把它存储在 Cookie 对象中。\n\n 2. 使用 setMaxAge() 方法设置 cookie 的年龄为零，来删除现有的 cookie。\n\n 3. 把这个 cookie 添加到响应头。\n\nDeleteCookies.java\n\nimport java.io.IOException;\nimport java.io.PrintWriter;\n\nimport javax.servlet.ServletException;\nimport javax.servlet.annotation.WebServlet;\nimport javax.servlet.http.Cookie;\nimport javax.servlet.http.HttpServlet;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\n\n@WebServlet("/servlet/DeleteCookies")\npublic class DeleteCookies extends HttpServlet {\n    private static final long serialVersionUID = 1L;\n\n    /**\n     * @see HttpServlet#HttpServlet()\n     */\n    public DeleteCookies() {\n        super();\n    }\n\n    /**\n     * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response)\n     */\n    public void doGet(HttpServletRequest request, HttpServletResponse response)\n                    throws ServletException, IOException {\n        Cookie cookie = null;\n        Cookie[] cookies = null;\n        // 获取与该域相关的 Cookie 的数组\n        cookies = request.getCookies();\n\n        // 设置响应内容类型\n        response.setContentType("text/html;charset=UTF-8");\n\n        PrintWriter out = response.getWriter();\n        String title = "删除 Cookie 实例";\n        String docType = "<!DOCTYPE html>\\n";\n        out.println(docType + "<html>\\n" + "<head><title>" + title + "</title></head>\\n"\n                        + "<body bgcolor=\\"#f0f0f0\\">\\n");\n        if (cookies != null) {\n            out.println("<h2>Cookie 名称和值</h2>");\n            for (int i = 0; i < cookies.length; i++) {\n                cookie = cookies[i];\n                if ((cookie.getName()).compareTo("url") == 0) {\n                    cookie.setMaxAge(0);\n                    response.addCookie(cookie);\n                    out.print("已删除的 cookie：" + cookie.getName() + "<br/>");\n                }\n                out.print("名称：" + cookie.getName() + "，");\n                out.print("值：" + cookie.getValue() + " <br/>");\n            }\n        } else {\n            out.println("<h2 class=\\"tutheader\\">No Cookie founds</h2>");\n        }\n        out.println("</body>");\n        out.println("</html>");\n    }\n\n    /**\n     * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response)\n     */\n    protected void doPost(HttpServletRequest request, HttpServletResponse response)\n                    throws ServletException, IOException {\n        doGet(request, response);\n    }\n\n}\n\n\n\n# Session\n\n\n# Session 是什么\n\n不同于 Cookie 保存在客户端浏览器中，Session 保存在服务器上。\n\n如果说 Cookie 机制是通过检查客户身上的“通行证”来确定客户身份的话，那么 Session 机制就是通过检查服务器上的“客户明细表”来确认客户身份。\n\nSession 对应的类为 javax.servlet.http.HttpSession 类。Session 对象是在客户第一次请求服务器时创建的。\n\n\n# Session 类中的方法\n\njavax.servlet.http.HttpSession 类中的方法：\n\n方法                                                    功能\npublic Object getAttribute(String name)               该方法返回在该 session 会话中具有指定名称的对象，如果没有指定名称的对象，则返回 null。\npublic Enumeration getAttributeNames()                该方法返回 String 对象的枚举，String 对象包含所有绑定到该 session 会话的对象的名称。\npublic long getCreationTime()                         该方法返回该 session 会话被创建的时间，自格林尼治标准时间 1970 年 1 月 1 日午夜算起，以毫秒为单位。\npublic String getId()                                 该方法返回一个包含分配给该 session 会话的唯一标识符的字符串。\npublic long getLastAccessedTime()                     该方法返回客户端最后一次发送与该 session 会话相关的请求的时间自格林尼治标准时间 1970 年 1 月 1\n                                                      日午夜算起，以毫秒为单位。\npublic int getMaxInactiveInterval()                   该方法返回 Servlet 容器在客户端访问时保持 session 会话打开的最大时间间隔，以秒为单位。\npublic void invalidate()                              该方法指示该 session 会话无效，并解除绑定到它上面的任何对象。\npublic boolean isNew()                                如果客户端还不知道该 session 会话，或者如果客户选择不参入该 session 会话，则该方法返回 true。\npublic void removeAttribute(String name)              该方法将从该 session 会话移除指定名称的对象。\npublic void setAttribute(String name, Object value)   该方法使用指定的名称绑定一个对象到该 session 会话。\npublic void setMaxInactiveInterval(int interval)      该方法在 Servlet 容器指示该 session 会话无效之前，指定客户端请求之间的时间，以秒为单位。\n\n\n# Session 的有效期\n\n由于会有越来越多的用户访问服务器，因此 Session 也会越来越多。为防止内存溢出，服务器会把长时间没有活跃的 Session 从内存中删除。\n\nSession 的超时时间为maxInactiveInterval属性，可以通过getMaxInactiveInterval()、setMaxInactiveInterval(longinterval)来读写这个属性。\n\nTomcat 中 Session 的默认超时时间为 20 分钟。可以修改 web.xml 改变 Session 的默认超时时间。\n\n例：\n\n<session-config>\n  <session-timeout>60</session-timeout>\n</session-config>\n\n\n\n# Session 对浏览器的要求\n\nHTTP 协议是无状态的，Session 不能依据 HTTP 连接来判断是否为同一客户。因此服务器向客户端浏览器发送一个名为 JESSIONID 的 Cookie，他的值为该 Session 的 id（也就是 HttpSession.getId()的返回值）。Session 依据该 Cookie 来识别是否为同一用户。\n\n该 Cookie 为服务器自动生成的，它的maxAge属性一般为-1，表示仅当前浏览器内有效，并且各浏览器窗口间不共享，关闭浏览器就会失效。\n\n\n# URL 地址重写\n\nURL 地址重写的原理是将该用户 Session 的 id 信息重写到 URL 地址中。服务器能够解析重写后的 URL 获取 Session 的 id。这样即使客户端不支持 Cookie，也可以使用 Session 来记录用户状态。\n\nHttpServletResponse类提供了encodeURL(Stringurl)实现 URL 地址重写。\n\n\n# Session 中禁用 Cookie\n\n在META-INF/context.xml中编辑如下：\n\n<Context path="/SessionNotes" cookies="true">\n</Context>\n\n\n部署后，TOMCAT 便不会自动生成名 JESSIONID 的 Cookie，Session 也不会以 Cookie 为识别标志，而仅仅以重写后的 URL 地址为识别标志了。\n\n\n# Session 实例\n\n# Session 跟踪\n\nSessionTrackServlet.java\n\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.text.SimpleDateFormat;\nimport java.util.Date;\n\nimport javax.servlet.ServletException;\nimport javax.servlet.annotation.WebServlet;\nimport javax.servlet.http.HttpServlet;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\nimport javax.servlet.http.HttpSession;\n\n@WebServlet("/servlet/SessionTrackServlet")\npublic class SessionTrackServlet extends HttpServlet {\n    private static final long serialVersionUID = 1L;\n\n    public void doGet(HttpServletRequest request, HttpServletResponse response)\n                    throws ServletException, IOException {\n        // 如果不存在 session 会话，则创建一个 session 对象\n        HttpSession session = request.getSession(true);\n        // 获取 session 创建时间\n        Date createTime = new Date(session.getCreationTime());\n        // 获取该网页的最后一次访问时间\n        Date lastAccessTime = new Date(session.getLastAccessedTime());\n\n        // 设置日期输出的格式\n        SimpleDateFormat df = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");\n\n        String title = "Servlet Session 实例";\n        Integer visitCount = new Integer(0);\n        String visitCountKey = new String("visitCount");\n        String userIDKey = new String("userID");\n        String userID = new String("admin");\n\n        // 检查网页上是否有新的访问者\n        if (session.isNew()) {\n            session.setAttribute(userIDKey, userID);\n        } else {\n            visitCount = (Integer) session.getAttribute(visitCountKey);\n            visitCount = visitCount + 1;\n            userID = (String) session.getAttribute(userIDKey);\n        }\n        session.setAttribute(visitCountKey, visitCount);\n\n        // 设置响应内容类型\n        response.setContentType("text/html;charset=UTF-8");\n        PrintWriter out = response.getWriter();\n\n        String docType = "<!DOCTYPE html>\\n";\n        out.println(docType + "<html>\\n" + "<head><title>" + title + "</title></head>\\n"\n                        + "<body bgcolor=\\"#f0f0f0\\">\\n" + "<h1 align=\\"center\\">" + title\n                        + "</h1>\\n" + "<h2 align=\\"center\\">Session 信息</h2>\\n"\n                        + "<table border=\\"1\\" align=\\"center\\">\\n" + "<tr bgcolor=\\"#949494\\">\\n"\n                        + "  <th>Session 信息</th><th>值</th></tr>\\n" + "<tr>\\n" + "  <td>id</td>\\n"\n                        + "  <td>" + session.getId() + "</td></tr>\\n" + "<tr>\\n"\n                        + "  <td>创建时间</td>\\n" + "  <td>" + df.format(createTime) + "  </td></tr>\\n"\n                        + "<tr>\\n" + "  <td>最后访问时间</td>\\n" + "  <td>" + df.format(lastAccessTime)\n                        + "  </td></tr>\\n" + "<tr>\\n" + "  <td>用户 ID</td>\\n" + "  <td>" + userID\n                        + "  </td></tr>\\n" + "<tr>\\n" + "  <td>访问统计：</td>\\n" + "  <td>" + visitCount\n                        + "</td></tr>\\n" + "</table>\\n" + "</body></html>");\n    }\n}\n\n\nweb.xml\n\n<servlet>\n  <servlet-name>SessionTrackServlet</servlet-name>\n  <servlet-class>SessionTrackServlet</servlet-class>\n</servlet>\n<servlet-mapping>\n  <servlet-name>SessionTrackServlet</servlet-name>\n  <url-pattern>/servlet/SessionTrackServlet</url-pattern>\n</servlet-mapping>\n\n\n# 删除 Session 会话数据\n\n当您完成了一个用户的 session 会话数据，您有以下几种选择：\n\n**移除一个特定的属性：**您可以调用 removeAttribute(String name) 方法来删除与特定的键相关联的值。\n\n**删除整个 session 会话：**您可以调用 invalidate() 方法来丢弃整个 session 会话。\n\n**设置 session 会话过期时间：**您可以调用 setMaxInactiveInterval(int interval) 方法来单独设置 session 会话超时。\n\n**注销用户：**如果使用的是支持 servlet 2.4 的服务器，您可以调用 logout 来注销 Web 服务器的客户端，并把属于所有用户的所有 session 会话设置为无效。\n\n**web.xml 配置：**如果您使用的是 Tomcat，除了上述方法，您还可以在 web.xml 文件中配置 session 会话超时，如下所示：\n\n<session-config>\n  <session-timeout>15</session-timeout>\n</session-config>\n\n\n上面实例中的超时时间是以分钟为单位，将覆盖 Tomcat 中默认的 30 分钟超时时间。\n\n在一个 Servlet 中的 getMaxInactiveInterval() 方法会返回 session 会话的超时时间，以秒为单位。所以，如果在 web.xml 中配置 session 会话超时时间为 15 分钟，那么getMaxInactiveInterval() 会返回 900。\n\n\n# Cookie vs Session\n\n\n# 存取方式\n\nCookie 只能保存ASCII字符串，如果需要存取 Unicode 字符或二进制数据，需要进行UTF-8、GBK或BASE64等方式的编码。\n\nSession 可以存取任何类型的数据，甚至是任何 Java 类。可以将 Session 看成是一个 Java 容器类。\n\n\n# 隐私安全\n\nCookie 存于客户端浏览器，一些客户端的程序可能会窥探、复制或修改 Cookie 内容。\n\nSession 存于服务器，对客户端是透明的，不存在敏感信息泄露的危险。\n\n\n# 有效期\n\n使用 Cookie 可以保证长时间登录有效，只要设置 Cookie 的maxAge属性为一个很大的数字。\n\n而 Session 虽然理论上也可以通过设置很大的数值来保持长时间登录有效，但是，由于 Session 依赖于名为JESSIONID的 Cookie，而 Cookie JESSIONID的maxAge默认为-1，只要关闭了浏览器该 Session 就会失效，因此，Session 不能实现信息永久有效的效果。使用 URL 地址重写也不能实现。\n\n\n# 服务器的开销\n\n由于 Session 是保存在服务器的，每个用户都会产生一个 Session，如果并发访问的用户非常多，会产生很多的 Session，消耗大量的内存。\n\n而 Cookie 由于保存在客户端浏览器上，所以不占用服务器资源。\n\n\n# 浏览器的支持\n\nCookie 需要浏览器支持才能使用。\n\n如果浏览器不支持 Cookie，需要使用 Session 以及 URL 地址重写。\n\n需要注意的事所有的用到 Session 程序的 URL 都要使用response.encodeURL(StringURL) 或response.encodeRediretURL(String URL)进行 URL 地址重写，否则导致 Session 会话跟踪失效。\n\n\n# 跨域名\n\n * Cookie 支持跨域名。\n * Session 不支持跨域名。',normalizedContent:'# javaweb 之 cookie 和 session\n\n\n# cookie\n\n由于 http 是一种无状态的协议，服务器单从网络连接上无从知道客户身份。\n\n会话跟踪是 web 程序中常用的技术，用来跟踪用户的整个会话。常用会话跟踪技术是 cookie 与 session。\n\n\n# cookie 是什么\n\ncookie 实际上是存储在客户端上的文本信息，并保留了各种跟踪的信息。\n\ncookie 工作步骤：\n\n 1. 客户端请求服务器，如果服务器需要记录该用户的状态，就是用 response 向客户端浏览器颁发一个 cookie。\n 2. 客户端浏览器会把 cookie 保存下来。\n 3. 当浏览器再请求该网站时，浏览器把该请求的网址连同 cookie 一同提交给服务器。服务器检查该 cookie，以此来辨认用户状态。\n\n注：cookie 功能需要浏览器的支持，如果浏览器不支持 cookie 或者 cookie 禁用了，cookie 功能就会失效。\n\njava 中把 cookie 封装成了javax.servlet.http.cookie类。\n\n\n# cookie 剖析\n\ncookies 通常设置在 http 头信息中（虽然 javascript 也可以直接在浏览器上设置一个 cookie）。\n\n设置 cookie 的 servlet 会发送如下的头信息：\n\nhttp/1.1 200 ok\ndate: fri, 04 feb 2000 21:03:38 gmt\nserver: apache/1.3.9 (unix) php/4.0b3\nset-cookie: name=xyz; expires=friday, 04-feb-07 22:03:38 gmt;\n                 path=/; domain=w3cschool.cc\nconnection: close\ncontent-type: text/html\n\n\n正如您所看到的，set-cookie 头包含了一个名称值对、一个 gmt 日期、一个路径和一个域。名称和值会被 url 编码。expires 字段是一个指令，告诉浏览器在给定的时间和日期之后"忘记"该 cookie。\n\n如果浏览器被配置为存储 cookies，它将会保留此信息直到到期日期。如果用户的浏览器指向任何匹配该 cookie 的路径和域的页面，它会重新发送 cookie 到服务器。浏览器的头信息可能如下所示：\n\nget / http/1.0\nconnection: keep-alive\nuser-agent: mozilla/4.6 (x11; i; linux 2.2.6-15apmac ppc)\nhost: zink.demon.co.uk:1126\naccept: image/gif, */*\naccept-encoding: gzip\naccept-language: en\naccept-charset: iso-8859-1,*,utf-8\ncookie: name=xyz\n\n\n\n# cookie 类中的方法\n\n方法                                       功能\npublic void setdomain(string pattern)    该方法设置 cookie 适用的域。\npublic string getdomain()                该方法获取 cookie 适用的域。\npublic void setmaxage(int expiry)        该方法设置 cookie 过期的时间（以秒为单位）。如果不这样设置，cookie 只会在当前 session\n                                         会话中持续有效。\npublic int getmaxage()                   该方法返回 cookie 的最大生存周期（以秒为单位），默认情况下，-1 表示 cookie\n                                         将持续下去，直到浏览器关闭。\npublic string getname()                  该方法返回 cookie 的名称。名称在创建后不能改变。\npublic void setvalue(string newvalue)    该方法设置与 cookie 关联的值。\npublic string getvalue()                 该方法获取与 cookie 关联的值。\npublic void setpath(string uri)          该方法设置 cookie 适用的路径。如果您不指定路径，与当前页面相同目录下的（包括子目录下的）所有 url 都会返回\n                                         cookie。\npublic string getpath()                  该方法获取 cookie 适用的路径。\npublic void setsecure(boolean flag)      该方法设置布尔值，向浏览器指示，只会在 https 和 ssl 等安全协议中传输此类 cookie。\npublic void setcomment(string purpose)   该方法规定了描述 cookie 目的的注释。该注释在浏览器向用户呈现 cookie 时非常有用。\npublic string getcomment()               该方法返回了描述 cookie 目的的注释，如果 cookie 没有注释则返回 null。\n\n\n# cookie 的有效期\n\ncookie的maxage决定着 cookie 的有效期，单位为秒。\n\n如果 maxage 为 0，则表示删除该 cookie；\n\n如果为负数，表示该 cookie 仅在本浏览器中以及本窗口打开的子窗口内有效，关闭窗口后该 cookie 即失效。\n\ncookie 中提供getmaxage()和setmaxage(int expiry)方法来读写maxage属性。\n\n\n# cookie 的域名\n\ncookie 是不可以跨域名的。域名 www.google.com 颁发的 cookie 不会被提交到域名 www.baidu.com 去。这是由 cookie 的隐私安全机制决定的。隐私安全机制能够禁止网站非法获取其他网站的 cookie。\n\n正常情况下，同一个一级域名的两个二级域名之间也不能互相使用 cookie。如果想让某域名下的子域名也可以使用该 cookie，需要设置 cookie 的 domain 参数。\n\njava 中使用setdomain(stringdomain)和getdomain()方法来设置、获取 domain。\n\n\n# cookie 的路径\n\npath 属性决定允许访问 cookie 的路径。\n\njava 中使用setpath(stringuri)和getpath()方法来设置、获取 path。\n\n\n# cookie 的安全属性\n\nhttp 协议不仅是无状态的，而且是不安全的。\n\n使用 http 协议的数据不经过任何加密就直接在网络上传播，有被截获的可能。如果不希望 cookie 在 http 等非安全协议中传输，可以设置 cookie 的 secure 属性为 true。浏览器只会在 https 和 ssl 等安全协议中传输此类 cookie。\n\njava 中使用setsecure(booleanflag)和getsecure ()方法来设置、获取 secure。\n\n\n# cookie 实例\n\n# 添加 cookie\n\n通过 servlet 添加 cookies 包括三个步骤：\n\n 1. 创建一个 cookie 对象：您可以调用带有 cookie 名称和 cookie 值的 cookie 构造函数，cookie 名称和 cookie 值都是字符串。\n\n 2. 设置最大生存周期：您可以使用 setmaxage 方法来指定 cookie 能够保持有效的时间（以秒为单位）。\n\n 3. 发送 cookie 到 http 响应头：您可以使用 response.addcookie 来添加 http 响应头中的 cookies。\n\naddcookies.java\n\nimport java.io.ioexception;\nimport java.io.printwriter;\nimport java.net.urlencoder;\n\nimport javax.servlet.servletexception;\nimport javax.servlet.annotation.webservlet;\nimport javax.servlet.http.cookie;\nimport javax.servlet.http.httpservlet;\nimport javax.servlet.http.httpservletrequest;\nimport javax.servlet.http.httpservletresponse;\n\n@webservlet("/servlet/addcookies")\npublic class addcookies extends httpservlet {\n    private static final long serialversionuid = 1l;\n\n    /**\n     * @see httpservlet#httpservlet()\n     */\n    public addcookies() {\n        super();\n    }\n\n    /**\n     * @see httpservlet#doget(httpservletrequest request, httpservletresponse response)\n     */\n    public void doget(httpservletrequest request, httpservletresponse response)\n                    throws servletexception, ioexception {\n        // 为名字和姓氏创建 cookie\n        cookie name = new cookie("name", urlencoder.encode(request.getparameter("name"), "utf-8")); // 中文转码\n        cookie url = new cookie("url", request.getparameter("url"));\n\n        // 为两个 cookie 设置过期日期为 24 小时后\n        name.setmaxage(60 * 60 * 24);\n        url.setmaxage(60 * 60 * 24);\n\n        // 在响应头中添加两个 cookie\n        response.addcookie(name);\n        response.addcookie(url);\n\n        // 设置响应内容类型\n        response.setcontenttype("text/html;charset=utf-8");\n\n        printwriter out = response.getwriter();\n        string title = "设置 cookie 实例";\n        string doctype = "<!doctype html>\\n";\n        out.println(doctype + "<html>\\n" + "<head><title>" + title + "</title></head>\\n"\n                        + "<body bgcolor=\\"#f0f0f0\\">\\n" + "<h1 align=\\"center\\">" + title\n                        + "</h1>\\n" + "<ul>\\n" + "  <li><b>站点名：</b>：" + request.getparameter("name")\n                        + "\\n</li>" + "  <li><b>站点 url：</b>：" + request.getparameter("url")\n                        + "\\n</li>" + "</ul>\\n" + "</body></html>");\n    }\n\n    /**\n     * @see httpservlet#dopost(httpservletrequest request, httpservletresponse response)\n     */\n    protected void dopost(httpservletrequest request, httpservletresponse response)\n                    throws servletexception, ioexception {\n        doget(request, response);\n    }\n\n}\n\n\naddcookies.jsp\n\n<%@ page language="java" pageencoding="utf-8" %>\n<!doctype html public "-//w3c//dtd html 4.01 transitional//en">\n<html>\n<head>\n  <meta charset="utf-8">\n  <title>添加cookie</title>\n</head>\n<body>\n<form action=/servlet/addcookies method="get">\n  站点名 ：<input type="text" name="name">\n  <br/>\n  站点 url：<input type="text" name="url"/><br>\n  <input type="submit" value="提交"/>\n</form>\n</body>\n</html>\n\n\n# 显示 cookie\n\n要读取 cookies，您需要通过调用 httpservletrequest 的 getcookies() 方法创建一个 javax.servlet.http.cookie 对象的数组。然后循环遍历数组，并使用 getname() 和 getvalue() 方法来访问每个 cookie 和关联的值。\n\nreadcookies.java\n\nimport java.io.ioexception;\nimport java.io.printwriter;\nimport java.net.urldecoder;\n\nimport javax.servlet.servletexception;\nimport javax.servlet.annotation.webservlet;\nimport javax.servlet.http.cookie;\nimport javax.servlet.http.httpservlet;\nimport javax.servlet.http.httpservletrequest;\nimport javax.servlet.http.httpservletresponse;\n\n@webservlet("/servlet/readcookies")\npublic class readcookies extends httpservlet {\n    private static final long serialversionuid = 1l;\n\n    /**\n     * @see httpservlet#httpservlet()\n     */\n    public readcookies() {\n        super();\n    }\n\n    /**\n     * @see httpservlet#doget(httpservletrequest request, httpservletresponse response)\n     */\n    public void doget(httpservletrequest request, httpservletresponse response)\n                    throws servletexception, ioexception {\n        cookie cookie = null;\n        cookie[] cookies = null;\n        // 获取与该域相关的 cookie 的数组\n        cookies = request.getcookies();\n\n        // 设置响应内容类型\n        response.setcontenttype("text/html;charset=utf-8");\n\n        printwriter out = response.getwriter();\n        string title = "delete cookie example";\n        string doctype = "<!doctype html>\\n";\n        out.println(doctype + "<html>\\n" + "<head><title>" + title + "</title></head>\\n"\n                        + "<body bgcolor=\\"#f0f0f0\\">\\n");\n        if (cookies != null) {\n            out.println("<h2>cookie 名称和值</h2>");\n            for (int i = 0; i < cookies.length; i++) {\n                cookie = cookies[i];\n                if ((cookie.getname()).compareto("name") == 0) {\n                    cookie.setmaxage(0);\n                    response.addcookie(cookie);\n                    out.print("已删除的 cookie：" + cookie.getname() + "<br/>");\n                }\n                out.print("名称：" + cookie.getname() + "，");\n                out.print("值：" + urldecoder.decode(cookie.getvalue(), "utf-8") + " <br/>");\n            }\n        } else {\n            out.println("<h2 class=\\"tutheader\\">no cookie founds</h2>");\n        }\n        out.println("</body>");\n        out.println("</html>");\n    }\n\n    /**\n     * @see httpservlet#dopost(httpservletrequest request, httpservletresponse response)\n     */\n    protected void dopost(httpservletrequest request, httpservletresponse response)\n                    throws servletexception, ioexception {\n        doget(request, response);\n    }\n\n}\n\n\n# 删除 cookie\n\njava 中并没有提供直接删除 cookie 的方法，如果想要删除一个 cookie，直接将这个 cookie 的有效期设为 0 就可以了。步骤如下：\n\n 1. 读取一个现有的 cookie，并把它存储在 cookie 对象中。\n\n 2. 使用 setmaxage() 方法设置 cookie 的年龄为零，来删除现有的 cookie。\n\n 3. 把这个 cookie 添加到响应头。\n\ndeletecookies.java\n\nimport java.io.ioexception;\nimport java.io.printwriter;\n\nimport javax.servlet.servletexception;\nimport javax.servlet.annotation.webservlet;\nimport javax.servlet.http.cookie;\nimport javax.servlet.http.httpservlet;\nimport javax.servlet.http.httpservletrequest;\nimport javax.servlet.http.httpservletresponse;\n\n@webservlet("/servlet/deletecookies")\npublic class deletecookies extends httpservlet {\n    private static final long serialversionuid = 1l;\n\n    /**\n     * @see httpservlet#httpservlet()\n     */\n    public deletecookies() {\n        super();\n    }\n\n    /**\n     * @see httpservlet#doget(httpservletrequest request, httpservletresponse response)\n     */\n    public void doget(httpservletrequest request, httpservletresponse response)\n                    throws servletexception, ioexception {\n        cookie cookie = null;\n        cookie[] cookies = null;\n        // 获取与该域相关的 cookie 的数组\n        cookies = request.getcookies();\n\n        // 设置响应内容类型\n        response.setcontenttype("text/html;charset=utf-8");\n\n        printwriter out = response.getwriter();\n        string title = "删除 cookie 实例";\n        string doctype = "<!doctype html>\\n";\n        out.println(doctype + "<html>\\n" + "<head><title>" + title + "</title></head>\\n"\n                        + "<body bgcolor=\\"#f0f0f0\\">\\n");\n        if (cookies != null) {\n            out.println("<h2>cookie 名称和值</h2>");\n            for (int i = 0; i < cookies.length; i++) {\n                cookie = cookies[i];\n                if ((cookie.getname()).compareto("url") == 0) {\n                    cookie.setmaxage(0);\n                    response.addcookie(cookie);\n                    out.print("已删除的 cookie：" + cookie.getname() + "<br/>");\n                }\n                out.print("名称：" + cookie.getname() + "，");\n                out.print("值：" + cookie.getvalue() + " <br/>");\n            }\n        } else {\n            out.println("<h2 class=\\"tutheader\\">no cookie founds</h2>");\n        }\n        out.println("</body>");\n        out.println("</html>");\n    }\n\n    /**\n     * @see httpservlet#dopost(httpservletrequest request, httpservletresponse response)\n     */\n    protected void dopost(httpservletrequest request, httpservletresponse response)\n                    throws servletexception, ioexception {\n        doget(request, response);\n    }\n\n}\n\n\n\n# session\n\n\n# session 是什么\n\n不同于 cookie 保存在客户端浏览器中，session 保存在服务器上。\n\n如果说 cookie 机制是通过检查客户身上的“通行证”来确定客户身份的话，那么 session 机制就是通过检查服务器上的“客户明细表”来确认客户身份。\n\nsession 对应的类为 javax.servlet.http.httpsession 类。session 对象是在客户第一次请求服务器时创建的。\n\n\n# session 类中的方法\n\njavax.servlet.http.httpsession 类中的方法：\n\n方法                                                    功能\npublic object getattribute(string name)               该方法返回在该 session 会话中具有指定名称的对象，如果没有指定名称的对象，则返回 null。\npublic enumeration getattributenames()                该方法返回 string 对象的枚举，string 对象包含所有绑定到该 session 会话的对象的名称。\npublic long getcreationtime()                         该方法返回该 session 会话被创建的时间，自格林尼治标准时间 1970 年 1 月 1 日午夜算起，以毫秒为单位。\npublic string getid()                                 该方法返回一个包含分配给该 session 会话的唯一标识符的字符串。\npublic long getlastaccessedtime()                     该方法返回客户端最后一次发送与该 session 会话相关的请求的时间自格林尼治标准时间 1970 年 1 月 1\n                                                      日午夜算起，以毫秒为单位。\npublic int getmaxinactiveinterval()                   该方法返回 servlet 容器在客户端访问时保持 session 会话打开的最大时间间隔，以秒为单位。\npublic void invalidate()                              该方法指示该 session 会话无效，并解除绑定到它上面的任何对象。\npublic boolean isnew()                                如果客户端还不知道该 session 会话，或者如果客户选择不参入该 session 会话，则该方法返回 true。\npublic void removeattribute(string name)              该方法将从该 session 会话移除指定名称的对象。\npublic void setattribute(string name, object value)   该方法使用指定的名称绑定一个对象到该 session 会话。\npublic void setmaxinactiveinterval(int interval)      该方法在 servlet 容器指示该 session 会话无效之前，指定客户端请求之间的时间，以秒为单位。\n\n\n# session 的有效期\n\n由于会有越来越多的用户访问服务器，因此 session 也会越来越多。为防止内存溢出，服务器会把长时间没有活跃的 session 从内存中删除。\n\nsession 的超时时间为maxinactiveinterval属性，可以通过getmaxinactiveinterval()、setmaxinactiveinterval(longinterval)来读写这个属性。\n\ntomcat 中 session 的默认超时时间为 20 分钟。可以修改 web.xml 改变 session 的默认超时时间。\n\n例：\n\n<session-config>\n  <session-timeout>60</session-timeout>\n</session-config>\n\n\n\n# session 对浏览器的要求\n\nhttp 协议是无状态的，session 不能依据 http 连接来判断是否为同一客户。因此服务器向客户端浏览器发送一个名为 jessionid 的 cookie，他的值为该 session 的 id（也就是 httpsession.getid()的返回值）。session 依据该 cookie 来识别是否为同一用户。\n\n该 cookie 为服务器自动生成的，它的maxage属性一般为-1，表示仅当前浏览器内有效，并且各浏览器窗口间不共享，关闭浏览器就会失效。\n\n\n# url 地址重写\n\nurl 地址重写的原理是将该用户 session 的 id 信息重写到 url 地址中。服务器能够解析重写后的 url 获取 session 的 id。这样即使客户端不支持 cookie，也可以使用 session 来记录用户状态。\n\nhttpservletresponse类提供了encodeurl(stringurl)实现 url 地址重写。\n\n\n# session 中禁用 cookie\n\n在meta-inf/context.xml中编辑如下：\n\n<context path="/sessionnotes" cookies="true">\n</context>\n\n\n部署后，tomcat 便不会自动生成名 jessionid 的 cookie，session 也不会以 cookie 为识别标志，而仅仅以重写后的 url 地址为识别标志了。\n\n\n# session 实例\n\n# session 跟踪\n\nsessiontrackservlet.java\n\nimport java.io.ioexception;\nimport java.io.printwriter;\nimport java.text.simpledateformat;\nimport java.util.date;\n\nimport javax.servlet.servletexception;\nimport javax.servlet.annotation.webservlet;\nimport javax.servlet.http.httpservlet;\nimport javax.servlet.http.httpservletrequest;\nimport javax.servlet.http.httpservletresponse;\nimport javax.servlet.http.httpsession;\n\n@webservlet("/servlet/sessiontrackservlet")\npublic class sessiontrackservlet extends httpservlet {\n    private static final long serialversionuid = 1l;\n\n    public void doget(httpservletrequest request, httpservletresponse response)\n                    throws servletexception, ioexception {\n        // 如果不存在 session 会话，则创建一个 session 对象\n        httpsession session = request.getsession(true);\n        // 获取 session 创建时间\n        date createtime = new date(session.getcreationtime());\n        // 获取该网页的最后一次访问时间\n        date lastaccesstime = new date(session.getlastaccessedtime());\n\n        // 设置日期输出的格式\n        simpledateformat df = new simpledateformat("yyyy-mm-dd hh:mm:ss");\n\n        string title = "servlet session 实例";\n        integer visitcount = new integer(0);\n        string visitcountkey = new string("visitcount");\n        string useridkey = new string("userid");\n        string userid = new string("admin");\n\n        // 检查网页上是否有新的访问者\n        if (session.isnew()) {\n            session.setattribute(useridkey, userid);\n        } else {\n            visitcount = (integer) session.getattribute(visitcountkey);\n            visitcount = visitcount + 1;\n            userid = (string) session.getattribute(useridkey);\n        }\n        session.setattribute(visitcountkey, visitcount);\n\n        // 设置响应内容类型\n        response.setcontenttype("text/html;charset=utf-8");\n        printwriter out = response.getwriter();\n\n        string doctype = "<!doctype html>\\n";\n        out.println(doctype + "<html>\\n" + "<head><title>" + title + "</title></head>\\n"\n                        + "<body bgcolor=\\"#f0f0f0\\">\\n" + "<h1 align=\\"center\\">" + title\n                        + "</h1>\\n" + "<h2 align=\\"center\\">session 信息</h2>\\n"\n                        + "<table border=\\"1\\" align=\\"center\\">\\n" + "<tr bgcolor=\\"#949494\\">\\n"\n                        + "  <th>session 信息</th><th>值</th></tr>\\n" + "<tr>\\n" + "  <td>id</td>\\n"\n                        + "  <td>" + session.getid() + "</td></tr>\\n" + "<tr>\\n"\n                        + "  <td>创建时间</td>\\n" + "  <td>" + df.format(createtime) + "  </td></tr>\\n"\n                        + "<tr>\\n" + "  <td>最后访问时间</td>\\n" + "  <td>" + df.format(lastaccesstime)\n                        + "  </td></tr>\\n" + "<tr>\\n" + "  <td>用户 id</td>\\n" + "  <td>" + userid\n                        + "  </td></tr>\\n" + "<tr>\\n" + "  <td>访问统计：</td>\\n" + "  <td>" + visitcount\n                        + "</td></tr>\\n" + "</table>\\n" + "</body></html>");\n    }\n}\n\n\nweb.xml\n\n<servlet>\n  <servlet-name>sessiontrackservlet</servlet-name>\n  <servlet-class>sessiontrackservlet</servlet-class>\n</servlet>\n<servlet-mapping>\n  <servlet-name>sessiontrackservlet</servlet-name>\n  <url-pattern>/servlet/sessiontrackservlet</url-pattern>\n</servlet-mapping>\n\n\n# 删除 session 会话数据\n\n当您完成了一个用户的 session 会话数据，您有以下几种选择：\n\n**移除一个特定的属性：**您可以调用 removeattribute(string name) 方法来删除与特定的键相关联的值。\n\n**删除整个 session 会话：**您可以调用 invalidate() 方法来丢弃整个 session 会话。\n\n**设置 session 会话过期时间：**您可以调用 setmaxinactiveinterval(int interval) 方法来单独设置 session 会话超时。\n\n**注销用户：**如果使用的是支持 servlet 2.4 的服务器，您可以调用 logout 来注销 web 服务器的客户端，并把属于所有用户的所有 session 会话设置为无效。\n\n**web.xml 配置：**如果您使用的是 tomcat，除了上述方法，您还可以在 web.xml 文件中配置 session 会话超时，如下所示：\n\n<session-config>\n  <session-timeout>15</session-timeout>\n</session-config>\n\n\n上面实例中的超时时间是以分钟为单位，将覆盖 tomcat 中默认的 30 分钟超时时间。\n\n在一个 servlet 中的 getmaxinactiveinterval() 方法会返回 session 会话的超时时间，以秒为单位。所以，如果在 web.xml 中配置 session 会话超时时间为 15 分钟，那么getmaxinactiveinterval() 会返回 900。\n\n\n# cookie vs session\n\n\n# 存取方式\n\ncookie 只能保存ascii字符串，如果需要存取 unicode 字符或二进制数据，需要进行utf-8、gbk或base64等方式的编码。\n\nsession 可以存取任何类型的数据，甚至是任何 java 类。可以将 session 看成是一个 java 容器类。\n\n\n# 隐私安全\n\ncookie 存于客户端浏览器，一些客户端的程序可能会窥探、复制或修改 cookie 内容。\n\nsession 存于服务器，对客户端是透明的，不存在敏感信息泄露的危险。\n\n\n# 有效期\n\n使用 cookie 可以保证长时间登录有效，只要设置 cookie 的maxage属性为一个很大的数字。\n\n而 session 虽然理论上也可以通过设置很大的数值来保持长时间登录有效，但是，由于 session 依赖于名为jessionid的 cookie，而 cookie jessionid的maxage默认为-1，只要关闭了浏览器该 session 就会失效，因此，session 不能实现信息永久有效的效果。使用 url 地址重写也不能实现。\n\n\n# 服务器的开销\n\n由于 session 是保存在服务器的，每个用户都会产生一个 session，如果并发访问的用户非常多，会产生很多的 session，消耗大量的内存。\n\n而 cookie 由于保存在客户端浏览器上，所以不占用服务器资源。\n\n\n# 浏览器的支持\n\ncookie 需要浏览器支持才能使用。\n\n如果浏览器不支持 cookie，需要使用 session 以及 url 地址重写。\n\n需要注意的事所有的用到 session 程序的 url 都要使用response.encodeurl(stringurl) 或response.encoderedireturl(string url)进行 url 地址重写，否则导致 session 会话跟踪失效。\n\n\n# 跨域名\n\n * cookie 支持跨域名。\n * session 不支持跨域名。',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"JavaWeb 面经",frontmatter:{title:"JavaWeb 面经",categories:["编程","Java","JavaWeb"],tags:["Java","JavaWeb","Servlet"],abbrlink:"f216aa98",date:"2020-02-07T23:04:47.000Z",permalink:"/pages/1933b3/"},regularPath:"/02.JavaEE/01.JavaWeb/99.JavaWeb%E9%9D%A2%E7%BB%8F.html",relativePath:"02.JavaEE/01.JavaWeb/99.JavaWeb面经.md",key:"v-1ee597b8",path:"/pages/1933b3/",headers:[{level:2,title:"Servlet",slug:"servlet",normalizedTitle:"servlet",charIndex:17},{level:3,title:"什么是 Servlet",slug:"什么是-servlet",normalizedTitle:"什么是 servlet",charIndex:29},{level:3,title:"Servlet 和 CGI 的区别",slug:"servlet-和-cgi-的区别",normalizedTitle:"servlet 和 cgi 的区别",charIndex:321},{level:3,title:"Servlet 版本以及主要特性",slug:"servlet-版本以及主要特性",normalizedTitle:"servlet 版本以及主要特性",charIndex:548},{level:3,title:"Servlet 和 JSP 的区别",slug:"servlet-和-jsp-的区别",normalizedTitle:"servlet 和 jsp 的区别",charIndex:1386},{level:3,title:"简述 Servlet 生命周期",slug:"简述-servlet-生命周期",normalizedTitle:"简述 servlet 生命周期",charIndex:1684},{level:3,title:"如何现实 servlet 的单线程模式",slug:"如何现实-servlet-的单线程模式",normalizedTitle:"如何现实 servlet 的单线程模式",charIndex:1967},{level:3,title:"Servlet 中如何获取用户提交的查询参数或者表单数据",slug:"servlet-中如何获取用户提交的查询参数或者表单数据",normalizedTitle:"servlet 中如何获取用户提交的查询参数或者表单数据",charIndex:2026},{level:3,title:"request 的主要方法",slug:"request-的主要方法",normalizedTitle:"request 的主要方法",charIndex:2198},{level:2,title:"JSP",slug:"jsp",normalizedTitle:"jsp",charIndex:1396},{level:3,title:"JSP 的内置对象",slug:"jsp-的内置对象",normalizedTitle:"jsp 的内置对象",charIndex:3265},{level:3,title:"JSP 的作用域",slug:"jsp-的作用域",normalizedTitle:"jsp 的作用域",charIndex:3605},{level:3,title:"JSP 中 7 个动作指令和作用",slug:"jsp-中-7-个动作指令和作用",normalizedTitle:"jsp 中 7 个动作指令和作用",charIndex:3697},{level:3,title:"JSP 中动态 INCLUDE 和静态 INCLUDE 有什么区别",slug:"jsp-中动态-include-和静态-include-有什么区别",normalizedTitle:"jsp 中动态 include 和静态 include 有什么区别",charIndex:3999},{level:2,title:"原理",slug:"原理",normalizedTitle:"原理",charIndex:249},{level:3,title:"请求转发(forward)和重定向(redirect)的区别",slug:"请求转发-forward-和重定向-redirect-的区别",normalizedTitle:"请求转发(forward)和重定向(redirect)的区别",charIndex:4251},{level:3,title:"get 请求和 post 请求的区别",slug:"get-请求和-post-请求的区别",normalizedTitle:"get 请求和 post 请求的区别",charIndex:4500},{level:3,title:"用户在浏览器中输入 URL 之后，发什么了什么？写出请求和响应的流程",slug:"用户在浏览器中输入-url-之后-发什么了什么-写出请求和响应的流程",normalizedTitle:"用户在浏览器中输入 url 之后，发什么了什么？写出请求和响应的流程",charIndex:4770},{level:3,title:"什么是 Web Service?",slug:"什么是-web-service",normalizedTitle:"什么是 web service?",charIndex:4933},{level:3,title:"会话跟踪技术有哪些?",slug:"会话跟踪技术有哪些",normalizedTitle:"会话跟踪技术有哪些?",charIndex:5082},{level:3,title:"响应结果状态码有哪些，并给出中文含义？",slug:"响应结果状态码有哪些-并给出中文含义",normalizedTitle:"响应结果状态码有哪些，并给出中文含义？",charIndex:6245},{level:3,title:"XML 文档定义有几种形式？它们之间有何本质区别？解析 XML 文档有哪几种方式？",slug:"xml-文档定义有几种形式-它们之间有何本质区别-解析-xml-文档有哪几种方式",normalizedTitle:"xml 文档定义有几种形式？它们之间有何本质区别？解析 xml 文档有哪几种方式？",charIndex:6640},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:7566}],headersStr:"Servlet 什么是 Servlet Servlet 和 CGI 的区别 Servlet 版本以及主要特性 Servlet 和 JSP 的区别 简述 Servlet 生命周期 如何现实 servlet 的单线程模式 Servlet 中如何获取用户提交的查询参数或者表单数据 request 的主要方法 JSP JSP 的内置对象 JSP 的作用域 JSP 中 7 个动作指令和作用 JSP 中动态 INCLUDE 和静态 INCLUDE 有什么区别 原理 请求转发(forward)和重定向(redirect)的区别 get 请求和 post 请求的区别 用户在浏览器中输入 URL 之后，发什么了什么？写出请求和响应的流程 什么是 Web Service? 会话跟踪技术有哪些? 响应结果状态码有哪些，并给出中文含义？ XML 文档定义有几种形式？它们之间有何本质区别？解析 XML 文档有哪几种方式？ 参考资料",content:'# JavaWeb 面经\n\n\n# Servlet\n\n\n# 什么是 Servlet\n\nServlet（Server Applet），即小服务程序或服务连接器。Servlet 是 Java 编写的服务器端程序，具有独立于平台和协议的特性，主要功能在于交互式地浏览和生成数据，生成动态 Web 内容。\n\n * 狭义的 Servlet 是指 Java 实现的一个接口。\n * 广义的 Servlet 是指任何实现了这个 Servlet 接口的类。\n\nServlet 运行于支持 Java 的应用服务器中。从原理上讲，Servlet 可以响应任何类型的请求，但绝大多数情况下 Servlet 只用来扩展基于 HTTP 协议的 Web 服务器。\n\n\n# Servlet 和 CGI 的区别\n\nServlet 技术出现之前，Web 主要使用 CGI 技术。它们的区别如下：\n\n * Servlet 是基于 Java 编写的，处于服务器进程中，他能够通过多线程方式运行 service() 方法，一个实例可以服务于多个请求，而且一般不会销毁；\n * CGI(Common Gateway Interface)，即通用网关接口。它会为每个请求产生新的进程，服务完成后销毁，所以效率上低于 Servlet。\n\n\n# Servlet 版本以及主要特性\n\n版本            日期            JAVA EE/JDK 版本       特性\nServlet 4.0   2017 年 10 月   JavaEE 8             HTTP2\nServlet 3.1   2013 年 5 月    JavaEE 7             非阻塞 I/O，HTTP 协议升级机制\nServlet 3.0   2009 年 12 月   JavaEE 6, JavaSE 6   可插拔性，易于开发，异步 Servlet，安全性，文件上传\nServlet 2.5   2005 年 10 月   JavaEE 5, JavaSE 5   依赖 JavaSE 5，支持注解\nServlet 2.4   2003 年 11 月   J2EE 1.4, J2SE 1.3   web.xml 使用 XML Schema\nServlet 2.3   2001 年 8 月    J2EE 1.3, J2SE 1.2   Filter\nServlet 2.2   1999 年 8 月    J2EE 1.2, J2SE 1.2   成为 J2EE 标准\nServlet 2.1   1998 年 11 月   未指定                  First official specification, added RequestDispatcher,\n                                                 ServletContext\nServlet 2.0                 JDK 1.1              Part of Java Servlet Development Kit 2.0\nServlet 1.0   1997 年 6 月                         \n\n\n# Servlet 和 JSP 的区别\n\n 1. Servlet 是一个运行在服务器上的 Java 类,依靠服务器支持向浏览器传输数据。\n 2. JSP 本质上就是 Servlet，每次运行的时候 JSP 都会被编译成 .java 文件，然后再被编译成 .class 文件。\n 3. 有了 JSP，Servlet 不再负责动态生成页面，转而去负责控制程序逻辑的作用，控制 JSP 与 JavaBean 之间的流转。\n 4. JSP 侧重于视图,而 Servlet 侧重于控制逻辑,在 MVC 架构模式中,JSP 适合充当视图 View,Servlet 适合充当控制器 Controller。\n\n\n# 简述 Servlet 生命周期\n\n\n\nServlet 生命周期如下：\n\n 1. 加载 - 第一个到达服务器的 HTTP 请求被委派到 Servlet 容器。容器通过类加载器使用 Servlet 类对应的文件加载 servlet；\n 2. 初始化 - Servlet 通过调用 init () 方法进行初始化。\n 3. 服务 - Servlet 调用 service() 方法来处理客户端的请求。\n 4. 销毁 - Servlet 通过调用 destroy() 方法终止（结束）。\n 5. 卸载 - Servlet 是由 JVM 的垃圾回收器进行垃圾回收的。\n\n\n# 如何现实 servlet 的单线程模式\n\n<%@ page isThreadSafe="false" %>\n\n\n\n# Servlet 中如何获取用户提交的查询参数或者表单数据\n\n * HttpServletRequest 的 getParameter() 方法。\n * HttpServletRequest 的 getParameterValues() 方法。\n * HttpServletRequest 的 getParameterMap() 方法。\n\n\n# request 的主要方法\n\n * setAttribute(String name,Object)：设置名字为 name 的 request 的参数值\n * getAttribute(String name)：返回由 name 指定的属性值\n * getAttributeNames()：返回 request 对象所有属性的名字集合，结果是一个枚举的实例\n * getCookies()：返回客户端的所有 Cookie 对象，结果是一个 Cookie 数组\n * getCharacterEncoding()：返回请求中的字符编码方式\n * getContentLength()：返回请求的 Body 的长度\n * getHeader(String name)：获得 HTTP 协议定义的文件头信息\n * getHeaders(String name)：返回指定名字的 request Header 的所有值，结果是一个枚举的实例\n * getHeaderNames()：返回所以 request Header 的名字，结果是一个枚举的实例\n * getInputStream()：返回请求的输入流，用于获得请求中的数据 getMethod()：获得客户端向服务器端传送数据的方法\n * getParameter(String name)：获得客户端传送给服务器端的有 name 指定的参数值\n * getParameterNames()：获得客户端传送给服务器端的所有参数的名字，结果是一个枚举的实例\n * getParameterValues(String name)：获得有 name 指定的参数的所有值\n * getProtocol()：获取客户端向服务器端传送数据所依据的协议名称\n * getQueryString()：获得查询字符串\n * getRequestURI()：获取发出请求字符串的客户端地址\n * getRemoteAddr()：获取客户端的 IP 地址\n * getRemoteHost()：获取客户端的名字\n * getSession([Boolean create])：返回和请求相关\n * Session getServerName()：获取服务器的名字\n * getServletPath()：获取客户端所请求的脚本文件的路径\n * getServerPort()：获取服务器的端口号\n * removeAttribute(String name)：删除请求中的一个属性\n\n\n# JSP\n\n\n# JSP 的内置对象\n\n 1. request：包含客户端请求的信息；\n 2. response：包含服务器传回客户端的响应信息；\n 3. session：主要用来区分每个用户信息和会话状态；\n 4. pageContext：管理页面属性；\n 5. application：服务器启动时创建，服务器关闭时停止，保存所有应用系统中的共有数据，一个共享的内置对象（即一个容器中的多个用户共享一个 application 对象）；\n 6. out：向客户端输出数据；\n 7. config：代码片段配置对象，用于初始化 Servlet 的配置参数；\n 8. page：指网页本身；\n 9. exception：处理 JSP 文件执行时发生的错误和异常，只要在错误页面里才能使用。\n\n\n# JSP 的作用域\n\n 1. page：一个页面；\n 2. request：一次请求；\n 3. session：一次会话；\n 4. application：服务器从启动到停止。\n\n\n# JSP 中 7 个动作指令和作用\n\n 1. jsp:forward - 执行页面转向，把请求转发到下一个页面；\n 2. jsp:param - 用于传递参数，必须与其他支持参数的标签一起使用；\n 3. jsp:include - 用于动态引入一个 JSP 页面；\n 4. jsp:plugin - 用于下载 JavaBean 或 Applet 到客户端执行；\n 5. jsp:useBean - 寻求或者实例化一个 JavaBean；\n 6. jsp:setProperty - 设置 JavaBean 的属性值；\n 7. jsp:getProperty - 获取 JavaBean 的属性值。\n\n\n# JSP 中动态 INCLUDE 和静态 INCLUDE 有什么区别\n\n * 静态 INCLUDE：用 include 伪码实现，不会检查所含文件的变化，适用于包含静态页面<%@ include file="页面名称.html" %>。先合并再编译。\n * 动态 INCLUDE：用 jsp:include 动作实现 <jsp:include page="页面名称 .jsp" flush="true"> 它总是会检查文件中的变化，适用于包含动态页面，并且可以带参数。先编译再合并。\n\n\n# 原理\n\n\n# 请求转发(forward)和重定向(redirect)的区别\n\n * 效率上\n   * 转发（forward） > 重定向（redirect）\n * 显示上\n   * 重定向（redirect）：显示新的 URL\n   * 转发（forward）：地址栏不变\n * 数据上\n   * 转发（forward）：可以共享 request 里面的数据\n   * 重定向（redirect）：不能\n * 请求次数\n   * 重定向（redirect）是两次\n   * 转发（forward）是一次\n\n\n# get 请求和 post 请求的区别\n\n\n\n * GET：\n   * 从服务器上获取数据，一般不能使用在写操作接口\n   * 由 URL 所限制，GET 方式传输的数据大小有所限制，传送的数据量不超过 2KB\n   * 请求的数据会附加在 URL 之后，以？分隔 URL 和传输数据，多个参数用&连接\n   * 安全性差\n * POST:\n   * 向服务器提交数据,一般处理写业务\n   * POST 方式传送的数据量比较大，一般被默认为没有限制\n   * 安全性高\n   * 请的求的数据内容放置在 HTML HEADER 中\n\n\n# 用户在浏览器中输入 URL 之后，发什么了什么？写出请求和响应的流程\n\n 1. 域名解析\n 2. TCP 三次握手\n 3. 浏览器向服务器发送 http 请求\n 4. 浏览器发送请求头信息\n 5. 服务器处理请求\n 6. 服务器做出应答\n 7. 服务器发送应答头信息\n 8. 服务器发送数据\n 9. TCP 连接关闭\n\n\n# 什么是 Web Service?\n\n 1. WebService 就是一个应用程序，它向外界暴露出一个能够通过 Web 进行调用的 API。\n 2. 它是基于 HTTP 协议传输数据，这使得运行在不同机上的不同应用程序，无须借助附加的、专门的第三方 软件或硬件，就可以相互交换数据或集成。\n\n\n# 会话跟踪技术有哪些?\n\n由于 HTTP 协议本身是无状态的，服务器为了区分不同的用户，就需要对用户会话进行跟踪，简单的说就是为用户进行登记，为用户分配唯一的 ID，下一次用户在请求中包含此 ID，服务器根据此判断到底是哪一个用户。\n\n * URL 重写：在 URL 中添加会话信息作为请求的参数，或者将唯一的会话 ID 添加到 URL 结尾，以表示一个会话。设置表单隐藏域：将和会话跟踪相关的字段添加到隐藏域中，这些信息不会在浏览器显示，但是提交表单时会提交给服务器。\n * cookie：cookie 有两种：\n   * 一种是基于窗口的，浏览器关闭后，cookie 就没有了；\n   * 另一种是将信息存储在一个临时文件中，并设置其有效路径和最大存活时间。当用户通过浏览器和服务器建立一次会话后，会话 ID 就会随相应信息储存在基于窗口的 cookie 中，那就意味着只要浏览器没有关闭，会话没有超时，下一次请求时这个会话 ID 又会提交给服务器，让服务器识别用户身份。\n   * 在使用 cookie 时要注意几点：\n     * 首先不要在 cookie 中存放敏 感信息；\n     * 其次 cookie 存储的数据量有限（4k），不能将过多的内容存储 cookie 中；\n     * 再者浏览器通常只允许一个站点最多存放 20 个 cookie。\n     * 当然，和用户会话相关的其他信息（除了会话 ID）也可以存在 cookie 方便进行会话 跟踪;\n * HttpSession：在所有会话跟踪技术中，HttpSession 对象是最强大也是功能最多的。当一个用户第一次访问某个网站时会自动创建 HttpSession，每个用户可以访问他自己的 HttpSession。可以通过 HttpServletRequest 对象的 getSession 方法获得 HttpSession，通过 HttpSession 的 setAttribute 方法可以将一个值放在 HttpSession 中，通过调用 HttpSession 对象的 getAttribute 方法，同时传入属性名就可以获取保存在 HttpSession 中的对象。\n   * 与上面三种方式不同的是，HttpSession 放在服务器的内存中，因此不要将过大的对象放在里面，即使目前的 Servlet 容器可以在内存将满时将 HttpSession 中的对象移到其他存储设备中，但是这样势必影响性能。\n   * 添加到 HttpSession 中 的值可以是任意 Java 对象，这个对象最好实现了 Serializable 接口，这样 Servlet 容器在必要的时候可以将其序列 化到文件中，否则在序列化时就会出现异常。\n\n\n# 响应结果状态码有哪些，并给出中文含义？\n\n * 1**：信息性状态码\n * 2**：成功状态码\n   * 200：请求正常成功\n   * 204：指示请求成功但没有返回新信息\n   * 206：指示服务器已完成对资源的部分 GET 请求\n * 3**：重定向状态码\n   * 301：永久性重定向\n   * 302：临时性重定向\n   * 304：服务器端允许请求访问资源，但未满足条件\n * 4**：客户端错误状态码\n   * 400：请求报文中存在语法错误\n   * 401：发送的请求需要有通过 HTTP 认证的认证信息\n   * 403：对请求资源的访问被服务器拒绝了\n   * 404：服务器上无法找到请求的资源\n * 5**：服务器错误状态码\n   * 500：服务器端在执行请求时发生了错误\n   * 503：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求\n\n\n# XML 文档定义有几种形式？它们之间有何本质区别？解析 XML 文档有哪几种方式？\n\n（1）XML 文档有两种约束方式：\n\n 1. DTD 约束\n 2. Schema 约束\n\n（2）XML 文档区别： 1 DTD 不符合 XML 的语法结构，schema 符合 XML 的语法结构； 2 DTD 的约束扩展性比较差，XML 文档只能引入一个 DTD 的文件。schema 可以引入多个文件； 3 DTD 不支持名称空间（理解包结构），schema 支持名称空间； 4 DTD 支持数据比较少，schema 支持更多的数据类型；\n\n（3）解析方式主要有三种：\n\n * DOM 解析：\n   * （a）加载整个 xml 的文档到内存中，形成树状结构，生成对象；\n   * （b）容易产生内存溢出；\n   * （c）可以做增删改\n * SAX 解析\n   * （a）边读边解析；\n   * （b）不可以做增删改\n * DOM4J 解析（hibernate 底层采用)\n   * （a）可让 SAX 解析也产生树状结构。\n   * （b）主要 api 开发步骤：\n     * 1）SAXReader.read(xxx.xml)代表解析 xml 的文档，返回对象是 Document；\n     * 2）Document.getRootElement(),返回的是文档的根节点，是 Element 对象；\n     * 3）Element:\n       * .element(...)-- 获得指定名称第一个子元素。可以不指定名称;\n       * .elements(...)-- 获得指定名称的所有子元素。可以不指定名称;\n       * .getText()-- 获得当前元素的文本内容；\n       * .elementText(...)-- 获得指定名称子元素的文本值\n       * .addElement()-- 添加子节点\n       * .setText()-- 设置子标签内容\n     * 4）XMLWriter.write("..")-- 写出\n     * 5）XMLWriter.close()-- 关闭输出流\n\n\n# 参考资料\n\n * https://blog.csdn.net/YM_IlY/article/details/81266959\n * https://www.jianshu.com/p/f073dde56262',normalizedContent:'# javaweb 面经\n\n\n# servlet\n\n\n# 什么是 servlet\n\nservlet（server applet），即小服务程序或服务连接器。servlet 是 java 编写的服务器端程序，具有独立于平台和协议的特性，主要功能在于交互式地浏览和生成数据，生成动态 web 内容。\n\n * 狭义的 servlet 是指 java 实现的一个接口。\n * 广义的 servlet 是指任何实现了这个 servlet 接口的类。\n\nservlet 运行于支持 java 的应用服务器中。从原理上讲，servlet 可以响应任何类型的请求，但绝大多数情况下 servlet 只用来扩展基于 http 协议的 web 服务器。\n\n\n# servlet 和 cgi 的区别\n\nservlet 技术出现之前，web 主要使用 cgi 技术。它们的区别如下：\n\n * servlet 是基于 java 编写的，处于服务器进程中，他能够通过多线程方式运行 service() 方法，一个实例可以服务于多个请求，而且一般不会销毁；\n * cgi(common gateway interface)，即通用网关接口。它会为每个请求产生新的进程，服务完成后销毁，所以效率上低于 servlet。\n\n\n# servlet 版本以及主要特性\n\n版本            日期            java ee/jdk 版本       特性\nservlet 4.0   2017 年 10 月   javaee 8             http2\nservlet 3.1   2013 年 5 月    javaee 7             非阻塞 i/o，http 协议升级机制\nservlet 3.0   2009 年 12 月   javaee 6, javase 6   可插拔性，易于开发，异步 servlet，安全性，文件上传\nservlet 2.5   2005 年 10 月   javaee 5, javase 5   依赖 javase 5，支持注解\nservlet 2.4   2003 年 11 月   j2ee 1.4, j2se 1.3   web.xml 使用 xml schema\nservlet 2.3   2001 年 8 月    j2ee 1.3, j2se 1.2   filter\nservlet 2.2   1999 年 8 月    j2ee 1.2, j2se 1.2   成为 j2ee 标准\nservlet 2.1   1998 年 11 月   未指定                  first official specification, added requestdispatcher,\n                                                 servletcontext\nservlet 2.0                 jdk 1.1              part of java servlet development kit 2.0\nservlet 1.0   1997 年 6 月                         \n\n\n# servlet 和 jsp 的区别\n\n 1. servlet 是一个运行在服务器上的 java 类,依靠服务器支持向浏览器传输数据。\n 2. jsp 本质上就是 servlet，每次运行的时候 jsp 都会被编译成 .java 文件，然后再被编译成 .class 文件。\n 3. 有了 jsp，servlet 不再负责动态生成页面，转而去负责控制程序逻辑的作用，控制 jsp 与 javabean 之间的流转。\n 4. jsp 侧重于视图,而 servlet 侧重于控制逻辑,在 mvc 架构模式中,jsp 适合充当视图 view,servlet 适合充当控制器 controller。\n\n\n# 简述 servlet 生命周期\n\n\n\nservlet 生命周期如下：\n\n 1. 加载 - 第一个到达服务器的 http 请求被委派到 servlet 容器。容器通过类加载器使用 servlet 类对应的文件加载 servlet；\n 2. 初始化 - servlet 通过调用 init () 方法进行初始化。\n 3. 服务 - servlet 调用 service() 方法来处理客户端的请求。\n 4. 销毁 - servlet 通过调用 destroy() 方法终止（结束）。\n 5. 卸载 - servlet 是由 jvm 的垃圾回收器进行垃圾回收的。\n\n\n# 如何现实 servlet 的单线程模式\n\n<%@ page isthreadsafe="false" %>\n\n\n\n# servlet 中如何获取用户提交的查询参数或者表单数据\n\n * httpservletrequest 的 getparameter() 方法。\n * httpservletrequest 的 getparametervalues() 方法。\n * httpservletrequest 的 getparametermap() 方法。\n\n\n# request 的主要方法\n\n * setattribute(string name,object)：设置名字为 name 的 request 的参数值\n * getattribute(string name)：返回由 name 指定的属性值\n * getattributenames()：返回 request 对象所有属性的名字集合，结果是一个枚举的实例\n * getcookies()：返回客户端的所有 cookie 对象，结果是一个 cookie 数组\n * getcharacterencoding()：返回请求中的字符编码方式\n * getcontentlength()：返回请求的 body 的长度\n * getheader(string name)：获得 http 协议定义的文件头信息\n * getheaders(string name)：返回指定名字的 request header 的所有值，结果是一个枚举的实例\n * getheadernames()：返回所以 request header 的名字，结果是一个枚举的实例\n * getinputstream()：返回请求的输入流，用于获得请求中的数据 getmethod()：获得客户端向服务器端传送数据的方法\n * getparameter(string name)：获得客户端传送给服务器端的有 name 指定的参数值\n * getparameternames()：获得客户端传送给服务器端的所有参数的名字，结果是一个枚举的实例\n * getparametervalues(string name)：获得有 name 指定的参数的所有值\n * getprotocol()：获取客户端向服务器端传送数据所依据的协议名称\n * getquerystring()：获得查询字符串\n * getrequesturi()：获取发出请求字符串的客户端地址\n * getremoteaddr()：获取客户端的 ip 地址\n * getremotehost()：获取客户端的名字\n * getsession([boolean create])：返回和请求相关\n * session getservername()：获取服务器的名字\n * getservletpath()：获取客户端所请求的脚本文件的路径\n * getserverport()：获取服务器的端口号\n * removeattribute(string name)：删除请求中的一个属性\n\n\n# jsp\n\n\n# jsp 的内置对象\n\n 1. request：包含客户端请求的信息；\n 2. response：包含服务器传回客户端的响应信息；\n 3. session：主要用来区分每个用户信息和会话状态；\n 4. pagecontext：管理页面属性；\n 5. application：服务器启动时创建，服务器关闭时停止，保存所有应用系统中的共有数据，一个共享的内置对象（即一个容器中的多个用户共享一个 application 对象）；\n 6. out：向客户端输出数据；\n 7. config：代码片段配置对象，用于初始化 servlet 的配置参数；\n 8. page：指网页本身；\n 9. exception：处理 jsp 文件执行时发生的错误和异常，只要在错误页面里才能使用。\n\n\n# jsp 的作用域\n\n 1. page：一个页面；\n 2. request：一次请求；\n 3. session：一次会话；\n 4. application：服务器从启动到停止。\n\n\n# jsp 中 7 个动作指令和作用\n\n 1. jsp:forward - 执行页面转向，把请求转发到下一个页面；\n 2. jsp:param - 用于传递参数，必须与其他支持参数的标签一起使用；\n 3. jsp:include - 用于动态引入一个 jsp 页面；\n 4. jsp:plugin - 用于下载 javabean 或 applet 到客户端执行；\n 5. jsp:usebean - 寻求或者实例化一个 javabean；\n 6. jsp:setproperty - 设置 javabean 的属性值；\n 7. jsp:getproperty - 获取 javabean 的属性值。\n\n\n# jsp 中动态 include 和静态 include 有什么区别\n\n * 静态 include：用 include 伪码实现，不会检查所含文件的变化，适用于包含静态页面<%@ include file="页面名称.html" %>。先合并再编译。\n * 动态 include：用 jsp:include 动作实现 <jsp:include page="页面名称 .jsp" flush="true"> 它总是会检查文件中的变化，适用于包含动态页面，并且可以带参数。先编译再合并。\n\n\n# 原理\n\n\n# 请求转发(forward)和重定向(redirect)的区别\n\n * 效率上\n   * 转发（forward） > 重定向（redirect）\n * 显示上\n   * 重定向（redirect）：显示新的 url\n   * 转发（forward）：地址栏不变\n * 数据上\n   * 转发（forward）：可以共享 request 里面的数据\n   * 重定向（redirect）：不能\n * 请求次数\n   * 重定向（redirect）是两次\n   * 转发（forward）是一次\n\n\n# get 请求和 post 请求的区别\n\n\n\n * get：\n   * 从服务器上获取数据，一般不能使用在写操作接口\n   * 由 url 所限制，get 方式传输的数据大小有所限制，传送的数据量不超过 2kb\n   * 请求的数据会附加在 url 之后，以？分隔 url 和传输数据，多个参数用&连接\n   * 安全性差\n * post:\n   * 向服务器提交数据,一般处理写业务\n   * post 方式传送的数据量比较大，一般被默认为没有限制\n   * 安全性高\n   * 请的求的数据内容放置在 html header 中\n\n\n# 用户在浏览器中输入 url 之后，发什么了什么？写出请求和响应的流程\n\n 1. 域名解析\n 2. tcp 三次握手\n 3. 浏览器向服务器发送 http 请求\n 4. 浏览器发送请求头信息\n 5. 服务器处理请求\n 6. 服务器做出应答\n 7. 服务器发送应答头信息\n 8. 服务器发送数据\n 9. tcp 连接关闭\n\n\n# 什么是 web service?\n\n 1. webservice 就是一个应用程序，它向外界暴露出一个能够通过 web 进行调用的 api。\n 2. 它是基于 http 协议传输数据，这使得运行在不同机上的不同应用程序，无须借助附加的、专门的第三方 软件或硬件，就可以相互交换数据或集成。\n\n\n# 会话跟踪技术有哪些?\n\n由于 http 协议本身是无状态的，服务器为了区分不同的用户，就需要对用户会话进行跟踪，简单的说就是为用户进行登记，为用户分配唯一的 id，下一次用户在请求中包含此 id，服务器根据此判断到底是哪一个用户。\n\n * url 重写：在 url 中添加会话信息作为请求的参数，或者将唯一的会话 id 添加到 url 结尾，以表示一个会话。设置表单隐藏域：将和会话跟踪相关的字段添加到隐藏域中，这些信息不会在浏览器显示，但是提交表单时会提交给服务器。\n * cookie：cookie 有两种：\n   * 一种是基于窗口的，浏览器关闭后，cookie 就没有了；\n   * 另一种是将信息存储在一个临时文件中，并设置其有效路径和最大存活时间。当用户通过浏览器和服务器建立一次会话后，会话 id 就会随相应信息储存在基于窗口的 cookie 中，那就意味着只要浏览器没有关闭，会话没有超时，下一次请求时这个会话 id 又会提交给服务器，让服务器识别用户身份。\n   * 在使用 cookie 时要注意几点：\n     * 首先不要在 cookie 中存放敏 感信息；\n     * 其次 cookie 存储的数据量有限（4k），不能将过多的内容存储 cookie 中；\n     * 再者浏览器通常只允许一个站点最多存放 20 个 cookie。\n     * 当然，和用户会话相关的其他信息（除了会话 id）也可以存在 cookie 方便进行会话 跟踪;\n * httpsession：在所有会话跟踪技术中，httpsession 对象是最强大也是功能最多的。当一个用户第一次访问某个网站时会自动创建 httpsession，每个用户可以访问他自己的 httpsession。可以通过 httpservletrequest 对象的 getsession 方法获得 httpsession，通过 httpsession 的 setattribute 方法可以将一个值放在 httpsession 中，通过调用 httpsession 对象的 getattribute 方法，同时传入属性名就可以获取保存在 httpsession 中的对象。\n   * 与上面三种方式不同的是，httpsession 放在服务器的内存中，因此不要将过大的对象放在里面，即使目前的 servlet 容器可以在内存将满时将 httpsession 中的对象移到其他存储设备中，但是这样势必影响性能。\n   * 添加到 httpsession 中 的值可以是任意 java 对象，这个对象最好实现了 serializable 接口，这样 servlet 容器在必要的时候可以将其序列 化到文件中，否则在序列化时就会出现异常。\n\n\n# 响应结果状态码有哪些，并给出中文含义？\n\n * 1**：信息性状态码\n * 2**：成功状态码\n   * 200：请求正常成功\n   * 204：指示请求成功但没有返回新信息\n   * 206：指示服务器已完成对资源的部分 get 请求\n * 3**：重定向状态码\n   * 301：永久性重定向\n   * 302：临时性重定向\n   * 304：服务器端允许请求访问资源，但未满足条件\n * 4**：客户端错误状态码\n   * 400：请求报文中存在语法错误\n   * 401：发送的请求需要有通过 http 认证的认证信息\n   * 403：对请求资源的访问被服务器拒绝了\n   * 404：服务器上无法找到请求的资源\n * 5**：服务器错误状态码\n   * 500：服务器端在执行请求时发生了错误\n   * 503：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求\n\n\n# xml 文档定义有几种形式？它们之间有何本质区别？解析 xml 文档有哪几种方式？\n\n（1）xml 文档有两种约束方式：\n\n 1. dtd 约束\n 2. schema 约束\n\n（2）xml 文档区别： 1 dtd 不符合 xml 的语法结构，schema 符合 xml 的语法结构； 2 dtd 的约束扩展性比较差，xml 文档只能引入一个 dtd 的文件。schema 可以引入多个文件； 3 dtd 不支持名称空间（理解包结构），schema 支持名称空间； 4 dtd 支持数据比较少，schema 支持更多的数据类型；\n\n（3）解析方式主要有三种：\n\n * dom 解析：\n   * （a）加载整个 xml 的文档到内存中，形成树状结构，生成对象；\n   * （b）容易产生内存溢出；\n   * （c）可以做增删改\n * sax 解析\n   * （a）边读边解析；\n   * （b）不可以做增删改\n * dom4j 解析（hibernate 底层采用)\n   * （a）可让 sax 解析也产生树状结构。\n   * （b）主要 api 开发步骤：\n     * 1）saxreader.read(xxx.xml)代表解析 xml 的文档，返回对象是 document；\n     * 2）document.getrootelement(),返回的是文档的根节点，是 element 对象；\n     * 3）element:\n       * .element(...)-- 获得指定名称第一个子元素。可以不指定名称;\n       * .elements(...)-- 获得指定名称的所有子元素。可以不指定名称;\n       * .gettext()-- 获得当前元素的文本内容；\n       * .elementtext(...)-- 获得指定名称子元素的文本值\n       * .addelement()-- 添加子节点\n       * .settext()-- 设置子标签内容\n     * 4）xmlwriter.write("..")-- 写出\n     * 5）xmlwriter.close()-- 关闭输出流\n\n\n# 参考资料\n\n * https://blog.csdn.net/ym_ily/article/details/81266959\n * https://www.jianshu.com/p/f073dde56262',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"JavaWeb",frontmatter:{title:"JavaWeb",categories:["编程","Java","JavaWeb"],tags:["JavaWeb"],hidden:!0,abbrlink:"99720b1c",date:"2020-02-07T23:04:47.000Z",permalink:"/pages/c1cee9/"},regularPath:"/02.JavaEE/01.JavaWeb/",relativePath:"02.JavaEE/01.JavaWeb/README.md",key:"v-17a7d10c",path:"/pages/c1cee9/",headers:[{level:2,title:"知识点",slug:"知识点",normalizedTitle:"知识点",charIndex:16},{level:2,title:"学习资料",slug:"学习资料",normalizedTitle:"学习资料",charIndex:144}],headersStr:"知识点 学习资料",content:"# ☕ JavaWeb\n\n\n# 知识点\n\n * JavaWeb 之 Servlet 指南\n * JavaWeb 之 Jsp 指南\n * JavaWeb 之 Filter 和 Listener\n * JavaWeb 之 Cookie 和 Session\n * JavaWeb 面经\n\n\n# 学习资料\n\n * 书籍\n   * Java Web 整合开发王者归来\n   * Head First Servlets & JSP\n * 教程\n   * 深入拆解 Tomcat & Jetty\n   * Servlet 教程\n   * 博客园孤傲苍狼 JavaWeb 学习总结\n   * JSP 教程",normalizedContent:"# ☕ javaweb\n\n\n# 知识点\n\n * javaweb 之 servlet 指南\n * javaweb 之 jsp 指南\n * javaweb 之 filter 和 listener\n * javaweb 之 cookie 和 session\n * javaweb 面经\n\n\n# 学习资料\n\n * 书籍\n   * java web 整合开发王者归来\n   * head first servlets & jsp\n * 教程\n   * 深入拆解 tomcat & jetty\n   * servlet 教程\n   * 博客园孤傲苍狼 javaweb 学习总结\n   * jsp 教程",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Tomcat 快速入门",frontmatter:{title:"Tomcat 快速入门",categories:["编程","Java","服务器"],tags:["Java","JavaWeb","服务器","Tomcat"],abbrlink:"ea4ca089",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/c50d2b/"},regularPath:"/02.JavaEE/02.%E6%9C%8D%E5%8A%A1%E5%99%A8/01.Tomcat/01.Tomcat%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8.html",relativePath:"02.JavaEE/02.服务器/01.Tomcat/01.Tomcat快速入门.md",key:"v-75ecbd16",path:"/pages/c50d2b/",headers:[{level:2,title:"1. Tomcat 简介",slug:"_1-tomcat-简介",normalizedTitle:"1. tomcat 简介",charIndex:71},{level:3,title:"1.1. Tomcat 是什么",slug:"_1-1-tomcat-是什么",normalizedTitle:"1.1. tomcat 是什么",charIndex:88},{level:3,title:"1.2. Tomcat 重要目录",slug:"_1-2-tomcat-重要目录",normalizedTitle:"1.2. tomcat 重要目录",charIndex:422},{level:3,title:"1.3. web 工程发布目录结构",slug:"_1-3-web-工程发布目录结构",normalizedTitle:"1.3. web 工程发布目录结构",charIndex:601},{level:3,title:"1.4. Tomcat 功能",slug:"_1-4-tomcat-功能",normalizedTitle:"1.4. tomcat 功能",charIndex:1548},{level:2,title:"2. Tomcat 入门",slug:"_2-tomcat-入门",normalizedTitle:"2. tomcat 入门",charIndex:1823},{level:3,title:"2.1. 安装",slug:"_2-1-安装",normalizedTitle:"2.1. 安装",charIndex:1840},{level:3,title:"2.2. 配置",slug:"_2-2-配置",normalizedTitle:"2.2. 配置",charIndex:2317},{level:4,title:"2.2.1. Server",slug:"_2-2-1-server",normalizedTitle:"2.2.1. server",charIndex:2385},{level:4,title:"2.2.2. Service",slug:"_2-2-2-service",normalizedTitle:"2.2.2. service",charIndex:2864},{level:4,title:"2.2.3. Executor",slug:"_2-2-3-executor",normalizedTitle:"2.2.3. executor",charIndex:3378},{level:4,title:"2.2.4. Connector",slug:"_2-2-4-connector",normalizedTitle:"2.2.4. connector",charIndex:4212},{level:4,title:"2.2.5. Context",slug:"_2-2-5-context",normalizedTitle:"2.2.5. context",charIndex:6442},{level:4,title:"2.2.6. Engine",slug:"_2-2-6-engine",normalizedTitle:"2.2.6. engine",charIndex:7503},{level:4,title:"2.2.7. Host",slug:"_2-2-7-host",normalizedTitle:"2.2.7. host",charIndex:7857},{level:4,title:"2.2.8. Cluster",slug:"_2-2-8-cluster",normalizedTitle:"2.2.8. cluster",charIndex:8899},{level:3,title:"2.3. 启动",slug:"_2-3-启动",normalizedTitle:"2.3. 启动",charIndex:8953},{level:4,title:"2.3.1. 部署方式",slug:"_2-3-1-部署方式",normalizedTitle:"2.3.1. 部署方式",charIndex:8964},{level:4,title:"2.3.2. 嵌入式",slug:"_2-3-2-嵌入式",normalizedTitle:"2.3.2. 嵌入式",charIndex:9269},{level:5,title:"2.3.2.1. API 方式",slug:"_2-3-2-1-api-方式",normalizedTitle:"2.3.2.1. api 方式",charIndex:9283},{level:5,title:"2.3.2.2. 使用 maven 插件启动（不推荐）",slug:"_2-3-2-2-使用-maven-插件启动-不推荐",normalizedTitle:"2.3.2.2. 使用 maven 插件启动（不推荐）",charIndex:10857},{level:4,title:"2.3.3. IDE 插件",slug:"_2-3-3-ide-插件",normalizedTitle:"2.3.3. ide 插件",charIndex:11396},{level:2,title:"3. Tomcat 架构",slug:"_3-tomcat-架构",normalizedTitle:"3. tomcat 架构",charIndex:11891},{level:3,title:"3.1. Service",slug:"_3-1-service",normalizedTitle:"3.1. service",charIndex:12093},{level:3,title:"3.2. 连接器",slug:"_3-2-连接器",normalizedTitle:"3.2. 连接器",charIndex:12681},{level:4,title:"3.2.1. ProtocolHandler 组件",slug:"_3-2-1-protocolhandler-组件",normalizedTitle:"3.2.1. protocolhandler 组件",charIndex:13459},{level:5,title:"3.2.1.1. EndPoint",slug:"_3-2-1-1-endpoint",normalizedTitle:"3.2.1.1. endpoint",charIndex:13622},{level:5,title:"3.2.1.2. Processor",slug:"_3-2-1-2-processor",normalizedTitle:"3.2.1.2. processor",charIndex:14040},{level:4,title:"3.2.2. Adapter",slug:"_3-2-2-adapter",normalizedTitle:"3.2.2. adapter",charIndex:14552},{level:3,title:"3.3. 容器",slug:"_3-3-容器",normalizedTitle:"3.3. 容器",charIndex:14939},{level:4,title:"3.3.1. 请求分发 Servlet 过程",slug:"_3-3-1-请求分发-servlet-过程",normalizedTitle:"3.3.1. 请求分发 servlet 过程",charIndex:15214},{level:4,title:"3.3.2. Pipeline-Value",slug:"_3-3-2-pipeline-value",normalizedTitle:"3.3.2. pipeline-value",charIndex:15876},{level:2,title:"4. Tomcat 生命周期",slug:"_4-tomcat-生命周期",normalizedTitle:"4. tomcat 生命周期",charIndex:17055},{level:3,title:"4.1. Tomcat 的启动过程",slug:"_4-1-tomcat-的启动过程",normalizedTitle:"4.1. tomcat 的启动过程",charIndex:17074},{level:4,title:"4.1.1. Catalina 组件",slug:"_4-1-1-catalina-组件",normalizedTitle:"4.1.1. catalina 组件",charIndex:17447},{level:4,title:"4.1.2. Server 组件",slug:"_4-1-2-server-组件",normalizedTitle:"4.1.2. server 组件",charIndex:18843},{level:4,title:"4.1.3. Service 组件",slug:"_4-1-3-service-组件",normalizedTitle:"4.1.3. service 组件",charIndex:20100},{level:4,title:"4.1.4. Engine 组件",slug:"_4-1-4-engine-组件",normalizedTitle:"4.1.4. engine 组件",charIndex:21714},{level:3,title:"4.2. Web 应用的部署方式",slug:"_4-2-web-应用的部署方式",normalizedTitle:"4.2. web 应用的部署方式",charIndex:21792},{level:3,title:"4.3. LifeCycle",slug:"_4-3-lifecycle",normalizedTitle:"4.3. lifecycle",charIndex:23040},{level:4,title:"4.3.1. 请求处理过程",slug:"_4-3-1-请求处理过程",normalizedTitle:"4.3.1. 请求处理过程",charIndex:23060},{level:3,title:"4.4. Connector 流程",slug:"_4-4-connector-流程",normalizedTitle:"4.4. connector 流程",charIndex:23294},{level:4,title:"4.4.1. 阻塞 IO",slug:"_4-4-1-阻塞-io",normalizedTitle:"4.4.1. 阻塞 io",charIndex:23317},{level:4,title:"4.4.2. 非阻塞 IO",slug:"_4-4-2-非阻塞-io",normalizedTitle:"4.4.2. 非阻塞 io",charIndex:23335},{level:4,title:"4.4.3. IO 多路复用",slug:"_4-4-3-io-多路复用",normalizedTitle:"4.4.3. io 多路复用",charIndex:23354},{level:4,title:"4.4.4. Tomcat 各类 Connector 对比",slug:"_4-4-4-tomcat-各类-connector-对比",normalizedTitle:"4.4.4. tomcat 各类 connector 对比",charIndex:23505},{level:3,title:"4.5. Comet",slug:"_4-5-comet",normalizedTitle:"4.5. comet",charIndex:24579},{level:3,title:"4.6. 异步 Servlet",slug:"_4-6-异步-servlet",normalizedTitle:"4.6. 异步 servlet",charIndex:25291},{level:2,title:"5. 参考资料",slug:"_5-参考资料",normalizedTitle:"5. 参考资料",charIndex:26192}],headersStr:"1. Tomcat 简介 1.1. Tomcat 是什么 1.2. Tomcat 重要目录 1.3. web 工程发布目录结构 1.4. Tomcat 功能 2. Tomcat 入门 2.1. 安装 2.2. 配置 2.2.1. Server 2.2.2. Service 2.2.3. Executor 2.2.4. Connector 2.2.5. Context 2.2.6. Engine 2.2.7. Host 2.2.8. Cluster 2.3. 启动 2.3.1. 部署方式 2.3.2. 嵌入式 2.3.2.1. API 方式 2.3.2.2. 使用 maven 插件启动（不推荐） 2.3.3. IDE 插件 3. Tomcat 架构 3.1. Service 3.2. 连接器 3.2.1. ProtocolHandler 组件 3.2.1.1. EndPoint 3.2.1.2. Processor 3.2.2. Adapter 3.3. 容器 3.3.1. 请求分发 Servlet 过程 3.3.2. Pipeline-Value 4. Tomcat 生命周期 4.1. Tomcat 的启动过程 4.1.1. Catalina 组件 4.1.2. Server 组件 4.1.3. Service 组件 4.1.4. Engine 组件 4.2. Web 应用的部署方式 4.3. LifeCycle 4.3.1. 请求处理过程 4.4. Connector 流程 4.4.1. 阻塞 IO 4.4.2. 非阻塞 IO 4.4.3. IO 多路复用 4.4.4. Tomcat 各类 Connector 对比 4.5. Comet 4.6. 异步 Servlet 5. 参考资料",content:'# Tomcat 快速入门\n\n> 🎁 版本说明\n> \n> 当前最新版本：Tomcat 8.5.24\n> \n> 环境要求：JDK7+\n\n\n# 1. Tomcat 简介\n\n\n# 1.1. Tomcat 是什么\n\nTomcat 是由 Apache 开发的一个 Servlet 容器，实现了对 Servlet 和 JSP 的支持，并提供了作为 Web 服务器的一些特有功能，如 Tomcat 管理和控制平台、安全域管理和 Tomcat 阀等。\n\n由于 Tomcat 本身也内含了一个 HTTP 服务器，它也可以被视作一个单独的 Web 服务器。但是，不能将 Tomcat 和 Apache HTTP 服务器混淆，Apache HTTP 服务器是一个用 C 语言实现的 HTTP Web 服务器；这两个 HTTP web server 不是捆绑在一起的。Tomcat 包含了一个配置管理工具，也可以通过编辑 XML 格式的配置文件来进行配置。\n\n\n# 1.2. Tomcat 重要目录\n\n * /bin - Tomcat 脚本存放目录（如启动、关闭脚本）。 *.sh 文件用于 Unix 系统； *.bat 文件用于 Windows 系统。\n * /conf - Tomcat 配置文件目录。\n * /logs - Tomcat 默认日志目录。\n * /webapps - webapp 运行的目录。\n\n\n# 1.3. web 工程发布目录结构\n\n一般 web 项目路径结构\n\n|-- webapp                         # 站点根目录\n    |-- META-INF                   # META-INF 目录\n    |   `-- MANIFEST.MF            # 配置清单文件\n    |-- WEB-INF                    # WEB-INF 目录\n    |   |-- classes                # class文件目录\n    |   |   |-- *.class            # 程序需要的 class 文件\n    |   |   `-- *.xml              # 程序需要的 xml 文件\n    |   |-- lib                    # 库文件夹\n    |   |   `-- *.jar              # 程序需要的 jar 包\n    |   `-- web.xml                # Web应用程序的部署描述文件\n    |-- <userdir>                  # 自定义的目录\n    |-- <userfiles>                # 自定义的资源文件\n\n\n * webapp：工程发布文件夹。其实每个 war 包都可以视为 webapp 的压缩包。\n\n * META-INF：META-INF 目录用于存放工程自身相关的一些信息，元文件信息，通常由开发工具，环境自动生成。\n\n * WEB-INF：Java web 应用的安全目录。所谓安全就是客户端无法访问，只有服务端可以访问的目录。\n\n * /WEB-INF/classes：存放程序所需要的所有 Java class 文件。\n\n * /WEB-INF/lib：存放程序所需要的所有 jar 文件。\n\n * /WEB-INF/web.xml：web 应用的部署配置文件。它是工程中最重要的配置文件，它描述了 servlet 和组成应用的其它组件，以及应用初始化参数、安全管理约束等。\n\n\n# 1.4. Tomcat 功能\n\nTomcat 支持的 I/O 模型有：\n\n * NIO：非阻塞 I/O，采用 Java NIO 类库实现。\n * NIO2：异步 I/O，采用 JDK 7 最新的 NIO2 类库实现。\n * APR：采用 Apache 可移植运行库实现，是 C/C++ 编写的本地库。\n\nTomcat 支持的应用层协议有：\n\n * HTTP/1.1：这是大部分 Web 应用采用的访问协议。\n * AJP：用于和 Web 服务器集成（如 Apache）。\n * HTTP/2：HTTP 2.0 大幅度的提升了 Web 性能。\n\n\n# 2. Tomcat 入门\n\n\n# 2.1. 安装\n\n前提条件\n\nTomcat 8.5 要求 JDK 版本为 1.7 以上。\n\n进入 Tomcat 官方下载地址 选择合适版本下载，并解压到本地。\n\nWindows\n\n添加环境变量 CATALINA_HOME ，值为 Tomcat 的安装路径。\n\n进入安装目录下的 bin 目录，运行 startup.bat 文件，启动 Tomcat\n\nLinux / Unix\n\n下面的示例以 8.5.24 版本为例，包含了下载、解压、启动操作。\n\n# 下载解压到本地\nwget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.24/bin/apache-tomcat-8.5.24.tar.gz\ntar -zxf apache-tomcat-8.5.24.tar.gz\n# 启动 Tomcat\n./apache-tomcat-8.5.24/bin/startup.sh\n\n\n启动后，访问 http://localhost:8080 ，可以看到 Tomcat 安装成功的测试页面。\n\n\n\n\n# 2.2. 配置\n\n本节将列举一些重要、常见的配置项。详细的 Tomcat8 配置可以参考 Tomcat 8 配置官方参考文档 。\n\n# 2.2.1. Server\n\n> Server 元素表示整个 Catalina servlet 容器。\n> \n> 因此，它必须是 conf/server.xml 配置文件中的根元素。它的属性代表了整个 servlet 容器的特性。\n\n属性表\n\n属性          描述                                               备注\nclassName   这个类必须实现 org.apache.catalina.Server 接口。           默认 org.apache.catalina.core.StandardServer\naddress     服务器等待关机命令的 TCP / IP 地址。如果没有指定地址，则使用 localhost。   \nport        服务器等待关机命令的 TCP / IP 端口号。设置为-1 以禁用关闭端口。           \nshutdown    必须通过 TCP / IP 连接接收到指定端口号的命令字符串，以关闭 Tomcat。       \n\n# 2.2.2. Service\n\n> Service 元素表示一个或多个连接器组件的组合，这些组件共享一个用于处理传入请求的引擎组件。Server 中可以有多个 Service。\n\n属性表\n\n属性          描述                                      备注\nclassName   这个类必须实现org.apache.catalina.Service接口。   默认 org.apache.catalina.core.StandardService\nname        此服务的显示名称，如果您使用标准 Catalina               \n            组件，将包含在日志消息中。与特定服务器关联的每个服务的名称必须是唯一的。\n\n实例 - conf/server.xml 配置文件示例\n\n<?xml version="1.0" encoding="UTF-8"?>\n<Server port="8080" shutdown="SHUTDOWN">\n  <Service name="xxx">\n  ...\n  </Service>\n</Server>\n\n\n# 2.2.3. Executor\n\n> Executor 表示可以在 Tomcat 中的组件之间共享的线程池。\n\n属性表\n\n属性                描述                                          备注\nclassName         这个类必须实现org.apache.catalina.Executor接口。      默认 org.apache.catalina.core.StandardThreadExecutor\nname              线程池名称。                                      要求唯一, 供 Connector 元素的 executor 属性使用\nnamePrefix        线程名称前缀。                                     \nmaxThreads        最大活跃线程数。                                    默认 200\nminSpareThreads   最小活跃线程数。                                    默认 25\nmaxIdleTime       当前活跃线程大于 minSpareThreads 时,空闲线程关闭的等待最大时间。   默认 60000ms\nmaxQueueSize      线程池满情况下的请求排队大小。                             默认 Integer.MAX_VALUE\n\n<Service name="xxx">\n  <Executor name="tomcatThreadPool" namePrefix="catalina-exec-" maxThreads="300" minSpareThreads="25"/>\n</Service>\n\n\n# 2.2.4. Connector\n\n> Connector 代表连接组件。Tomcat 支持三种协议：HTTP/1.1、HTTP/2.0、AJP。\n\n属性表\n\n属性                      说明                                                             备注\nasyncTimeout            Servlet3.0 规范中的异步请求超时                                          默认 30s\nport                    请求连接的 TCP Port                                                 设置为 0,则会随机选取一个未占用的端口号\nprotocol                协议. 一般情况下设置为 HTTP/1.1,这种情况下连接模型会在 NIO 和 APR/native 中自动根据配置选择   \nURIEncoding             对 URI 的编码方式.                                                   如果设置系统变量 org.apache.catalina.STRICT_SERVLET_COMPLIANCE 为\n                                                                                       true,使用 ISO-8859-1 编码;如果未设置此系统变量且未设置此属性, 使用 UTF-8 编码\nuseBodyEncodingForURI   是否采用指定的 contentType 而不是 URIEncoding 来编码 URI 中的请求参数             \n\n以下属性在标准的 Connector(NIO, NIO2 和 APR/native)中有效:\n\n属性                  说明                                                  备注\nacceptCount         当最大请求连接 maxConnections 满时的最大排队大小                    默认 100,注意此属性和 Executor 中属性 maxQueueSize\n                                                                        的区别.这个指的是请求连接满时的堆栈大小,Executor 的 maxQueueSize 指的是处理线程满时的堆栈大小\nconnectionTimeout   请求连接超时                                              默认 60000ms\nexecutor            指定配置的线程池名称                                          \nkeepAliveTimeout    keeAlive 超时时间                                       默认值为 connectionTimeout 配置值.-1 表示不超时\nmaxConnections      最大连接数                                               连接满时后续连接放入最大为 acceptCount 的队列中. 对 NIO 和 NIO2 连接,默认值为 10000;对\n                                                                        APR/native,默认值为 8192\nmaxThreads          如果指定了 Executor, 此属性忽略;否则为 Connector 创建的内部线程池最大值     默认 200\nminSpareThreads     如果指定了 Executor, 此属性忽略;否则为 Connector 创建线程池的最小活跃线程数   默认 10\nprocessorCache      协议处理器缓存 Processor 对象的大小                             -1 表示不限制.当不使用 servlet3.0 的异步处理情况下: 如果配置 Executor,配置为\n                                                                        Executor 的 maxThreads;否则配置为 Connnector 的 maxThreads. 如果使用\n                                                                        Serlvet3.0 异步处理, 取 maxThreads 和 maxConnections 的最大值\n\n# 2.2.5. Context\n\n> Context 元素表示一个 Web 应用程序，它在特定的虚拟主机中运行。每个 Web 应用程序都基于 Web 应用程序存档（WAR）文件，或者包含相应的解包内容的相应目录，如 Servlet 规范中所述。\n\n属性表\n\n属性                           说明                                                          备注\naltDDName                    web.xml 部署描述符路径                                             默认 /WEB-INF/web.xml\ndocBase                      Context 的 Root 路径                                           和 Host 的 appBase 相结合, 可确定 web 应用的实际目录\nfailCtxIfServletStartFails   同 Host 中的 failCtxIfServletStartFails, 只对当前 Context 有效       默认为 false\nlogEffectiveWebXml           是否日志打印 web.xml 内容(web.xml 由默认的 web.xml 和应用中的 web.xml 组成)    默认为 false\npath                         web 应用的 context path                                        如果为根路径,则配置为空字符串(""), 不能不配置\nprivileged                   是否使用 Tomcat 提供的 manager servlet                             \nreloadable                   /WEB-INF/classes/ 和/WEB-INF/lib/ 目录中 class 文件发生变化是否自动重新加载   默认为 false\nswallowOutput                true 情况下, System.out 和 System.err 输出将被定向到 web 应用日志中         默认为 false\n\n# 2.2.6. Engine\n\n> Engine 元素表示与特定的 Catalina 服务相关联的整个请求处理机器。它接收并处理来自一个或多个连接器的所有请求，并将完成的响应返回给连接器，以便最终传输回客户端。\n\n属性表\n\n属性            描述                                           备注\ndefaultHost   默认主机名，用于标识将处理指向此服务器上主机名称但未在此配置文件中配置的请求的主机。   这个名字必须匹配其中一个嵌套的主机元素的名字属性。\nname          此引擎的逻辑名称，用于日志和错误消息。                          在同一服务器中使用多个服务元素时，每个引擎必须分配一个唯一的名称。\n\n# 2.2.7. Host\n\n> Host 元素表示一个虚拟主机，它是一个服务器的网络名称（如“www.mycompany.com”）与运行 Tomcat 的特定服务器的关联。\n\n属性表\n\n属性                           说明                                                         备注\nname                         名称                                                         用于日志输出\nappBase                      虚拟主机对应的应用基础路径                                              可以是个绝对路径, 或${CATALINA_BASE}相对路径\nxmlBase                      虚拟主机 XML 基础路径,里面应该有 Context xml 配置文件                       可以是个绝对路径, 或${CATALINA_BASE}相对路径\ncreateDirs                   当 appBase 和 xmlBase 不存在时,是否创建目录                            默认为 true\nautoDeploy                   是否周期性的检查 appBase 和 xmlBase 并 deploy web 应用和 context 描述符    默认为 true\ndeployIgnore                 忽略 deploy 的正则                                              \ndeployOnStartup              Tomcat 启动时是否自动 deploy                                      默认为 true\nfailCtxIfServletStartFails   配置为 true 情况下,任何 load-on-startup >=0 的 servlet 启动失败,则其对应的   默认为 false\n                             Contxt 也启动失败\n\n# 2.2.8. Cluster\n\n由于在实际开发中，我从未用过 Tomcat 集群配置，所以没研究。\n\n\n# 2.3. 启动\n\n# 2.3.1. 部署方式\n\n这种方式要求本地必须安装 Tomcat 。\n\n将打包好的 war 包放在 Tomcat 安装目录下的 webapps 目录下，然后在 bin 目录下执行 startup.bat 或 startup.sh ，Tomcat 会自动解压 webapps 目录下的 war 包。\n\n成功后，可以访问 http://localhost:8080/xxx （xxx 是 war 包文件名）。\n\n> 注意\n> \n> 以上步骤是最简单的示例。步骤中的 war 包解压路径、启动端口以及一些更多的功能都可以修改配置文件来定制 （主要是 server.xml 或 context.xml 文件）。\n\n# 2.3.2. 嵌入式\n\n# 2.3.2.1. API 方式\n\n在 pom.xml 中添加依赖\n\n<dependency>\n  <groupId>org.apache.tomcat.embed</groupId>\n  <artifactId>tomcat-embed-core</artifactId>\n  <version>8.5.24</version>\n</dependency>\n\n\n添加 SimpleEmbedTomcatServer.java 文件，内容如下：\n\nimport java.util.Optional;\nimport org.apache.catalina.startup.Tomcat;\n\npublic class SimpleTomcatServer {\n    private static final int PORT = 8080;\n    private static final String CONTEXT_PATH = "/javatool-server";\n\n    public static void main(String[] args) throws Exception {\n        // 设定 profile\n        Optional<String> profile = Optional.ofNullable(System.getProperty("spring.profiles.active"));\n        System.setProperty("spring.profiles.active", profile.orElse("develop"));\n\n        Tomcat tomcat = new Tomcat();\n        tomcat.setPort(PORT);\n        tomcat.getHost().setAppBase(".");\n        tomcat.addWebapp(CONTEXT_PATH, getAbsolutePath() + "src/main/webapp");\n        tomcat.start();\n        tomcat.getServer().await();\n    }\n\n    private static String getAbsolutePath() {\n        String path = null;\n        String folderPath = SimpleEmbedTomcatServer.class.getProtectionDomain().getCodeSource().getLocation().getPath()\n                .substring(1);\n        if (folderPath.indexOf("target") > 0) {\n            path = folderPath.substring(0, folderPath.indexOf("target"));\n        }\n        return path;\n    }\n}\n\n\n成功后，可以访问 http://localhost:8080/javatool-server 。\n\n> 说明\n> \n> 本示例是使用 org.apache.tomcat.embed 启动嵌入式 Tomcat 的最简示例。\n> \n> 这个示例中使用的是 Tomcat 默认的配置，但通常，我们需要对 Tomcat 配置进行一些定制和调优。为了加载配置文件，启动类就要稍微再复杂一些。这里不想再贴代码，有兴趣的同学可以参考：\n> \n> 示例项目\n\n# 2.3.2.2. 使用 maven 插件启动（不推荐）\n\n不推荐理由：这种方式启动 maven 虽然最简单，但是有一个很大的问题是，真的很久很久没发布新版本了（最新版本发布时间：2013-11-11）。且貌似只能找到 Tomcat6 、Tomcat7 插件。\n\n使用方法\n\n在 pom.xml 中引入插件\n\n<plugin>\n  <groupId>org.apache.tomcat.maven</groupId>\n  <artifactId>tomcat7-maven-plugin</artifactId>\n  <version>2.2</version>\n  <configuration>\n    <port>8080</port>\n    <path>/${project.artifactId}</path>\n    <uriEncoding>UTF-8</uriEncoding>\n  </configuration>\n</plugin>\n\n\n运行 mvn tomcat7:run 命令，启动 Tomcat。\n\n成功后，可以访问 http://localhost:8080/xxx （xxx 是 ${project.artifactId} 指定的项目名）。\n\n# 2.3.3. IDE 插件\n\n常见 Java IDE 一般都有对 Tomcat 的支持。\n\n以 Intellij IDEA 为例，提供了 Tomcat and TomEE Integration 插件（一般默认会安装）。\n\n使用步骤\n\n * 点击 Run/Debug Configurations > New Tomcat Server > local ，打开 Tomcat 配置页面。\n * 点击 Confiure... 按钮，设置 Tomcat 安装路径。\n * 点击 Deployment 标签页，设置要启动的应用。\n * 设置启动应用的端口、JVM 参数、启动浏览器等。\n * 成功后，可以访问 http://localhost:8080/（当然，你也可以在 url 中设置上下文名称）。\n\n\n\n> 说明\n> \n> 个人认为这个插件不如 Eclipse 的 Tomcat 插件好用，Eclipse 的 Tomcat 插件支持对 Tomcat xml 配置文件进行配置。而这里，你只能自己去 Tomcat 安装路径下修改配置文件。\n\n文中的嵌入式启动示例可以参考我的示例项目\n\n\n# 3. Tomcat 架构\n\n\n\nTomcat 要实现 2 个核心功能：\n\n * 处理 Socket 连接，负责网络字节流与 Request 和 Response 对象的转化。\n * 加载和管理 Servlet，以及处理具体的 Request 请求。\n\n为此，Tomcat 设计了两个核心组件：\n\n * 连接器（Connector）：负责和外部通信\n * 容器（Container）：负责内部处理\n\n\n# 3.1. Service\n\nTomcat 支持的 I/O 模型有：\n\n * NIO：非阻塞 I/O，采用 Java NIO 类库实现。\n * NIO2：异步 I/O，采用 JDK 7 最新的 NIO2 类库实现。\n * APR：采用 Apache 可移植运行库实现，是 C/C++ 编写的本地库。\n\nTomcat 支持的应用层协议有：\n\n * HTTP/1.1：这是大部分 Web 应用采用的访问协议。\n * AJP：用于和 Web 服务器集成（如 Apache）。\n * HTTP/2：HTTP 2.0 大幅度的提升了 Web 性能。\n\nTomcat 支持多种 I/O 模型和应用层协议。为了实现这点，一个容器可能对接多个连接器。但是，单独的连接器或容器都不能对外提供服务，需要把它们组装起来才能工作，组装后这个整体叫作 Service 组件。Tomcat 内可能有多个 Service，通过在 Tomcat 中配置多个 Service，可以实现通过不同的端口号来访问同一台机器上部署的不同应用。\n\n\n\n一个 Tomcat 实例有一个或多个 Service；一个 Service 有多个 Connector 和 Container。Connector 和 Container 之间通过标准的 ServletRequest 和 ServletResponse 通信。\n\n\n# 3.2. 连接器\n\n连接器对 Servlet 容器屏蔽了协议及 I/O 模型等的区别，无论是 HTTP 还是 AJP，在容器中获取到的都是一个标准的 ServletRequest 对象。\n\n连接器的主要功能是：\n\n * 网络通信\n * 应用层协议解析\n * Tomcat Request/Response 与 ServletRequest/ServletResponse 的转化\n\nTomcat 设计了 3 个组件来实现这 3 个功能，分别是 EndPoint、Processor 和 Adapter。\n\n\n\n组件间通过抽象接口交互。这样做还有一个好处是**封装变化。**这是面向对象设计的精髓，将系统中经常变化的部分和稳定的部分隔离，有助于增加复用性，并降低系统耦合度。网络通信的 I/O 模型是变化的，可能是非阻塞 I/O、异步 I/O 或者 APR。应用层协议也是变化的，可能是 HTTP、HTTPS、AJP。浏览器端发送的请求信息也是变化的。但是整体的处理逻辑是不变的，EndPoint 负责提供字节流给 Processor，Processor 负责提供 Tomcat Request 对象给 Adapter，Adapter 负责提供 ServletRequest 对象给容器。\n\n如果要支持新的 I/O 方案、新的应用层协议，只需要实现相关的具体子类，上层通用的处理逻辑是不变的。由于 I/O 模型和应用层协议可以自由组合，比如 NIO + HTTP 或者 NIO2 + AJP。Tomcat 的设计者将网络通信和应用层协议解析放在一起考虑，设计了一个叫 ProtocolHandler 的接口来封装这两种变化点。各种协议和通信模型的组合有相应的具体实现类。比如：Http11NioProtocol 和 AjpNioProtocol。\n\n\n\n# 3.2.1. ProtocolHandler 组件\n\n连接器用 ProtocolHandler 接口来封装通信协议和 I/O 模型的差异。ProtocolHandler 内部又分为 EndPoint 和 Processor 模块，EndPoint 负责底层 Socket 通信，Proccesor 负责应用层协议解析。\n\n# 3.2.1.1. EndPoint\n\nEndPoint 是通信端点，即通信监听的接口，是具体的 Socket 接收和发送处理器，是对传输层的抽象，因此 EndPoint 是用来实现 TCP/IP 协议的。\n\nEndPoint 是一个接口，对应的抽象实现类是 AbstractEndpoint，而 AbstractEndpoint 的具体子类，比如在 NioEndpoint 和 Nio2Endpoint 中，有两个重要的子组件：Acceptor 和 SocketProcessor。\n\n其中 Acceptor 用于监听 Socket 连接请求。SocketProcessor 用于处理接收到的 Socket 请求，它实现 Runnable 接口，在 Run 方法里调用协议处理组件 Processor 进行处理。为了提高处理能力，SocketProcessor 被提交到线程池来执行。而这个线程池叫作执行器（Executor)。\n\n# 3.2.1.2. Processor\n\n如果说 EndPoint 是用来实现 TCP/IP 协议的，那么 Processor 用来实现 HTTP 协议，Processor 接收来自 EndPoint 的 Socket，读取字节流解析成 Tomcat Request 和 Response 对象，并通过 Adapter 将其提交到容器处理，Processor 是对应用层协议的抽象。\n\nProcessor 是一个接口，定义了请求的处理等方法。它的抽象实现类 AbstractProcessor 对一些协议共有的属性进行封装，没有对方法进行实现。具体的实现有 AJPProcessor、HTTP11Processor 等，这些具体实现类实现了特定协议的解析方法和请求处理方式。\n\n\n\n从图中我们看到，EndPoint 接收到 Socket 连接后，生成一个 SocketProcessor 任务提交到线程池去处理，SocketProcessor 的 Run 方法会调用 Processor 组件去解析应用层协议，Processor 通过解析生成 Request 对象后，会调用 Adapter 的 Service 方法。\n\n# 3.2.2. Adapter\n\n连接器通过适配器 Adapter 调用容器。\n\n由于协议不同，客户端发过来的请求信息也不尽相同，Tomcat 定义了自己的 Request 类来适配这些请求信息。\n\nProtocolHandler 接口负责解析请求并生成 Tomcat Request 类。但是这个 Request 对象不是标准的 ServletRequest，也就意味着，不能用 Tomcat Request 作为参数来调用容器。Tomcat 的解决方案是引入 CoyoteAdapter，这是适配器模式的经典运用，连接器调用 CoyoteAdapter 的 Sevice 方法，传入的是 Tomcat Request 对象，CoyoteAdapter 负责将 Tomcat Request 转成 ServletRequest，再调用容器的 Service 方法。\n\n\n# 3.3. 容器\n\nTomcat 设计了 4 种容器，分别是 Engine、Host、Context 和 Wrapper。\n\n * Engine - Servlet 的顶层容器，包含一 个或多个 Host 子容器；\n * Host - 虚拟主机，负责 web 应用的部署和 Context 的创建；\n * Context - Web 应用上下文，包含多个 Wrapper，负责 web 配置的解析、管理所有的 Web 资源；\n * Wrapper - 最底层的容器，是对 Servlet 的封装，负责 Servlet 实例的创 建、执行和销毁。\n\n# 3.3.1. 请求分发 Servlet 过程\n\nTomcat 是怎么确定请求是由哪个 Wrapper 容器里的 Servlet 来处理的呢？答案是，Tomcat 是用 Mapper 组件来完成这个任务的。\n\n举例来说，假如有一个网购系统，有面向网站管理人员的后台管理系统，还有面向终端客户的在线购物系统。这两个系统跑在同一个 Tomcat 上，为了隔离它们的访问域名，配置了两个虚拟域名：manage.shopping.com和user.shopping.com，网站管理人员通过manage.shopping.com域名访问 Tomcat 去管理用户和商品，而用户管理和商品管理是两个单独的 Web 应用。终端客户通过user.shopping.com域名去搜索商品和下订单，搜索功能和订单管理也是两个独立的 Web 应用。如下所示，演示了 url 应声 Servlet 的处理流程。\n\n\n\n假如有用户访问一个 URL，比如图中的http://user.shopping.com:8080/order/buy，Tomcat 如何将这个 URL 定位到一个 Servlet 呢？\n\n 1. 首先，根据协议和端口号选定 Service 和 Engine。\n 2. 然后，根据域名选定 Host。\n 3. 之后，根据 URL 路径找到 Context 组件。\n 4. 最后，根据 URL 路径找到 Wrapper（Servlet）。\n\n这个路由分发过程具体是怎么实现的呢？答案是使用 Pipeline-Valve 管道。\n\n# 3.3.2. Pipeline-Value\n\nPipeline 可以理解为现实中的管道，Valve 为管道中的阀门，Request 和 Response 对象在管道中经过各个阀门的处理和控制。\n\nPipeline-Valve 是责任链模式，责任链模式是指在一个请求处理的过程中有很多处理者依次对请求进行处理，每个处理者负责做自己相应的处理，处理完之后将再调用下一个处理者继续处理。Valve 表示一个处理点，比如权限认证和记录日志。\n\n先来了解一下 Valve 和 Pipeline 接口的设计：\n\n\n\n * 每一个容器都有一个 Pipeline 对象，只要触发这个 Pipeline 的第一个 Valve，这个容器里 Pipeline 中的 Valve 就都会被调用到。但是，不同容器的 Pipeline 是怎么链式触发的呢，比如 Engine 中 Pipeline 需要调用下层容器 Host 中的 Pipeline。\n * 这是因为 Pipeline 中还有个 getBasic 方法。这个 BasicValve 处于 Valve 链表的末端，它是 Pipeline 中必不可少的一个 Valve，负责调用下层容器的 Pipeline 里的第一个 Valve。\n * Pipeline 中有 addValve 方法。Pipeline 中维护了 Valve 链表，Valve 可以插入到 Pipeline 中，对请求做某些处理。我们还发现 Pipeline 中没有 invoke 方法，因为整个调用链的触发是 Valve 来完成的，Valve 完成自己的处理后，调用 getNext.invoke() 来触发下一个 Valve 调用。\n * Valve 中主要的三个方法：setNext、getNext、invoke。Valve 之间的关系是单向链式结构，本身 invoke 方法中会调用下一个 Valve 的 invoke 方法。\n * 各层容器对应的 basic valve 分别是 StandardEngineValve、StandardHostValve、 StandardContextValve、StandardWrapperValve。\n * 由于 Valve 是一个处理点，因此 invoke 方法就是来处理请求的。注意到 Valve 中有 getNext 和 setNext 方法，因此我们大概可以猜到有一个链表将 Valve 链起来了。\n\n\n\n整个调用过程由连接器中的 Adapter 触发的，它会调用 Engine 的第一个 Valve：\n\nconnector.getService().getContainer().getPipeline().getFirst().invoke(request, response);\n\n\n\n# 4. Tomcat 生命周期\n\n\n# 4.1. Tomcat 的启动过程\n\n\n\n 1. Tomcat 是一个 Java 程序，它的运行从执行 startup.sh 脚本开始。startup.sh 会启动一个 JVM 来运行 Tomcat 的启动类 Bootstrap。\n 2. Bootstrap 会初始化 Tomcat 的类加载器并实例化 Catalina。\n 3. Catalina 会通过 Digester 解析 server.xml，根据其中的配置信息来创建相应组件，并调用 Server 的 start 方法。\n 4. Server 负责管理 Service 组件，它会调用 Service 的 start 方法。\n 5. Service 负责管理 Connector 和顶层容器 Engine，它会调用 Connector 和 Engine 的 start 方法。\n\n# 4.1.1. Catalina 组件\n\nCatalina 的职责就是解析 server.xml 配置，并据此实例化 Server。接下来，调用 Server 组件的 init 方法和 start 方法，将 Tomcat 启动起来。\n\nCatalina 还需要处理各种“异常”情况，比如当我们通过“Ctrl + C”关闭 Tomcat 时，Tomcat 将如何优雅的停止并且清理资源呢？因此 Catalina 在 JVM 中注册一个“关闭钩子”。\n\npublic void start() {\n    //1. 如果持有的 Server 实例为空，就解析 server.xml 创建出来\n    if (getServer() == null) {\n        load();\n    }\n\n    //2. 如果创建失败，报错退出\n    if (getServer() == null) {\n        log.fatal(sm.getString("catalina.noServer"));\n        return;\n    }\n\n    //3. 启动 Server\n    try {\n        getServer().start();\n    } catch (LifecycleException e) {\n        return;\n    }\n\n    // 创建并注册关闭钩子\n    if (useShutdownHook) {\n        if (shutdownHook == null) {\n            shutdownHook = new CatalinaShutdownHook();\n        }\n        Runtime.getRuntime().addShutdownHook(shutdownHook);\n    }\n\n    // 用 await 方法监听停止请求\n    if (await) {\n        await();\n        stop();\n    }\n}\n\n\n为什么需要关闭钩子？\n\n如果我们需要在 JVM 关闭时做一些清理工作，比如将缓存数据刷到磁盘上，或者清理一些临时文件，可以向 JVM 注册一个“关闭钩子”。“关闭钩子”其实就是一个线程，JVM 在停止之前会尝试执行这个线程的 run 方法。\n\nTomcat 的“关闭钩子”—— CatalinaShutdownHook 做了些什么呢？\n\nprotected class CatalinaShutdownHook extends Thread {\n\n    @Override\n    public void run() {\n        try {\n            if (getServer() != null) {\n                Catalina.this.stop();\n            }\n        } catch (Throwable ex) {\n           ...\n        }\n    }\n}\n\n\nTomcat 的“关闭钩子”实际上就执行了 Server 的 stop 方法，Server 的 stop 方法会释放和清理所有的资源。\n\n# 4.1.2. Server 组件\n\nServer 组件的具体实现类是 StandardServer，Server 继承了 LifeCycleBase，它的生命周期被统一管理，并且它的子组件是 Service，因此它还需要管理 Service 的生命周期，也就是说在启动时调用 Service 组件的启动方法，在停止时调用它们的停止方法。Server 在内部维护了若干 Service 组件，它是以数组来保存的。\n\n@Override\npublic void addService(Service service) {\n\n    service.setServer(this);\n\n    synchronized (servicesLock) {\n        // 创建一个长度 +1 的新数组\n        Service results[] = new Service[services.length + 1];\n\n        // 将老的数据复制过去\n        System.arraycopy(services, 0, results, 0, services.length);\n        results[services.length] = service;\n        services = results;\n\n        // 启动 Service 组件\n        if (getState().isAvailable()) {\n            try {\n                service.start();\n            } catch (LifecycleException e) {\n                // Ignore\n            }\n        }\n\n        // 触发监听事件\n        support.firePropertyChange("service", null, service);\n    }\n\n}\n\n\nServer 并没有一开始就分配一个很长的数组，而是在添加的过程中动态地扩展数组长度，当添加一个新的 Service 实例时，会创建一个新数组并把原来数组内容复制到新数组，这样做的目的其实是为了节省内存空间。\n\n除此之外，Server 组件还有一个重要的任务是启动一个 Socket 来监听停止端口，这就是为什么你能通过 shutdown 命令来关闭 Tomcat。不知道你留意到没有，上面 Caralina 的启动方法的最后一行代码就是调用了 Server 的 await 方法。\n\n在 await 方法里会创建一个 Socket 监听 8005 端口，并在一个死循环里接收 Socket 上的连接请求，如果有新的连接到来就建立连接，然后从 Socket 中读取数据；如果读到的数据是停止命令“SHUTDOWN”，就退出循环，进入 stop 流程。\n\n# 4.1.3. Service 组件\n\nService 组件的具体实现类是 StandardService。\n\n【源码】StandardService 源码定义\n\npublic class StandardService extends LifecycleBase implements Service {\n    // 名字\n    private String name = null;\n\n    //Server 实例\n    private Server server = null;\n\n    // 连接器数组\n    protected Connector connectors[] = new Connector[0];\n    private final Object connectorsLock = new Object();\n\n    // 对应的 Engine 容器\n    private Engine engine = null;\n\n    // 映射器及其监听器\n    protected final Mapper mapper = new Mapper();\n    protected final MapperListener mapperListener = new MapperListener(this);\n\n\t// ...\n}\n\n\nStandardService 继承了 LifecycleBase 抽象类。\n\nStandardService 维护了一个 MapperListener 用于支持 Tomcat 热部署。当 Web 应用的部署发生变化时，Mapper 中的映射信息也要跟着变化，MapperListener 就是一个监听器，它监听容器的变化，并把信息更新到 Mapper 中，这是典型的观察者模式。\n\n作为“管理”角色的组件，最重要的是维护其他组件的生命周期。此外在启动各种组件时，要注意它们的依赖关系，也就是说，要注意启动的顺序。\n\nprotected void startInternal() throws LifecycleException {\n\n    //1. 触发启动监听器\n    setState(LifecycleState.STARTING);\n\n    //2. 先启动 Engine，Engine 会启动它子容器\n    if (engine != null) {\n        synchronized (engine) {\n            engine.start();\n        }\n    }\n\n    //3. 再启动 Mapper 监听器\n    mapperListener.start();\n\n    //4. 最后启动连接器，连接器会启动它子组件，比如 Endpoint\n    synchronized (connectorsLock) {\n        for (Connector connector: connectors) {\n            if (connector.getState() != LifecycleState.FAILED) {\n                connector.start();\n            }\n        }\n    }\n}\n\n\n从启动方法可以看到，Service 先启动了 Engine 组件，再启动 Mapper 监听器，最后才是启动连接器。这很好理解，因为内层组件启动好了才能对外提供服务，才能启动外层的连接器组件。而 Mapper 也依赖容器组件，容器组件启动好了才能监听它们的变化，因此 Mapper 和 MapperListener 在容器组件之后启动。组件停止的顺序跟启动顺序正好相反的，也是基于它们的依赖关系。\n\n# 4.1.4. Engine 组件\n\nEngine 本质是一个容器，因此它继承了 ContainerBase 基类，并且实现了 Engine 接口。\n\n\n# 4.2. Web 应用的部署方式\n\n注：catalina.home：安装目录;catalina.base：工作目录;默认值 user.dir\n\n * Server.xml 配置 Host 元素，指定 appBase 属性，默认$catalina.base/webapps/\n * Server.xml 配置 Context 元素，指定 docBase，元素，指定 web 应用的路径\n * 自定义配置：在$catalina.base/EngineName/HostName/XXX.xml 配置 Context 元素\n\nHostConfig 监听了 StandardHost 容器的事件，在 start 方法中解析上述配置文件：\n\n * 扫描 appbase 路径下的所有文件夹和 war 包，解析各个应用的 META-INF/context.xml，并 创建 StandardContext，并将 Context 加入到 Host 的子容器中。\n * 解析$catalina.base/EngineName/HostName/下的所有 Context 配置，找到相应 web 应 用的位置，解析各个应用的 META-INF/context.xml，并创建 StandardContext，并将 Context 加入到 Host 的子容器中。\n\n注：\n\n * HostConfig 并没有实际解析 Context.xml，而是在 ContextConfig 中进行的。\n * HostConfig 中会定期检查 watched 资源文件(context.xml 配置文件)\n\nContextConfig 解析 context.xml 顺序：\n\n * 先解析全局的配置 config/context.xml\n * 然后解析 Host 的默认配置 EngineName/HostName/context.xml.default\n * 最后解析应用的 META-INF/context.xml\n\nContextConfig 解析 web.xml 顺序：\n\n * 先解析全局的配置 config/web.xml\n * 然后解析 Host 的默认配置 EngineName/HostName/web.xml.default 接着解析应用的 MEB-INF/web.xml\n * 扫描应用 WEB-INF/lib/下的 jar 文件，解析其中的 META-INF/web-fragment.xml 最后合并 xml 封装成 WebXml，并设置 Context\n\n注：\n\n * 扫描 web 应用和 jar 中的注解(Filter、Listener、Servlet)就是上述步骤中进行的。\n * 容器的定期执行：backgroundProcess，由 ContainerBase 来实现的，并且只有在顶层容器 中才会开启线程。(backgroundProcessorDelay=10 标志位来控制)\n\n\n# 4.3. LifeCycle\n\n\n\n# 4.3.1. 请求处理过程\n\n\n 1. 根据 server.xml 配置的指定的 connector 以及端口监听 http、或者 ajp 请求\n 2. 请求到来时建立连接,解析请求参数,创建 Request 和 Response 对象,调用顶层容器 pipeline 的 invoke 方法\n 3. 容器之间层层调用,最终调用业务 servlet 的 service 方法\n 4. Connector 将 response 流中的数据写到 socket 中\n\n\n# 4.4. Connector 流程\n\n\n\n# 4.4.1. 阻塞 IO\n\n\n\n# 4.4.2. 非阻塞 IO\n\n\n\n# 4.4.3. IO 多路复用\n\n\n\n阻塞与非阻塞的区别在于进行读操作和写操作的系统调用时，如果此时内核态没有数据可读或者没有缓冲空间可写时，是否阻塞。\n\nIO 多路复用的好处在于可同时监听多个 socket 的可读和可写事件，这样就能使得应用可以同时监听多个 socket，释放了应用线程资源。\n\n# 4.4.4. Tomcat 各类 Connector 对比\n\n\n * JIO：用 java.io 编写的 TCP 模块，阻塞 IO\n * NIO：用 java.nio 编写的 TCP 模块，非阻塞 IO，（IO 多路复用）\n * APR：全称 Apache Portable Runtime，使用 JNI 的方式来进行读取文件以及进行网络传输\n\nApache Portable Runtime 是一个高度可移植的库，它是 Apache HTTP Server 2.x 的核心。 APR 具有许多用途，包括访问高级 IO 功能（如 sendfile，epoll 和 OpenSSL），操作系统级功能（随机数生成，系统状态等）和本地进程处理（共享内存，NT 管道和 Unix 套接字）。\n\n表格中字段含义说明：\n\n * Support Polling - 是否支持基于 IO 多路复用的 socket 事件轮询\n * Polling Size - 轮询的最大连接数\n * Wait for next Request - 在等待下一个请求时，处理线程是否释放，BIO 是没有释放的，所以在 keep-alive=true 的情况下处理的并发连接数有限\n * Read Request Headers - 由于 request header 数据较少，可以由容器提前解析完毕，不需要阻塞\n * Read Request Body - 读取 request body 的数据是应用业务逻辑的事情，同时 Servlet 的限制，是需要阻塞读取的\n * Write Response - 跟读取 request body 的逻辑类似，同样需要阻塞写\n\nNIO 处理相关类\n\n\n\nPoller 线程从 EventQueue 获取 PollerEvent，并执行 PollerEvent 的 run 方法，调用 Selector 的 select 方法，如果有可读的 Socket 则创建 Http11NioProcessor，放入到线程池中执行；\n\nCoyoteAdapter 是 Connector 到 Container 的适配器，Http11NioProcessor 调用其提供的 service 方法，内部创建 Request 和 Response 对象，并调用最顶层容器的 Pipeline 中的第一个 Valve 的 invoke 方法\n\nMapper 主要处理 http url 到 servlet 的映射规则的解析，对外提供 map 方法\n\n\n# 4.5. Comet\n\nComet 是一种用于 web 的推送技术，能使服务器实时地将更新的信息传送到客户端，而无须客户端发出请求 在 WebSocket 出来之前，如果不适用 comet，只能通过浏览器端轮询 Server 来模拟实现服务器端推送。 Comet 支持 servlet 异步处理 IO，当连接上数据可读时触发事件，并异步写数据(阻塞)\n\nTomcat 要实现 Comet，只需继承 HttpServlet 同时，实现 CometProcessor 接口\n\n * Begin：新的请求连接接入调用，可进行与 Request 和 Response 相关的对象初始化操作，并保存 response 对象，用于后续写入数据\n * Read：请求连接有数据可读时调用\n * End：当数据可用时，如果读取到文件结束或者 response 被关闭时则被调用\n * Error：在连接上发生异常时调用，数据读取异常、连接断开、处理异常、socket 超时\n\nNote：\n\n * Read：在 post 请求有数据，但在 begin 事件中没有处理，则会调用 read，如果 read 没有读取数据，在会触发 Error 回调，关闭 socket\n * End：当 socket 超时，并且 response 被关闭时也会调用；server 被关闭时调用\n * Error：除了 socket 超时不会关闭 socket，其他都会关闭 socket\n * End 和 Error 时间触发时应关闭当前 comet 会话，即调用 CometEvent 的 close 方法 Note：在事件触发时要做好线程安全的操作\n\n\n# 4.6. 异步 Servlet\n\n\n\n传统流程：\n\n * 首先，Servlet 接收到请求之后，request 数据解析；\n * 接着，调用业务接口的某些方法，以完成业务处理；\n * 最后，根据处理的结果提交响应，Servlet 线程结束\n\n\n\n异步处理流程：\n\n * 客户端发送一个请求\n * Servlet 容器分配一个线程来处理容器中的一个 servlet\n * servlet 调用 request.startAsync()，保存 AsyncContext, 然后返回\n * 任何方式存在的容器线程都将退出，但是 response 仍然保持开放\n * 业务线程使用保存的 AsyncContext 来完成响应（线程池）\n * 客户端收到响应\n\nServlet 线程将请求转交给一个异步线程来执行业务处理，线程本身返回至容器，此时 Servlet 还没有生成响应数据，异步线程处理完业务以后，可以直接生成响应数据（异步线程拥有 ServletRequest 和 ServletResponse 对象的引用）\n\n为什么 web 应用中支持异步？\n\n推出异步，主要是针对那些比较耗时的请求：比如一次缓慢的数据库查询，一次外部 REST API 调用, 或者是其他一些 I/O 密集型操作。这种耗时的请求会很快的耗光 Servlet 容器的线程池，继而影响可扩展性。\n\nNote：从客户端的角度来看，request 仍然像任何其他的 HTTP 的 request-response 交互一样，只是耗费了更长的时间而已\n\n异步事件监听\n\n * onStartAsync：Request 调用 startAsync 方法时触发\n * onComplete：syncContext 调用 complete 方法时触发\n * onError：处理请求的过程出现异常时触发\n * onTimeout：socket 超时触发\n\nNote : onError/ onTimeout 触发后，会紧接着回调 onComplete onComplete 执行后，就不可再操作 request 和 response\n\n\n# 5. 参考资料\n\n * 官方\n   \n   * Tomcat 官方网站\n   * Tomcat Wiki\n   * Tomee 官方网站\n\n * 文章\n   \n   * Creating a Web App with Bootstrap and Tomcat Embedded\n   * Tomcat 组成与工作原理\n   * Tomcat 工作原理\n   * Tomcat 设计模式分析',normalizedContent:'# tomcat 快速入门\n\n> 🎁 版本说明\n> \n> 当前最新版本：tomcat 8.5.24\n> \n> 环境要求：jdk7+\n\n\n# 1. tomcat 简介\n\n\n# 1.1. tomcat 是什么\n\ntomcat 是由 apache 开发的一个 servlet 容器，实现了对 servlet 和 jsp 的支持，并提供了作为 web 服务器的一些特有功能，如 tomcat 管理和控制平台、安全域管理和 tomcat 阀等。\n\n由于 tomcat 本身也内含了一个 http 服务器，它也可以被视作一个单独的 web 服务器。但是，不能将 tomcat 和 apache http 服务器混淆，apache http 服务器是一个用 c 语言实现的 http web 服务器；这两个 http web server 不是捆绑在一起的。tomcat 包含了一个配置管理工具，也可以通过编辑 xml 格式的配置文件来进行配置。\n\n\n# 1.2. tomcat 重要目录\n\n * /bin - tomcat 脚本存放目录（如启动、关闭脚本）。 *.sh 文件用于 unix 系统； *.bat 文件用于 windows 系统。\n * /conf - tomcat 配置文件目录。\n * /logs - tomcat 默认日志目录。\n * /webapps - webapp 运行的目录。\n\n\n# 1.3. web 工程发布目录结构\n\n一般 web 项目路径结构\n\n|-- webapp                         # 站点根目录\n    |-- meta-inf                   # meta-inf 目录\n    |   `-- manifest.mf            # 配置清单文件\n    |-- web-inf                    # web-inf 目录\n    |   |-- classes                # class文件目录\n    |   |   |-- *.class            # 程序需要的 class 文件\n    |   |   `-- *.xml              # 程序需要的 xml 文件\n    |   |-- lib                    # 库文件夹\n    |   |   `-- *.jar              # 程序需要的 jar 包\n    |   `-- web.xml                # web应用程序的部署描述文件\n    |-- <userdir>                  # 自定义的目录\n    |-- <userfiles>                # 自定义的资源文件\n\n\n * webapp：工程发布文件夹。其实每个 war 包都可以视为 webapp 的压缩包。\n\n * meta-inf：meta-inf 目录用于存放工程自身相关的一些信息，元文件信息，通常由开发工具，环境自动生成。\n\n * web-inf：java web 应用的安全目录。所谓安全就是客户端无法访问，只有服务端可以访问的目录。\n\n * /web-inf/classes：存放程序所需要的所有 java class 文件。\n\n * /web-inf/lib：存放程序所需要的所有 jar 文件。\n\n * /web-inf/web.xml：web 应用的部署配置文件。它是工程中最重要的配置文件，它描述了 servlet 和组成应用的其它组件，以及应用初始化参数、安全管理约束等。\n\n\n# 1.4. tomcat 功能\n\ntomcat 支持的 i/o 模型有：\n\n * nio：非阻塞 i/o，采用 java nio 类库实现。\n * nio2：异步 i/o，采用 jdk 7 最新的 nio2 类库实现。\n * apr：采用 apache 可移植运行库实现，是 c/c++ 编写的本地库。\n\ntomcat 支持的应用层协议有：\n\n * http/1.1：这是大部分 web 应用采用的访问协议。\n * ajp：用于和 web 服务器集成（如 apache）。\n * http/2：http 2.0 大幅度的提升了 web 性能。\n\n\n# 2. tomcat 入门\n\n\n# 2.1. 安装\n\n前提条件\n\ntomcat 8.5 要求 jdk 版本为 1.7 以上。\n\n进入 tomcat 官方下载地址 选择合适版本下载，并解压到本地。\n\nwindows\n\n添加环境变量 catalina_home ，值为 tomcat 的安装路径。\n\n进入安装目录下的 bin 目录，运行 startup.bat 文件，启动 tomcat\n\nlinux / unix\n\n下面的示例以 8.5.24 版本为例，包含了下载、解压、启动操作。\n\n# 下载解压到本地\nwget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.24/bin/apache-tomcat-8.5.24.tar.gz\ntar -zxf apache-tomcat-8.5.24.tar.gz\n# 启动 tomcat\n./apache-tomcat-8.5.24/bin/startup.sh\n\n\n启动后，访问 http://localhost:8080 ，可以看到 tomcat 安装成功的测试页面。\n\n\n\n\n# 2.2. 配置\n\n本节将列举一些重要、常见的配置项。详细的 tomcat8 配置可以参考 tomcat 8 配置官方参考文档 。\n\n# 2.2.1. server\n\n> server 元素表示整个 catalina servlet 容器。\n> \n> 因此，它必须是 conf/server.xml 配置文件中的根元素。它的属性代表了整个 servlet 容器的特性。\n\n属性表\n\n属性          描述                                               备注\nclassname   这个类必须实现 org.apache.catalina.server 接口。           默认 org.apache.catalina.core.standardserver\naddress     服务器等待关机命令的 tcp / ip 地址。如果没有指定地址，则使用 localhost。   \nport        服务器等待关机命令的 tcp / ip 端口号。设置为-1 以禁用关闭端口。           \nshutdown    必须通过 tcp / ip 连接接收到指定端口号的命令字符串，以关闭 tomcat。       \n\n# 2.2.2. service\n\n> service 元素表示一个或多个连接器组件的组合，这些组件共享一个用于处理传入请求的引擎组件。server 中可以有多个 service。\n\n属性表\n\n属性          描述                                      备注\nclassname   这个类必须实现org.apache.catalina.service接口。   默认 org.apache.catalina.core.standardservice\nname        此服务的显示名称，如果您使用标准 catalina               \n            组件，将包含在日志消息中。与特定服务器关联的每个服务的名称必须是唯一的。\n\n实例 - conf/server.xml 配置文件示例\n\n<?xml version="1.0" encoding="utf-8"?>\n<server port="8080" shutdown="shutdown">\n  <service name="xxx">\n  ...\n  </service>\n</server>\n\n\n# 2.2.3. executor\n\n> executor 表示可以在 tomcat 中的组件之间共享的线程池。\n\n属性表\n\n属性                描述                                          备注\nclassname         这个类必须实现org.apache.catalina.executor接口。      默认 org.apache.catalina.core.standardthreadexecutor\nname              线程池名称。                                      要求唯一, 供 connector 元素的 executor 属性使用\nnameprefix        线程名称前缀。                                     \nmaxthreads        最大活跃线程数。                                    默认 200\nminsparethreads   最小活跃线程数。                                    默认 25\nmaxidletime       当前活跃线程大于 minsparethreads 时,空闲线程关闭的等待最大时间。   默认 60000ms\nmaxqueuesize      线程池满情况下的请求排队大小。                             默认 integer.max_value\n\n<service name="xxx">\n  <executor name="tomcatthreadpool" nameprefix="catalina-exec-" maxthreads="300" minsparethreads="25"/>\n</service>\n\n\n# 2.2.4. connector\n\n> connector 代表连接组件。tomcat 支持三种协议：http/1.1、http/2.0、ajp。\n\n属性表\n\n属性                      说明                                                             备注\nasynctimeout            servlet3.0 规范中的异步请求超时                                          默认 30s\nport                    请求连接的 tcp port                                                 设置为 0,则会随机选取一个未占用的端口号\nprotocol                协议. 一般情况下设置为 http/1.1,这种情况下连接模型会在 nio 和 apr/native 中自动根据配置选择   \nuriencoding             对 uri 的编码方式.                                                   如果设置系统变量 org.apache.catalina.strict_servlet_compliance 为\n                                                                                       true,使用 iso-8859-1 编码;如果未设置此系统变量且未设置此属性, 使用 utf-8 编码\nusebodyencodingforuri   是否采用指定的 contenttype 而不是 uriencoding 来编码 uri 中的请求参数             \n\n以下属性在标准的 connector(nio, nio2 和 apr/native)中有效:\n\n属性                  说明                                                  备注\nacceptcount         当最大请求连接 maxconnections 满时的最大排队大小                    默认 100,注意此属性和 executor 中属性 maxqueuesize\n                                                                        的区别.这个指的是请求连接满时的堆栈大小,executor 的 maxqueuesize 指的是处理线程满时的堆栈大小\nconnectiontimeout   请求连接超时                                              默认 60000ms\nexecutor            指定配置的线程池名称                                          \nkeepalivetimeout    keealive 超时时间                                       默认值为 connectiontimeout 配置值.-1 表示不超时\nmaxconnections      最大连接数                                               连接满时后续连接放入最大为 acceptcount 的队列中. 对 nio 和 nio2 连接,默认值为 10000;对\n                                                                        apr/native,默认值为 8192\nmaxthreads          如果指定了 executor, 此属性忽略;否则为 connector 创建的内部线程池最大值     默认 200\nminsparethreads     如果指定了 executor, 此属性忽略;否则为 connector 创建线程池的最小活跃线程数   默认 10\nprocessorcache      协议处理器缓存 processor 对象的大小                             -1 表示不限制.当不使用 servlet3.0 的异步处理情况下: 如果配置 executor,配置为\n                                                                        executor 的 maxthreads;否则配置为 connnector 的 maxthreads. 如果使用\n                                                                        serlvet3.0 异步处理, 取 maxthreads 和 maxconnections 的最大值\n\n# 2.2.5. context\n\n> context 元素表示一个 web 应用程序，它在特定的虚拟主机中运行。每个 web 应用程序都基于 web 应用程序存档（war）文件，或者包含相应的解包内容的相应目录，如 servlet 规范中所述。\n\n属性表\n\n属性                           说明                                                          备注\naltddname                    web.xml 部署描述符路径                                             默认 /web-inf/web.xml\ndocbase                      context 的 root 路径                                           和 host 的 appbase 相结合, 可确定 web 应用的实际目录\nfailctxifservletstartfails   同 host 中的 failctxifservletstartfails, 只对当前 context 有效       默认为 false\nlogeffectivewebxml           是否日志打印 web.xml 内容(web.xml 由默认的 web.xml 和应用中的 web.xml 组成)    默认为 false\npath                         web 应用的 context path                                        如果为根路径,则配置为空字符串(""), 不能不配置\nprivileged                   是否使用 tomcat 提供的 manager servlet                             \nreloadable                   /web-inf/classes/ 和/web-inf/lib/ 目录中 class 文件发生变化是否自动重新加载   默认为 false\nswallowoutput                true 情况下, system.out 和 system.err 输出将被定向到 web 应用日志中         默认为 false\n\n# 2.2.6. engine\n\n> engine 元素表示与特定的 catalina 服务相关联的整个请求处理机器。它接收并处理来自一个或多个连接器的所有请求，并将完成的响应返回给连接器，以便最终传输回客户端。\n\n属性表\n\n属性            描述                                           备注\ndefaulthost   默认主机名，用于标识将处理指向此服务器上主机名称但未在此配置文件中配置的请求的主机。   这个名字必须匹配其中一个嵌套的主机元素的名字属性。\nname          此引擎的逻辑名称，用于日志和错误消息。                          在同一服务器中使用多个服务元素时，每个引擎必须分配一个唯一的名称。\n\n# 2.2.7. host\n\n> host 元素表示一个虚拟主机，它是一个服务器的网络名称（如“www.mycompany.com”）与运行 tomcat 的特定服务器的关联。\n\n属性表\n\n属性                           说明                                                         备注\nname                         名称                                                         用于日志输出\nappbase                      虚拟主机对应的应用基础路径                                              可以是个绝对路径, 或${catalina_base}相对路径\nxmlbase                      虚拟主机 xml 基础路径,里面应该有 context xml 配置文件                       可以是个绝对路径, 或${catalina_base}相对路径\ncreatedirs                   当 appbase 和 xmlbase 不存在时,是否创建目录                            默认为 true\nautodeploy                   是否周期性的检查 appbase 和 xmlbase 并 deploy web 应用和 context 描述符    默认为 true\ndeployignore                 忽略 deploy 的正则                                              \ndeployonstartup              tomcat 启动时是否自动 deploy                                      默认为 true\nfailctxifservletstartfails   配置为 true 情况下,任何 load-on-startup >=0 的 servlet 启动失败,则其对应的   默认为 false\n                             contxt 也启动失败\n\n# 2.2.8. cluster\n\n由于在实际开发中，我从未用过 tomcat 集群配置，所以没研究。\n\n\n# 2.3. 启动\n\n# 2.3.1. 部署方式\n\n这种方式要求本地必须安装 tomcat 。\n\n将打包好的 war 包放在 tomcat 安装目录下的 webapps 目录下，然后在 bin 目录下执行 startup.bat 或 startup.sh ，tomcat 会自动解压 webapps 目录下的 war 包。\n\n成功后，可以访问 http://localhost:8080/xxx （xxx 是 war 包文件名）。\n\n> 注意\n> \n> 以上步骤是最简单的示例。步骤中的 war 包解压路径、启动端口以及一些更多的功能都可以修改配置文件来定制 （主要是 server.xml 或 context.xml 文件）。\n\n# 2.3.2. 嵌入式\n\n# 2.3.2.1. api 方式\n\n在 pom.xml 中添加依赖\n\n<dependency>\n  <groupid>org.apache.tomcat.embed</groupid>\n  <artifactid>tomcat-embed-core</artifactid>\n  <version>8.5.24</version>\n</dependency>\n\n\n添加 simpleembedtomcatserver.java 文件，内容如下：\n\nimport java.util.optional;\nimport org.apache.catalina.startup.tomcat;\n\npublic class simpletomcatserver {\n    private static final int port = 8080;\n    private static final string context_path = "/javatool-server";\n\n    public static void main(string[] args) throws exception {\n        // 设定 profile\n        optional<string> profile = optional.ofnullable(system.getproperty("spring.profiles.active"));\n        system.setproperty("spring.profiles.active", profile.orelse("develop"));\n\n        tomcat tomcat = new tomcat();\n        tomcat.setport(port);\n        tomcat.gethost().setappbase(".");\n        tomcat.addwebapp(context_path, getabsolutepath() + "src/main/webapp");\n        tomcat.start();\n        tomcat.getserver().await();\n    }\n\n    private static string getabsolutepath() {\n        string path = null;\n        string folderpath = simpleembedtomcatserver.class.getprotectiondomain().getcodesource().getlocation().getpath()\n                .substring(1);\n        if (folderpath.indexof("target") > 0) {\n            path = folderpath.substring(0, folderpath.indexof("target"));\n        }\n        return path;\n    }\n}\n\n\n成功后，可以访问 http://localhost:8080/javatool-server 。\n\n> 说明\n> \n> 本示例是使用 org.apache.tomcat.embed 启动嵌入式 tomcat 的最简示例。\n> \n> 这个示例中使用的是 tomcat 默认的配置，但通常，我们需要对 tomcat 配置进行一些定制和调优。为了加载配置文件，启动类就要稍微再复杂一些。这里不想再贴代码，有兴趣的同学可以参考：\n> \n> 示例项目\n\n# 2.3.2.2. 使用 maven 插件启动（不推荐）\n\n不推荐理由：这种方式启动 maven 虽然最简单，但是有一个很大的问题是，真的很久很久没发布新版本了（最新版本发布时间：2013-11-11）。且貌似只能找到 tomcat6 、tomcat7 插件。\n\n使用方法\n\n在 pom.xml 中引入插件\n\n<plugin>\n  <groupid>org.apache.tomcat.maven</groupid>\n  <artifactid>tomcat7-maven-plugin</artifactid>\n  <version>2.2</version>\n  <configuration>\n    <port>8080</port>\n    <path>/${project.artifactid}</path>\n    <uriencoding>utf-8</uriencoding>\n  </configuration>\n</plugin>\n\n\n运行 mvn tomcat7:run 命令，启动 tomcat。\n\n成功后，可以访问 http://localhost:8080/xxx （xxx 是 ${project.artifactid} 指定的项目名）。\n\n# 2.3.3. ide 插件\n\n常见 java ide 一般都有对 tomcat 的支持。\n\n以 intellij idea 为例，提供了 tomcat and tomee integration 插件（一般默认会安装）。\n\n使用步骤\n\n * 点击 run/debug configurations > new tomcat server > local ，打开 tomcat 配置页面。\n * 点击 confiure... 按钮，设置 tomcat 安装路径。\n * 点击 deployment 标签页，设置要启动的应用。\n * 设置启动应用的端口、jvm 参数、启动浏览器等。\n * 成功后，可以访问 http://localhost:8080/（当然，你也可以在 url 中设置上下文名称）。\n\n\n\n> 说明\n> \n> 个人认为这个插件不如 eclipse 的 tomcat 插件好用，eclipse 的 tomcat 插件支持对 tomcat xml 配置文件进行配置。而这里，你只能自己去 tomcat 安装路径下修改配置文件。\n\n文中的嵌入式启动示例可以参考我的示例项目\n\n\n# 3. tomcat 架构\n\n\n\ntomcat 要实现 2 个核心功能：\n\n * 处理 socket 连接，负责网络字节流与 request 和 response 对象的转化。\n * 加载和管理 servlet，以及处理具体的 request 请求。\n\n为此，tomcat 设计了两个核心组件：\n\n * 连接器（connector）：负责和外部通信\n * 容器（container）：负责内部处理\n\n\n# 3.1. service\n\ntomcat 支持的 i/o 模型有：\n\n * nio：非阻塞 i/o，采用 java nio 类库实现。\n * nio2：异步 i/o，采用 jdk 7 最新的 nio2 类库实现。\n * apr：采用 apache 可移植运行库实现，是 c/c++ 编写的本地库。\n\ntomcat 支持的应用层协议有：\n\n * http/1.1：这是大部分 web 应用采用的访问协议。\n * ajp：用于和 web 服务器集成（如 apache）。\n * http/2：http 2.0 大幅度的提升了 web 性能。\n\ntomcat 支持多种 i/o 模型和应用层协议。为了实现这点，一个容器可能对接多个连接器。但是，单独的连接器或容器都不能对外提供服务，需要把它们组装起来才能工作，组装后这个整体叫作 service 组件。tomcat 内可能有多个 service，通过在 tomcat 中配置多个 service，可以实现通过不同的端口号来访问同一台机器上部署的不同应用。\n\n\n\n一个 tomcat 实例有一个或多个 service；一个 service 有多个 connector 和 container。connector 和 container 之间通过标准的 servletrequest 和 servletresponse 通信。\n\n\n# 3.2. 连接器\n\n连接器对 servlet 容器屏蔽了协议及 i/o 模型等的区别，无论是 http 还是 ajp，在容器中获取到的都是一个标准的 servletrequest 对象。\n\n连接器的主要功能是：\n\n * 网络通信\n * 应用层协议解析\n * tomcat request/response 与 servletrequest/servletresponse 的转化\n\ntomcat 设计了 3 个组件来实现这 3 个功能，分别是 endpoint、processor 和 adapter。\n\n\n\n组件间通过抽象接口交互。这样做还有一个好处是**封装变化。**这是面向对象设计的精髓，将系统中经常变化的部分和稳定的部分隔离，有助于增加复用性，并降低系统耦合度。网络通信的 i/o 模型是变化的，可能是非阻塞 i/o、异步 i/o 或者 apr。应用层协议也是变化的，可能是 http、https、ajp。浏览器端发送的请求信息也是变化的。但是整体的处理逻辑是不变的，endpoint 负责提供字节流给 processor，processor 负责提供 tomcat request 对象给 adapter，adapter 负责提供 servletrequest 对象给容器。\n\n如果要支持新的 i/o 方案、新的应用层协议，只需要实现相关的具体子类，上层通用的处理逻辑是不变的。由于 i/o 模型和应用层协议可以自由组合，比如 nio + http 或者 nio2 + ajp。tomcat 的设计者将网络通信和应用层协议解析放在一起考虑，设计了一个叫 protocolhandler 的接口来封装这两种变化点。各种协议和通信模型的组合有相应的具体实现类。比如：http11nioprotocol 和 ajpnioprotocol。\n\n\n\n# 3.2.1. protocolhandler 组件\n\n连接器用 protocolhandler 接口来封装通信协议和 i/o 模型的差异。protocolhandler 内部又分为 endpoint 和 processor 模块，endpoint 负责底层 socket 通信，proccesor 负责应用层协议解析。\n\n# 3.2.1.1. endpoint\n\nendpoint 是通信端点，即通信监听的接口，是具体的 socket 接收和发送处理器，是对传输层的抽象，因此 endpoint 是用来实现 tcp/ip 协议的。\n\nendpoint 是一个接口，对应的抽象实现类是 abstractendpoint，而 abstractendpoint 的具体子类，比如在 nioendpoint 和 nio2endpoint 中，有两个重要的子组件：acceptor 和 socketprocessor。\n\n其中 acceptor 用于监听 socket 连接请求。socketprocessor 用于处理接收到的 socket 请求，它实现 runnable 接口，在 run 方法里调用协议处理组件 processor 进行处理。为了提高处理能力，socketprocessor 被提交到线程池来执行。而这个线程池叫作执行器（executor)。\n\n# 3.2.1.2. processor\n\n如果说 endpoint 是用来实现 tcp/ip 协议的，那么 processor 用来实现 http 协议，processor 接收来自 endpoint 的 socket，读取字节流解析成 tomcat request 和 response 对象，并通过 adapter 将其提交到容器处理，processor 是对应用层协议的抽象。\n\nprocessor 是一个接口，定义了请求的处理等方法。它的抽象实现类 abstractprocessor 对一些协议共有的属性进行封装，没有对方法进行实现。具体的实现有 ajpprocessor、http11processor 等，这些具体实现类实现了特定协议的解析方法和请求处理方式。\n\n\n\n从图中我们看到，endpoint 接收到 socket 连接后，生成一个 socketprocessor 任务提交到线程池去处理，socketprocessor 的 run 方法会调用 processor 组件去解析应用层协议，processor 通过解析生成 request 对象后，会调用 adapter 的 service 方法。\n\n# 3.2.2. adapter\n\n连接器通过适配器 adapter 调用容器。\n\n由于协议不同，客户端发过来的请求信息也不尽相同，tomcat 定义了自己的 request 类来适配这些请求信息。\n\nprotocolhandler 接口负责解析请求并生成 tomcat request 类。但是这个 request 对象不是标准的 servletrequest，也就意味着，不能用 tomcat request 作为参数来调用容器。tomcat 的解决方案是引入 coyoteadapter，这是适配器模式的经典运用，连接器调用 coyoteadapter 的 sevice 方法，传入的是 tomcat request 对象，coyoteadapter 负责将 tomcat request 转成 servletrequest，再调用容器的 service 方法。\n\n\n# 3.3. 容器\n\ntomcat 设计了 4 种容器，分别是 engine、host、context 和 wrapper。\n\n * engine - servlet 的顶层容器，包含一 个或多个 host 子容器；\n * host - 虚拟主机，负责 web 应用的部署和 context 的创建；\n * context - web 应用上下文，包含多个 wrapper，负责 web 配置的解析、管理所有的 web 资源；\n * wrapper - 最底层的容器，是对 servlet 的封装，负责 servlet 实例的创 建、执行和销毁。\n\n# 3.3.1. 请求分发 servlet 过程\n\ntomcat 是怎么确定请求是由哪个 wrapper 容器里的 servlet 来处理的呢？答案是，tomcat 是用 mapper 组件来完成这个任务的。\n\n举例来说，假如有一个网购系统，有面向网站管理人员的后台管理系统，还有面向终端客户的在线购物系统。这两个系统跑在同一个 tomcat 上，为了隔离它们的访问域名，配置了两个虚拟域名：manage.shopping.com和user.shopping.com，网站管理人员通过manage.shopping.com域名访问 tomcat 去管理用户和商品，而用户管理和商品管理是两个单独的 web 应用。终端客户通过user.shopping.com域名去搜索商品和下订单，搜索功能和订单管理也是两个独立的 web 应用。如下所示，演示了 url 应声 servlet 的处理流程。\n\n\n\n假如有用户访问一个 url，比如图中的http://user.shopping.com:8080/order/buy，tomcat 如何将这个 url 定位到一个 servlet 呢？\n\n 1. 首先，根据协议和端口号选定 service 和 engine。\n 2. 然后，根据域名选定 host。\n 3. 之后，根据 url 路径找到 context 组件。\n 4. 最后，根据 url 路径找到 wrapper（servlet）。\n\n这个路由分发过程具体是怎么实现的呢？答案是使用 pipeline-valve 管道。\n\n# 3.3.2. pipeline-value\n\npipeline 可以理解为现实中的管道，valve 为管道中的阀门，request 和 response 对象在管道中经过各个阀门的处理和控制。\n\npipeline-valve 是责任链模式，责任链模式是指在一个请求处理的过程中有很多处理者依次对请求进行处理，每个处理者负责做自己相应的处理，处理完之后将再调用下一个处理者继续处理。valve 表示一个处理点，比如权限认证和记录日志。\n\n先来了解一下 valve 和 pipeline 接口的设计：\n\n\n\n * 每一个容器都有一个 pipeline 对象，只要触发这个 pipeline 的第一个 valve，这个容器里 pipeline 中的 valve 就都会被调用到。但是，不同容器的 pipeline 是怎么链式触发的呢，比如 engine 中 pipeline 需要调用下层容器 host 中的 pipeline。\n * 这是因为 pipeline 中还有个 getbasic 方法。这个 basicvalve 处于 valve 链表的末端，它是 pipeline 中必不可少的一个 valve，负责调用下层容器的 pipeline 里的第一个 valve。\n * pipeline 中有 addvalve 方法。pipeline 中维护了 valve 链表，valve 可以插入到 pipeline 中，对请求做某些处理。我们还发现 pipeline 中没有 invoke 方法，因为整个调用链的触发是 valve 来完成的，valve 完成自己的处理后，调用 getnext.invoke() 来触发下一个 valve 调用。\n * valve 中主要的三个方法：setnext、getnext、invoke。valve 之间的关系是单向链式结构，本身 invoke 方法中会调用下一个 valve 的 invoke 方法。\n * 各层容器对应的 basic valve 分别是 standardenginevalve、standardhostvalve、 standardcontextvalve、standardwrappervalve。\n * 由于 valve 是一个处理点，因此 invoke 方法就是来处理请求的。注意到 valve 中有 getnext 和 setnext 方法，因此我们大概可以猜到有一个链表将 valve 链起来了。\n\n\n\n整个调用过程由连接器中的 adapter 触发的，它会调用 engine 的第一个 valve：\n\nconnector.getservice().getcontainer().getpipeline().getfirst().invoke(request, response);\n\n\n\n# 4. tomcat 生命周期\n\n\n# 4.1. tomcat 的启动过程\n\n\n\n 1. tomcat 是一个 java 程序，它的运行从执行 startup.sh 脚本开始。startup.sh 会启动一个 jvm 来运行 tomcat 的启动类 bootstrap。\n 2. bootstrap 会初始化 tomcat 的类加载器并实例化 catalina。\n 3. catalina 会通过 digester 解析 server.xml，根据其中的配置信息来创建相应组件，并调用 server 的 start 方法。\n 4. server 负责管理 service 组件，它会调用 service 的 start 方法。\n 5. service 负责管理 connector 和顶层容器 engine，它会调用 connector 和 engine 的 start 方法。\n\n# 4.1.1. catalina 组件\n\ncatalina 的职责就是解析 server.xml 配置，并据此实例化 server。接下来，调用 server 组件的 init 方法和 start 方法，将 tomcat 启动起来。\n\ncatalina 还需要处理各种“异常”情况，比如当我们通过“ctrl + c”关闭 tomcat 时，tomcat 将如何优雅的停止并且清理资源呢？因此 catalina 在 jvm 中注册一个“关闭钩子”。\n\npublic void start() {\n    //1. 如果持有的 server 实例为空，就解析 server.xml 创建出来\n    if (getserver() == null) {\n        load();\n    }\n\n    //2. 如果创建失败，报错退出\n    if (getserver() == null) {\n        log.fatal(sm.getstring("catalina.noserver"));\n        return;\n    }\n\n    //3. 启动 server\n    try {\n        getserver().start();\n    } catch (lifecycleexception e) {\n        return;\n    }\n\n    // 创建并注册关闭钩子\n    if (useshutdownhook) {\n        if (shutdownhook == null) {\n            shutdownhook = new catalinashutdownhook();\n        }\n        runtime.getruntime().addshutdownhook(shutdownhook);\n    }\n\n    // 用 await 方法监听停止请求\n    if (await) {\n        await();\n        stop();\n    }\n}\n\n\n为什么需要关闭钩子？\n\n如果我们需要在 jvm 关闭时做一些清理工作，比如将缓存数据刷到磁盘上，或者清理一些临时文件，可以向 jvm 注册一个“关闭钩子”。“关闭钩子”其实就是一个线程，jvm 在停止之前会尝试执行这个线程的 run 方法。\n\ntomcat 的“关闭钩子”—— catalinashutdownhook 做了些什么呢？\n\nprotected class catalinashutdownhook extends thread {\n\n    @override\n    public void run() {\n        try {\n            if (getserver() != null) {\n                catalina.this.stop();\n            }\n        } catch (throwable ex) {\n           ...\n        }\n    }\n}\n\n\ntomcat 的“关闭钩子”实际上就执行了 server 的 stop 方法，server 的 stop 方法会释放和清理所有的资源。\n\n# 4.1.2. server 组件\n\nserver 组件的具体实现类是 standardserver，server 继承了 lifecyclebase，它的生命周期被统一管理，并且它的子组件是 service，因此它还需要管理 service 的生命周期，也就是说在启动时调用 service 组件的启动方法，在停止时调用它们的停止方法。server 在内部维护了若干 service 组件，它是以数组来保存的。\n\n@override\npublic void addservice(service service) {\n\n    service.setserver(this);\n\n    synchronized (serviceslock) {\n        // 创建一个长度 +1 的新数组\n        service results[] = new service[services.length + 1];\n\n        // 将老的数据复制过去\n        system.arraycopy(services, 0, results, 0, services.length);\n        results[services.length] = service;\n        services = results;\n\n        // 启动 service 组件\n        if (getstate().isavailable()) {\n            try {\n                service.start();\n            } catch (lifecycleexception e) {\n                // ignore\n            }\n        }\n\n        // 触发监听事件\n        support.firepropertychange("service", null, service);\n    }\n\n}\n\n\nserver 并没有一开始就分配一个很长的数组，而是在添加的过程中动态地扩展数组长度，当添加一个新的 service 实例时，会创建一个新数组并把原来数组内容复制到新数组，这样做的目的其实是为了节省内存空间。\n\n除此之外，server 组件还有一个重要的任务是启动一个 socket 来监听停止端口，这就是为什么你能通过 shutdown 命令来关闭 tomcat。不知道你留意到没有，上面 caralina 的启动方法的最后一行代码就是调用了 server 的 await 方法。\n\n在 await 方法里会创建一个 socket 监听 8005 端口，并在一个死循环里接收 socket 上的连接请求，如果有新的连接到来就建立连接，然后从 socket 中读取数据；如果读到的数据是停止命令“shutdown”，就退出循环，进入 stop 流程。\n\n# 4.1.3. service 组件\n\nservice 组件的具体实现类是 standardservice。\n\n【源码】standardservice 源码定义\n\npublic class standardservice extends lifecyclebase implements service {\n    // 名字\n    private string name = null;\n\n    //server 实例\n    private server server = null;\n\n    // 连接器数组\n    protected connector connectors[] = new connector[0];\n    private final object connectorslock = new object();\n\n    // 对应的 engine 容器\n    private engine engine = null;\n\n    // 映射器及其监听器\n    protected final mapper mapper = new mapper();\n    protected final mapperlistener mapperlistener = new mapperlistener(this);\n\n\t// ...\n}\n\n\nstandardservice 继承了 lifecyclebase 抽象类。\n\nstandardservice 维护了一个 mapperlistener 用于支持 tomcat 热部署。当 web 应用的部署发生变化时，mapper 中的映射信息也要跟着变化，mapperlistener 就是一个监听器，它监听容器的变化，并把信息更新到 mapper 中，这是典型的观察者模式。\n\n作为“管理”角色的组件，最重要的是维护其他组件的生命周期。此外在启动各种组件时，要注意它们的依赖关系，也就是说，要注意启动的顺序。\n\nprotected void startinternal() throws lifecycleexception {\n\n    //1. 触发启动监听器\n    setstate(lifecyclestate.starting);\n\n    //2. 先启动 engine，engine 会启动它子容器\n    if (engine != null) {\n        synchronized (engine) {\n            engine.start();\n        }\n    }\n\n    //3. 再启动 mapper 监听器\n    mapperlistener.start();\n\n    //4. 最后启动连接器，连接器会启动它子组件，比如 endpoint\n    synchronized (connectorslock) {\n        for (connector connector: connectors) {\n            if (connector.getstate() != lifecyclestate.failed) {\n                connector.start();\n            }\n        }\n    }\n}\n\n\n从启动方法可以看到，service 先启动了 engine 组件，再启动 mapper 监听器，最后才是启动连接器。这很好理解，因为内层组件启动好了才能对外提供服务，才能启动外层的连接器组件。而 mapper 也依赖容器组件，容器组件启动好了才能监听它们的变化，因此 mapper 和 mapperlistener 在容器组件之后启动。组件停止的顺序跟启动顺序正好相反的，也是基于它们的依赖关系。\n\n# 4.1.4. engine 组件\n\nengine 本质是一个容器，因此它继承了 containerbase 基类，并且实现了 engine 接口。\n\n\n# 4.2. web 应用的部署方式\n\n注：catalina.home：安装目录;catalina.base：工作目录;默认值 user.dir\n\n * server.xml 配置 host 元素，指定 appbase 属性，默认$catalina.base/webapps/\n * server.xml 配置 context 元素，指定 docbase，元素，指定 web 应用的路径\n * 自定义配置：在$catalina.base/enginename/hostname/xxx.xml 配置 context 元素\n\nhostconfig 监听了 standardhost 容器的事件，在 start 方法中解析上述配置文件：\n\n * 扫描 appbase 路径下的所有文件夹和 war 包，解析各个应用的 meta-inf/context.xml，并 创建 standardcontext，并将 context 加入到 host 的子容器中。\n * 解析$catalina.base/enginename/hostname/下的所有 context 配置，找到相应 web 应 用的位置，解析各个应用的 meta-inf/context.xml，并创建 standardcontext，并将 context 加入到 host 的子容器中。\n\n注：\n\n * hostconfig 并没有实际解析 context.xml，而是在 contextconfig 中进行的。\n * hostconfig 中会定期检查 watched 资源文件(context.xml 配置文件)\n\ncontextconfig 解析 context.xml 顺序：\n\n * 先解析全局的配置 config/context.xml\n * 然后解析 host 的默认配置 enginename/hostname/context.xml.default\n * 最后解析应用的 meta-inf/context.xml\n\ncontextconfig 解析 web.xml 顺序：\n\n * 先解析全局的配置 config/web.xml\n * 然后解析 host 的默认配置 enginename/hostname/web.xml.default 接着解析应用的 meb-inf/web.xml\n * 扫描应用 web-inf/lib/下的 jar 文件，解析其中的 meta-inf/web-fragment.xml 最后合并 xml 封装成 webxml，并设置 context\n\n注：\n\n * 扫描 web 应用和 jar 中的注解(filter、listener、servlet)就是上述步骤中进行的。\n * 容器的定期执行：backgroundprocess，由 containerbase 来实现的，并且只有在顶层容器 中才会开启线程。(backgroundprocessordelay=10 标志位来控制)\n\n\n# 4.3. lifecycle\n\n\n\n# 4.3.1. 请求处理过程\n\n\n 1. 根据 server.xml 配置的指定的 connector 以及端口监听 http、或者 ajp 请求\n 2. 请求到来时建立连接,解析请求参数,创建 request 和 response 对象,调用顶层容器 pipeline 的 invoke 方法\n 3. 容器之间层层调用,最终调用业务 servlet 的 service 方法\n 4. connector 将 response 流中的数据写到 socket 中\n\n\n# 4.4. connector 流程\n\n\n\n# 4.4.1. 阻塞 io\n\n\n\n# 4.4.2. 非阻塞 io\n\n\n\n# 4.4.3. io 多路复用\n\n\n\n阻塞与非阻塞的区别在于进行读操作和写操作的系统调用时，如果此时内核态没有数据可读或者没有缓冲空间可写时，是否阻塞。\n\nio 多路复用的好处在于可同时监听多个 socket 的可读和可写事件，这样就能使得应用可以同时监听多个 socket，释放了应用线程资源。\n\n# 4.4.4. tomcat 各类 connector 对比\n\n\n * jio：用 java.io 编写的 tcp 模块，阻塞 io\n * nio：用 java.nio 编写的 tcp 模块，非阻塞 io，（io 多路复用）\n * apr：全称 apache portable runtime，使用 jni 的方式来进行读取文件以及进行网络传输\n\napache portable runtime 是一个高度可移植的库，它是 apache http server 2.x 的核心。 apr 具有许多用途，包括访问高级 io 功能（如 sendfile，epoll 和 openssl），操作系统级功能（随机数生成，系统状态等）和本地进程处理（共享内存，nt 管道和 unix 套接字）。\n\n表格中字段含义说明：\n\n * support polling - 是否支持基于 io 多路复用的 socket 事件轮询\n * polling size - 轮询的最大连接数\n * wait for next request - 在等待下一个请求时，处理线程是否释放，bio 是没有释放的，所以在 keep-alive=true 的情况下处理的并发连接数有限\n * read request headers - 由于 request header 数据较少，可以由容器提前解析完毕，不需要阻塞\n * read request body - 读取 request body 的数据是应用业务逻辑的事情，同时 servlet 的限制，是需要阻塞读取的\n * write response - 跟读取 request body 的逻辑类似，同样需要阻塞写\n\nnio 处理相关类\n\n\n\npoller 线程从 eventqueue 获取 pollerevent，并执行 pollerevent 的 run 方法，调用 selector 的 select 方法，如果有可读的 socket 则创建 http11nioprocessor，放入到线程池中执行；\n\ncoyoteadapter 是 connector 到 container 的适配器，http11nioprocessor 调用其提供的 service 方法，内部创建 request 和 response 对象，并调用最顶层容器的 pipeline 中的第一个 valve 的 invoke 方法\n\nmapper 主要处理 http url 到 servlet 的映射规则的解析，对外提供 map 方法\n\n\n# 4.5. comet\n\ncomet 是一种用于 web 的推送技术，能使服务器实时地将更新的信息传送到客户端，而无须客户端发出请求 在 websocket 出来之前，如果不适用 comet，只能通过浏览器端轮询 server 来模拟实现服务器端推送。 comet 支持 servlet 异步处理 io，当连接上数据可读时触发事件，并异步写数据(阻塞)\n\ntomcat 要实现 comet，只需继承 httpservlet 同时，实现 cometprocessor 接口\n\n * begin：新的请求连接接入调用，可进行与 request 和 response 相关的对象初始化操作，并保存 response 对象，用于后续写入数据\n * read：请求连接有数据可读时调用\n * end：当数据可用时，如果读取到文件结束或者 response 被关闭时则被调用\n * error：在连接上发生异常时调用，数据读取异常、连接断开、处理异常、socket 超时\n\nnote：\n\n * read：在 post 请求有数据，但在 begin 事件中没有处理，则会调用 read，如果 read 没有读取数据，在会触发 error 回调，关闭 socket\n * end：当 socket 超时，并且 response 被关闭时也会调用；server 被关闭时调用\n * error：除了 socket 超时不会关闭 socket，其他都会关闭 socket\n * end 和 error 时间触发时应关闭当前 comet 会话，即调用 cometevent 的 close 方法 note：在事件触发时要做好线程安全的操作\n\n\n# 4.6. 异步 servlet\n\n\n\n传统流程：\n\n * 首先，servlet 接收到请求之后，request 数据解析；\n * 接着，调用业务接口的某些方法，以完成业务处理；\n * 最后，根据处理的结果提交响应，servlet 线程结束\n\n\n\n异步处理流程：\n\n * 客户端发送一个请求\n * servlet 容器分配一个线程来处理容器中的一个 servlet\n * servlet 调用 request.startasync()，保存 asynccontext, 然后返回\n * 任何方式存在的容器线程都将退出，但是 response 仍然保持开放\n * 业务线程使用保存的 asynccontext 来完成响应（线程池）\n * 客户端收到响应\n\nservlet 线程将请求转交给一个异步线程来执行业务处理，线程本身返回至容器，此时 servlet 还没有生成响应数据，异步线程处理完业务以后，可以直接生成响应数据（异步线程拥有 servletrequest 和 servletresponse 对象的引用）\n\n为什么 web 应用中支持异步？\n\n推出异步，主要是针对那些比较耗时的请求：比如一次缓慢的数据库查询，一次外部 rest api 调用, 或者是其他一些 i/o 密集型操作。这种耗时的请求会很快的耗光 servlet 容器的线程池，继而影响可扩展性。\n\nnote：从客户端的角度来看，request 仍然像任何其他的 http 的 request-response 交互一样，只是耗费了更长的时间而已\n\n异步事件监听\n\n * onstartasync：request 调用 startasync 方法时触发\n * oncomplete：synccontext 调用 complete 方法时触发\n * onerror：处理请求的过程出现异常时触发\n * ontimeout：socket 超时触发\n\nnote : onerror/ ontimeout 触发后，会紧接着回调 oncomplete oncomplete 执行后，就不可再操作 request 和 response\n\n\n# 5. 参考资料\n\n * 官方\n   \n   * tomcat 官方网站\n   * tomcat wiki\n   * tomee 官方网站\n\n * 文章\n   \n   * creating a web app with bootstrap and tomcat embedded\n   * tomcat 组成与工作原理\n   * tomcat 工作原理\n   * tomcat 设计模式分析',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Tomcat连接器",frontmatter:{title:"Tomcat连接器",categories:["编程","Java","服务器"],tags:["Java","JavaWeb","服务器","Tomcat"],abbrlink:"23822cab",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/3c954b/"},regularPath:"/02.JavaEE/02.%E6%9C%8D%E5%8A%A1%E5%99%A8/01.Tomcat/02.Tomcat%E8%BF%9E%E6%8E%A5%E5%99%A8.html",relativePath:"02.JavaEE/02.服务器/01.Tomcat/02.Tomcat连接器.md",key:"v-f0e9a0d2",path:"/pages/3c954b/",headers:[{level:2,title:"1. NioEndpoint 组件",slug:"_1-nioendpoint-组件",normalizedTitle:"1. nioendpoint 组件",charIndex:17},{level:3,title:"1.1. LimitLatch",slug:"_1-1-limitlatch",normalizedTitle:"1.1. limitlatch",charIndex:891},{level:3,title:"1.2. Acceptor",slug:"_1-2-acceptor",normalizedTitle:"1.2. acceptor",charIndex:2483},{level:3,title:"1.3. Poller",slug:"_1-3-poller",normalizedTitle:"1.3. poller",charIndex:3163},{level:3,title:"1.4. SocketProcessor",slug:"_1-4-socketprocessor",normalizedTitle:"1.4. socketprocessor",charIndex:3708},{level:2,title:"2. Nio2Endpoint 组件",slug:"_2-nio2endpoint-组件",normalizedTitle:"2. nio2endpoint 组件",charIndex:4180},{level:3,title:"2.1. Nio2Acceptor",slug:"_2-1-nio2acceptor",normalizedTitle:"2.1. nio2acceptor",charIndex:4852},{level:3,title:"2.2. Nio2SocketWrapper",slug:"_2-2-nio2socketwrapper",normalizedTitle:"2.2. nio2socketwrapper",charIndex:6316},{level:2,title:"3. AprEndpoint 组件",slug:"_3-aprendpoint-组件",normalizedTitle:"3. aprendpoint 组件",charIndex:7769},{level:3,title:"3.1. AprEndpoint 工作流程",slug:"_3-1-aprendpoint-工作流程",normalizedTitle:"3.1. aprendpoint 工作流程",charIndex:8655},{level:4,title:"3.1.1. Acceptor",slug:"_3-1-1-acceptor",normalizedTitle:"3.1.1. acceptor",charIndex:8682},{level:4,title:"3.1.2. Poller",slug:"_3-1-2-poller",normalizedTitle:"3.1.2. poller",charIndex:9767},{level:3,title:"3.2. APR 提升性能的秘密",slug:"_3-2-apr-提升性能的秘密",normalizedTitle:"3.2. apr 提升性能的秘密",charIndex:10320},{level:4,title:"3.2.1. sendfile",slug:"_3-2-1-sendfile",normalizedTitle:"3.2.1. sendfile",charIndex:12292},{level:2,title:"4. Executor 组件",slug:"_4-executor-组件",normalizedTitle:"4. executor 组件",charIndex:12966},{level:3,title:"4.1. Tomcat 定制线程池",slug:"_4-1-tomcat-定制线程池",normalizedTitle:"4.1. tomcat 定制线程池",charIndex:13067},{level:3,title:"4.2. Tomcat 定制任务队列",slug:"_4-2-tomcat-定制任务队列",normalizedTitle:"4.2. tomcat 定制任务队列",charIndex:15220},{level:2,title:"5. WebSocket 组件",slug:"_5-websocket-组件",normalizedTitle:"5. websocket 组件",charIndex:17124},{level:3,title:"5.1. WebSocket 加载",slug:"_5-1-websocket-加载",normalizedTitle:"5.1. websocket 加载",charIndex:17531},{level:3,title:"5.2. WebSocket 请求处理",slug:"_5-2-websocket-请求处理",normalizedTitle:"5.2. websocket 请求处理",charIndex:18654},{level:2,title:"6. 参考资料",slug:"_6-参考资料",normalizedTitle:"6. 参考资料",charIndex:19738}],headersStr:"1. NioEndpoint 组件 1.1. LimitLatch 1.2. Acceptor 1.3. Poller 1.4. SocketProcessor 2. Nio2Endpoint 组件 2.1. Nio2Acceptor 2.2. Nio2SocketWrapper 3. AprEndpoint 组件 3.1. AprEndpoint 工作流程 3.1.1. Acceptor 3.1.2. Poller 3.2. APR 提升性能的秘密 3.2.1. sendfile 4. Executor 组件 4.1. Tomcat 定制线程池 4.2. Tomcat 定制任务队列 5. WebSocket 组件 5.1. WebSocket 加载 5.2. WebSocket 请求处理 6. 参考资料",content:'# Tomcat 连接器\n\n\n# 1. NioEndpoint 组件\n\nTomcat 的 NioEndPoint 组件利用 Java NIO 实现了 I/O 多路复用模型。\n\n\n\nNioEndPoint 子组件功能简介：\n\n * LimitLatch 是连接控制器，负责控制最大连接数。NIO 模式下默认是 10000，达到这个阈值后，连接请求被拒绝。\n * Acceptor 负责监听连接请求。Acceptor 运行在一个单独的线程里，它在一个死循环里调用 accept 方法来接收新连接，一旦有新的连接请求到来，accept 方法返回一个 Channel 对象，接着把 Channel 对象交给 Poller 去处理。\n * Poller 的本质是一个 Selector，也运行在单独线程里。Poller 内部维护一个 Channel 数组，它在一个死循环里不断检测 Channel 的数据就绪状态，一旦有 Channel 可读，就生成一个 SocketProcessor 任务对象扔给 Executor 去处理。\n * Executor 就是线程池，负责运行 SocketProcessor 任务类，SocketProcessor 的 run 方法会调用 Http11Processor 来读取和解析请求数据。我们知道，Http11Processor 是应用层协议的封装，它会调用容器获得响应，再把响应通过 Channel 写出。\n\nNioEndpoint 如何实现高并发的呢？\n\n要实现高并发需要合理设计线程模型充分利用 CPU 资源，尽量不要让线程阻塞；另外，就是有多少任务，就用相应规模的线程数去处理。\n\nNioEndpoint 要完成三件事情：接收连接、检测 I/O 事件以及处理请求，那么最核心的就是把这三件事情分开，用不同规模的线程去处理，比如用专门的线程组去跑 Acceptor，并且 Acceptor 的个数可以配置；用专门的线程组去跑 Poller，Poller 的个数也可以配置；最后具体任务的执行也由专门的线程池来处理，也可以配置线程池的大小。\n\n\n# 1.1. LimitLatch\n\nLimitLatch 用来控制连接个数，当连接数到达最大时阻塞线程，直到后续组件处理完一个连接后将连接数减 1。请你注意到达最大连接数后操作系统底层还是会接收客户端连接，但用户层已经不再接收。\n\npublic class LimitLatch {\n    private class Sync extends AbstractQueuedSynchronizer {\n\n        @Override\n        protected int tryAcquireShared() {\n            long newCount = count.incrementAndGet();\n            if (newCount > limit) {\n                count.decrementAndGet();\n                return -1;\n            } else {\n                return 1;\n            }\n        }\n\n        @Override\n        protected boolean tryReleaseShared(int arg) {\n            count.decrementAndGet();\n            return true;\n        }\n    }\n\n    private final Sync sync;\n    private final AtomicLong count;\n    private volatile long limit;\n\n    // 线程调用这个方法来获得接收新连接的许可，线程可能被阻塞\n    public void countUpOrAwait() throws InterruptedException {\n      sync.acquireSharedInterruptibly(1);\n    }\n\n    // 调用这个方法来释放一个连接许可，那么前面阻塞的线程可能被唤醒\n    public long countDown() {\n      sync.releaseShared(0);\n      long result = getCount();\n      return result;\n   }\n}\n\n\nLimitLatch 内步定义了内部类 Sync，而 Sync 扩展了 AQS，AQS 是 Java 并发包中的一个核心类，它在内部维护一个状态和一个线程队列，可以用来控制线程什么时候挂起，什么时候唤醒。我们可以扩展它来实现自己的同步器，实际上 Java 并发包里的锁和条件变量等等都是通过 AQS 来实现的，而这里的 LimitLatch 也不例外。\n\n理解源码要点：\n\n * 用户线程通过调用 LimitLatch 的 countUpOrAwait 方法来拿到锁，如果暂时无法获取，这个线程会被阻塞到 AQS 的队列中。那 AQS 怎么知道是阻塞还是不阻塞用户线程呢？其实这是由 AQS 的使用者来决定的，也就是内部类 Sync 来决定的，因为 Sync 类重写了 AQS 的tryAcquireShared() 方法。它的实现逻辑是如果当前连接数 count 小于 limit，线程能获取锁，返回 1，否则返回 -1。\n * 如何用户线程被阻塞到了 AQS 的队列，那什么时候唤醒呢？同样是由 Sync 内部类决定，Sync 重写了 AQS 的releaseShared() 方法，其实就是当一个连接请求处理完了，这时又可以接收一个新连接了，这样前面阻塞的线程将会被唤醒。\n\n\n# 1.2. Acceptor\n\nAcceptor 实现了 Runnable 接口，因此可以跑在单独线程里。一个端口号只能对应一个 ServerSocketChannel，因此这个 ServerSocketChannel 是在多个 Acceptor 线程之间共享的，它是 Endpoint 的属性，由 Endpoint 完成初始化和端口绑定。\n\nserverSock = ServerSocketChannel.open();\nserverSock.socket().bind(addr,getAcceptCount());\nserverSock.configureBlocking(true);\n\n\n * bind 方法的第二个参数表示操作系统的等待队列长度，我在上面提到，当应用层面的连接数到达最大值时，操作系统可以继续接收连接，那么操作系统能继续接收的最大连接数就是这个队列长度，可以通过 acceptCount 参数配置，默认是 100。\n * ServerSocketChannel 被设置成阻塞模式，也就是说它是以阻塞的方式接收连接的。ServerSocketChannel 通过 accept() 接受新的连接，accept() 方法返回获得 SocketChannel 对象，然后将 SocketChannel 对象封装在一个 PollerEvent 对象中，并将 PollerEvent 对象压入 Poller 的 Queue 里，这是个典型的生产者 - 消费者模式，Acceptor 与 Poller 线程之间通过 Queue 通信。\n\n\n# 1.3. Poller\n\nPoller 本质是一个 Selector，它内部维护一个 Queue。\n\nprivate final SynchronizedQueue<PollerEvent> events = new SynchronizedQueue<>();\n\n\nSynchronizedQueue 的核心方法都使用了 Synchronized 关键字进行修饰，用来保证同一时刻只有一个线程进行读写。\n\n使用 SynchronizedQueue，意味着同一时刻只有一个 Acceptor 线程对队列进行读写；同时有多个 Poller 线程在运行，每个 Poller 线程都有自己的队列。每个 Poller 线程可能同时被多个 Acceptor 线程调用来注册 PollerEvent。同样 Poller 的个数可以通过 pollers 参数配置。\n\nPoller 不断的通过内部的 Selector 对象向内核查询 Channel 的状态，一旦可读就生成任务类 SocketProcessor 交给 Executor 去处理。Poller 的另一个重要任务是循环遍历检查自己所管理的 SocketChannel 是否已经超时，如果有超时就关闭这个 SocketChannel。\n\n\n# 1.4. SocketProcessor\n\n我们知道，Poller 会创建 SocketProcessor 任务类交给线程池处理，而 SocketProcessor 实现了 Runnable 接口，用来定义 Executor 中线程所执行的任务，主要就是调用 Http11Processor 组件来处理请求。Http11Processor 读取 Channel 的数据来生成 ServletRequest 对象，这里请你注意：\n\nHttp11Processor 并不是直接读取 Channel 的。这是因为 Tomcat 支持同步非阻塞 I/O 模型和异步 I/O 模型，在 Java API 中，相应的 Channel 类也是不一样的，比如有 AsynchronousSocketChannel 和 SocketChannel，为了对 Http11Processor 屏蔽这些差异，Tomcat 设计了一个包装类叫作 SocketWrapper，Http11Processor 只调用 SocketWrapper 的方法去读写数据。\n\n\n# 2. Nio2Endpoint 组件\n\nNio2Endpoint 工作流程跟 NioEndpoint 较为相似。\n\n\n\nNio2Endpoint 子组件功能说明：\n\n * LimitLatch 是连接控制器，它负责控制最大连接数。\n * Nio2Acceptor 扩展了 Acceptor，用异步 I/O 的方式来接收连接，跑在一个单独的线程里，也是一个线程组。Nio2Acceptor 接收新的连接后，得到一个 AsynchronousSocketChannel，Nio2Acceptor 把 AsynchronousSocketChannel 封装成一个 Nio2SocketWrapper，并创建一个 SocketProcessor 任务类交给线程池处理，并且 SocketProcessor 持有 Nio2SocketWrapper 对象。\n * Executor 在执行 SocketProcessor 时，SocketProcessor 的 run 方法会调用 Http11Processor 来处理请求，Http11Processor 会通过 Nio2SocketWrapper 读取和解析请求数据，请求经过容器处理后，再把响应通过 Nio2SocketWrapper 写出。\n\nNio2Endpoint 跟 NioEndpoint 的一个明显不同点是，Nio2Endpoint 中没有 Poller 组件，也就是没有 Selector。这是为什么呢？因为在异步 I/O 模式下，Selector 的工作交给内核来做了。\n\n\n# 2.1. Nio2Acceptor\n\n和 NioEndpint 一样，Nio2Endpoint 的基本思路是用 LimitLatch 组件来控制连接数。\n\n但是 Nio2Acceptor 的监听连接的过程不是在一个死循环里不断的调 accept 方法，而是通过回调函数来完成的。我们来看看它的连接监听方法：\n\nserverSock.accept(null, this);\n\n\n其实就是调用了 accept 方法，注意它的第二个参数是 this，表明 Nio2Acceptor 自己就是处理连接的回调类，因此 Nio2Acceptor 实现了 CompletionHandler 接口。那么它是如何实现 CompletionHandler 接口的呢？\n\nprotected class Nio2Acceptor extends Acceptor<AsynchronousSocketChannel>\n    implements CompletionHandler<AsynchronousSocketChannel, Void> {\n\n    @Override\n    public void completed(AsynchronousSocketChannel socket,\n        Void attachment) {\n\n        if (isRunning() && !isPaused()) {\n            if (getMaxConnections() == -1) {\n                // 如果没有连接限制，继续接收新的连接\n                serverSock.accept(null, this);\n            } else {\n                // 如果有连接限制，就在线程池里跑 Run 方法，Run 方法会检查连接数\n                getExecutor().execute(this);\n            }\n            // 处理请求\n            if (!setSocketOptions(socket)) {\n                closeSocket(socket);\n            }\n        }\n    }\n}\n\n\n可以看到 CompletionHandler 的两个模板参数分别是 AsynchronousServerSocketChannel 和 Void，我在前面说过第一个参数就是 accept 方法的返回值，第二个参数是附件类，由用户自己决定，这里为 Void。completed 方法的处理逻辑比较简单：\n\n * 如果没有连接限制，继续在本线程中调用 accept 方法接收新的连接。\n * 如果有连接限制，就在线程池里跑 run 方法去接收新的连接。那为什么要跑 run 方法呢，因为在 run 方法里会检查连接数，当连接达到最大数时，线程可能会被 LimitLatch 阻塞。为什么要放在线程池里跑呢？这是因为如果放在当前线程里执行，completed 方法可能被阻塞，会导致这个回调方法一直不返回。\n\n接着 completed 方法会调用 setSocketOptions 方法，在这个方法里，会创建 Nio2SocketWrapper 和 SocketProcessor，并交给线程池处理。\n\n\n# 2.2. Nio2SocketWrapper\n\nNio2SocketWrapper 的主要作用是封装 Channel，并提供接口给 Http11Processor 读写数据。讲到这里你是不是有个疑问：Http11Processor 是不能阻塞等待数据的，按照异步 I/O 的套路，Http11Processor 在调用 Nio2SocketWrapper 的 read 方法时需要注册回调类，read 调用会立即返回，问题是立即返回后 Http11Processor 还没有读到数据， 怎么办呢？这个请求的处理不就失败了吗？\n\n为了解决这个问题，Http11Processor 是通过 2 次 read 调用来完成数据读取操作的。\n\n * 第一次 read 调用：连接刚刚建立好后，Acceptor 创建 SocketProcessor 任务类交给线程池去处理，Http11Processor 在处理请求的过程中，会调用 Nio2SocketWrapper 的 read 方法发出第一次读请求，同时注册了回调类 readCompletionHandler，因为数据没读到，Http11Processor 把当前的 Nio2SocketWrapper 标记为数据不完整。接着 SocketProcessor 线程被回收，Http11Processor 并没有阻塞等待数据。这里请注意，Http11Processor 维护了一个 Nio2SocketWrapper 列表，也就是维护了连接的状态。\n * 第二次 read 调用：当数据到达后，内核已经把数据拷贝到 Http11Processor 指定的 Buffer 里，同时回调类 readCompletionHandler 被调用，在这个回调处理方法里会重新创建一个新的 SocketProcessor 任务来继续处理这个连接，而这个新的 SocketProcessor 任务类持有原来那个 Nio2SocketWrapper，这一次 Http11Processor 可以通过 Nio2SocketWrapper 读取数据了，因为数据已经到了应用层的 Buffer。\n\n这个回调类 readCompletionHandler 的源码如下，最关键的一点是，Nio2SocketWrapper 是作为附件类来传递的，这样在回调函数里能拿到所有的上下文。\n\nthis.readCompletionHandler = new CompletionHandler<Integer, SocketWrapperBase<Nio2Channel>>() {\n    public void completed(Integer nBytes, SocketWrapperBase<Nio2Channel> attachment) {\n        ...\n        // 通过附件类 SocketWrapper 拿到所有的上下文\n        Nio2SocketWrapper.this.getEndpoint().processSocket(attachment, SocketEvent.OPEN_READ, false);\n    }\n\n    public void failed(Throwable exc, SocketWrapperBase<Nio2Channel> attachment) {\n        ...\n    }\n}\n\n\n\n# 3. AprEndpoint 组件\n\n我们在使用 Tomcat 时，可能会在启动日志里看到这样的提示信息：\n\n> The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: ***\n\n这句话的意思就是推荐你去安装 APR 库，可以提高系统性能。\n\nAPR（Apache Portable Runtime Libraries）是 Apache 可移植运行时库，它是用 C 语言实现的，其目的是向上层应用程序提供一个跨平台的操作系统接口库。Tomcat 可以用它来处理包括文件和网络 I/O，从而提升性能。Tomcat 支持的连接器有 NIO、NIO.2 和 APR。跟 NioEndpoint 一样，AprEndpoint 也实现了非阻塞 I/O，它们的区别是：NioEndpoint 通过调用 Java 的 NIO API 来实现非阻塞 I/O，而 AprEndpoint 是通过 JNI 调用 APR 本地库而实现非阻塞 I/O 的。\n\n同样是非阻塞 I/O，为什么 Tomcat 会提示使用 APR 本地库的性能会更好呢？这是因为在某些场景下，比如需要频繁与操作系统进行交互，Socket 网络通信就是这样一个场景，特别是如果你的 Web 应用使用了 TLS 来加密传输，我们知道 TLS 协议在握手过程中有多次网络交互，在这种情况下 Java 跟 C 语言程序相比还是有一定的差距，而这正是 APR 的强项。\n\nTomcat 本身是 Java 编写的，为了调用 C 语言编写的 APR，需要通过 JNI 方式来调用。JNI（Java Native Interface） 是 JDK 提供的一个编程接口，它允许 Java 程序调用其他语言编写的程序或者代码库，其实 JDK 本身的实现也大量用到 JNI 技术来调用本地 C 程序库。\n\n\n# 3.1. AprEndpoint 工作流程\n\n\n\n# 3.1.1. Acceptor\n\nAccpetor 的功能就是监听连接，接收并建立连接。它的本质就是调用了四个操作系统 API：socket、bind、listen 和 accept。那 Java 语言如何直接调用 C 语言 API 呢？答案就是通过 JNI。具体来说就是两步：先封装一个 Java 类，在里面定义一堆用native 关键字修饰的方法，像下面这样。\n\npublic class Socket {\n  ...\n  // 用 native 修饰这个方法，表明这个函数是 C 语言实现\n  public static native long create(int family, int type,\n                                 int protocol, long cont)\n\n  public static native int bind(long sock, long sa);\n\n  public static native int listen(long sock, int backlog);\n\n  public static native long accept(long sock)\n}\n\n\n接着用 C 代码实现这些方法，比如 bind 函数就是这样实现的：\n\n// 注意函数的名字要符合 JNI 规范的要求\nJNIEXPORT jint JNICALL\nJava_org_apache_tomcat_jni_Socket_bind(JNIEnv *e, jlong sock,jlong sa)\n\t{\n\t    jint rv = APR_SUCCESS;\n\t    tcn_socket_t *s = (tcn_socket_t *）sock;\n\t    apr_sockaddr_t *a = (apr_sockaddr_t *) sa;\n\n        // 调用 APR 库自己实现的 bind 函数\n\t    rv = (jint)apr_socket_bind(s->sock, a);\n\t    return rv;\n\t}\n\n\n专栏里我就不展开 JNI 的细节了，你可以扩展阅读获得更多信息和例子。我们要注意的是函数名字要符合 JNI 的规范，以及 Java 和 C 语言如何互相传递参数，比如在 C 语言有指针，Java 没有指针的概念，所以在 Java 中用 long 类型来表示指针。AprEndpoint 的 Acceptor 组件就是调用了 APR 实现的四个 API。\n\n# 3.1.2. Poller\n\nAcceptor 接收到一个新的 Socket 连接后，按照 NioEndpoint 的实现，它会把这个 Socket 交给 Poller 去查询 I/O 事件。AprEndpoint 也是这样做的，不过 AprEndpoint 的 Poller 并不是调用 Java NIO 里的 Selector 来查询 Socket 的状态，而是通过 JNI 调用 APR 中的 poll 方法，而 APR 又是调用了操作系统的 epoll API 来实现的。\n\n这里有个特别的地方是在 AprEndpoint 中，我们可以配置一个叫deferAccept的参数，它对应的是 TCP 协议中的TCP_DEFER_ACCEPT，设置这个参数后，当 TCP 客户端有新的连接请求到达时，TCP 服务端先不建立连接，而是再等等，直到客户端有请求数据发过来时再建立连接。这样的好处是服务端不需要用 Selector 去反复查询请求数据是否就绪。\n\n这是一种 TCP 协议层的优化，不是每个操作系统内核都支持，因为 Java 作为一种跨平台语言，需要屏蔽各种操作系统的差异，因此并没有把这个参数提供给用户；但是对于 APR 来说，它的目的就是尽可能提升性能，因此它向用户暴露了这个参数。\n\n\n# 3.2. APR 提升性能的秘密\n\nAPR 连接器之所以能提高 Tomcat 的性能，除了 APR 本身是 C 程序库之外，还有哪些提速的秘密呢？\n\nJVM 堆 VS 本地内存\n\n我们知道 Java 的类实例一般在 JVM 堆上分配，而 Java 是通过 JNI 调用 C 代码来实现 Socket 通信的，那么 C 代码在运行过程中需要的内存又是从哪里分配的呢？C 代码能否直接操作 Java 堆？\n\n为了回答这些问题，我先来说说 JVM 和用户进程的关系。如果你想运行一个 Java 类文件，可以用下面的 Java 命令来执行。\n\njava my.class\n\n\n这个命令行中的java其实是一个可执行程序，这个程序会创建 JVM 来加载和运行你的 Java 类。操作系统会创建一个进程来执行这个java可执行程序，而每个进程都有自己的虚拟地址空间，JVM 用到的内存（包括堆、栈和方法区）就是从进程的虚拟地址空间上分配的。请你注意的是，JVM 内存只是进程空间的一部分，除此之外进程空间内还有代码段、数据段、内存映射区、内核空间等。从 JVM 的角度看，JVM 内存之外的部分叫作本地内存，C 程序代码在运行过程中用到的内存就是本地内存中分配的。下面我们通过一张图来理解一下。\n\n\n\nTomcat 的 Endpoint 组件在接收网络数据时需要预先分配好一块 Buffer，所谓的 Buffer 就是字节数组byte[]，Java 通过 JNI 调用把这块 Buffer 的地址传给 C 代码，C 代码通过操作系统 API 读取 Socket 并把数据填充到这块 Buffer。Java NIO API 提供了两种 Buffer 来接收数据：HeapByteBuffer 和 DirectByteBuffer，下面的代码演示了如何创建两种 Buffer。\n\n// 分配 HeapByteBuffer\nByteBuffer buf = ByteBuffer.allocate(1024);\n\n// 分配 DirectByteBuffer\nByteBuffer buf = ByteBuffer.allocateDirect(1024);\n\n\n创建好 Buffer 后直接传给 Channel 的 read 或者 write 函数，最终这块 Buffer 会通过 JNI 调用传递给 C 程序。\n\n// 将 buf 作为 read 函数的参数\nint bytesRead = socketChannel.read(buf);\n\n\n那 HeapByteBuffer 和 DirectByteBuffer 有什么区别呢？HeapByteBuffer 对象本身在 JVM 堆上分配，并且它持有的字节数组byte[]也是在 JVM 堆上分配。但是如果用HeapByteBuffer来接收网络数据，需要把数据从内核先拷贝到一个临时的本地内存，再从临时本地内存拷贝到 JVM 堆，而不是直接从内核拷贝到 JVM 堆上。这是为什么呢？这是因为数据从内核拷贝到 JVM 堆的过程中，JVM 可能会发生 GC，GC 过程中对象可能会被移动，也就是说 JVM 堆上的字节数组可能会被移动，这样的话 Buffer 地址就失效了。如果这中间经过本地内存中转，从本地内存到 JVM 堆的拷贝过程中 JVM 可以保证不做 GC。\n\n如果使用 HeapByteBuffer，你会发现 JVM 堆和内核之间多了一层中转，而 DirectByteBuffer 用来解决这个问题，DirectByteBuffer 对象本身在 JVM 堆上，但是它持有的字节数组不是从 JVM 堆上分配的，而是从本地内存分配的。DirectByteBuffer 对象中有个 long 类型字段 address，记录着本地内存的地址，这样在接收数据的时候，直接把这个本地内存地址传递给 C 程序，C 程序会将网络数据从内核拷贝到这个本地内存，JVM 可以直接读取这个本地内存，这种方式比 HeapByteBuffer 少了一次拷贝，因此一般来说它的速度会比 HeapByteBuffer 快好几倍。你可以通过上面的图加深理解。\n\nTomcat 中的 AprEndpoint 就是通过 DirectByteBuffer 来接收数据的，而 NioEndpoint 和 Nio2Endpoint 是通过 HeapByteBuffer 来接收数据的。你可能会问，NioEndpoint 和 Nio2Endpoint 为什么不用 DirectByteBuffer 呢？这是因为本地内存不好管理，发生内存泄漏难以定位，从稳定性考虑，NioEndpoint 和 Nio2Endpoint 没有去冒这个险。\n\n# 3.2.1. sendfile\n\n我们再来考虑另一个网络通信的场景，也就是静态文件的处理。浏览器通过 Tomcat 来获取一个 HTML 文件，而 Tomcat 的处理逻辑无非是两步：\n\n 1. 从磁盘读取 HTML 到内存。\n 2. 将这段内存的内容通过 Socket 发送出去。\n\n但是在传统方式下，有很多次的内存拷贝：\n\n * 读取文件时，首先是内核把文件内容读取到内核缓冲区。\n * 如果使用 HeapByteBuffer，文件数据从内核到 JVM 堆内存需要经过本地内存中转。\n * 同样在将文件内容推入网络时，从 JVM 堆到内核缓冲区需要经过本地内存中转。\n * 最后还需要把文件从内核缓冲区拷贝到网卡缓冲区。\n\n从下面的图你会发现这个过程有 6 次内存拷贝，并且 read 和 write 等系统调用将导致进程从用户态到内核态的切换，会耗费大量的 CPU 和内存资源。\n\n\n\n而 Tomcat 的 AprEndpoint 通过操作系统层面的 sendfile 特性解决了这个问题，sendfile 系统调用方式非常简洁。\n\nsendfile(socket, file, len);\n\n\n它带有两个关键参数：Socket 和文件句柄。将文件从磁盘写入 Socket 的过程只有两步：\n\n第一步：将文件内容读取到内核缓冲区。\n\n第二步：数据并没有从内核缓冲区复制到 Socket 关联的缓冲区，只有记录数据位置和长度的描述符被添加到 Socket 缓冲区中；接着把数据直接从内核缓冲区传递给网卡。这个过程你可以看下面的图。\n\n\n\n\n# 4. Executor 组件\n\n为了提高处理能力和并发度，Web 容器一般会把处理请求的工作放到线程池里来执行，Tomcat 扩展了原生的 Java 线程池，来满足 Web 容器高并发的需求。\n\n\n# 4.1. Tomcat 定制线程池\n\nTomcat 的线程池也是一个定制版的 ThreadPoolExecutor。Tomcat 传入的参数是这样的：\n\n// 定制版的任务队列\ntaskqueue = new TaskQueue(maxQueueSize);\n\n// 定制版的线程工厂\nTaskThreadFactory tf = new TaskThreadFactory(namePrefix,daemon,getThreadPriority());\n\n// 定制版的线程池\nexecutor = new ThreadPoolExecutor(getMinSpareThreads(), getMaxThreads(), maxIdleTime, TimeUnit.MILLISECONDS,taskqueue, tf);\n\n\n其中的两个关键点：\n\n * Tomcat 有自己的定制版任务队列和线程工厂，并且可以限制任务队列的长度，它的最大长度是 maxQueueSize。\n * Tomcat 对线程数也有限制，设置了核心线程数（minSpareThreads）和最大线程池数（maxThreads）。\n\n除了资源限制以外，Tomcat 线程池还定制自己的任务处理流程。我们知道 Java 原生线程池的任务处理逻辑比较简单：\n\n 1. 前 corePoolSize 个任务时，来一个任务就创建一个新线程。\n 2. 后面再来任务，就把任务添加到任务队列里让所有的线程去抢，如果队列满了就创建临时线程。\n 3. 如果总线程数达到 maximumPoolSize，执行拒绝策略。\n\nTomcat 线程池扩展了原生的 ThreadPoolExecutor，通过重写 execute 方法实现了自己的任务处理逻辑：\n\n 1. 前 corePoolSize 个任务时，来一个任务就创建一个新线程。\n 2. 再来任务的话，就把任务添加到任务队列里让所有的线程去抢，如果队列满了就创建临时线程。\n 3. 如果总线程数达到 maximumPoolSize，则继续尝试把任务添加到任务队列中去。\n 4. 如果缓冲队列也满了，插入失败，执行拒绝策略。\n\n观察 Tomcat 线程池和 Java 原生线程池的区别，其实就是在第 3 步，Tomcat 在线程总数达到最大数时，不是立即执行拒绝策略，而是再尝试向任务队列添加任务，添加失败后再执行拒绝策略。那具体如何实现呢，其实很简单，我们来看一下 Tomcat 线程池的 execute 方法的核心代码。\n\npublic class ThreadPoolExecutor extends java.util.concurrent.ThreadPoolExecutor {\n\n  ...\n\n  public void execute(Runnable command, long timeout, TimeUnit unit) {\n      submittedCount.incrementAndGet();\n      try {\n          // 调用 Java 原生线程池的 execute 去执行任务\n          super.execute(command);\n      } catch (RejectedExecutionException rx) {\n         // 如果总线程数达到 maximumPoolSize，Java 原生线程池执行拒绝策略\n          if (super.getQueue() instanceof TaskQueue) {\n              final TaskQueue queue = (TaskQueue)super.getQueue();\n              try {\n                  // 继续尝试把任务放到任务队列中去\n                  if (!queue.force(command, timeout, unit)) {\n                      submittedCount.decrementAndGet();\n                      // 如果缓冲队列也满了，插入失败，执行拒绝策略。\n                      throw new RejectedExecutionException("...");\n                  }\n              }\n          }\n      }\n}\n\n\n从这个方法你可以看到，Tomcat 线程池的 execute 方法会调用 Java 原生线程池的 execute 去执行任务，如果总线程数达到 maximumPoolSize，Java 原生线程池的 execute 方法会抛出 RejectedExecutionException 异常，但是这个异常会被 Tomcat 线程池的 execute 方法捕获到，并继续尝试把这个任务放到任务队列中去；如果任务队列也满了，再执行拒绝策略。\n\n\n# 4.2. Tomcat 定制任务队列\n\n细心的你有没有发现，在 Tomcat 线程池的 execute 方法最开始有这么一行：\n\nsubmittedCount.incrementAndGet();\n\n\n这行代码的意思把 submittedCount 这个原子变量加一，并且在任务执行失败，抛出拒绝异常时，将这个原子变量减一：\n\nsubmittedCount.decrementAndGet();\n\n\n其实 Tomcat 线程池是用这个变量 submittedCount 来维护已经提交到了线程池，但是还没有执行完的任务个数。Tomcat 为什么要维护这个变量呢？这跟 Tomcat 的定制版的任务队列有关。Tomcat 的任务队列 TaskQueue 扩展了 Java 中的 LinkedBlockingQueue，我们知道 LinkedBlockingQueue 默认情况下长度是没有限制的，除非给它一个 capacity。因此 Tomcat 给了它一个 capacity，TaskQueue 的构造函数中有个整型的参数 capacity，TaskQueue 将 capacity 传给父类 LinkedBlockingQueue 的构造函数。\n\npublic class TaskQueue extends LinkedBlockingQueue<Runnable> {\n\n  public TaskQueue(int capacity) {\n      super(capacity);\n  }\n  ...\n}\n\n\n这个 capacity 参数是通过 Tomcat 的 maxQueueSize 参数来设置的，但问题是默认情况下 maxQueueSize 的值是Integer.MAX_VALUE，等于没有限制，这样就带来一个问题：当前线程数达到核心线程数之后，再来任务的话线程池会把任务添加到任务队列，并且总是会成功，这样永远不会有机会创建新线程了。\n\n为了解决这个问题，TaskQueue 重写了 LinkedBlockingQueue 的 offer 方法，在合适的时机返回 false，返回 false 表示任务添加失败，这时线程池会创建新的线程。那什么是合适的时机呢？请看下面 offer 方法的核心源码：\n\npublic class TaskQueue extends LinkedBlockingQueue<Runnable> {\n\n  ...\n   @Override\n  // 线程池调用任务队列的方法时，当前线程数肯定已经大于核心线程数了\n  public boolean offer(Runnable o) {\n\n      // 如果线程数已经到了最大值，不能创建新线程了，只能把任务添加到任务队列。\n      if (parent.getPoolSize() == parent.getMaximumPoolSize())\n          return super.offer(o);\n\n      // 执行到这里，表明当前线程数大于核心线程数，并且小于最大线程数。\n      // 表明是可以创建新线程的，那到底要不要创建呢？分两种情况：\n\n      //1. 如果已提交的任务数小于当前线程数，表示还有空闲线程，无需创建新线程\n      if (parent.getSubmittedCount()<=(parent.getPoolSize()))\n          return super.offer(o);\n\n      //2. 如果已提交的任务数大于当前线程数，线程不够用了，返回 false 去创建新线程\n      if (parent.getPoolSize()<parent.getMaximumPoolSize())\n          return false;\n\n      // 默认情况下总是把任务添加到任务队列\n      return super.offer(o);\n  }\n\n}\n\n\n从上面的代码我们看到，只有当前线程数大于核心线程数、小于最大线程数，并且已提交的任务个数大于当前线程数时，也就是说线程不够用了，但是线程数又没达到极限，才会去创建新的线程。这就是为什么 Tomcat 需要维护已提交任务数这个变量，它的目的就是在任务队列的长度无限制的情况下，让线程池有机会创建新的线程。\n\n当然默认情况下 Tomcat 的任务队列是没有限制的，你可以通过设置 maxQueueSize 参数来限制任务队列的长度。\n\n\n# 5. WebSocket 组件\n\nHTTP 协议是“请求 - 响应”模式，浏览器必须先发请求给服务器，服务器才会响应这个请求。也就是说，服务器不会主动发送数据给浏览器。\n\n对于实时性要求比较的高的应用，比如在线游戏、股票基金实时报价和在线协同编辑等，浏览器需要实时显示服务器上最新的数据，因此出现了 Ajax 和 Comet 技术。Ajax 本质上还是轮询，而 Comet 是在 HTTP 长连接的基础上做了一些 hack，但是它们的实时性不高，另外频繁的请求会给服务器带来压力，也会浪费网络流量和带宽。于是 HTML5 推出了 WebSocket 标准，使得浏览器和服务器之间任何一方都可以主动发消息给对方，这样服务器有新数据时可以主动推送给浏览器。\n\nTomcat 如何支持 WebSocket？简单来说，Tomcat 做了两件事：\n\n * Endpoint 加载\n * WebSocket 请求处理\n\n\n# 5.1. WebSocket 加载\n\nTomcat 的 WebSocket 加载是通过 SCI 机制完成的。SCI 全称 ServletContainerInitializer，是 Servlet 3.0 规范中定义的用来接收 Web 应用启动事件的接口。那为什么要监听 Servlet 容器的启动事件呢？因为这样我们有机会在 Web 应用启动时做一些初始化工作，比如 WebSocket 需要扫描和加载 Endpoint 类。SCI 的使用也比较简单，将实现 ServletContainerInitializer 接口的类增加 HandlesTypes 注解，并且在注解内指定的一系列类和接口集合。比如 Tomcat 为了扫描和加载 Endpoint 而定义的 SCI 类如下：\n\n@HandlesTypes({ServerEndpoint.class, ServerApplicationConfig.class, Endpoint.class})\npublic class WsSci implements ServletContainerInitializer {\n\n  public void onStartup(Set<Class<?>> clazzes, ServletContext ctx) throws ServletException {\n  ...\n  }\n}\n\n\n一旦定义好了 SCI，Tomcat 在启动阶段扫描类时，会将 HandlesTypes 注解中指定的类都扫描出来，作为 SCI 的 onStartup 方法的参数，并调用 SCI 的 onStartup 方法。注意到 WsSci 的 HandlesTypes 注解中定义了ServerEndpoint.class、ServerApplicationConfig.class和Endpoint.class，因此在 Tomcat 的启动阶段会将这些类的类实例（注意不是对象实例）传递给 WsSci 的 onStartup 方法。那么 WsSci 的 onStartup 方法又做了什么事呢？\n\n它会构造一个 WebSocketContainer 实例，你可以把 WebSocketContainer 理解成一个专门处理 WebSocket 请求的Endpoint 容器。也就是说 Tomcat 会把扫描到的 Endpoint 子类和添加了注解@ServerEndpoint的类注册到这个容器中，并且这个容器还维护了 URL 到 Endpoint 的映射关系，这样通过请求 URL 就能找到具体的 Endpoint 来处理 WebSocket 请求。\n\n\n# 5.2. WebSocket 请求处理\n\nTomcat 用 ProtocolHandler 组件屏蔽应用层协议的差异，其中 ProtocolHandler 中有两个关键组件：Endpoint 和 Processor。需要注意，这里的 Endpoint 跟上文提到的 WebSocket 中的 Endpoint 完全是两回事，连接器中的 Endpoint 组件用来处理 I/O 通信。WebSocket 本质就是一个应用层协议，因此不能用 HttpProcessor 来处理 WebSocket 请求，而要用专门 Processor 来处理，而在 Tomcat 中这样的 Processor 叫作 UpgradeProcessor。\n\n为什么叫 Upgrade Processor 呢？这是因为 Tomcat 是将 HTTP 协议升级成 WebSocket 协议的。\n\nWebSocket 是通过 HTTP 协议来进行握手的，因此当 WebSocket 的握手请求到来时，HttpProtocolHandler 首先接收到这个请求，在处理这个 HTTP 请求时，Tomcat 通过一个特殊的 Filter 判断该当前 HTTP 请求是否是一个 WebSocket Upgrade 请求（即包含Upgrade: websocket的 HTTP 头信息），如果是，则在 HTTP 响应里添加 WebSocket 相关的响应头信息，并进行协议升级。具体来说就是用 UpgradeProtocolHandler 替换当前的 HttpProtocolHandler，相应的，把当前 Socket 的 Processor 替换成 UpgradeProcessor，同时 Tomcat 会创建 WebSocket Session 实例和 Endpoint 实例，并跟当前的 WebSocket 连接一一对应起来。这个 WebSocket 连接不会立即关闭，并且在请求处理中，不再使用原有的 HttpProcessor，而是用专门的 UpgradeProcessor，UpgradeProcessor 最终会调用相应的 Endpoint 实例来处理请求。\n\n\n\n你可以看到，Tomcat 对 WebSocket 请求的处理没有经过 Servlet 容器，而是通过 UpgradeProcessor 组件直接把请求发到 ServerEndpoint 实例，并且 Tomcat 的 WebSocket 实现不需要关注具体 I/O 模型的细节，从而实现了与具体 I/O 方式的解耦。\n\n\n# 6. 参考资料\n\n * 官方\n   * Tomcat 官方网站\n   * Tomcat Wiki\n   * Tomee 官方网站\n * 教程\n   * 深入拆解 Tomcat & Jetty',normalizedContent:'# tomcat 连接器\n\n\n# 1. nioendpoint 组件\n\ntomcat 的 nioendpoint 组件利用 java nio 实现了 i/o 多路复用模型。\n\n\n\nnioendpoint 子组件功能简介：\n\n * limitlatch 是连接控制器，负责控制最大连接数。nio 模式下默认是 10000，达到这个阈值后，连接请求被拒绝。\n * acceptor 负责监听连接请求。acceptor 运行在一个单独的线程里，它在一个死循环里调用 accept 方法来接收新连接，一旦有新的连接请求到来，accept 方法返回一个 channel 对象，接着把 channel 对象交给 poller 去处理。\n * poller 的本质是一个 selector，也运行在单独线程里。poller 内部维护一个 channel 数组，它在一个死循环里不断检测 channel 的数据就绪状态，一旦有 channel 可读，就生成一个 socketprocessor 任务对象扔给 executor 去处理。\n * executor 就是线程池，负责运行 socketprocessor 任务类，socketprocessor 的 run 方法会调用 http11processor 来读取和解析请求数据。我们知道，http11processor 是应用层协议的封装，它会调用容器获得响应，再把响应通过 channel 写出。\n\nnioendpoint 如何实现高并发的呢？\n\n要实现高并发需要合理设计线程模型充分利用 cpu 资源，尽量不要让线程阻塞；另外，就是有多少任务，就用相应规模的线程数去处理。\n\nnioendpoint 要完成三件事情：接收连接、检测 i/o 事件以及处理请求，那么最核心的就是把这三件事情分开，用不同规模的线程去处理，比如用专门的线程组去跑 acceptor，并且 acceptor 的个数可以配置；用专门的线程组去跑 poller，poller 的个数也可以配置；最后具体任务的执行也由专门的线程池来处理，也可以配置线程池的大小。\n\n\n# 1.1. limitlatch\n\nlimitlatch 用来控制连接个数，当连接数到达最大时阻塞线程，直到后续组件处理完一个连接后将连接数减 1。请你注意到达最大连接数后操作系统底层还是会接收客户端连接，但用户层已经不再接收。\n\npublic class limitlatch {\n    private class sync extends abstractqueuedsynchronizer {\n\n        @override\n        protected int tryacquireshared() {\n            long newcount = count.incrementandget();\n            if (newcount > limit) {\n                count.decrementandget();\n                return -1;\n            } else {\n                return 1;\n            }\n        }\n\n        @override\n        protected boolean tryreleaseshared(int arg) {\n            count.decrementandget();\n            return true;\n        }\n    }\n\n    private final sync sync;\n    private final atomiclong count;\n    private volatile long limit;\n\n    // 线程调用这个方法来获得接收新连接的许可，线程可能被阻塞\n    public void countuporawait() throws interruptedexception {\n      sync.acquiresharedinterruptibly(1);\n    }\n\n    // 调用这个方法来释放一个连接许可，那么前面阻塞的线程可能被唤醒\n    public long countdown() {\n      sync.releaseshared(0);\n      long result = getcount();\n      return result;\n   }\n}\n\n\nlimitlatch 内步定义了内部类 sync，而 sync 扩展了 aqs，aqs 是 java 并发包中的一个核心类，它在内部维护一个状态和一个线程队列，可以用来控制线程什么时候挂起，什么时候唤醒。我们可以扩展它来实现自己的同步器，实际上 java 并发包里的锁和条件变量等等都是通过 aqs 来实现的，而这里的 limitlatch 也不例外。\n\n理解源码要点：\n\n * 用户线程通过调用 limitlatch 的 countuporawait 方法来拿到锁，如果暂时无法获取，这个线程会被阻塞到 aqs 的队列中。那 aqs 怎么知道是阻塞还是不阻塞用户线程呢？其实这是由 aqs 的使用者来决定的，也就是内部类 sync 来决定的，因为 sync 类重写了 aqs 的tryacquireshared() 方法。它的实现逻辑是如果当前连接数 count 小于 limit，线程能获取锁，返回 1，否则返回 -1。\n * 如何用户线程被阻塞到了 aqs 的队列，那什么时候唤醒呢？同样是由 sync 内部类决定，sync 重写了 aqs 的releaseshared() 方法，其实就是当一个连接请求处理完了，这时又可以接收一个新连接了，这样前面阻塞的线程将会被唤醒。\n\n\n# 1.2. acceptor\n\nacceptor 实现了 runnable 接口，因此可以跑在单独线程里。一个端口号只能对应一个 serversocketchannel，因此这个 serversocketchannel 是在多个 acceptor 线程之间共享的，它是 endpoint 的属性，由 endpoint 完成初始化和端口绑定。\n\nserversock = serversocketchannel.open();\nserversock.socket().bind(addr,getacceptcount());\nserversock.configureblocking(true);\n\n\n * bind 方法的第二个参数表示操作系统的等待队列长度，我在上面提到，当应用层面的连接数到达最大值时，操作系统可以继续接收连接，那么操作系统能继续接收的最大连接数就是这个队列长度，可以通过 acceptcount 参数配置，默认是 100。\n * serversocketchannel 被设置成阻塞模式，也就是说它是以阻塞的方式接收连接的。serversocketchannel 通过 accept() 接受新的连接，accept() 方法返回获得 socketchannel 对象，然后将 socketchannel 对象封装在一个 pollerevent 对象中，并将 pollerevent 对象压入 poller 的 queue 里，这是个典型的生产者 - 消费者模式，acceptor 与 poller 线程之间通过 queue 通信。\n\n\n# 1.3. poller\n\npoller 本质是一个 selector，它内部维护一个 queue。\n\nprivate final synchronizedqueue<pollerevent> events = new synchronizedqueue<>();\n\n\nsynchronizedqueue 的核心方法都使用了 synchronized 关键字进行修饰，用来保证同一时刻只有一个线程进行读写。\n\n使用 synchronizedqueue，意味着同一时刻只有一个 acceptor 线程对队列进行读写；同时有多个 poller 线程在运行，每个 poller 线程都有自己的队列。每个 poller 线程可能同时被多个 acceptor 线程调用来注册 pollerevent。同样 poller 的个数可以通过 pollers 参数配置。\n\npoller 不断的通过内部的 selector 对象向内核查询 channel 的状态，一旦可读就生成任务类 socketprocessor 交给 executor 去处理。poller 的另一个重要任务是循环遍历检查自己所管理的 socketchannel 是否已经超时，如果有超时就关闭这个 socketchannel。\n\n\n# 1.4. socketprocessor\n\n我们知道，poller 会创建 socketprocessor 任务类交给线程池处理，而 socketprocessor 实现了 runnable 接口，用来定义 executor 中线程所执行的任务，主要就是调用 http11processor 组件来处理请求。http11processor 读取 channel 的数据来生成 servletrequest 对象，这里请你注意：\n\nhttp11processor 并不是直接读取 channel 的。这是因为 tomcat 支持同步非阻塞 i/o 模型和异步 i/o 模型，在 java api 中，相应的 channel 类也是不一样的，比如有 asynchronoussocketchannel 和 socketchannel，为了对 http11processor 屏蔽这些差异，tomcat 设计了一个包装类叫作 socketwrapper，http11processor 只调用 socketwrapper 的方法去读写数据。\n\n\n# 2. nio2endpoint 组件\n\nnio2endpoint 工作流程跟 nioendpoint 较为相似。\n\n\n\nnio2endpoint 子组件功能说明：\n\n * limitlatch 是连接控制器，它负责控制最大连接数。\n * nio2acceptor 扩展了 acceptor，用异步 i/o 的方式来接收连接，跑在一个单独的线程里，也是一个线程组。nio2acceptor 接收新的连接后，得到一个 asynchronoussocketchannel，nio2acceptor 把 asynchronoussocketchannel 封装成一个 nio2socketwrapper，并创建一个 socketprocessor 任务类交给线程池处理，并且 socketprocessor 持有 nio2socketwrapper 对象。\n * executor 在执行 socketprocessor 时，socketprocessor 的 run 方法会调用 http11processor 来处理请求，http11processor 会通过 nio2socketwrapper 读取和解析请求数据，请求经过容器处理后，再把响应通过 nio2socketwrapper 写出。\n\nnio2endpoint 跟 nioendpoint 的一个明显不同点是，nio2endpoint 中没有 poller 组件，也就是没有 selector。这是为什么呢？因为在异步 i/o 模式下，selector 的工作交给内核来做了。\n\n\n# 2.1. nio2acceptor\n\n和 nioendpint 一样，nio2endpoint 的基本思路是用 limitlatch 组件来控制连接数。\n\n但是 nio2acceptor 的监听连接的过程不是在一个死循环里不断的调 accept 方法，而是通过回调函数来完成的。我们来看看它的连接监听方法：\n\nserversock.accept(null, this);\n\n\n其实就是调用了 accept 方法，注意它的第二个参数是 this，表明 nio2acceptor 自己就是处理连接的回调类，因此 nio2acceptor 实现了 completionhandler 接口。那么它是如何实现 completionhandler 接口的呢？\n\nprotected class nio2acceptor extends acceptor<asynchronoussocketchannel>\n    implements completionhandler<asynchronoussocketchannel, void> {\n\n    @override\n    public void completed(asynchronoussocketchannel socket,\n        void attachment) {\n\n        if (isrunning() && !ispaused()) {\n            if (getmaxconnections() == -1) {\n                // 如果没有连接限制，继续接收新的连接\n                serversock.accept(null, this);\n            } else {\n                // 如果有连接限制，就在线程池里跑 run 方法，run 方法会检查连接数\n                getexecutor().execute(this);\n            }\n            // 处理请求\n            if (!setsocketoptions(socket)) {\n                closesocket(socket);\n            }\n        }\n    }\n}\n\n\n可以看到 completionhandler 的两个模板参数分别是 asynchronousserversocketchannel 和 void，我在前面说过第一个参数就是 accept 方法的返回值，第二个参数是附件类，由用户自己决定，这里为 void。completed 方法的处理逻辑比较简单：\n\n * 如果没有连接限制，继续在本线程中调用 accept 方法接收新的连接。\n * 如果有连接限制，就在线程池里跑 run 方法去接收新的连接。那为什么要跑 run 方法呢，因为在 run 方法里会检查连接数，当连接达到最大数时，线程可能会被 limitlatch 阻塞。为什么要放在线程池里跑呢？这是因为如果放在当前线程里执行，completed 方法可能被阻塞，会导致这个回调方法一直不返回。\n\n接着 completed 方法会调用 setsocketoptions 方法，在这个方法里，会创建 nio2socketwrapper 和 socketprocessor，并交给线程池处理。\n\n\n# 2.2. nio2socketwrapper\n\nnio2socketwrapper 的主要作用是封装 channel，并提供接口给 http11processor 读写数据。讲到这里你是不是有个疑问：http11processor 是不能阻塞等待数据的，按照异步 i/o 的套路，http11processor 在调用 nio2socketwrapper 的 read 方法时需要注册回调类，read 调用会立即返回，问题是立即返回后 http11processor 还没有读到数据， 怎么办呢？这个请求的处理不就失败了吗？\n\n为了解决这个问题，http11processor 是通过 2 次 read 调用来完成数据读取操作的。\n\n * 第一次 read 调用：连接刚刚建立好后，acceptor 创建 socketprocessor 任务类交给线程池去处理，http11processor 在处理请求的过程中，会调用 nio2socketwrapper 的 read 方法发出第一次读请求，同时注册了回调类 readcompletionhandler，因为数据没读到，http11processor 把当前的 nio2socketwrapper 标记为数据不完整。接着 socketprocessor 线程被回收，http11processor 并没有阻塞等待数据。这里请注意，http11processor 维护了一个 nio2socketwrapper 列表，也就是维护了连接的状态。\n * 第二次 read 调用：当数据到达后，内核已经把数据拷贝到 http11processor 指定的 buffer 里，同时回调类 readcompletionhandler 被调用，在这个回调处理方法里会重新创建一个新的 socketprocessor 任务来继续处理这个连接，而这个新的 socketprocessor 任务类持有原来那个 nio2socketwrapper，这一次 http11processor 可以通过 nio2socketwrapper 读取数据了，因为数据已经到了应用层的 buffer。\n\n这个回调类 readcompletionhandler 的源码如下，最关键的一点是，nio2socketwrapper 是作为附件类来传递的，这样在回调函数里能拿到所有的上下文。\n\nthis.readcompletionhandler = new completionhandler<integer, socketwrapperbase<nio2channel>>() {\n    public void completed(integer nbytes, socketwrapperbase<nio2channel> attachment) {\n        ...\n        // 通过附件类 socketwrapper 拿到所有的上下文\n        nio2socketwrapper.this.getendpoint().processsocket(attachment, socketevent.open_read, false);\n    }\n\n    public void failed(throwable exc, socketwrapperbase<nio2channel> attachment) {\n        ...\n    }\n}\n\n\n\n# 3. aprendpoint 组件\n\n我们在使用 tomcat 时，可能会在启动日志里看到这样的提示信息：\n\n> the apr based apache tomcat native library which allows optimal performance in production environments was not found on the java.library.path: ***\n\n这句话的意思就是推荐你去安装 apr 库，可以提高系统性能。\n\napr（apache portable runtime libraries）是 apache 可移植运行时库，它是用 c 语言实现的，其目的是向上层应用程序提供一个跨平台的操作系统接口库。tomcat 可以用它来处理包括文件和网络 i/o，从而提升性能。tomcat 支持的连接器有 nio、nio.2 和 apr。跟 nioendpoint 一样，aprendpoint 也实现了非阻塞 i/o，它们的区别是：nioendpoint 通过调用 java 的 nio api 来实现非阻塞 i/o，而 aprendpoint 是通过 jni 调用 apr 本地库而实现非阻塞 i/o 的。\n\n同样是非阻塞 i/o，为什么 tomcat 会提示使用 apr 本地库的性能会更好呢？这是因为在某些场景下，比如需要频繁与操作系统进行交互，socket 网络通信就是这样一个场景，特别是如果你的 web 应用使用了 tls 来加密传输，我们知道 tls 协议在握手过程中有多次网络交互，在这种情况下 java 跟 c 语言程序相比还是有一定的差距，而这正是 apr 的强项。\n\ntomcat 本身是 java 编写的，为了调用 c 语言编写的 apr，需要通过 jni 方式来调用。jni（java native interface） 是 jdk 提供的一个编程接口，它允许 java 程序调用其他语言编写的程序或者代码库，其实 jdk 本身的实现也大量用到 jni 技术来调用本地 c 程序库。\n\n\n# 3.1. aprendpoint 工作流程\n\n\n\n# 3.1.1. acceptor\n\naccpetor 的功能就是监听连接，接收并建立连接。它的本质就是调用了四个操作系统 api：socket、bind、listen 和 accept。那 java 语言如何直接调用 c 语言 api 呢？答案就是通过 jni。具体来说就是两步：先封装一个 java 类，在里面定义一堆用native 关键字修饰的方法，像下面这样。\n\npublic class socket {\n  ...\n  // 用 native 修饰这个方法，表明这个函数是 c 语言实现\n  public static native long create(int family, int type,\n                                 int protocol, long cont)\n\n  public static native int bind(long sock, long sa);\n\n  public static native int listen(long sock, int backlog);\n\n  public static native long accept(long sock)\n}\n\n\n接着用 c 代码实现这些方法，比如 bind 函数就是这样实现的：\n\n// 注意函数的名字要符合 jni 规范的要求\njniexport jint jnicall\njava_org_apache_tomcat_jni_socket_bind(jnienv *e, jlong sock,jlong sa)\n\t{\n\t    jint rv = apr_success;\n\t    tcn_socket_t *s = (tcn_socket_t *）sock;\n\t    apr_sockaddr_t *a = (apr_sockaddr_t *) sa;\n\n        // 调用 apr 库自己实现的 bind 函数\n\t    rv = (jint)apr_socket_bind(s->sock, a);\n\t    return rv;\n\t}\n\n\n专栏里我就不展开 jni 的细节了，你可以扩展阅读获得更多信息和例子。我们要注意的是函数名字要符合 jni 的规范，以及 java 和 c 语言如何互相传递参数，比如在 c 语言有指针，java 没有指针的概念，所以在 java 中用 long 类型来表示指针。aprendpoint 的 acceptor 组件就是调用了 apr 实现的四个 api。\n\n# 3.1.2. poller\n\nacceptor 接收到一个新的 socket 连接后，按照 nioendpoint 的实现，它会把这个 socket 交给 poller 去查询 i/o 事件。aprendpoint 也是这样做的，不过 aprendpoint 的 poller 并不是调用 java nio 里的 selector 来查询 socket 的状态，而是通过 jni 调用 apr 中的 poll 方法，而 apr 又是调用了操作系统的 epoll api 来实现的。\n\n这里有个特别的地方是在 aprendpoint 中，我们可以配置一个叫deferaccept的参数，它对应的是 tcp 协议中的tcp_defer_accept，设置这个参数后，当 tcp 客户端有新的连接请求到达时，tcp 服务端先不建立连接，而是再等等，直到客户端有请求数据发过来时再建立连接。这样的好处是服务端不需要用 selector 去反复查询请求数据是否就绪。\n\n这是一种 tcp 协议层的优化，不是每个操作系统内核都支持，因为 java 作为一种跨平台语言，需要屏蔽各种操作系统的差异，因此并没有把这个参数提供给用户；但是对于 apr 来说，它的目的就是尽可能提升性能，因此它向用户暴露了这个参数。\n\n\n# 3.2. apr 提升性能的秘密\n\napr 连接器之所以能提高 tomcat 的性能，除了 apr 本身是 c 程序库之外，还有哪些提速的秘密呢？\n\njvm 堆 vs 本地内存\n\n我们知道 java 的类实例一般在 jvm 堆上分配，而 java 是通过 jni 调用 c 代码来实现 socket 通信的，那么 c 代码在运行过程中需要的内存又是从哪里分配的呢？c 代码能否直接操作 java 堆？\n\n为了回答这些问题，我先来说说 jvm 和用户进程的关系。如果你想运行一个 java 类文件，可以用下面的 java 命令来执行。\n\njava my.class\n\n\n这个命令行中的java其实是一个可执行程序，这个程序会创建 jvm 来加载和运行你的 java 类。操作系统会创建一个进程来执行这个java可执行程序，而每个进程都有自己的虚拟地址空间，jvm 用到的内存（包括堆、栈和方法区）就是从进程的虚拟地址空间上分配的。请你注意的是，jvm 内存只是进程空间的一部分，除此之外进程空间内还有代码段、数据段、内存映射区、内核空间等。从 jvm 的角度看，jvm 内存之外的部分叫作本地内存，c 程序代码在运行过程中用到的内存就是本地内存中分配的。下面我们通过一张图来理解一下。\n\n\n\ntomcat 的 endpoint 组件在接收网络数据时需要预先分配好一块 buffer，所谓的 buffer 就是字节数组byte[]，java 通过 jni 调用把这块 buffer 的地址传给 c 代码，c 代码通过操作系统 api 读取 socket 并把数据填充到这块 buffer。java nio api 提供了两种 buffer 来接收数据：heapbytebuffer 和 directbytebuffer，下面的代码演示了如何创建两种 buffer。\n\n// 分配 heapbytebuffer\nbytebuffer buf = bytebuffer.allocate(1024);\n\n// 分配 directbytebuffer\nbytebuffer buf = bytebuffer.allocatedirect(1024);\n\n\n创建好 buffer 后直接传给 channel 的 read 或者 write 函数，最终这块 buffer 会通过 jni 调用传递给 c 程序。\n\n// 将 buf 作为 read 函数的参数\nint bytesread = socketchannel.read(buf);\n\n\n那 heapbytebuffer 和 directbytebuffer 有什么区别呢？heapbytebuffer 对象本身在 jvm 堆上分配，并且它持有的字节数组byte[]也是在 jvm 堆上分配。但是如果用heapbytebuffer来接收网络数据，需要把数据从内核先拷贝到一个临时的本地内存，再从临时本地内存拷贝到 jvm 堆，而不是直接从内核拷贝到 jvm 堆上。这是为什么呢？这是因为数据从内核拷贝到 jvm 堆的过程中，jvm 可能会发生 gc，gc 过程中对象可能会被移动，也就是说 jvm 堆上的字节数组可能会被移动，这样的话 buffer 地址就失效了。如果这中间经过本地内存中转，从本地内存到 jvm 堆的拷贝过程中 jvm 可以保证不做 gc。\n\n如果使用 heapbytebuffer，你会发现 jvm 堆和内核之间多了一层中转，而 directbytebuffer 用来解决这个问题，directbytebuffer 对象本身在 jvm 堆上，但是它持有的字节数组不是从 jvm 堆上分配的，而是从本地内存分配的。directbytebuffer 对象中有个 long 类型字段 address，记录着本地内存的地址，这样在接收数据的时候，直接把这个本地内存地址传递给 c 程序，c 程序会将网络数据从内核拷贝到这个本地内存，jvm 可以直接读取这个本地内存，这种方式比 heapbytebuffer 少了一次拷贝，因此一般来说它的速度会比 heapbytebuffer 快好几倍。你可以通过上面的图加深理解。\n\ntomcat 中的 aprendpoint 就是通过 directbytebuffer 来接收数据的，而 nioendpoint 和 nio2endpoint 是通过 heapbytebuffer 来接收数据的。你可能会问，nioendpoint 和 nio2endpoint 为什么不用 directbytebuffer 呢？这是因为本地内存不好管理，发生内存泄漏难以定位，从稳定性考虑，nioendpoint 和 nio2endpoint 没有去冒这个险。\n\n# 3.2.1. sendfile\n\n我们再来考虑另一个网络通信的场景，也就是静态文件的处理。浏览器通过 tomcat 来获取一个 html 文件，而 tomcat 的处理逻辑无非是两步：\n\n 1. 从磁盘读取 html 到内存。\n 2. 将这段内存的内容通过 socket 发送出去。\n\n但是在传统方式下，有很多次的内存拷贝：\n\n * 读取文件时，首先是内核把文件内容读取到内核缓冲区。\n * 如果使用 heapbytebuffer，文件数据从内核到 jvm 堆内存需要经过本地内存中转。\n * 同样在将文件内容推入网络时，从 jvm 堆到内核缓冲区需要经过本地内存中转。\n * 最后还需要把文件从内核缓冲区拷贝到网卡缓冲区。\n\n从下面的图你会发现这个过程有 6 次内存拷贝，并且 read 和 write 等系统调用将导致进程从用户态到内核态的切换，会耗费大量的 cpu 和内存资源。\n\n\n\n而 tomcat 的 aprendpoint 通过操作系统层面的 sendfile 特性解决了这个问题，sendfile 系统调用方式非常简洁。\n\nsendfile(socket, file, len);\n\n\n它带有两个关键参数：socket 和文件句柄。将文件从磁盘写入 socket 的过程只有两步：\n\n第一步：将文件内容读取到内核缓冲区。\n\n第二步：数据并没有从内核缓冲区复制到 socket 关联的缓冲区，只有记录数据位置和长度的描述符被添加到 socket 缓冲区中；接着把数据直接从内核缓冲区传递给网卡。这个过程你可以看下面的图。\n\n\n\n\n# 4. executor 组件\n\n为了提高处理能力和并发度，web 容器一般会把处理请求的工作放到线程池里来执行，tomcat 扩展了原生的 java 线程池，来满足 web 容器高并发的需求。\n\n\n# 4.1. tomcat 定制线程池\n\ntomcat 的线程池也是一个定制版的 threadpoolexecutor。tomcat 传入的参数是这样的：\n\n// 定制版的任务队列\ntaskqueue = new taskqueue(maxqueuesize);\n\n// 定制版的线程工厂\ntaskthreadfactory tf = new taskthreadfactory(nameprefix,daemon,getthreadpriority());\n\n// 定制版的线程池\nexecutor = new threadpoolexecutor(getminsparethreads(), getmaxthreads(), maxidletime, timeunit.milliseconds,taskqueue, tf);\n\n\n其中的两个关键点：\n\n * tomcat 有自己的定制版任务队列和线程工厂，并且可以限制任务队列的长度，它的最大长度是 maxqueuesize。\n * tomcat 对线程数也有限制，设置了核心线程数（minsparethreads）和最大线程池数（maxthreads）。\n\n除了资源限制以外，tomcat 线程池还定制自己的任务处理流程。我们知道 java 原生线程池的任务处理逻辑比较简单：\n\n 1. 前 corepoolsize 个任务时，来一个任务就创建一个新线程。\n 2. 后面再来任务，就把任务添加到任务队列里让所有的线程去抢，如果队列满了就创建临时线程。\n 3. 如果总线程数达到 maximumpoolsize，执行拒绝策略。\n\ntomcat 线程池扩展了原生的 threadpoolexecutor，通过重写 execute 方法实现了自己的任务处理逻辑：\n\n 1. 前 corepoolsize 个任务时，来一个任务就创建一个新线程。\n 2. 再来任务的话，就把任务添加到任务队列里让所有的线程去抢，如果队列满了就创建临时线程。\n 3. 如果总线程数达到 maximumpoolsize，则继续尝试把任务添加到任务队列中去。\n 4. 如果缓冲队列也满了，插入失败，执行拒绝策略。\n\n观察 tomcat 线程池和 java 原生线程池的区别，其实就是在第 3 步，tomcat 在线程总数达到最大数时，不是立即执行拒绝策略，而是再尝试向任务队列添加任务，添加失败后再执行拒绝策略。那具体如何实现呢，其实很简单，我们来看一下 tomcat 线程池的 execute 方法的核心代码。\n\npublic class threadpoolexecutor extends java.util.concurrent.threadpoolexecutor {\n\n  ...\n\n  public void execute(runnable command, long timeout, timeunit unit) {\n      submittedcount.incrementandget();\n      try {\n          // 调用 java 原生线程池的 execute 去执行任务\n          super.execute(command);\n      } catch (rejectedexecutionexception rx) {\n         // 如果总线程数达到 maximumpoolsize，java 原生线程池执行拒绝策略\n          if (super.getqueue() instanceof taskqueue) {\n              final taskqueue queue = (taskqueue)super.getqueue();\n              try {\n                  // 继续尝试把任务放到任务队列中去\n                  if (!queue.force(command, timeout, unit)) {\n                      submittedcount.decrementandget();\n                      // 如果缓冲队列也满了，插入失败，执行拒绝策略。\n                      throw new rejectedexecutionexception("...");\n                  }\n              }\n          }\n      }\n}\n\n\n从这个方法你可以看到，tomcat 线程池的 execute 方法会调用 java 原生线程池的 execute 去执行任务，如果总线程数达到 maximumpoolsize，java 原生线程池的 execute 方法会抛出 rejectedexecutionexception 异常，但是这个异常会被 tomcat 线程池的 execute 方法捕获到，并继续尝试把这个任务放到任务队列中去；如果任务队列也满了，再执行拒绝策略。\n\n\n# 4.2. tomcat 定制任务队列\n\n细心的你有没有发现，在 tomcat 线程池的 execute 方法最开始有这么一行：\n\nsubmittedcount.incrementandget();\n\n\n这行代码的意思把 submittedcount 这个原子变量加一，并且在任务执行失败，抛出拒绝异常时，将这个原子变量减一：\n\nsubmittedcount.decrementandget();\n\n\n其实 tomcat 线程池是用这个变量 submittedcount 来维护已经提交到了线程池，但是还没有执行完的任务个数。tomcat 为什么要维护这个变量呢？这跟 tomcat 的定制版的任务队列有关。tomcat 的任务队列 taskqueue 扩展了 java 中的 linkedblockingqueue，我们知道 linkedblockingqueue 默认情况下长度是没有限制的，除非给它一个 capacity。因此 tomcat 给了它一个 capacity，taskqueue 的构造函数中有个整型的参数 capacity，taskqueue 将 capacity 传给父类 linkedblockingqueue 的构造函数。\n\npublic class taskqueue extends linkedblockingqueue<runnable> {\n\n  public taskqueue(int capacity) {\n      super(capacity);\n  }\n  ...\n}\n\n\n这个 capacity 参数是通过 tomcat 的 maxqueuesize 参数来设置的，但问题是默认情况下 maxqueuesize 的值是integer.max_value，等于没有限制，这样就带来一个问题：当前线程数达到核心线程数之后，再来任务的话线程池会把任务添加到任务队列，并且总是会成功，这样永远不会有机会创建新线程了。\n\n为了解决这个问题，taskqueue 重写了 linkedblockingqueue 的 offer 方法，在合适的时机返回 false，返回 false 表示任务添加失败，这时线程池会创建新的线程。那什么是合适的时机呢？请看下面 offer 方法的核心源码：\n\npublic class taskqueue extends linkedblockingqueue<runnable> {\n\n  ...\n   @override\n  // 线程池调用任务队列的方法时，当前线程数肯定已经大于核心线程数了\n  public boolean offer(runnable o) {\n\n      // 如果线程数已经到了最大值，不能创建新线程了，只能把任务添加到任务队列。\n      if (parent.getpoolsize() == parent.getmaximumpoolsize())\n          return super.offer(o);\n\n      // 执行到这里，表明当前线程数大于核心线程数，并且小于最大线程数。\n      // 表明是可以创建新线程的，那到底要不要创建呢？分两种情况：\n\n      //1. 如果已提交的任务数小于当前线程数，表示还有空闲线程，无需创建新线程\n      if (parent.getsubmittedcount()<=(parent.getpoolsize()))\n          return super.offer(o);\n\n      //2. 如果已提交的任务数大于当前线程数，线程不够用了，返回 false 去创建新线程\n      if (parent.getpoolsize()<parent.getmaximumpoolsize())\n          return false;\n\n      // 默认情况下总是把任务添加到任务队列\n      return super.offer(o);\n  }\n\n}\n\n\n从上面的代码我们看到，只有当前线程数大于核心线程数、小于最大线程数，并且已提交的任务个数大于当前线程数时，也就是说线程不够用了，但是线程数又没达到极限，才会去创建新的线程。这就是为什么 tomcat 需要维护已提交任务数这个变量，它的目的就是在任务队列的长度无限制的情况下，让线程池有机会创建新的线程。\n\n当然默认情况下 tomcat 的任务队列是没有限制的，你可以通过设置 maxqueuesize 参数来限制任务队列的长度。\n\n\n# 5. websocket 组件\n\nhttp 协议是“请求 - 响应”模式，浏览器必须先发请求给服务器，服务器才会响应这个请求。也就是说，服务器不会主动发送数据给浏览器。\n\n对于实时性要求比较的高的应用，比如在线游戏、股票基金实时报价和在线协同编辑等，浏览器需要实时显示服务器上最新的数据，因此出现了 ajax 和 comet 技术。ajax 本质上还是轮询，而 comet 是在 http 长连接的基础上做了一些 hack，但是它们的实时性不高，另外频繁的请求会给服务器带来压力，也会浪费网络流量和带宽。于是 html5 推出了 websocket 标准，使得浏览器和服务器之间任何一方都可以主动发消息给对方，这样服务器有新数据时可以主动推送给浏览器。\n\ntomcat 如何支持 websocket？简单来说，tomcat 做了两件事：\n\n * endpoint 加载\n * websocket 请求处理\n\n\n# 5.1. websocket 加载\n\ntomcat 的 websocket 加载是通过 sci 机制完成的。sci 全称 servletcontainerinitializer，是 servlet 3.0 规范中定义的用来接收 web 应用启动事件的接口。那为什么要监听 servlet 容器的启动事件呢？因为这样我们有机会在 web 应用启动时做一些初始化工作，比如 websocket 需要扫描和加载 endpoint 类。sci 的使用也比较简单，将实现 servletcontainerinitializer 接口的类增加 handlestypes 注解，并且在注解内指定的一系列类和接口集合。比如 tomcat 为了扫描和加载 endpoint 而定义的 sci 类如下：\n\n@handlestypes({serverendpoint.class, serverapplicationconfig.class, endpoint.class})\npublic class wssci implements servletcontainerinitializer {\n\n  public void onstartup(set<class<?>> clazzes, servletcontext ctx) throws servletexception {\n  ...\n  }\n}\n\n\n一旦定义好了 sci，tomcat 在启动阶段扫描类时，会将 handlestypes 注解中指定的类都扫描出来，作为 sci 的 onstartup 方法的参数，并调用 sci 的 onstartup 方法。注意到 wssci 的 handlestypes 注解中定义了serverendpoint.class、serverapplicationconfig.class和endpoint.class，因此在 tomcat 的启动阶段会将这些类的类实例（注意不是对象实例）传递给 wssci 的 onstartup 方法。那么 wssci 的 onstartup 方法又做了什么事呢？\n\n它会构造一个 websocketcontainer 实例，你可以把 websocketcontainer 理解成一个专门处理 websocket 请求的endpoint 容器。也就是说 tomcat 会把扫描到的 endpoint 子类和添加了注解@serverendpoint的类注册到这个容器中，并且这个容器还维护了 url 到 endpoint 的映射关系，这样通过请求 url 就能找到具体的 endpoint 来处理 websocket 请求。\n\n\n# 5.2. websocket 请求处理\n\ntomcat 用 protocolhandler 组件屏蔽应用层协议的差异，其中 protocolhandler 中有两个关键组件：endpoint 和 processor。需要注意，这里的 endpoint 跟上文提到的 websocket 中的 endpoint 完全是两回事，连接器中的 endpoint 组件用来处理 i/o 通信。websocket 本质就是一个应用层协议，因此不能用 httpprocessor 来处理 websocket 请求，而要用专门 processor 来处理，而在 tomcat 中这样的 processor 叫作 upgradeprocessor。\n\n为什么叫 upgrade processor 呢？这是因为 tomcat 是将 http 协议升级成 websocket 协议的。\n\nwebsocket 是通过 http 协议来进行握手的，因此当 websocket 的握手请求到来时，httpprotocolhandler 首先接收到这个请求，在处理这个 http 请求时，tomcat 通过一个特殊的 filter 判断该当前 http 请求是否是一个 websocket upgrade 请求（即包含upgrade: websocket的 http 头信息），如果是，则在 http 响应里添加 websocket 相关的响应头信息，并进行协议升级。具体来说就是用 upgradeprotocolhandler 替换当前的 httpprotocolhandler，相应的，把当前 socket 的 processor 替换成 upgradeprocessor，同时 tomcat 会创建 websocket session 实例和 endpoint 实例，并跟当前的 websocket 连接一一对应起来。这个 websocket 连接不会立即关闭，并且在请求处理中，不再使用原有的 httpprocessor，而是用专门的 upgradeprocessor，upgradeprocessor 最终会调用相应的 endpoint 实例来处理请求。\n\n\n\n你可以看到，tomcat 对 websocket 请求的处理没有经过 servlet 容器，而是通过 upgradeprocessor 组件直接把请求发到 serverendpoint 实例，并且 tomcat 的 websocket 实现不需要关注具体 i/o 模型的细节，从而实现了与具体 i/o 方式的解耦。\n\n\n# 6. 参考资料\n\n * 官方\n   * tomcat 官方网站\n   * tomcat wiki\n   * tomee 官方网站\n * 教程\n   * 深入拆解 tomcat & jetty',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Tomcat容器",frontmatter:{title:"Tomcat容器",categories:["编程","Java","服务器"],tags:["Java","JavaWeb","服务器","Tomcat"],abbrlink:"fc56014a",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/2fea08/"},regularPath:"/02.JavaEE/02.%E6%9C%8D%E5%8A%A1%E5%99%A8/01.Tomcat/03.Tomcat%E5%AE%B9%E5%99%A8.html",relativePath:"02.JavaEE/02.服务器/01.Tomcat/03.Tomcat容器.md",key:"v-0a24b240",path:"/pages/2fea08/",headers:[{level:2,title:"Tomcat 实现热部署和热加载",slug:"tomcat-实现热部署和热加载",normalizedTitle:"tomcat 实现热部署和热加载",charIndex:16},{level:3,title:"ContainerBackgroundProcessor 实现",slug:"containerbackgroundprocessor-实现",normalizedTitle:"containerbackgroundprocessor 实现",charIndex:732},{level:3,title:"backgroundProcess 方法",slug:"backgroundprocess-方法",normalizedTitle:"backgroundprocess 方法",charIndex:1101},{level:3,title:"Tomcat 热加载",slug:"tomcat-热加载",normalizedTitle:"tomcat 热加载",charIndex:3363},{level:3,title:"Tomcat 热部署",slug:"tomcat-热部署",normalizedTitle:"tomcat 热部署",charIndex:4898},{level:2,title:"Tomcat 的类加载机制",slug:"tomcat-的类加载机制",normalizedTitle:"tomcat 的类加载机制",charIndex:6049},{level:3,title:"findClass 方法",slug:"findclass-方法",normalizedTitle:"findclass 方法",charIndex:6213},{level:3,title:"loadClass 方法",slug:"loadclass-方法",normalizedTitle:"loadclass 方法",charIndex:7015},{level:3,title:"Tomcat 实现应用隔离",slug:"tomcat-实现应用隔离",normalizedTitle:"tomcat 实现应用隔离",charIndex:9756},{level:4,title:"WebAppClassLoader",slug:"webappclassloader",normalizedTitle:"webappclassloader",charIndex:6080},{level:4,title:"SharedClassLoader",slug:"sharedclassloader",normalizedTitle:"sharedclassloader",charIndex:10577},{level:4,title:"CatalinaClassloader",slug:"catalinaclassloader",normalizedTitle:"catalinaclassloader",charIndex:10953},{level:4,title:"CommonClassLoader",slug:"commonclassloader",normalizedTitle:"commonclassloader",charIndex:11185},{level:2,title:"Tomcat 实现 Servlet 规范",slug:"tomcat-实现-servlet-规范",normalizedTitle:"tomcat 实现 servlet 规范",charIndex:11493},{level:3,title:"Servlet 管理",slug:"servlet-管理",normalizedTitle:"servlet 管理",charIndex:11984},{level:3,title:"Filter 管理",slug:"filter-管理",normalizedTitle:"filter 管理",charIndex:14030},{level:3,title:"Listener 管理",slug:"listener-管理",normalizedTitle:"listener 管理",charIndex:16214},{level:2,title:"Tomcat 支持异步 Servlet",slug:"tomcat-支持异步-servlet",normalizedTitle:"tomcat 支持异步 servlet",charIndex:17460},{level:3,title:"异步示例",slug:"异步示例",normalizedTitle:"异步示例",charIndex:17484},{level:3,title:"异步 Servlet 原理",slug:"异步-servlet-原理",normalizedTitle:"异步 servlet 原理",charIndex:18733},{level:4,title:"startAsync 方法",slug:"startasync-方法",normalizedTitle:"startasync 方法",charIndex:18426},{level:4,title:"complete 方法",slug:"complete-方法",normalizedTitle:"complete 方法",charIndex:18208},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:22919}],headersStr:"Tomcat 实现热部署和热加载 ContainerBackgroundProcessor 实现 backgroundProcess 方法 Tomcat 热加载 Tomcat 热部署 Tomcat 的类加载机制 findClass 方法 loadClass 方法 Tomcat 实现应用隔离 WebAppClassLoader SharedClassLoader CatalinaClassloader CommonClassLoader Tomcat 实现 Servlet 规范 Servlet 管理 Filter 管理 Listener 管理 Tomcat 支持异步 Servlet 异步示例 异步 Servlet 原理 startAsync 方法 complete 方法 参考资料",content:'# Tomcat 容器\n\n\n# Tomcat 实现热部署和热加载\n\n * 热加载的实现方式是 Web 容器启动一个后台线程，定期检测类文件的变化，如果有变化，就重新加载类，在这个过程中不会清空 Session ，一般用在开发环境。\n * 热部署原理类似，也是由后台线程定时检测 Web 应用的变化，但它会重新加载整个 Web 应用。这种方式会清空 Session，比热加载更加干净、彻底，一般用在生产环境。\n\nTomcat 通过开启后台线程，使得各个层次的容器组件都有机会完成一些周期性任务。Tomcat 是基于 ScheduledThreadPoolExecutor 实现周期性任务的：\n\nbgFuture = exec.scheduleWithFixedDelay(\n              new ContainerBackgroundProcessor(),// 要执行的 Runnable\n              backgroundProcessorDelay, // 第一次执行延迟多久\n              backgroundProcessorDelay, // 之后每次执行间隔多久\n              TimeUnit.SECONDS);        // 时间单位\n\n\n第一个参数就是要周期性执行的任务类 ContainerBackgroundProcessor，它是一个 Runnable，同时也是 ContainerBase 的内部类，ContainerBase 是所有容器组件的基类，我们来回忆一下容器组件有哪些，有 Engine、Host、Context 和 Wrapper 等，它们具有父子关系。\n\n\n# ContainerBackgroundProcessor 实现\n\n我们接来看 ContainerBackgroundProcessor 具体是如何实现的。\n\nprotected class ContainerBackgroundProcessor implements Runnable {\n\n    @Override\n    public void run() {\n        // 请注意这里传入的参数是 " 宿主类 " 的实例\n        processChildren(ContainerBase.this);\n    }\n\n    protected void processChildren(Container container) {\n        try {\n            //1. 调用当前容器的 backgroundProcess 方法。\n            container.backgroundProcess();\n\n            //2. 遍历所有的子容器，递归调用 processChildren，\n            // 这样当前容器的子孙都会被处理\n            Container[] children = container.findChildren();\n            for (int i = 0; i < children.length; i++) {\n            // 这里请你注意，容器基类有个变量叫做 backgroundProcessorDelay，如果大于 0，表明子容器有自己的后台线程，无需父容器来调用它的 processChildren 方法。\n                if (children[i].getBackgroundProcessorDelay() <= 0) {\n                    processChildren(children[i]);\n                }\n            }\n        } catch (Throwable t) { ... }\n\n\n上面的代码逻辑也是比较清晰的，首先 ContainerBackgroundProcessor 是一个 Runnable，它需要实现 run 方法，它的 run 很简单，就是调用了 processChildren 方法。这里有个小技巧，它把“宿主类”，也就是ContainerBase 的类实例当成参数传给了 run 方法。\n\n而在 processChildren 方法里，就做了两步：调用当前容器的 backgroundProcess 方法，以及递归调用子孙的 backgroundProcess 方法。请你注意 backgroundProcess 是 Container 接口中的方法，也就是说所有类型的容器都可以实现这个方法，在这个方法里完成需要周期性执行的任务。\n\n这样的设计意味着什么呢？我们只需要在顶层容器，也就是 Engine 容器中启动一个后台线程，那么这个线程不但会执行 Engine 容器的周期性任务，它还会执行所有子容器的周期性任务。\n\n\n# backgroundProcess 方法\n\n上述代码都是在基类 ContainerBase 中实现的，那具体容器类需要做什么呢？其实很简单，如果有周期性任务要执行，就实现 backgroundProcess 方法；如果没有，就重用基类 ContainerBase 的方法。ContainerBase 的 backgroundProcess 方法实现如下：\n\npublic void backgroundProcess() {\n\n    //1. 执行容器中 Cluster 组件的周期性任务\n    Cluster cluster = getClusterInternal();\n    if (cluster != null) {\n        cluster.backgroundProcess();\n    }\n\n    //2. 执行容器中 Realm 组件的周期性任务\n    Realm realm = getRealmInternal();\n    if (realm != null) {\n        realm.backgroundProcess();\n   }\n\n   //3. 执行容器中 Valve 组件的周期性任务\n    Valve current = pipeline.getFirst();\n    while (current != null) {\n       current.backgroundProcess();\n       current = current.getNext();\n    }\n\n    //4. 触发容器的 " 周期事件 "，Host 容器的监听器 HostConfig 就靠它来调用\n    fireLifecycleEvent(Lifecycle.PERIODIC_EVENT, null);\n}\n\n\n从上面的代码可以看到，不仅每个容器可以有周期性任务，每个容器中的其他通用组件，比如跟集群管理有关的 Cluster 组件、跟安全管理有关的 Realm 组件都可以有自己的周期性任务。\n\n我在前面的专栏里提到过，容器之间的链式调用是通过 Pipeline-Valve 机制来实现的，从上面的代码你可以看到容器中的 Valve 也可以有周期性任务，并且被 ContainerBase 统一处理。\n\n请你特别注意的是，在 backgroundProcess 方法的最后，还触发了容器的“周期事件”。我们知道容器的生命周期事件有初始化、启动和停止等，那“周期事件”又是什么呢？它跟生命周期事件一样，是一种扩展机制，你可以这样理解：\n\n又一段时间过去了，容器还活着，你想做点什么吗？如果你想做点什么，就创建一个监听器来监听这个“周期事件”，事件到了我负责调用你的方法。\n\n总之，有了 ContainerBase 中的后台线程和 backgroundProcess 方法，各种子容器和通用组件不需要各自弄一个后台线程来处理周期性任务，这样的设计显得优雅和整洁。\n\n\n# Tomcat 热加载\n\n有了 ContainerBase 的周期性任务处理“框架”，作为具体容器子类，只需要实现自己的周期性任务就行。而 Tomcat 的热加载，就是在 Context 容器中实现的。Context 容器的 backgroundProcess 方法是这样实现的：\n\npublic void backgroundProcess() {\n\n    //WebappLoader 周期性的检查 WEB-INF/classes 和 WEB-INF/lib 目录下的类文件\n    Loader loader = getLoader();\n    if (loader != null) {\n        loader.backgroundProcess();\n    }\n\n    //Session 管理器周期性的检查是否有过期的 Session\n    Manager manager = getManager();\n    if (manager != null) {\n        manager.backgroundProcess();\n    }\n\n    // 周期性的检查静态资源是否有变化\n    WebResourceRoot resources = getResources();\n    if (resources != null) {\n        resources.backgroundProcess();\n    }\n\n    // 调用父类 ContainerBase 的 backgroundProcess 方法\n    super.backgroundProcess();\n}\n\n\n从上面的代码我们看到 Context 容器通过 WebappLoader 来检查类文件是否有更新，通过 Session 管理器来检查是否有 Session 过期，并且通过资源管理器来检查静态资源是否有更新，最后还调用了父类 ContainerBase 的 backgroundProcess 方法。\n\n这里我们要重点关注，WebappLoader 是如何实现热加载的，它主要是调用了 Context 容器的 reload 方法，而 Context 的 reload 方法比较复杂，总结起来，主要完成了下面这些任务：\n\n 1. 停止和销毁 Context 容器及其所有子容器，子容器其实就是 Wrapper，也就是说 Wrapper 里面 Servlet 实例也被销毁了。\n 2. 停止和销毁 Context 容器关联的 Listener 和 Filter。\n 3. 停止和销毁 Context 下的 Pipeline 和各种 Valve。\n 4. 停止和销毁 Context 的类加载器，以及类加载器加载的类文件资源。\n 5. 启动 Context 容器，在这个过程中会重新创建前面四步被销毁的资源。\n\n在这个过程中，类加载器发挥着关键作用。一个 Context 容器对应一个类加载器，类加载器在销毁的过程中会把它加载的所有类也全部销毁。Context 容器在启动过程中，会创建一个新的类加载器来加载新的类文件。\n\n在 Context 的 reload 方法里，并没有调用 Session 管理器的 distroy 方法，也就是说这个 Context 关联的 Session 是没有销毁的。你还需要注意的是，Tomcat 的热加载默认是关闭的，你需要在 conf 目录下的 Context.xml 文件中设置 reloadable 参数来开启这个功能，像下面这样：\n\n<Context reloadable="true"/>\n\n\n\n# Tomcat 热部署\n\n我们再来看看热部署，热部署跟热加载的本质区别是，热部署会重新部署 Web 应用，原来的 Context 对象会整个被销毁掉，因此这个 Context 所关联的一切资源都会被销毁，包括 Session。\n\n那么 Tomcat 热部署又是由哪个容器来实现的呢？应该不是由 Context，因为热部署过程中 Context 容器被销毁了，那么这个重担就落在 Host 身上了，因为它是 Context 的父容器。\n\n跟 Context 不一样，Host 容器并没有在 backgroundProcess 方法中实现周期性检测的任务，而是通过监听器 HostConfig 来实现的，HostConfig 就是前面提到的“周期事件”的监听器，那“周期事件”达到时，HostConfig 会做什么事呢？\n\npublic void lifecycleEvent(LifecycleEvent event) {\n    // 执行 check 方法。\n    if (event.getType().equals(Lifecycle.PERIODIC_EVENT)) {\n        check();\n    }\n}\n\n\n它执行了 check 方法，我们接着来看 check 方法里做了什么。\n\nprotected void check() {\n\n    if (host.getAutoDeploy()) {\n        // 检查这个 Host 下所有已经部署的 Web 应用\n        DeployedApplication[] apps =\n            deployed.values().toArray(new DeployedApplication[0]);\n\n        for (int i = 0; i < apps.length; i++) {\n            // 检查 Web 应用目录是否有变化\n            checkResources(apps[i], false);\n        }\n\n        // 执行部署\n        deployApps();\n    }\n}\n\n\n其实 HostConfig 会检查 webapps 目录下的所有 Web 应用：\n\n * 如果原来 Web 应用目录被删掉了，就把相应 Context 容器整个销毁掉。\n * 是否有新的 Web 应用目录放进来了，或者有新的 WAR 包放进来了，就部署相应的 Web 应用。\n\n因此 HostConfig 做的事情都是比较“宏观”的，它不会去检查具体类文件或者资源文件是否有变化，而是检查 Web 应用目录级别的变化。\n\n\n# Tomcat 的类加载机制\n\nTomcat 的自定义类加载器 WebAppClassLoader 打破了双亲委派机制，它首先自己尝试去加载某个类，如果找不到再代理给父类加载器，其目的是优先加载 Web 应用自己定义的类。具体实现就是重写 ClassLoader 的两个方法：findClass 和 loadClass。\n\n\n# findClass 方法\n\n我们先来看看 findClass 方法的实现，为了方便理解和阅读，我去掉了一些细节：\n\npublic Class<?> findClass(String name) throws ClassNotFoundException {\n    ...\n\n    Class<?> clazz = null;\n    try {\n            //1. 先在 Web 应用目录下查找类\n            clazz = findClassInternal(name);\n    }  catch (RuntimeException e) {\n           throw e;\n       }\n\n    if (clazz == null) {\n    try {\n            //2. 如果在本地目录没有找到，交给父加载器去查找\n            clazz = super.findClass(name);\n    }  catch (RuntimeException e) {\n           throw e;\n       }\n\n    //3. 如果父类也没找到，抛出 ClassNotFoundException\n    if (clazz == null) {\n        throw new ClassNotFoundException(name);\n     }\n\n    return clazz;\n}\n\n\n在 findClass 方法里，主要有三个步骤：\n\n 1. 先在 Web 应用本地目录下查找要加载的类。\n 2. 如果没有找到，交给父加载器去查找，它的父加载器就是上面提到的系统类加载器 AppClassLoader。\n 3. 如何父加载器也没找到这个类，抛出 ClassNotFound 异常。\n\n\n# loadClass 方法\n\n接着我们再来看 Tomcat 类加载器的 loadClass 方法的实现，同样我也去掉了一些细节：\n\npublic Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {\n\n    synchronized (getClassLoadingLock(name)) {\n\n        Class<?> clazz = null;\n\n        //1. 先在本地 cache 查找该类是否已经加载过\n        clazz = findLoadedClass0(name);\n        if (clazz != null) {\n            if (resolve)\n                resolveClass(clazz);\n            return clazz;\n        }\n\n        //2. 从系统类加载器的 cache 中查找是否加载过\n        clazz = findLoadedClass(name);\n        if (clazz != null) {\n            if (resolve)\n                resolveClass(clazz);\n            return clazz;\n        }\n\n        // 3. 尝试用 ExtClassLoader 类加载器类加载，为什么？\n        ClassLoader javaseLoader = getJavaseClassLoader();\n        try {\n            clazz = javaseLoader.loadClass(name);\n            if (clazz != null) {\n                if (resolve)\n                    resolveClass(clazz);\n                return clazz;\n            }\n        } catch (ClassNotFoundException e) {\n            // Ignore\n        }\n\n        // 4. 尝试在本地目录搜索 class 并加载\n        try {\n            clazz = findClass(name);\n            if (clazz != null) {\n                if (resolve)\n                    resolveClass(clazz);\n                return clazz;\n            }\n        } catch (ClassNotFoundException e) {\n            // Ignore\n        }\n\n        // 5. 尝试用系统类加载器 (也就是 AppClassLoader) 来加载\n            try {\n                clazz = Class.forName(name, false, parent);\n                if (clazz != null) {\n                    if (resolve)\n                        resolveClass(clazz);\n                    return clazz;\n                }\n            } catch (ClassNotFoundException e) {\n                // Ignore\n            }\n       }\n\n    //6. 上述过程都加载失败，抛出异常\n    throw new ClassNotFoundException(name);\n}\n\n\nloadClass 方法稍微复杂一点，主要有六个步骤：\n\n 1. 先在本地 Cache 查找该类是否已经加载过，也就是说 Tomcat 的类加载器是否已经加载过这个类。\n 2. 如果 Tomcat 类加载器没有加载过这个类，再看看系统类加载器是否加载过。\n 3. 如果都没有，就让ExtClassLoader去加载，这一步比较关键，目的防止 Web 应用自己的类覆盖 JRE 的核心类。因为 Tomcat 需要打破双亲委派机制，假如 Web 应用里自定义了一个叫 Object 的类，如果先加载这个 Object 类，就会覆盖 JRE 里面的那个 Object 类，这就是为什么 Tomcat 的类加载器会优先尝试用 ExtClassLoader 去加载，因为 ExtClassLoader 会委托给 BootstrapClassLoader 去加载，BootstrapClassLoader 发现自己已经加载了 Object 类，直接返回给 Tomcat 的类加载器，这样 Tomcat 的类加载器就不会去加载 Web 应用下的 Object 类了，也就避免了覆盖 JRE 核心类的问题。\n 4. 如果 ExtClassLoader 加载器加载失败，也就是说 JRE 核心类中没有这类，那么就在本地 Web 应用目录下查找并加载。\n 5. 如果本地目录下没有这个类，说明不是 Web 应用自己定义的类，那么由系统类加载器去加载。这里请你注意，Web 应用是通过Class.forName调用交给系统类加载器的，因为Class.forName的默认加载器就是系统类加载器。\n 6. 如果上述加载过程全部失败，抛出 ClassNotFound 异常。\n\n从上面的过程我们可以看到，Tomcat 的类加载器打破了双亲委派机制，没有一上来就直接委托给父加载器，而是先在本地目录下加载，为了避免本地目录下的类覆盖 JRE 的核心类，先尝试用 JVM 扩展类加载器 ExtClassLoader 去加载。那为什么不先用系统类加载器 AppClassLoader 去加载？很显然，如果是这样的话，那就变成双亲委派机制了，这就是 Tomcat 类加载器的巧妙之处。\n\n\n# Tomcat 实现应用隔离\n\nTomcat 作为 Web 容器，需要解决以下问题：\n\n 1. 如果在 Tomcat 中运行了两个 Web 应用程序，两个 Web 应用中有同名的 Servlet，但是功能不同，Tomcat 需要同时加载和管理这两个同名的 Servlet 类，保证它们不会冲突，因此 Web 应用之间的类需要隔离。\n 2. 两个 Web 应用都依赖同一个第三方的 JAR 包，比如 Spring，那 Spring 的 JAR 包被加载到内存后，Tomcat 要保证这两个 Web 应用能够共享，也就是说 Spring 的 JAR 包只被加载一次，否则随着依赖的第三方 JAR 包增多，JVM 的内存会膨胀。\n 3. 需要隔离 Tomcat 本身的类和 Web 应用的类。\n\n\n\n# WebAppClassLoader\n\n针对第一个问题：\n\n如果使用 JVM 默认 AppClassLoader 来加载 Web 应用，AppClassLoader 只能加载一个 Servlet 类，在加载第二个同名 Servlet 类时，AppClassLoader 会返回第一个 Servlet 类的 Class 实例，这是因为在 AppClassLoader 看来，同名的 Servlet 类只被加载一次。\n\nTomcat 的解决方案是自定义一个类加载器 WebAppClassLoader， 并且给每个 Web 应用创建一个类加载器实例。我们知道，Context 容器组件对应一个 Web 应用，因此，每个 Context 容器负责创建和维护一个 WebAppClassLoader 加载器实例。这背后的原理是，不同的加载器实例加载的类被认为是不同的类，即使它们的类名相同。这就相当于在 Java 虚拟机内部创建了一个个相互隔离的 Java 类空间，每一个 Web 应用都有自己的类空间，Web 应用之间通过各自的类加载器互相隔离。\n\n# SharedClassLoader\n\n针对第二个问题：\n\n本质需求是两个 Web 应用之间怎么共享库类，并且不能重复加载相同的类。我们知道，在双亲委派机制里，各个子加载器都可以通过父加载器去加载类，那么把需要共享的类放到父加载器的加载路径下不就行了吗，应用程序也正是通过这种方式共享 JRE 的核心类。因此 Tomcat 的设计者又加了一个类加载器 SharedClassLoader，作为 WebAppClassLoader 的父加载器，专门来加载 Web 应用之间共享的类。如果 WebAppClassLoader 自己没有加载到某个类，就会委托父加载器 SharedClassLoader 去加载这个类，SharedClassLoader 会在指定目录下加载共享类，之后返回给 WebAppClassLoader，这样共享的问题就解决了。\n\n# CatalinaClassloader\n\n如何隔离 Tomcat 本身的类和 Web 应用的类？\n\n要共享可以通过父子关系，要隔离那就需要兄弟关系了。兄弟关系就是指两个类加载器是平行的，它们可能拥有同一个父加载器，但是两个兄弟类加载器加载的类是隔离的。基于此 Tomcat 又设计一个类加载器 CatalinaClassloader，专门来加载 Tomcat 自身的类。这样设计有个问题，那 Tomcat 和各 Web 应用之间需要共享一些类时该怎么办呢？\n\n# CommonClassLoader\n\n老办法，还是再增加一个 CommonClassLoader，作为 CatalinaClassloader 和 SharedClassLoader 的父加载器。CommonClassLoader 能加载的类都可以被 CatalinaClassLoader 和 SharedClassLoader 使用，而 CatalinaClassLoader 和 SharedClassLoader 能加载的类则与对方相互隔离。WebAppClassLoader 可以使用 SharedClassLoader 加载到的类，但各个 WebAppClassLoader 实例之间相互隔离。\n\n\n# Tomcat 实现 Servlet 规范\n\nServlet 容器最重要的任务就是创建 Servlet 的实例并且调用 Servlet。\n\n一个 Web 应用里往往有多个 Servlet，而在 Tomcat 中一个 Web 应用对应一个 Context 容器，也就是说一个 Context 容器需要管理多个 Servlet 实例。但 Context 容器并不直接持有 Servlet 实例，而是通过子容器 Wrapper 来管理 Servlet，你可以把 Wrapper 容器看作是 Servlet 的包装。\n\n为什么需要 Wrapper 呢？Context 容器直接维护一个 Servlet 数组不就行了吗？这是因为 Servlet 不仅仅是一个类实例，它还有相关的配置信息，比如它的 URL 映射、它的初始化参数，因此设计出了一个包装器，把 Servlet 本身和它相关的数据包起来，没错，这就是面向对象的思想。\n\n除此以外，Servlet 规范中还有两个重要特性：Listener 和 Filter，Tomcat 也需要创建它们的实例，并在合适的时机去调用它们的方法。\n\n\n# Servlet 管理\n\nTomcat 是用 Wrapper 容器来管理 Servlet 的，那 Wrapper 容器具体长什么样子呢？我们先来看看它里面有哪些关键的成员变量：\n\nprotected volatile Servlet instance = null;\n\n\n它拥有一个 Servlet 实例，并且 Wrapper 通过 loadServlet 方法来实例化 Servlet。为了方便你阅读，我简化了代码：\n\npublic synchronized Servlet loadServlet() throws ServletException {\n    Servlet servlet;\n\n    //1. 创建一个 Servlet 实例\n    servlet = (Servlet) instanceManager.newInstance(servletClass);\n\n    //2. 调用了 Servlet 的 init 方法，这是 Servlet 规范要求的\n    initServlet(servlet);\n\n    return servlet;\n}\n\n\n其实 loadServlet 主要做了两件事：创建 Servlet 的实例，并且调用 Servlet 的 init 方法，因为这是 Servlet 规范要求的。\n\n那接下来的问题是，什么时候会调到这个 loadServlet 方法呢？为了加快系统的启动速度，我们往往会采取资源延迟加载的策略，Tomcat 也不例外，默认情况下 Tomcat 在启动时不会加载你的 Servlet，除非你把 Servlet 的loadOnStartup参数设置为true。\n\n这里还需要你注意的是，虽然 Tomcat 在启动时不会创建 Servlet 实例，但是会创建 Wrapper 容器，就好比尽管枪里面还没有子弹，先把枪造出来。那子弹什么时候造呢？是真正需要开枪的时候，也就是说有请求来访问某个 Servlet 时，这个 Servlet 的实例才会被创建。\n\n那 Servlet 是被谁调用的呢？我们回忆一下专栏前面提到过 Tomcat 的 Pipeline-Valve 机制，每个容器组件都有自己的 Pipeline，每个 Pipeline 中有一个 Valve 链，并且每个容器组件有一个 BasicValve（基础阀）。Wrapper 作为一个容器组件，它也有自己的 Pipeline 和 BasicValve，Wrapper 的 BasicValve 叫 StandardWrapperValve。\n\n你可以想到，当请求到来时，Context 容器的 BasicValve 会调用 Wrapper 容器中 Pipeline 中的第一个 Valve，然后会调用到 StandardWrapperValve。我们先来看看它的 invoke 方法是如何实现的，同样为了方便你阅读，我简化了代码：\n\npublic final void invoke(Request request, Response response) {\n\n    //1. 实例化 Servlet\n    servlet = wrapper.allocate();\n\n    //2. 给当前请求创建一个 Filter 链\n    ApplicationFilterChain filterChain =\n        ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);\n\n   //3. 调用这个 Filter 链，Filter 链中的最后一个 Filter 会调用 Servlet\n   filterChain.doFilter(request.getRequest(), response.getResponse());\n\n}\n\n\nStandardWrapperValve 的 invoke 方法比较复杂，去掉其他异常处理的一些细节，本质上就是三步：\n\n * 第一步，创建 Servlet 实例；\n * 第二步，给当前请求创建一个 Filter 链；\n * 第三步，调用这个 Filter 链。\n\n你可能会问，为什么需要给每个请求创建一个 Filter 链？这是因为每个请求的请求路径都不一样，而 Filter 都有相应的路径映射，因此不是所有的 Filter 都需要来处理当前的请求，我们需要根据请求的路径来选择特定的一些 Filter 来处理。\n\n第二个问题是，为什么没有看到调到 Servlet 的 service 方法？这是因为 Filter 链的 doFilter 方法会负责调用 Servlet，具体来说就是 Filter 链中的最后一个 Filter 会负责调用 Servlet。\n\n接下来我们来看 Filter 的实现原理。\n\n\n# Filter 管理\n\n我们知道，跟 Servlet 一样，Filter 也可以在web.xml文件里进行配置，不同的是，Filter 的作用域是整个 Web 应用，因此 Filter 的实例是在 Context 容器中进行管理的，Context 容器用 Map 集合来保存 Filter。\n\nprivate Map<String, FilterDef> filterDefs = new HashMap<>();\n\n\n那上面提到的 Filter 链又是什么呢？Filter 链的存活期很短，它是跟每个请求对应的。一个新的请求来了，就动态创建一个 FIlter 链，请求处理完了，Filter 链也就被回收了。理解它的原理也非常关键，我们还是来看看源码：\n\npublic final class ApplicationFilterChain implements FilterChain {\n\n  //Filter 链中有 Filter 数组，这个好理解\n  private ApplicationFilterConfig[] filters = new ApplicationFilterConfig[0];\n\n  //Filter 链中的当前的调用位置\n  private int pos = 0;\n\n  // 总共有多少了 Filter\n  private int n = 0;\n\n  // 每个 Filter 链对应一个 Servlet，也就是它要调用的 Servlet\n  private Servlet servlet = null;\n\n  public void doFilter(ServletRequest req, ServletResponse res) {\n        internalDoFilter(request,response);\n  }\n\n  private void internalDoFilter(ServletRequest req,\n                                ServletResponse res){\n\n    // 每个 Filter 链在内部维护了一个 Filter 数组\n    if (pos < n) {\n        ApplicationFilterConfig filterConfig = filters[pos++];\n        Filter filter = filterConfig.getFilter();\n\n        filter.doFilter(request, response, this);\n        return;\n    }\n\n    servlet.service(request, response);\n\n}\n\n\n从 ApplicationFilterChain 的源码我们可以看到几个关键信息：\n\n * Filter 链中除了有 Filter 对象的数组，还有一个整数变量 pos，这个变量用来记录当前被调用的 Filter 在数组中的位置。\n * Filter 链中有个 Servlet 实例，这个好理解，因为上面提到了，每个 Filter 链最后都会调到一个 Servlet。\n * Filter 链本身也实现了 doFilter 方法，直接调用了一个内部方法 internalDoFilter。\n * internalDoFilter 方法的实现比较有意思，它做了一个判断，如果当前 Filter 的位置小于 Filter 数组的长度，也就是说 Filter 还没调完，就从 Filter 数组拿下一个 Filter，调用它的 doFilter 方法。否则，意味着所有 Filter 都调到了，就调用 Servlet 的 service 方法。\n\n但问题是，方法体里没看到循环，谁在不停地调用 Filter 链的 doFIlter 方法呢？Filter 是怎么依次调到的呢？\n\n答案是Filter 本身的 doFilter 方法会调用 Filter 链的 doFilter 方法，我们还是来看看代码就明白了：\n\npublic void doFilter(ServletRequest request, ServletResponse response,\n        FilterChain chain){\n\n          ...\n\n          // 调用 Filter 的方法\n          chain.doFilter(request, response);\n\n      }\n\n\n注意 Filter 的 doFilter 方法有个关键参数 FilterChain，就是 Filter 链。并且每个 Filter 在实现 doFilter 时，必须要调用 Filter 链的 doFilter 方法，而 Filter 链中保存当前 FIlter 的位置，会调用下一个 FIlter 的 doFilter 方法，这样链式调用就完成了。\n\nFilter 链跟 Tomcat 的 Pipeline-Valve 本质都是责任链模式，但是在具体实现上稍有不同，你可以细细体会一下。\n\n\n# Listener 管理\n\n我们接着聊 Servlet 规范里 Listener。跟 Filter 一样，Listener 也是一种扩展机制，你可以监听容器内部发生的事件，主要有两类事件：\n\n * 第一类是生命状态的变化，比如 Context 容器启动和停止、Session 的创建和销毁。\n * 第二类是属性的变化，比如 Context 容器某个属性值变了、Session 的某个属性值变了以及新的请求来了等。\n\n我们可以在web.xml配置或者通过注解的方式来添加监听器，在监听器里实现我们的业务逻辑。对于 Tomcat 来说，它需要读取配置文件，拿到监听器类的名字，实例化这些类，并且在合适的时机调用这些监听器的方法。\n\nTomcat 是通过 Context 容器来管理这些监听器的。Context 容器将两类事件分开来管理，分别用不同的集合来存放不同类型事件的监听器：\n\n// 监听属性值变化的监听器\nprivate List<Object> applicationEventListenersList = new CopyOnWriteArrayList<>();\n\n// 监听生命事件的监听器\nprivate Object applicationLifecycleListenersObjects[] = new Object[0];\n\n\n剩下的事情就是触发监听器了，比如在 Context 容器的启动方法里，就触发了所有的 ServletContextListener：\n\n//1. 拿到所有的生命周期监听器\nObject instances[] = getApplicationLifecycleListeners();\n\nfor (int i = 0; i < instances.length; i++) {\n   //2. 判断 Listener 的类型是不是 ServletContextListener\n   if (!(instances[i] instanceof ServletContextListener))\n      continue;\n\n   //3. 触发 Listener 的方法\n   ServletContextListener lr = (ServletContextListener) instances[i];\n   lr.contextInitialized(event);\n}\n\n\n需要注意的是，这里的 ServletContextListener 接口是一种留给用户的扩展机制，用户可以实现这个接口来定义自己的监听器，监听 Context 容器的启停事件。Spring 就是这么做的。ServletContextListener 跟 Tomcat 自己的生命周期事件 LifecycleListener 是不同的。LifecycleListener 定义在生命周期管理组件中，由基类 LifeCycleBase 统一管理。\n\n\n# Tomcat 支持异步 Servlet\n\n\n# 异步示例\n\n@WebServlet(urlPatterns = {"/async"}, asyncSupported = true)\npublic class AsyncServlet extends HttpServlet {\n\n    //Web 应用线程池，用来处理异步 Servlet\n    ExecutorService executor = Executors.newSingleThreadExecutor();\n\n    public void service(HttpServletRequest req, HttpServletResponse resp) {\n        //1. 调用 startAsync 或者异步上下文\n        final AsyncContext ctx = req.startAsync();\n\n       // 用线程池来执行耗时操作\n        executor.execute(new Runnable() {\n\n            @Override\n            public void run() {\n\n                // 在这里做耗时的操作\n                try {\n                    ctx.getResponse().getWriter().println("Handling Async Servlet");\n                } catch (IOException e) {}\n\n                //3. 异步 Servlet 处理完了调用异步上下文的 complete 方法\n                ctx.complete();\n            }\n\n        });\n    }\n}\n\n\n有三个要点：\n\n 1. 通过注解的方式来注册 Servlet，除了 @WebServlet 注解，还需要加上 asyncSupported=true 的属性，表明当前的 Servlet 是一个异步 Servlet。\n 2. Web 应用程序需要调用 Request 对象的 startAsync 方法来拿到一个异步上下文 AsyncContext。这个上下文保存了请求和响应对象。\n 3. Web 应用需要开启一个新线程来处理耗时的操作，处理完成后需要调用 AsyncContext 的 complete 方法。目的是告诉 Tomcat，请求已经处理完成。\n\n这里请你注意，虽然异步 Servlet 允许用更长的时间来处理请求，但是也有超时限制的，默认是 30 秒，如果 30 秒内请求还没处理完，Tomcat 会触发超时机制，向浏览器返回超时错误，如果这个时候你的 Web 应用再调用ctx.complete方法，会得到一个 IllegalStateException 异常。\n\n\n# 异步 Servlet 原理\n\n通过上面的例子，相信你对 Servlet 的异步实现有了基本的理解。要理解 Tomcat 在这个过程都做了什么事情，关键就是要弄清楚req.startAsync方法和ctx.complete方法都做了什么。\n\n# startAsync 方法\n\nstartAsync 方法其实就是创建了一个异步上下文 AsyncContext 对象，AsyncContext 对象的作用是保存请求的中间信息，比如 Request 和 Response 对象等上下文信息。你来思考一下为什么需要保存这些信息呢？\n\n这是因为 Tomcat 的工作线程在Request.startAsync调用之后，就直接结束回到线程池中了，线程本身不会保存任何信息。也就是说一个请求到服务端，执行到一半，你的 Web 应用正在处理，这个时候 Tomcat 的工作线程没了，这就需要有个缓存能够保存原始的 Request 和 Response 对象，而这个缓存就是 AsyncContext。\n\n有了 AsyncContext，你的 Web 应用通过它拿到 request 和 response 对象，拿到 Request 对象后就可以读取请求信息，请求处理完了还需要通过 Response 对象将 HTTP 响应发送给浏览器。\n\n除了创建 AsyncContext 对象，startAsync 还需要完成一个关键任务，那就是告诉 Tomcat 当前的 Servlet 处理方法返回时，不要把响应发到浏览器，因为这个时候，响应还没生成呢；并且不能把 Request 对象和 Response 对象销毁，因为后面 Web 应用还要用呢。\n\n在 Tomcat 中，负责 flush 响应数据的是 CoyoteAdaptor，它还会销毁 Request 对象和 Response 对象，因此需要通过某种机制通知 CoyoteAdaptor，具体来说是通过下面这行代码：\n\nthis.request.getCoyoteRequest().action(ActionCode.ASYNC_START, this);\n\n\n你可以把它理解为一个 Callback，在这个 action 方法里设置了 Request 对象的状态，设置它为一个异步 Servlet 请求。\n\n我们知道连接器是调用 CoyoteAdapter 的 service 方法来处理请求的，而 CoyoteAdapter 会调用容器的 service 方法，当容器的 service 方法返回时，CoyoteAdapter 判断当前的请求是不是异步 Servlet 请求，如果是，就不会销毁 Request 和 Response 对象，也不会把响应信息发到浏览器。你可以通过下面的代码理解一下，这是 CoyoteAdapter 的 service 方法，我对它进行了简化：\n\npublic void service(org.apache.coyote.Request req, org.apache.coyote.Response res) {\n\n   // 调用容器的 service 方法处理请求\n    connector.getService().getContainer().getPipeline().\n           getFirst().invoke(request, response);\n\n   // 如果是异步 Servlet 请求，仅仅设置一个标志，\n   // 否则说明是同步 Servlet 请求，就将响应数据刷到浏览器\n    if (request.isAsync()) {\n        async = true;\n    } else {\n        request.finishRequest();\n        response.finishResponse();\n    }\n\n   // 如果不是异步 Servlet 请求，就销毁 Request 对象和 Response 对象\n    if (!async) {\n        request.recycle();\n        response.recycle();\n    }\n}\n\n\n接下来，当 CoyoteAdaptor 的 service 方法返回到 ProtocolHandler 组件时，ProtocolHandler 判断返回值，如果当前请求是一个异步 Servlet 请求，它会把当前 Socket 的协议处理者 Processor 缓存起来，将 SocketWrapper 对象和相应的 Processor 存到一个 Map 数据结构里。\n\nprivate final Map<S,Processor> connections = new ConcurrentHashMap<>();\n\n\n之所以要缓存是因为这个请求接下来还要接着处理，还是由原来的 Processor 来处理，通过 SocketWrapper 就能从 Map 里找到相应的 Processor。\n\n# complete 方法\n\n接着我们再来看关键的ctx.complete方法，当请求处理完成时，Web 应用调用这个方法。那么这个方法做了些什么事情呢？最重要的就是把响应数据发送到浏览器。\n\n这件事情不能由 Web 应用线程来做，也就是说ctx.complete方法不能直接把响应数据发送到浏览器，因为这件事情应该由 Tomcat 线程来做，但具体怎么做呢？\n\n我们知道，连接器中的 Endpoint 组件检测到有请求数据达到时，会创建一个 SocketProcessor 对象交给线程池去处理，因此 Endpoint 的通信处理和具体请求处理在两个线程里运行。\n\n在异步 Servlet 的场景里，Web 应用通过调用ctx.complete方法时，也可以生成一个新的 SocketProcessor 任务类，交给线程池处理。对于异步 Servlet 请求来说，相应的 Socket 和协议处理组件 Processor 都被缓存起来了，并且这些对象都可以通过 Request 对象拿到。\n\n讲到这里，你可能已经猜到ctx.complete是如何实现的了：\n\npublic void complete() {\n    // 检查状态合法性，我们先忽略这句\n    check();\n\n    // 调用 Request 对象的 action 方法，其实就是通知连接器，这个异步请求处理完了\nrequest.getCoyoteRequest().action(ActionCode.ASYNC_COMPLETE, null);\n\n}\n\n\n我们可以看到 complete 方法调用了 Request 对象的 action 方法。而在 action 方法里，则是调用了 Processor 的 processSocketEvent 方法，并且传入了操作码 OPEN_READ。\n\ncase ASYNC_COMPLETE: {\n    clearDispatches();\n    if (asyncStateMachine.asyncComplete()) {\n        processSocketEvent(SocketEvent.OPEN_READ, true);\n    }\n    break;\n}\n\n\n我们接着看 processSocketEvent 方法，它调用 SocketWrapper 的 processSocket 方法：\n\nprotected void processSocketEvent(SocketEvent event, boolean dispatch) {\n    SocketWrapperBase<?> socketWrapper = getSocketWrapper();\n    if (socketWrapper != null) {\n        socketWrapper.processSocket(event, dispatch);\n    }\n}\n\n\n而 SocketWrapper 的 processSocket 方法会创建 SocketProcessor 任务类，并通过 Tomcat 线程池来处理：\n\npublic boolean processSocket(SocketWrapperBase<S> socketWrapper,\n        SocketEvent event, boolean dispatch) {\n\n      if (socketWrapper == null) {\n          return false;\n      }\n\n      SocketProcessorBase<S> sc = processorCache.pop();\n      if (sc == null) {\n          sc = createSocketProcessor(socketWrapper, event);\n      } else {\n          sc.reset(socketWrapper, event);\n      }\n      // 线程池运行\n      Executor executor = getExecutor();\n      if (dispatch && executor != null) {\n          executor.execute(sc);\n      } else {\n          sc.run();\n      }\n}\n\n\n请你注意 createSocketProcessor 函数的第二个参数是 SocketEvent，这里我们传入的是 OPEN_READ。通过这个参数，我们就能控制 SocketProcessor 的行为，因为我们不需要再把请求发送到容器进行处理，只需要向浏览器端发送数据，并且重新在这个 Socket 上监听新的请求就行了。\n\n\n# 参考资料\n\n * 官方\n   * Tomcat 官方网站\n   * Tomcat Wiki\n   * Tomee 官方网站\n * 教程\n   * 深入拆解 Tomcat & Jetty',normalizedContent:'# tomcat 容器\n\n\n# tomcat 实现热部署和热加载\n\n * 热加载的实现方式是 web 容器启动一个后台线程，定期检测类文件的变化，如果有变化，就重新加载类，在这个过程中不会清空 session ，一般用在开发环境。\n * 热部署原理类似，也是由后台线程定时检测 web 应用的变化，但它会重新加载整个 web 应用。这种方式会清空 session，比热加载更加干净、彻底，一般用在生产环境。\n\ntomcat 通过开启后台线程，使得各个层次的容器组件都有机会完成一些周期性任务。tomcat 是基于 scheduledthreadpoolexecutor 实现周期性任务的：\n\nbgfuture = exec.schedulewithfixeddelay(\n              new containerbackgroundprocessor(),// 要执行的 runnable\n              backgroundprocessordelay, // 第一次执行延迟多久\n              backgroundprocessordelay, // 之后每次执行间隔多久\n              timeunit.seconds);        // 时间单位\n\n\n第一个参数就是要周期性执行的任务类 containerbackgroundprocessor，它是一个 runnable，同时也是 containerbase 的内部类，containerbase 是所有容器组件的基类，我们来回忆一下容器组件有哪些，有 engine、host、context 和 wrapper 等，它们具有父子关系。\n\n\n# containerbackgroundprocessor 实现\n\n我们接来看 containerbackgroundprocessor 具体是如何实现的。\n\nprotected class containerbackgroundprocessor implements runnable {\n\n    @override\n    public void run() {\n        // 请注意这里传入的参数是 " 宿主类 " 的实例\n        processchildren(containerbase.this);\n    }\n\n    protected void processchildren(container container) {\n        try {\n            //1. 调用当前容器的 backgroundprocess 方法。\n            container.backgroundprocess();\n\n            //2. 遍历所有的子容器，递归调用 processchildren，\n            // 这样当前容器的子孙都会被处理\n            container[] children = container.findchildren();\n            for (int i = 0; i < children.length; i++) {\n            // 这里请你注意，容器基类有个变量叫做 backgroundprocessordelay，如果大于 0，表明子容器有自己的后台线程，无需父容器来调用它的 processchildren 方法。\n                if (children[i].getbackgroundprocessordelay() <= 0) {\n                    processchildren(children[i]);\n                }\n            }\n        } catch (throwable t) { ... }\n\n\n上面的代码逻辑也是比较清晰的，首先 containerbackgroundprocessor 是一个 runnable，它需要实现 run 方法，它的 run 很简单，就是调用了 processchildren 方法。这里有个小技巧，它把“宿主类”，也就是containerbase 的类实例当成参数传给了 run 方法。\n\n而在 processchildren 方法里，就做了两步：调用当前容器的 backgroundprocess 方法，以及递归调用子孙的 backgroundprocess 方法。请你注意 backgroundprocess 是 container 接口中的方法，也就是说所有类型的容器都可以实现这个方法，在这个方法里完成需要周期性执行的任务。\n\n这样的设计意味着什么呢？我们只需要在顶层容器，也就是 engine 容器中启动一个后台线程，那么这个线程不但会执行 engine 容器的周期性任务，它还会执行所有子容器的周期性任务。\n\n\n# backgroundprocess 方法\n\n上述代码都是在基类 containerbase 中实现的，那具体容器类需要做什么呢？其实很简单，如果有周期性任务要执行，就实现 backgroundprocess 方法；如果没有，就重用基类 containerbase 的方法。containerbase 的 backgroundprocess 方法实现如下：\n\npublic void backgroundprocess() {\n\n    //1. 执行容器中 cluster 组件的周期性任务\n    cluster cluster = getclusterinternal();\n    if (cluster != null) {\n        cluster.backgroundprocess();\n    }\n\n    //2. 执行容器中 realm 组件的周期性任务\n    realm realm = getrealminternal();\n    if (realm != null) {\n        realm.backgroundprocess();\n   }\n\n   //3. 执行容器中 valve 组件的周期性任务\n    valve current = pipeline.getfirst();\n    while (current != null) {\n       current.backgroundprocess();\n       current = current.getnext();\n    }\n\n    //4. 触发容器的 " 周期事件 "，host 容器的监听器 hostconfig 就靠它来调用\n    firelifecycleevent(lifecycle.periodic_event, null);\n}\n\n\n从上面的代码可以看到，不仅每个容器可以有周期性任务，每个容器中的其他通用组件，比如跟集群管理有关的 cluster 组件、跟安全管理有关的 realm 组件都可以有自己的周期性任务。\n\n我在前面的专栏里提到过，容器之间的链式调用是通过 pipeline-valve 机制来实现的，从上面的代码你可以看到容器中的 valve 也可以有周期性任务，并且被 containerbase 统一处理。\n\n请你特别注意的是，在 backgroundprocess 方法的最后，还触发了容器的“周期事件”。我们知道容器的生命周期事件有初始化、启动和停止等，那“周期事件”又是什么呢？它跟生命周期事件一样，是一种扩展机制，你可以这样理解：\n\n又一段时间过去了，容器还活着，你想做点什么吗？如果你想做点什么，就创建一个监听器来监听这个“周期事件”，事件到了我负责调用你的方法。\n\n总之，有了 containerbase 中的后台线程和 backgroundprocess 方法，各种子容器和通用组件不需要各自弄一个后台线程来处理周期性任务，这样的设计显得优雅和整洁。\n\n\n# tomcat 热加载\n\n有了 containerbase 的周期性任务处理“框架”，作为具体容器子类，只需要实现自己的周期性任务就行。而 tomcat 的热加载，就是在 context 容器中实现的。context 容器的 backgroundprocess 方法是这样实现的：\n\npublic void backgroundprocess() {\n\n    //webapploader 周期性的检查 web-inf/classes 和 web-inf/lib 目录下的类文件\n    loader loader = getloader();\n    if (loader != null) {\n        loader.backgroundprocess();\n    }\n\n    //session 管理器周期性的检查是否有过期的 session\n    manager manager = getmanager();\n    if (manager != null) {\n        manager.backgroundprocess();\n    }\n\n    // 周期性的检查静态资源是否有变化\n    webresourceroot resources = getresources();\n    if (resources != null) {\n        resources.backgroundprocess();\n    }\n\n    // 调用父类 containerbase 的 backgroundprocess 方法\n    super.backgroundprocess();\n}\n\n\n从上面的代码我们看到 context 容器通过 webapploader 来检查类文件是否有更新，通过 session 管理器来检查是否有 session 过期，并且通过资源管理器来检查静态资源是否有更新，最后还调用了父类 containerbase 的 backgroundprocess 方法。\n\n这里我们要重点关注，webapploader 是如何实现热加载的，它主要是调用了 context 容器的 reload 方法，而 context 的 reload 方法比较复杂，总结起来，主要完成了下面这些任务：\n\n 1. 停止和销毁 context 容器及其所有子容器，子容器其实就是 wrapper，也就是说 wrapper 里面 servlet 实例也被销毁了。\n 2. 停止和销毁 context 容器关联的 listener 和 filter。\n 3. 停止和销毁 context 下的 pipeline 和各种 valve。\n 4. 停止和销毁 context 的类加载器，以及类加载器加载的类文件资源。\n 5. 启动 context 容器，在这个过程中会重新创建前面四步被销毁的资源。\n\n在这个过程中，类加载器发挥着关键作用。一个 context 容器对应一个类加载器，类加载器在销毁的过程中会把它加载的所有类也全部销毁。context 容器在启动过程中，会创建一个新的类加载器来加载新的类文件。\n\n在 context 的 reload 方法里，并没有调用 session 管理器的 distroy 方法，也就是说这个 context 关联的 session 是没有销毁的。你还需要注意的是，tomcat 的热加载默认是关闭的，你需要在 conf 目录下的 context.xml 文件中设置 reloadable 参数来开启这个功能，像下面这样：\n\n<context reloadable="true"/>\n\n\n\n# tomcat 热部署\n\n我们再来看看热部署，热部署跟热加载的本质区别是，热部署会重新部署 web 应用，原来的 context 对象会整个被销毁掉，因此这个 context 所关联的一切资源都会被销毁，包括 session。\n\n那么 tomcat 热部署又是由哪个容器来实现的呢？应该不是由 context，因为热部署过程中 context 容器被销毁了，那么这个重担就落在 host 身上了，因为它是 context 的父容器。\n\n跟 context 不一样，host 容器并没有在 backgroundprocess 方法中实现周期性检测的任务，而是通过监听器 hostconfig 来实现的，hostconfig 就是前面提到的“周期事件”的监听器，那“周期事件”达到时，hostconfig 会做什么事呢？\n\npublic void lifecycleevent(lifecycleevent event) {\n    // 执行 check 方法。\n    if (event.gettype().equals(lifecycle.periodic_event)) {\n        check();\n    }\n}\n\n\n它执行了 check 方法，我们接着来看 check 方法里做了什么。\n\nprotected void check() {\n\n    if (host.getautodeploy()) {\n        // 检查这个 host 下所有已经部署的 web 应用\n        deployedapplication[] apps =\n            deployed.values().toarray(new deployedapplication[0]);\n\n        for (int i = 0; i < apps.length; i++) {\n            // 检查 web 应用目录是否有变化\n            checkresources(apps[i], false);\n        }\n\n        // 执行部署\n        deployapps();\n    }\n}\n\n\n其实 hostconfig 会检查 webapps 目录下的所有 web 应用：\n\n * 如果原来 web 应用目录被删掉了，就把相应 context 容器整个销毁掉。\n * 是否有新的 web 应用目录放进来了，或者有新的 war 包放进来了，就部署相应的 web 应用。\n\n因此 hostconfig 做的事情都是比较“宏观”的，它不会去检查具体类文件或者资源文件是否有变化，而是检查 web 应用目录级别的变化。\n\n\n# tomcat 的类加载机制\n\ntomcat 的自定义类加载器 webappclassloader 打破了双亲委派机制，它首先自己尝试去加载某个类，如果找不到再代理给父类加载器，其目的是优先加载 web 应用自己定义的类。具体实现就是重写 classloader 的两个方法：findclass 和 loadclass。\n\n\n# findclass 方法\n\n我们先来看看 findclass 方法的实现，为了方便理解和阅读，我去掉了一些细节：\n\npublic class<?> findclass(string name) throws classnotfoundexception {\n    ...\n\n    class<?> clazz = null;\n    try {\n            //1. 先在 web 应用目录下查找类\n            clazz = findclassinternal(name);\n    }  catch (runtimeexception e) {\n           throw e;\n       }\n\n    if (clazz == null) {\n    try {\n            //2. 如果在本地目录没有找到，交给父加载器去查找\n            clazz = super.findclass(name);\n    }  catch (runtimeexception e) {\n           throw e;\n       }\n\n    //3. 如果父类也没找到，抛出 classnotfoundexception\n    if (clazz == null) {\n        throw new classnotfoundexception(name);\n     }\n\n    return clazz;\n}\n\n\n在 findclass 方法里，主要有三个步骤：\n\n 1. 先在 web 应用本地目录下查找要加载的类。\n 2. 如果没有找到，交给父加载器去查找，它的父加载器就是上面提到的系统类加载器 appclassloader。\n 3. 如何父加载器也没找到这个类，抛出 classnotfound 异常。\n\n\n# loadclass 方法\n\n接着我们再来看 tomcat 类加载器的 loadclass 方法的实现，同样我也去掉了一些细节：\n\npublic class<?> loadclass(string name, boolean resolve) throws classnotfoundexception {\n\n    synchronized (getclassloadinglock(name)) {\n\n        class<?> clazz = null;\n\n        //1. 先在本地 cache 查找该类是否已经加载过\n        clazz = findloadedclass0(name);\n        if (clazz != null) {\n            if (resolve)\n                resolveclass(clazz);\n            return clazz;\n        }\n\n        //2. 从系统类加载器的 cache 中查找是否加载过\n        clazz = findloadedclass(name);\n        if (clazz != null) {\n            if (resolve)\n                resolveclass(clazz);\n            return clazz;\n        }\n\n        // 3. 尝试用 extclassloader 类加载器类加载，为什么？\n        classloader javaseloader = getjavaseclassloader();\n        try {\n            clazz = javaseloader.loadclass(name);\n            if (clazz != null) {\n                if (resolve)\n                    resolveclass(clazz);\n                return clazz;\n            }\n        } catch (classnotfoundexception e) {\n            // ignore\n        }\n\n        // 4. 尝试在本地目录搜索 class 并加载\n        try {\n            clazz = findclass(name);\n            if (clazz != null) {\n                if (resolve)\n                    resolveclass(clazz);\n                return clazz;\n            }\n        } catch (classnotfoundexception e) {\n            // ignore\n        }\n\n        // 5. 尝试用系统类加载器 (也就是 appclassloader) 来加载\n            try {\n                clazz = class.forname(name, false, parent);\n                if (clazz != null) {\n                    if (resolve)\n                        resolveclass(clazz);\n                    return clazz;\n                }\n            } catch (classnotfoundexception e) {\n                // ignore\n            }\n       }\n\n    //6. 上述过程都加载失败，抛出异常\n    throw new classnotfoundexception(name);\n}\n\n\nloadclass 方法稍微复杂一点，主要有六个步骤：\n\n 1. 先在本地 cache 查找该类是否已经加载过，也就是说 tomcat 的类加载器是否已经加载过这个类。\n 2. 如果 tomcat 类加载器没有加载过这个类，再看看系统类加载器是否加载过。\n 3. 如果都没有，就让extclassloader去加载，这一步比较关键，目的防止 web 应用自己的类覆盖 jre 的核心类。因为 tomcat 需要打破双亲委派机制，假如 web 应用里自定义了一个叫 object 的类，如果先加载这个 object 类，就会覆盖 jre 里面的那个 object 类，这就是为什么 tomcat 的类加载器会优先尝试用 extclassloader 去加载，因为 extclassloader 会委托给 bootstrapclassloader 去加载，bootstrapclassloader 发现自己已经加载了 object 类，直接返回给 tomcat 的类加载器，这样 tomcat 的类加载器就不会去加载 web 应用下的 object 类了，也就避免了覆盖 jre 核心类的问题。\n 4. 如果 extclassloader 加载器加载失败，也就是说 jre 核心类中没有这类，那么就在本地 web 应用目录下查找并加载。\n 5. 如果本地目录下没有这个类，说明不是 web 应用自己定义的类，那么由系统类加载器去加载。这里请你注意，web 应用是通过class.forname调用交给系统类加载器的，因为class.forname的默认加载器就是系统类加载器。\n 6. 如果上述加载过程全部失败，抛出 classnotfound 异常。\n\n从上面的过程我们可以看到，tomcat 的类加载器打破了双亲委派机制，没有一上来就直接委托给父加载器，而是先在本地目录下加载，为了避免本地目录下的类覆盖 jre 的核心类，先尝试用 jvm 扩展类加载器 extclassloader 去加载。那为什么不先用系统类加载器 appclassloader 去加载？很显然，如果是这样的话，那就变成双亲委派机制了，这就是 tomcat 类加载器的巧妙之处。\n\n\n# tomcat 实现应用隔离\n\ntomcat 作为 web 容器，需要解决以下问题：\n\n 1. 如果在 tomcat 中运行了两个 web 应用程序，两个 web 应用中有同名的 servlet，但是功能不同，tomcat 需要同时加载和管理这两个同名的 servlet 类，保证它们不会冲突，因此 web 应用之间的类需要隔离。\n 2. 两个 web 应用都依赖同一个第三方的 jar 包，比如 spring，那 spring 的 jar 包被加载到内存后，tomcat 要保证这两个 web 应用能够共享，也就是说 spring 的 jar 包只被加载一次，否则随着依赖的第三方 jar 包增多，jvm 的内存会膨胀。\n 3. 需要隔离 tomcat 本身的类和 web 应用的类。\n\n\n\n# webappclassloader\n\n针对第一个问题：\n\n如果使用 jvm 默认 appclassloader 来加载 web 应用，appclassloader 只能加载一个 servlet 类，在加载第二个同名 servlet 类时，appclassloader 会返回第一个 servlet 类的 class 实例，这是因为在 appclassloader 看来，同名的 servlet 类只被加载一次。\n\ntomcat 的解决方案是自定义一个类加载器 webappclassloader， 并且给每个 web 应用创建一个类加载器实例。我们知道，context 容器组件对应一个 web 应用，因此，每个 context 容器负责创建和维护一个 webappclassloader 加载器实例。这背后的原理是，不同的加载器实例加载的类被认为是不同的类，即使它们的类名相同。这就相当于在 java 虚拟机内部创建了一个个相互隔离的 java 类空间，每一个 web 应用都有自己的类空间，web 应用之间通过各自的类加载器互相隔离。\n\n# sharedclassloader\n\n针对第二个问题：\n\n本质需求是两个 web 应用之间怎么共享库类，并且不能重复加载相同的类。我们知道，在双亲委派机制里，各个子加载器都可以通过父加载器去加载类，那么把需要共享的类放到父加载器的加载路径下不就行了吗，应用程序也正是通过这种方式共享 jre 的核心类。因此 tomcat 的设计者又加了一个类加载器 sharedclassloader，作为 webappclassloader 的父加载器，专门来加载 web 应用之间共享的类。如果 webappclassloader 自己没有加载到某个类，就会委托父加载器 sharedclassloader 去加载这个类，sharedclassloader 会在指定目录下加载共享类，之后返回给 webappclassloader，这样共享的问题就解决了。\n\n# catalinaclassloader\n\n如何隔离 tomcat 本身的类和 web 应用的类？\n\n要共享可以通过父子关系，要隔离那就需要兄弟关系了。兄弟关系就是指两个类加载器是平行的，它们可能拥有同一个父加载器，但是两个兄弟类加载器加载的类是隔离的。基于此 tomcat 又设计一个类加载器 catalinaclassloader，专门来加载 tomcat 自身的类。这样设计有个问题，那 tomcat 和各 web 应用之间需要共享一些类时该怎么办呢？\n\n# commonclassloader\n\n老办法，还是再增加一个 commonclassloader，作为 catalinaclassloader 和 sharedclassloader 的父加载器。commonclassloader 能加载的类都可以被 catalinaclassloader 和 sharedclassloader 使用，而 catalinaclassloader 和 sharedclassloader 能加载的类则与对方相互隔离。webappclassloader 可以使用 sharedclassloader 加载到的类，但各个 webappclassloader 实例之间相互隔离。\n\n\n# tomcat 实现 servlet 规范\n\nservlet 容器最重要的任务就是创建 servlet 的实例并且调用 servlet。\n\n一个 web 应用里往往有多个 servlet，而在 tomcat 中一个 web 应用对应一个 context 容器，也就是说一个 context 容器需要管理多个 servlet 实例。但 context 容器并不直接持有 servlet 实例，而是通过子容器 wrapper 来管理 servlet，你可以把 wrapper 容器看作是 servlet 的包装。\n\n为什么需要 wrapper 呢？context 容器直接维护一个 servlet 数组不就行了吗？这是因为 servlet 不仅仅是一个类实例，它还有相关的配置信息，比如它的 url 映射、它的初始化参数，因此设计出了一个包装器，把 servlet 本身和它相关的数据包起来，没错，这就是面向对象的思想。\n\n除此以外，servlet 规范中还有两个重要特性：listener 和 filter，tomcat 也需要创建它们的实例，并在合适的时机去调用它们的方法。\n\n\n# servlet 管理\n\ntomcat 是用 wrapper 容器来管理 servlet 的，那 wrapper 容器具体长什么样子呢？我们先来看看它里面有哪些关键的成员变量：\n\nprotected volatile servlet instance = null;\n\n\n它拥有一个 servlet 实例，并且 wrapper 通过 loadservlet 方法来实例化 servlet。为了方便你阅读，我简化了代码：\n\npublic synchronized servlet loadservlet() throws servletexception {\n    servlet servlet;\n\n    //1. 创建一个 servlet 实例\n    servlet = (servlet) instancemanager.newinstance(servletclass);\n\n    //2. 调用了 servlet 的 init 方法，这是 servlet 规范要求的\n    initservlet(servlet);\n\n    return servlet;\n}\n\n\n其实 loadservlet 主要做了两件事：创建 servlet 的实例，并且调用 servlet 的 init 方法，因为这是 servlet 规范要求的。\n\n那接下来的问题是，什么时候会调到这个 loadservlet 方法呢？为了加快系统的启动速度，我们往往会采取资源延迟加载的策略，tomcat 也不例外，默认情况下 tomcat 在启动时不会加载你的 servlet，除非你把 servlet 的loadonstartup参数设置为true。\n\n这里还需要你注意的是，虽然 tomcat 在启动时不会创建 servlet 实例，但是会创建 wrapper 容器，就好比尽管枪里面还没有子弹，先把枪造出来。那子弹什么时候造呢？是真正需要开枪的时候，也就是说有请求来访问某个 servlet 时，这个 servlet 的实例才会被创建。\n\n那 servlet 是被谁调用的呢？我们回忆一下专栏前面提到过 tomcat 的 pipeline-valve 机制，每个容器组件都有自己的 pipeline，每个 pipeline 中有一个 valve 链，并且每个容器组件有一个 basicvalve（基础阀）。wrapper 作为一个容器组件，它也有自己的 pipeline 和 basicvalve，wrapper 的 basicvalve 叫 standardwrappervalve。\n\n你可以想到，当请求到来时，context 容器的 basicvalve 会调用 wrapper 容器中 pipeline 中的第一个 valve，然后会调用到 standardwrappervalve。我们先来看看它的 invoke 方法是如何实现的，同样为了方便你阅读，我简化了代码：\n\npublic final void invoke(request request, response response) {\n\n    //1. 实例化 servlet\n    servlet = wrapper.allocate();\n\n    //2. 给当前请求创建一个 filter 链\n    applicationfilterchain filterchain =\n        applicationfilterfactory.createfilterchain(request, wrapper, servlet);\n\n   //3. 调用这个 filter 链，filter 链中的最后一个 filter 会调用 servlet\n   filterchain.dofilter(request.getrequest(), response.getresponse());\n\n}\n\n\nstandardwrappervalve 的 invoke 方法比较复杂，去掉其他异常处理的一些细节，本质上就是三步：\n\n * 第一步，创建 servlet 实例；\n * 第二步，给当前请求创建一个 filter 链；\n * 第三步，调用这个 filter 链。\n\n你可能会问，为什么需要给每个请求创建一个 filter 链？这是因为每个请求的请求路径都不一样，而 filter 都有相应的路径映射，因此不是所有的 filter 都需要来处理当前的请求，我们需要根据请求的路径来选择特定的一些 filter 来处理。\n\n第二个问题是，为什么没有看到调到 servlet 的 service 方法？这是因为 filter 链的 dofilter 方法会负责调用 servlet，具体来说就是 filter 链中的最后一个 filter 会负责调用 servlet。\n\n接下来我们来看 filter 的实现原理。\n\n\n# filter 管理\n\n我们知道，跟 servlet 一样，filter 也可以在web.xml文件里进行配置，不同的是，filter 的作用域是整个 web 应用，因此 filter 的实例是在 context 容器中进行管理的，context 容器用 map 集合来保存 filter。\n\nprivate map<string, filterdef> filterdefs = new hashmap<>();\n\n\n那上面提到的 filter 链又是什么呢？filter 链的存活期很短，它是跟每个请求对应的。一个新的请求来了，就动态创建一个 filter 链，请求处理完了，filter 链也就被回收了。理解它的原理也非常关键，我们还是来看看源码：\n\npublic final class applicationfilterchain implements filterchain {\n\n  //filter 链中有 filter 数组，这个好理解\n  private applicationfilterconfig[] filters = new applicationfilterconfig[0];\n\n  //filter 链中的当前的调用位置\n  private int pos = 0;\n\n  // 总共有多少了 filter\n  private int n = 0;\n\n  // 每个 filter 链对应一个 servlet，也就是它要调用的 servlet\n  private servlet servlet = null;\n\n  public void dofilter(servletrequest req, servletresponse res) {\n        internaldofilter(request,response);\n  }\n\n  private void internaldofilter(servletrequest req,\n                                servletresponse res){\n\n    // 每个 filter 链在内部维护了一个 filter 数组\n    if (pos < n) {\n        applicationfilterconfig filterconfig = filters[pos++];\n        filter filter = filterconfig.getfilter();\n\n        filter.dofilter(request, response, this);\n        return;\n    }\n\n    servlet.service(request, response);\n\n}\n\n\n从 applicationfilterchain 的源码我们可以看到几个关键信息：\n\n * filter 链中除了有 filter 对象的数组，还有一个整数变量 pos，这个变量用来记录当前被调用的 filter 在数组中的位置。\n * filter 链中有个 servlet 实例，这个好理解，因为上面提到了，每个 filter 链最后都会调到一个 servlet。\n * filter 链本身也实现了 dofilter 方法，直接调用了一个内部方法 internaldofilter。\n * internaldofilter 方法的实现比较有意思，它做了一个判断，如果当前 filter 的位置小于 filter 数组的长度，也就是说 filter 还没调完，就从 filter 数组拿下一个 filter，调用它的 dofilter 方法。否则，意味着所有 filter 都调到了，就调用 servlet 的 service 方法。\n\n但问题是，方法体里没看到循环，谁在不停地调用 filter 链的 dofilter 方法呢？filter 是怎么依次调到的呢？\n\n答案是filter 本身的 dofilter 方法会调用 filter 链的 dofilter 方法，我们还是来看看代码就明白了：\n\npublic void dofilter(servletrequest request, servletresponse response,\n        filterchain chain){\n\n          ...\n\n          // 调用 filter 的方法\n          chain.dofilter(request, response);\n\n      }\n\n\n注意 filter 的 dofilter 方法有个关键参数 filterchain，就是 filter 链。并且每个 filter 在实现 dofilter 时，必须要调用 filter 链的 dofilter 方法，而 filter 链中保存当前 filter 的位置，会调用下一个 filter 的 dofilter 方法，这样链式调用就完成了。\n\nfilter 链跟 tomcat 的 pipeline-valve 本质都是责任链模式，但是在具体实现上稍有不同，你可以细细体会一下。\n\n\n# listener 管理\n\n我们接着聊 servlet 规范里 listener。跟 filter 一样，listener 也是一种扩展机制，你可以监听容器内部发生的事件，主要有两类事件：\n\n * 第一类是生命状态的变化，比如 context 容器启动和停止、session 的创建和销毁。\n * 第二类是属性的变化，比如 context 容器某个属性值变了、session 的某个属性值变了以及新的请求来了等。\n\n我们可以在web.xml配置或者通过注解的方式来添加监听器，在监听器里实现我们的业务逻辑。对于 tomcat 来说，它需要读取配置文件，拿到监听器类的名字，实例化这些类，并且在合适的时机调用这些监听器的方法。\n\ntomcat 是通过 context 容器来管理这些监听器的。context 容器将两类事件分开来管理，分别用不同的集合来存放不同类型事件的监听器：\n\n// 监听属性值变化的监听器\nprivate list<object> applicationeventlistenerslist = new copyonwritearraylist<>();\n\n// 监听生命事件的监听器\nprivate object applicationlifecyclelistenersobjects[] = new object[0];\n\n\n剩下的事情就是触发监听器了，比如在 context 容器的启动方法里，就触发了所有的 servletcontextlistener：\n\n//1. 拿到所有的生命周期监听器\nobject instances[] = getapplicationlifecyclelisteners();\n\nfor (int i = 0; i < instances.length; i++) {\n   //2. 判断 listener 的类型是不是 servletcontextlistener\n   if (!(instances[i] instanceof servletcontextlistener))\n      continue;\n\n   //3. 触发 listener 的方法\n   servletcontextlistener lr = (servletcontextlistener) instances[i];\n   lr.contextinitialized(event);\n}\n\n\n需要注意的是，这里的 servletcontextlistener 接口是一种留给用户的扩展机制，用户可以实现这个接口来定义自己的监听器，监听 context 容器的启停事件。spring 就是这么做的。servletcontextlistener 跟 tomcat 自己的生命周期事件 lifecyclelistener 是不同的。lifecyclelistener 定义在生命周期管理组件中，由基类 lifecyclebase 统一管理。\n\n\n# tomcat 支持异步 servlet\n\n\n# 异步示例\n\n@webservlet(urlpatterns = {"/async"}, asyncsupported = true)\npublic class asyncservlet extends httpservlet {\n\n    //web 应用线程池，用来处理异步 servlet\n    executorservice executor = executors.newsinglethreadexecutor();\n\n    public void service(httpservletrequest req, httpservletresponse resp) {\n        //1. 调用 startasync 或者异步上下文\n        final asynccontext ctx = req.startasync();\n\n       // 用线程池来执行耗时操作\n        executor.execute(new runnable() {\n\n            @override\n            public void run() {\n\n                // 在这里做耗时的操作\n                try {\n                    ctx.getresponse().getwriter().println("handling async servlet");\n                } catch (ioexception e) {}\n\n                //3. 异步 servlet 处理完了调用异步上下文的 complete 方法\n                ctx.complete();\n            }\n\n        });\n    }\n}\n\n\n有三个要点：\n\n 1. 通过注解的方式来注册 servlet，除了 @webservlet 注解，还需要加上 asyncsupported=true 的属性，表明当前的 servlet 是一个异步 servlet。\n 2. web 应用程序需要调用 request 对象的 startasync 方法来拿到一个异步上下文 asynccontext。这个上下文保存了请求和响应对象。\n 3. web 应用需要开启一个新线程来处理耗时的操作，处理完成后需要调用 asynccontext 的 complete 方法。目的是告诉 tomcat，请求已经处理完成。\n\n这里请你注意，虽然异步 servlet 允许用更长的时间来处理请求，但是也有超时限制的，默认是 30 秒，如果 30 秒内请求还没处理完，tomcat 会触发超时机制，向浏览器返回超时错误，如果这个时候你的 web 应用再调用ctx.complete方法，会得到一个 illegalstateexception 异常。\n\n\n# 异步 servlet 原理\n\n通过上面的例子，相信你对 servlet 的异步实现有了基本的理解。要理解 tomcat 在这个过程都做了什么事情，关键就是要弄清楚req.startasync方法和ctx.complete方法都做了什么。\n\n# startasync 方法\n\nstartasync 方法其实就是创建了一个异步上下文 asynccontext 对象，asynccontext 对象的作用是保存请求的中间信息，比如 request 和 response 对象等上下文信息。你来思考一下为什么需要保存这些信息呢？\n\n这是因为 tomcat 的工作线程在request.startasync调用之后，就直接结束回到线程池中了，线程本身不会保存任何信息。也就是说一个请求到服务端，执行到一半，你的 web 应用正在处理，这个时候 tomcat 的工作线程没了，这就需要有个缓存能够保存原始的 request 和 response 对象，而这个缓存就是 asynccontext。\n\n有了 asynccontext，你的 web 应用通过它拿到 request 和 response 对象，拿到 request 对象后就可以读取请求信息，请求处理完了还需要通过 response 对象将 http 响应发送给浏览器。\n\n除了创建 asynccontext 对象，startasync 还需要完成一个关键任务，那就是告诉 tomcat 当前的 servlet 处理方法返回时，不要把响应发到浏览器，因为这个时候，响应还没生成呢；并且不能把 request 对象和 response 对象销毁，因为后面 web 应用还要用呢。\n\n在 tomcat 中，负责 flush 响应数据的是 coyoteadaptor，它还会销毁 request 对象和 response 对象，因此需要通过某种机制通知 coyoteadaptor，具体来说是通过下面这行代码：\n\nthis.request.getcoyoterequest().action(actioncode.async_start, this);\n\n\n你可以把它理解为一个 callback，在这个 action 方法里设置了 request 对象的状态，设置它为一个异步 servlet 请求。\n\n我们知道连接器是调用 coyoteadapter 的 service 方法来处理请求的，而 coyoteadapter 会调用容器的 service 方法，当容器的 service 方法返回时，coyoteadapter 判断当前的请求是不是异步 servlet 请求，如果是，就不会销毁 request 和 response 对象，也不会把响应信息发到浏览器。你可以通过下面的代码理解一下，这是 coyoteadapter 的 service 方法，我对它进行了简化：\n\npublic void service(org.apache.coyote.request req, org.apache.coyote.response res) {\n\n   // 调用容器的 service 方法处理请求\n    connector.getservice().getcontainer().getpipeline().\n           getfirst().invoke(request, response);\n\n   // 如果是异步 servlet 请求，仅仅设置一个标志，\n   // 否则说明是同步 servlet 请求，就将响应数据刷到浏览器\n    if (request.isasync()) {\n        async = true;\n    } else {\n        request.finishrequest();\n        response.finishresponse();\n    }\n\n   // 如果不是异步 servlet 请求，就销毁 request 对象和 response 对象\n    if (!async) {\n        request.recycle();\n        response.recycle();\n    }\n}\n\n\n接下来，当 coyoteadaptor 的 service 方法返回到 protocolhandler 组件时，protocolhandler 判断返回值，如果当前请求是一个异步 servlet 请求，它会把当前 socket 的协议处理者 processor 缓存起来，将 socketwrapper 对象和相应的 processor 存到一个 map 数据结构里。\n\nprivate final map<s,processor> connections = new concurrenthashmap<>();\n\n\n之所以要缓存是因为这个请求接下来还要接着处理，还是由原来的 processor 来处理，通过 socketwrapper 就能从 map 里找到相应的 processor。\n\n# complete 方法\n\n接着我们再来看关键的ctx.complete方法，当请求处理完成时，web 应用调用这个方法。那么这个方法做了些什么事情呢？最重要的就是把响应数据发送到浏览器。\n\n这件事情不能由 web 应用线程来做，也就是说ctx.complete方法不能直接把响应数据发送到浏览器，因为这件事情应该由 tomcat 线程来做，但具体怎么做呢？\n\n我们知道，连接器中的 endpoint 组件检测到有请求数据达到时，会创建一个 socketprocessor 对象交给线程池去处理，因此 endpoint 的通信处理和具体请求处理在两个线程里运行。\n\n在异步 servlet 的场景里，web 应用通过调用ctx.complete方法时，也可以生成一个新的 socketprocessor 任务类，交给线程池处理。对于异步 servlet 请求来说，相应的 socket 和协议处理组件 processor 都被缓存起来了，并且这些对象都可以通过 request 对象拿到。\n\n讲到这里，你可能已经猜到ctx.complete是如何实现的了：\n\npublic void complete() {\n    // 检查状态合法性，我们先忽略这句\n    check();\n\n    // 调用 request 对象的 action 方法，其实就是通知连接器，这个异步请求处理完了\nrequest.getcoyoterequest().action(actioncode.async_complete, null);\n\n}\n\n\n我们可以看到 complete 方法调用了 request 对象的 action 方法。而在 action 方法里，则是调用了 processor 的 processsocketevent 方法，并且传入了操作码 open_read。\n\ncase async_complete: {\n    cleardispatches();\n    if (asyncstatemachine.asynccomplete()) {\n        processsocketevent(socketevent.open_read, true);\n    }\n    break;\n}\n\n\n我们接着看 processsocketevent 方法，它调用 socketwrapper 的 processsocket 方法：\n\nprotected void processsocketevent(socketevent event, boolean dispatch) {\n    socketwrapperbase<?> socketwrapper = getsocketwrapper();\n    if (socketwrapper != null) {\n        socketwrapper.processsocket(event, dispatch);\n    }\n}\n\n\n而 socketwrapper 的 processsocket 方法会创建 socketprocessor 任务类，并通过 tomcat 线程池来处理：\n\npublic boolean processsocket(socketwrapperbase<s> socketwrapper,\n        socketevent event, boolean dispatch) {\n\n      if (socketwrapper == null) {\n          return false;\n      }\n\n      socketprocessorbase<s> sc = processorcache.pop();\n      if (sc == null) {\n          sc = createsocketprocessor(socketwrapper, event);\n      } else {\n          sc.reset(socketwrapper, event);\n      }\n      // 线程池运行\n      executor executor = getexecutor();\n      if (dispatch && executor != null) {\n          executor.execute(sc);\n      } else {\n          sc.run();\n      }\n}\n\n\n请你注意 createsocketprocessor 函数的第二个参数是 socketevent，这里我们传入的是 open_read。通过这个参数，我们就能控制 socketprocessor 的行为，因为我们不需要再把请求发送到容器进行处理，只需要向浏览器端发送数据，并且重新在这个 socket 上监听新的请求就行了。\n\n\n# 参考资料\n\n * 官方\n   * tomcat 官方网站\n   * tomcat wiki\n   * tomee 官方网站\n * 教程\n   * 深入拆解 tomcat & jetty',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Tomcat优化",frontmatter:{title:"Tomcat优化",categories:["编程","Java","服务器"],tags:["Java","JavaWeb","服务器","Tomcat"],abbrlink:"c37025e9",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/6c22f4/"},regularPath:"/02.JavaEE/02.%E6%9C%8D%E5%8A%A1%E5%99%A8/01.Tomcat/04.Tomcat%E4%BC%98%E5%8C%96.html",relativePath:"02.JavaEE/02.服务器/01.Tomcat/04.Tomcat优化.md",key:"v-2626d1fc",path:"/pages/6c22f4/",headers:[{level:2,title:"Tomcat 启动优化",slug:"tomcat-启动优化",normalizedTitle:"tomcat 启动优化",charIndex:16},{level:3,title:"清理 Tomcat",slug:"清理-tomcat",normalizedTitle:"清理 tomcat",charIndex:59},{level:3,title:"禁止 Tomcat TLD 扫描",slug:"禁止-tomcat-tld-扫描",normalizedTitle:"禁止 tomcat tld 扫描",charIndex:595},{level:3,title:"关闭 WebSocket 支持",slug:"关闭-websocket-支持",normalizedTitle:"关闭 websocket 支持",charIndex:1673},{level:3,title:"关闭 JSP 支持",slug:"关闭-jsp-支持",normalizedTitle:"关闭 jsp 支持",charIndex:2063},{level:3,title:"禁止扫描 Servlet 注解",slug:"禁止扫描-servlet-注解",normalizedTitle:"禁止扫描 servlet 注解",charIndex:2363},{level:3,title:"配置 Web-Fragment 扫描",slug:"配置-web-fragment-扫描",normalizedTitle:"配置 web-fragment 扫描",charIndex:2699},{level:3,title:"随机数熵源优化",slug:"随机数熵源优化",normalizedTitle:"随机数熵源优化",charIndex:3113},{level:3,title:"并行启动多个 Web 应用",slug:"并行启动多个-web-应用",normalizedTitle:"并行启动多个 web 应用",charIndex:3812},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:4273}],headersStr:"Tomcat 启动优化 清理 Tomcat 禁止 Tomcat TLD 扫描 关闭 WebSocket 支持 关闭 JSP 支持 禁止扫描 Servlet 注解 配置 Web-Fragment 扫描 随机数熵源优化 并行启动多个 Web 应用 参考资料",content:'# Tomcat 优化\n\n\n# Tomcat 启动优化\n\n如果 Tomcat 启动比较慢，可以考虑一些优化点\n\n\n# 清理 Tomcat\n\n * 清理不必要的 Web 应用：首先我们要做的是删除掉 webapps 文件夹下不需要的工程，一般是 host-manager、example、doc 等这些默认的工程，可能还有以前添加的但现在用不着的工程，最好把这些全都删除掉。\n * 清理 XML 配置文件：Tomcat 在启动时会解析所有的 XML 配置文件，解析 XML 较为耗时，所以应该尽量保持配置文件的简洁。\n * 清理 JAR 文件：JVM 的类加载器在加载类时，需要查找每一个 JAR 文件，去找到所需要的类。如果删除了不需要的 JAR 文件，查找的速度就会快一些。这里请注意：Web 应用中的 lib 目录下不应该出现 Servlet API 或者 Tomcat 自身的 JAR，这些 JAR 由 Tomcat 负责提供。\n * 清理其他文件：及时清理日志，删除 logs 文件夹下不需要的日志文件。同样还有 work 文件夹下的 catalina 文件夹，它其实是 Tomcat 把 JSP 转换为 Class 文件的工作目录。有时候我们也许会遇到修改了代码，重启了 Tomcat，但是仍没效果，这时候便可以删除掉这个文件夹，Tomcat 下次启动的时候会重新生成。\n\n\n# 禁止 Tomcat TLD 扫描\n\nTomcat 为了支持 JSP，在应用启动的时候会扫描 JAR 包里面的 TLD 文件，加载里面定义的标签库。所以在 Tomcat 的启动日志里，你可能会碰到这种提示：\n\n> At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.\n\nTomcat 的意思是，我扫描了你 Web 应用下的 JAR 包，发现 JAR 包里没有 TLD 文件。我建议配置一下 Tomcat 不要去扫描这些 JAR 包，这样可以提高 Tomcat 的启动速度，并节省 JSP 编译时间。\n\n如何配置不去扫描这些 JAR 包呢，这里分两种情况：\n\n * 如果你的项目没有使用 JSP 作为 Web 页面模板，而是使用 Velocity 之类的模板引擎，你完全可以把 TLD 扫描禁止掉。方法是，找到 Tomcat 的conf/目录下的context.xml文件，在这个文件里 Context 标签下，加上JarScanner和JarScanFilter子标签，像下面这样。\n   \n   <Context>\n      <JarScanner >\n         <JarScanFilter defaultTldScan="true" defaultpluggabilityScan="true" />\n      </JarScanner>\n   </Context>\n   \n\n * 如果你的项目使用了 JSP 作为 Web 页面模块，意味着 TLD 扫描无法避免，但是我们可以通过配置来告诉 Tomcat，只扫描那些包含 TLD 文件的 JAR 包。方法是，找到 Tomcat 的conf/目录下的catalina.properties文件，在这个文件里的 jarsToSkip 配置项中，加上你的 JAR 包。\n   \n   tomcat.util.scan.StandardJarScanFilter.jarsToSkip=xxx.jar\n   \n\n\n# 关闭 WebSocket 支持\n\nTomcat 会扫描 WebSocket 注解的 API 实现，比如 @ServerEndpoint 注解的类。如果不需要使用 WebSockets 就可以关闭它。具体方法是，找到 Tomcat 的 conf/ 目录下的 context.xml 文件，给 Context 标签加一个 containerSciFilter 的属性：\n\n<Context containerSciFilter="org.apache.tomcat.websocket.server.WsSci">\n...\n</Context>\n\n\n更进一步，如果你不需要 WebSockets 这个功能，你可以把 Tomcat lib 目录下的 websocket-api.jar 和 tomcat-websocket.jar 这两个 JAR 文件删除掉，进一步提高性能。\n\n\n# 关闭 JSP 支持\n\n如果不需要使用 JSP，可以关闭 JSP 功能：\n\n<Context containerSciFilter="org.apache.jasper.servlet.JasperInitializer">\n...\n</Context>\n\n\n如果要同时关闭 WebSocket 和 Jsp，可以这样配置：\n\n<Context containerSciFilter="org.apache.tomcat.websocket.server.WsSci | org.apache.jasper.servlet.JasperInitializer">\n...\n</Context>\n\n\n\n# 禁止扫描 Servlet 注解\n\nServlet 3.0 引入了注解 Servlet，Tomcat 为了支持这个特性，会在 Web 应用启动时扫描你的类文件，因此如果你没有使用 Servlet 注解这个功能，可以告诉 Tomcat 不要去扫描 Servlet 注解。具体配置方法是，在你的 Web 应用的web.xml文件中，设置<web-app>元素的属性metadata-complete="true"，像下面这样。\n\n<web-app metadata-complete="true">\n</web-app>\n\n\nmetadata-complete 的意思是，web.xml 里配置的 Servlet 是完整的，不需要再去库类中找 Servlet 的定义。\n\n\n# 配置 Web-Fragment 扫描\n\nServlet 3.0 还引入了“Web 模块部署描述符片段”的 web-fragment.xml，这是一个部署描述文件，可以完成 web.xml 的配置功能。而这个 web-fragment.xml 文件必须存放在 JAR 文件的 META-INF 目录下，而 JAR 包通常放在 WEB-INF/lib 目录下，因此 Tomcat 需要对 JAR 文件进行扫描才能支持这个功能。\n\n可以通过配置 web.xml 里面的 <absolute-ordering> 元素直接指定了哪些 JAR 包需要扫描 web fragment，如果 <absolute-ordering/> 元素是空的， 则表示不需要扫描，像下面这样。\n\n<web-app metadata-complete="true">\n...\n<absolute-ordering />\n...\n</web-app>\n\n\n\n# 随机数熵源优化\n\nTomcat 7 以上的版本依赖 Java 的 SecureRandom 类来生成随机数，比如 Session ID。而 JVM 默认使用阻塞式熵源（/dev/random）， 在某些情况下就会导致 Tomcat 启动变慢。当阻塞时间较长时， 你会看到这样一条警告日志：\n\n<DATE> org.apache.catalina.util.SessionIdGenerator createSecureRandom\nINFO: Creation of SecureRandom instance for session ID generation using [SHA1PRNG] took [8152] milliseconds.\n\n\n解决方案是通过设置，让 JVM 使用非阻塞式的熵源。\n\n我们可以设置 JVM 的参数：\n\n-Djava.security.egd=file:/dev/./urandom\n\n\n或者是设置 java.security 文件，位于 $JAVA_HOME/jre/lib/security 目录之下： securerandom.source=file:/dev/./urandom\n\n这里请你注意，/dev/./urandom 中间有个 ./ 的原因是 Oracle JRE 中的 Bug，Java 8 里面的 SecureRandom 类已经修正这个 Bug。 阻塞式的熵源（/dev/random）安全性较高， 非阻塞式的熵源（/dev/./urandom）安全性会低一些，因为如果你对随机数的要求比较高， 可以考虑使用硬件方式生成熵源。\n\n\n# 并行启动多个 Web 应用\n\nTomcat 启动的时候，默认情况下 Web 应用都是一个一个启动的，等所有 Web 应用全部启动完成，Tomcat 才算启动完毕。如果在一个 Tomcat 下有多个 Web 应用，为了优化启动速度，你可以配置多个应用程序并行启动，可以通过修改 server.xml 中 Host 元素的 startStopThreads 属性来完成。startStopThreads 的值表示你想用多少个线程来启动你的 Web 应用，如果设成 0 表示你要并行启动 Web 应用，像下面这样的配置。\n\n<Engine startStopThreads="0">\n    ...\n    <Host startStopThreads="0">\n        ...\n    </Host>\n    ...\n</Engine>\n\n\n需要注意的是，Engine 元素里也配置了这个参数，这意味着如果你的 Tomcat 配置了多个 Host（虚拟主机），Tomcat 会以并行的方式启动多个 Host。\n\n\n# 参考资料\n\n * 官方\n   * Tomcat 官方网站\n   * Tomcat Wiki\n   * Tomee 官方网站\n * 教程\n   * 深入拆解 Tomcat & Jetty',normalizedContent:'# tomcat 优化\n\n\n# tomcat 启动优化\n\n如果 tomcat 启动比较慢，可以考虑一些优化点\n\n\n# 清理 tomcat\n\n * 清理不必要的 web 应用：首先我们要做的是删除掉 webapps 文件夹下不需要的工程，一般是 host-manager、example、doc 等这些默认的工程，可能还有以前添加的但现在用不着的工程，最好把这些全都删除掉。\n * 清理 xml 配置文件：tomcat 在启动时会解析所有的 xml 配置文件，解析 xml 较为耗时，所以应该尽量保持配置文件的简洁。\n * 清理 jar 文件：jvm 的类加载器在加载类时，需要查找每一个 jar 文件，去找到所需要的类。如果删除了不需要的 jar 文件，查找的速度就会快一些。这里请注意：web 应用中的 lib 目录下不应该出现 servlet api 或者 tomcat 自身的 jar，这些 jar 由 tomcat 负责提供。\n * 清理其他文件：及时清理日志，删除 logs 文件夹下不需要的日志文件。同样还有 work 文件夹下的 catalina 文件夹，它其实是 tomcat 把 jsp 转换为 class 文件的工作目录。有时候我们也许会遇到修改了代码，重启了 tomcat，但是仍没效果，这时候便可以删除掉这个文件夹，tomcat 下次启动的时候会重新生成。\n\n\n# 禁止 tomcat tld 扫描\n\ntomcat 为了支持 jsp，在应用启动的时候会扫描 jar 包里面的 tld 文件，加载里面定义的标签库。所以在 tomcat 的启动日志里，你可能会碰到这种提示：\n\n> at least one jar was scanned for tlds yet contained no tlds. enable debug logging for this logger for a complete list of jars that were scanned but no tlds were found in them. skipping unneeded jars during scanning can improve startup time and jsp compilation time.\n\ntomcat 的意思是，我扫描了你 web 应用下的 jar 包，发现 jar 包里没有 tld 文件。我建议配置一下 tomcat 不要去扫描这些 jar 包，这样可以提高 tomcat 的启动速度，并节省 jsp 编译时间。\n\n如何配置不去扫描这些 jar 包呢，这里分两种情况：\n\n * 如果你的项目没有使用 jsp 作为 web 页面模板，而是使用 velocity 之类的模板引擎，你完全可以把 tld 扫描禁止掉。方法是，找到 tomcat 的conf/目录下的context.xml文件，在这个文件里 context 标签下，加上jarscanner和jarscanfilter子标签，像下面这样。\n   \n   <context>\n      <jarscanner >\n         <jarscanfilter defaulttldscan="true" defaultpluggabilityscan="true" />\n      </jarscanner>\n   </context>\n   \n\n * 如果你的项目使用了 jsp 作为 web 页面模块，意味着 tld 扫描无法避免，但是我们可以通过配置来告诉 tomcat，只扫描那些包含 tld 文件的 jar 包。方法是，找到 tomcat 的conf/目录下的catalina.properties文件，在这个文件里的 jarstoskip 配置项中，加上你的 jar 包。\n   \n   tomcat.util.scan.standardjarscanfilter.jarstoskip=xxx.jar\n   \n\n\n# 关闭 websocket 支持\n\ntomcat 会扫描 websocket 注解的 api 实现，比如 @serverendpoint 注解的类。如果不需要使用 websockets 就可以关闭它。具体方法是，找到 tomcat 的 conf/ 目录下的 context.xml 文件，给 context 标签加一个 containerscifilter 的属性：\n\n<context containerscifilter="org.apache.tomcat.websocket.server.wssci">\n...\n</context>\n\n\n更进一步，如果你不需要 websockets 这个功能，你可以把 tomcat lib 目录下的 websocket-api.jar 和 tomcat-websocket.jar 这两个 jar 文件删除掉，进一步提高性能。\n\n\n# 关闭 jsp 支持\n\n如果不需要使用 jsp，可以关闭 jsp 功能：\n\n<context containerscifilter="org.apache.jasper.servlet.jasperinitializer">\n...\n</context>\n\n\n如果要同时关闭 websocket 和 jsp，可以这样配置：\n\n<context containerscifilter="org.apache.tomcat.websocket.server.wssci | org.apache.jasper.servlet.jasperinitializer">\n...\n</context>\n\n\n\n# 禁止扫描 servlet 注解\n\nservlet 3.0 引入了注解 servlet，tomcat 为了支持这个特性，会在 web 应用启动时扫描你的类文件，因此如果你没有使用 servlet 注解这个功能，可以告诉 tomcat 不要去扫描 servlet 注解。具体配置方法是，在你的 web 应用的web.xml文件中，设置<web-app>元素的属性metadata-complete="true"，像下面这样。\n\n<web-app metadata-complete="true">\n</web-app>\n\n\nmetadata-complete 的意思是，web.xml 里配置的 servlet 是完整的，不需要再去库类中找 servlet 的定义。\n\n\n# 配置 web-fragment 扫描\n\nservlet 3.0 还引入了“web 模块部署描述符片段”的 web-fragment.xml，这是一个部署描述文件，可以完成 web.xml 的配置功能。而这个 web-fragment.xml 文件必须存放在 jar 文件的 meta-inf 目录下，而 jar 包通常放在 web-inf/lib 目录下，因此 tomcat 需要对 jar 文件进行扫描才能支持这个功能。\n\n可以通过配置 web.xml 里面的 <absolute-ordering> 元素直接指定了哪些 jar 包需要扫描 web fragment，如果 <absolute-ordering/> 元素是空的， 则表示不需要扫描，像下面这样。\n\n<web-app metadata-complete="true">\n...\n<absolute-ordering />\n...\n</web-app>\n\n\n\n# 随机数熵源优化\n\ntomcat 7 以上的版本依赖 java 的 securerandom 类来生成随机数，比如 session id。而 jvm 默认使用阻塞式熵源（/dev/random）， 在某些情况下就会导致 tomcat 启动变慢。当阻塞时间较长时， 你会看到这样一条警告日志：\n\n<date> org.apache.catalina.util.sessionidgenerator createsecurerandom\ninfo: creation of securerandom instance for session id generation using [sha1prng] took [8152] milliseconds.\n\n\n解决方案是通过设置，让 jvm 使用非阻塞式的熵源。\n\n我们可以设置 jvm 的参数：\n\n-djava.security.egd=file:/dev/./urandom\n\n\n或者是设置 java.security 文件，位于 $java_home/jre/lib/security 目录之下： securerandom.source=file:/dev/./urandom\n\n这里请你注意，/dev/./urandom 中间有个 ./ 的原因是 oracle jre 中的 bug，java 8 里面的 securerandom 类已经修正这个 bug。 阻塞式的熵源（/dev/random）安全性较高， 非阻塞式的熵源（/dev/./urandom）安全性会低一些，因为如果你对随机数的要求比较高， 可以考虑使用硬件方式生成熵源。\n\n\n# 并行启动多个 web 应用\n\ntomcat 启动的时候，默认情况下 web 应用都是一个一个启动的，等所有 web 应用全部启动完成，tomcat 才算启动完毕。如果在一个 tomcat 下有多个 web 应用，为了优化启动速度，你可以配置多个应用程序并行启动，可以通过修改 server.xml 中 host 元素的 startstopthreads 属性来完成。startstopthreads 的值表示你想用多少个线程来启动你的 web 应用，如果设成 0 表示你要并行启动 web 应用，像下面这样的配置。\n\n<engine startstopthreads="0">\n    ...\n    <host startstopthreads="0">\n        ...\n    </host>\n    ...\n</engine>\n\n\n需要注意的是，engine 元素里也配置了这个参数，这意味着如果你的 tomcat 配置了多个 host（虚拟主机），tomcat 会以并行的方式启动多个 host。\n\n\n# 参考资料\n\n * 官方\n   * tomcat 官方网站\n   * tomcat wiki\n   * tomee 官方网站\n * 教程\n   * 深入拆解 tomcat & jetty',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Tomcat 和 Jetty",frontmatter:{title:"Tomcat 和 Jetty",categories:["编程","Java","服务器"],tags:["Java","JavaWeb","服务器","Tomcat","Jetty"],abbrlink:"a6fd024b",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/f1bba6/"},regularPath:"/02.JavaEE/02.%E6%9C%8D%E5%8A%A1%E5%99%A8/01.Tomcat/05.Tomcat%E5%92%8CJetty.html",relativePath:"02.JavaEE/02.服务器/01.Tomcat/05.Tomcat和Jetty.md",key:"v-34fe61e4",path:"/pages/f1bba6/",headers:[{level:2,title:"Tomcat 和 Jetty",slug:"tomcat-和-jetty",normalizedTitle:"tomcat 和 jetty",charIndex:2},{level:2,title:"Web 容器",slug:"web-容器",normalizedTitle:"web 容器",charIndex:18}],headersStr:"Tomcat 和 Jetty Web 容器",content:"# Tomcat 和 Jetty\n\nWeb 容器 Tomcat 或 Jetty，作为重要的系统中间件，连接着浏览器和你的 Web 应用，并且支撑着 Web 程序的运行，可以说，弄懂了 Tomcat 和 Jetty 的原理，Java Web 开发对你来说就毫无秘密可言。\n\n\n# Web 容器\n\n早期的 Web 应用主要用于浏览新闻等静态页面，HTTP 服务器（比如 Apache、Nginx）向浏览器返回静态 HTML，浏览器负责解析 HTML，将结果呈现给用户。\n\n随着互联网的发展，我们已经不满足于仅仅浏览静态页面，还希望通过一些交互操作，来获取动态结果，因此也就需要一些扩展机制能够让 HTTP 服务器调用服务端程序。\n\n于是 Sun 公司推出了 Servlet 技术。你可以把 Servlet 简单理解为运行在服务端的 Java 小程序，但是 Servlet 没有 main 方法，不能独立运行，因此必须把它部署到 Servlet 容器中，由容器来实例化并调用 Servlet。\n\n而 Tomcat 和 Jetty 就是一个 Servlet 容器。为了方便使用，它们也具有 HTTP 服务器的功能，因此Tomcat 或者 Jetty 就是一个“HTTP 服务器 + Servlet 容器”，我们也叫它们 Web 容器。\n\n其他应用服务器比如 JBoss 和 WebLogic，它们不仅仅有 Servlet 容器的功能，也包含 EJB 容器，是完整的 Java EE 应用服务器。从这个角度看，Tomcat 和 Jetty 算是一个轻量级的应用服务器。\n\n在微服务架构日渐流行的今天，开发人员更喜欢稳定的、轻量级的应用服务器，并且应用程序用内嵌的方式来运行 Servlet 容器也逐渐流行起来。之所以选择轻量级，是因为在微服务架构下，我们把一个大而全的单体应用，拆分成一个个功能单一的微服务，在这个过程中，服务的数量必然要增加，但为了减少资源的消耗，并且降低部署的成本，我们希望运行服务的 Web 容器也是轻量级的，Web 容器本身应该消耗较少的内存和 CPU 资源，并且由应用本身来启动一个嵌入式的 Web 容器，而不是通过 Web 容器来部署和启动应用，这样可以降低应用部署的复杂度。",normalizedContent:"# tomcat 和 jetty\n\nweb 容器 tomcat 或 jetty，作为重要的系统中间件，连接着浏览器和你的 web 应用，并且支撑着 web 程序的运行，可以说，弄懂了 tomcat 和 jetty 的原理，java web 开发对你来说就毫无秘密可言。\n\n\n# web 容器\n\n早期的 web 应用主要用于浏览新闻等静态页面，http 服务器（比如 apache、nginx）向浏览器返回静态 html，浏览器负责解析 html，将结果呈现给用户。\n\n随着互联网的发展，我们已经不满足于仅仅浏览静态页面，还希望通过一些交互操作，来获取动态结果，因此也就需要一些扩展机制能够让 http 服务器调用服务端程序。\n\n于是 sun 公司推出了 servlet 技术。你可以把 servlet 简单理解为运行在服务端的 java 小程序，但是 servlet 没有 main 方法，不能独立运行，因此必须把它部署到 servlet 容器中，由容器来实例化并调用 servlet。\n\n而 tomcat 和 jetty 就是一个 servlet 容器。为了方便使用，它们也具有 http 服务器的功能，因此tomcat 或者 jetty 就是一个“http 服务器 + servlet 容器”，我们也叫它们 web 容器。\n\n其他应用服务器比如 jboss 和 weblogic，它们不仅仅有 servlet 容器的功能，也包含 ejb 容器，是完整的 java ee 应用服务器。从这个角度看，tomcat 和 jetty 算是一个轻量级的应用服务器。\n\n在微服务架构日渐流行的今天，开发人员更喜欢稳定的、轻量级的应用服务器，并且应用程序用内嵌的方式来运行 servlet 容器也逐渐流行起来。之所以选择轻量级，是因为在微服务架构下，我们把一个大而全的单体应用，拆分成一个个功能单一的微服务，在这个过程中，服务的数量必然要增加，但为了减少资源的消耗，并且降低部署的成本，我们希望运行服务的 web 容器也是轻量级的，web 容器本身应该消耗较少的内存和 cpu 资源，并且由应用本身来启动一个嵌入式的 web 容器，而不是通过 web 容器来部署和启动应用，这样可以降低应用部署的复杂度。",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Tomcat 教程",frontmatter:{title:"Tomcat 教程",categories:["编程","Java","服务器"],tags:["Java","JavaWeb","服务器","Tomcat"],hidden:!0,abbrlink:"3804ebfc",date:"2022-02-18T08:53:11.000Z",permalink:"/pages/86288e/"},regularPath:"/02.JavaEE/02.%E6%9C%8D%E5%8A%A1%E5%99%A8/01.Tomcat/",relativePath:"02.JavaEE/02.服务器/01.Tomcat/README.md",key:"v-00b2ebc6",path:"/pages/86288e/",headers:[{level:2,title:"📖 内容",slug:"📖-内容",normalizedTitle:"📖 内容",charIndex:16},{level:2,title:"📚 资料",slug:"📚-资料",normalizedTitle:"📚 资料",charIndex:100},{level:2,title:"🚪 传送",slug:"🚪-传送",normalizedTitle:"🚪 传送",charIndex:147}],headersStr:"📖 内容 📚 资料 🚪 传送",content:"# Tomcat 教程\n\n\n# 📖 内容\n\n * Tomcat 快速入门\n * Tomcat 连接器\n * Tomcat 容器\n * Tomcat 优化\n * Tomcat 和 Jetty\n\n\n# 📚 资料\n\n * Tomcat 官网\n * 深入拆解 Tomcat & Jetty\n\n\n# 🚪 传送\n\n◾ 🏠 JAVA-TUTORIAL 首页 ◾ 🎯 我的博客 ◾",normalizedContent:"# tomcat 教程\n\n\n# 📖 内容\n\n * tomcat 快速入门\n * tomcat 连接器\n * tomcat 容器\n * tomcat 优化\n * tomcat 和 jetty\n\n\n# 📚 资料\n\n * tomcat 官网\n * 深入拆解 tomcat & jetty\n\n\n# 🚪 传送\n\n◾ 🏠 java-tutorial 首页 ◾ 🎯 我的博客 ◾",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Jetty 快速入门",frontmatter:{title:"Jetty 快速入门",categories:["编程","Java","服务器"],tags:["Java","JavaWeb","服务器","Jetty"],abbrlink:"9709eee9",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/9ecdc1/"},regularPath:"/02.JavaEE/02.%E6%9C%8D%E5%8A%A1%E5%99%A8/02.Jetty.html",relativePath:"02.JavaEE/02.服务器/02.Jetty.md",key:"v-612590a5",path:"/pages/9ecdc1/",headers:[{level:2,title:"Jetty 简介",slug:"jetty-简介",normalizedTitle:"jetty 简介",charIndex:17},{level:2,title:"Jetty 的使用",slug:"jetty-的使用",normalizedTitle:"jetty 的使用",charIndex:437},{level:3,title:"API 方式",slug:"api-方式",normalizedTitle:"api 方式",charIndex:514},{level:3,title:"Maven 插件方式",slug:"maven-插件方式",normalizedTitle:"maven 插件方式",charIndex:2878},{level:2,title:"Jetty 的架构",slug:"jetty-的架构",normalizedTitle:"jetty 的架构",charIndex:5677},{level:3,title:"Jetty 架构简介",slug:"jetty-架构简介",normalizedTitle:"jetty 架构简介",charIndex:5691},{level:3,title:"Jetty 和 Tomcat 架构区别",slug:"jetty-和-tomcat-架构区别",normalizedTitle:"jetty 和 tomcat 架构区别",charIndex:6242},{level:3,title:"Connector 组件",slug:"connector-组件",normalizedTitle:"connector 组件",charIndex:5824},{level:4,title:"Acceptor",slug:"acceptor",normalizedTitle:"acceptor",charIndex:6803},{level:3,title:"Handler 组件",slug:"handler-组件",normalizedTitle:"handler 组件",charIndex:5838},{level:4,title:"Handler 继承关系",slug:"handler-继承关系",normalizedTitle:"handler 继承关系",charIndex:11406},{level:4,title:"实现 Servlet 规范",slug:"实现-servlet-规范",normalizedTitle:"实现 servlet 规范",charIndex:12865},{level:2,title:"Jetty 的线程策略",slug:"jetty-的线程策略",normalizedTitle:"jetty 的线程策略",charIndex:13927},{level:3,title:"传统 Selector 编程模型",slug:"传统-selector-编程模型",normalizedTitle:"传统 selector 编程模型",charIndex:13943},{level:3,title:"Jetty 的 Selector 编程模型",slug:"jetty-的-selector-编程模型",normalizedTitle:"jetty 的 selector 编程模型",charIndex:14210},{level:4,title:"ManagedSelector",slug:"managedselector",normalizedTitle:"managedselector",charIndex:8042},{level:4,title:"SelectorUpdate 接口",slug:"selectorupdate-接口",normalizedTitle:"selectorupdate 接口",charIndex:15533},{level:4,title:"Selectable 接口",slug:"selectable-接口",normalizedTitle:"selectable 接口",charIndex:16671},{level:4,title:"ExecutionStrategy",slug:"executionstrategy",normalizedTitle:"executionstrategy",charIndex:15206},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:20913}],headersStr:"Jetty 简介 Jetty 的使用 API 方式 Maven 插件方式 Jetty 的架构 Jetty 架构简介 Jetty 和 Tomcat 架构区别 Connector 组件 Acceptor Handler 组件 Handler 继承关系 实现 Servlet 规范 Jetty 的线程策略 传统 Selector 编程模型 Jetty 的 Selector 编程模型 ManagedSelector SelectorUpdate 接口 Selectable 接口 ExecutionStrategy 参考资料",content:'# Jetty 快速入门\n\n\n# Jetty 简介\n\njetty 是什么？\n\njetty 是轻量级的 web 服务器和 servlet 引擎。\n\n它的最大特点是：可以很方便的作为嵌入式服务器。\n\n它是 eclipse 的一个开源项目。不用怀疑，就是你常用的那个 eclipse。\n\n它是使用 Java 开发的，所以天然对 Java 支持良好。\n\n官方网址\n\ngithub 源码地址\n\n什么是嵌入式服务器？\n\n以 jetty 来说明，就是只要引入 jetty 的 jar 包，可以通过直接调用其 API 的方式来启动 web 服务。\n\n用过 Tomcat、Resin 等服务器的朋友想必不会陌生那一套安装、配置、部署的流程吧，还是挺繁琐的。使用 jetty，就不需要这些过程了。\n\njetty 非常适用于项目的开发、测试，因为非常快捷。如果想用于生产环境，则需要谨慎考虑，它不一定能像成熟的 Tomcat、Resin 等服务器一样支持企业级 Java EE 的需要。\n\n\n# Jetty 的使用\n\n我觉得嵌入式启动方式的一个好处在于：可以直接运行项目，无需每次部署都得再配置服务器。\n\njetty 的嵌入式启动使用有两种方式：\n\nAPI 方式\n\nmaven 插件方式\n\n\n# API 方式\n\n添加 maven 依赖\n\n<dependency>\n  <groupId>org.eclipse.jetty</groupId>\n  <artifactId>jetty-webapp</artifactId>\n  <version>9.3.2.v20150730</version>\n  <scope>test</scope>\n</dependency>\n<dependency>\n  <groupId>org.eclipse.jetty</groupId>\n  <artifactId>jetty-annotations</artifactId>\n  <version>9.3.2.v20150730</version>\n  <scope>test</scope>\n</dependency>\n<dependency>\n  <groupId>org.eclipse.jetty</groupId>\n  <artifactId>apache-jsp</artifactId>\n  <version>9.3.2.v20150730</version>\n  <scope>test</scope>\n</dependency>\n<dependency>\n  <groupId>org.eclipse.jetty</groupId>\n  <artifactId>apache-jstl</artifactId>\n  <version>9.3.2.v20150730</version>\n  <scope>test</scope>\n</dependency>\n\n\n官方的启动代码\n\npublic class SplitFileServer\n{\n    public static void main( String[] args ) throws Exception\n    {\n        // 创建Server对象，并绑定端口\n        Server server = new Server();\n        ServerConnector connector = new ServerConnector(server);\n        connector.setPort(8090);\n        server.setConnectors(new Connector[] { connector });\n\n        // 创建上下文句柄，绑定上下文路径。这样启动后的url就会是:http://host:port/context\n        ResourceHandler rh0 = new ResourceHandler();\n        ContextHandler context0 = new ContextHandler();\n        context0.setContextPath("/");\n\n        // 绑定测试资源目录（在本例的配置目录dir0的路径是src/test/resources/dir0）\n        File dir0 = MavenTestingUtils.getTestResourceDir("dir0");\n        context0.setBaseResource(Resource.newResource(dir0));\n        context0.setHandler(rh0);\n\n        // 和上面的例子一样\n        ResourceHandler rh1 = new ResourceHandler();\n        ContextHandler context1 = new ContextHandler();\n        context1.setContextPath("/");\n        File dir1 = MavenTestingUtils.getTestResourceDir("dir1");\n        context1.setBaseResource(Resource.newResource(dir1));\n        context1.setHandler(rh1);\n\n        // 绑定两个资源句柄\n        ContextHandlerCollection contexts = new ContextHandlerCollection();\n        contexts.setHandlers(new Handler[] { context0, context1 });\n        server.setHandler(contexts);\n\n        // 启动\n        server.start();\n\n        // 打印dump时的信息\n        System.out.println(server.dump());\n\n        // join当前线程\n        server.join();\n    }\n}\n\n\n直接运行 Main 方法，就可以启动 web 服务。\n\n注：以上代码在 eclipse 中运行没有问题，如果想在 Intellij 中运行还需要为它指定配置文件。\n\n如果想了解在 Eclipse 和 Intellij 都能运行的通用方法可以参考我的 github 代码示例。\n\n我的实现也是参考 springside 的方式。\n\n代码行数有点多，不在这里贴代码了。\n\n完整参考代码\n\n\n# Maven 插件方式\n\n如果你熟悉 maven，那么实在太简单了\n\n注： Maven 版本必须在 3.3 及以上版本。\n\n(1) 添加 maven 插件\n\n<plugin>\n  <groupId>org.eclipse.jetty</groupId>\n  <artifactId>jetty-maven-plugin</artifactId>\n  <version>9.3.12.v20160915</version>\n</plugin>\n\n\n(2) 执行 maven 命令：\n\nmvn jetty:run\n\n\n讲真，就是这么简单。jetty 默认会为你创建一个 web 服务，地址为 127.0.0.1:8080。\n\n当然，你也可以在插件中配置你的 webapp 环境\n\n<plugin>\n  <groupId>org.eclipse.jetty</groupId>\n  <artifactId>jetty-maven-plugin</artifactId>\n  <version>9.3.12.v20160915</version>\n\n  <configuration>\n <webAppSourceDirectory>${project.basedir}/src/staticfiles</webAppSourceDirectory>\n\n    \x3c!-- 配置webapp --\x3e\n <webApp>\n   <contextPath>/</contextPath>\n   <descriptor>${project.basedir}/src/over/here/web.xml</descriptor>\n   <jettyEnvXml>${project.basedir}/src/over/here/jetty-env.xml</jettyEnvXml>\n </webApp>\n\n    \x3c!-- 配置classes --\x3e\n <classesDirectory>${project.basedir}/somewhere/else</classesDirectory>\n <scanClassesPattern>\n   <excludes>\n  <exclude>**/Foo.class</exclude>\n   </excludes>\n </scanClassesPattern>\n <scanTargets>\n   <scanTarget>src/mydir</scanTarget>\n   <scanTarget>src/myfile.txt</scanTarget>\n </scanTargets>\n\n    \x3c!-- 扫描target目录下的资源文件 --\x3e\n <scanTargetPatterns>\n   <scanTargetPattern>\n <directory>src/other-resources</directory>\n <includes>\n   <include>**/*.xml</include>\n   <include>**/*.properties</include>\n </includes>\n <excludes>\n   <exclude>**/myspecial.xml</exclude>\n   <exclude>**/myspecial.properties</exclude>\n </excludes>\n   </scanTargetPattern>\n </scanTargetPatterns>\n  </configuration>\n</plugin>\n\n\n官方给的 jetty-env.xml 范例\n\n <?xml version="1.0"?>\n <!DOCTYPE Configure PUBLIC "-//Mort Bay Consulting//DTD Configure//EN" "http://jetty.mortbay.org/configure.dtd">\n\n <Configure class="org.eclipse.jetty.webapp.WebAppContext">\n\n   \x3c!-- Add an EnvEntry only valid for this webapp               --\x3e\n   <New id="gargle"  class="org.eclipse.jetty.plus.jndi.EnvEntry">\n     <Arg>gargle</Arg>\n     <Arg type="java.lang.Double">100</Arg>\n     <Arg type="boolean">true</Arg>\n   </New>\n\n  \x3c!-- Add an override for a global EnvEntry                           --\x3e\n   <New id="wiggle"  class="org.eclipse.jetty.plus.jndi.EnvEntry">\n     <Arg>wiggle</Arg>\n     <Arg type="java.lang.Double">55.0</Arg>\n     <Arg type="boolean">true</Arg>\n   </New>\n\n   \x3c!-- an XADataSource                                                --\x3e\n   <New id="mydatasource99" class="org.eclipse.jetty.plus.jndi.Resource">\n     <Arg>jdbc/mydatasource99</Arg>\n     <Arg>\n       <New class="com.atomikos.jdbc.SimpleDataSourceBean">\n         <Set name="xaDataSourceClassName">org.apache.derby.jdbc.EmbeddedXADataSource</Set>\n         <Set name="xaDataSourceProperties">databaseName=testdb99;createDatabase=create</Set>\n         <Set name="UniqueResourceName">mydatasource99</Set>\n       </New>\n     </Arg>\n   </New>\n\n </Configure>\n\n\n\n# Jetty 的架构\n\n\n# Jetty 架构简介\n\n\n\nJetty Server 就是由多个 Connector（连接器）、多个 Handler（处理器），以及一个线程池组成。\n\n跟 Tomcat 一样，Jetty 也有 HTTP 服务器和 Servlet 容器的功能，因此 Jetty 中的 Connector 组件和 Handler 组件分别来实现这两个功能，而这两个组件工作时所需要的线程资源都直接从一个全局线程池 ThreadPool 中获取。\n\nJetty Server 可以有多个 Connector 在不同的端口上监听客户请求，而对于请求处理的 Handler 组件，也可以根据具体场景使用不同的 Handler。这样的设计提高了 Jetty 的灵活性，需要支持 Servlet，则可以使用 ServletHandler；需要支持 Session，则再增加一个 SessionHandler。也就是说我们可以不使用 Servlet 或者 Session，只要不配置这个 Handler 就行了。\n\n为了启动和协调上面的核心组件工作，Jetty 提供了一个 Server 类来做这个事情，它负责创建并初始化 Connector、Handler、ThreadPool 组件，然后调用 start 方法启动它们。\n\n\n# Jetty 和 Tomcat 架构区别\n\n对比一下 Tomcat 的整体架构图，你会发现 Tomcat 在整体上跟 Jetty 很相似，它们的第一个区别是 Jetty 中没有 Service 的概念，Tomcat 中的 Service 包装了多个连接器和一个容器组件，一个 Tomcat 实例可以配置多个 Service，不同的 Service 通过不同的连接器监听不同的端口；而 Jetty 中 Connector 是被所有 Handler 共享的。\n\n第二个区别是，在 Tomcat 中每个连接器都有自己的线程池，而在 Jetty 中所有的 Connector 共享一个全局的线程池。\n\n\n# Connector 组件\n\n跟 Tomcat 一样，Connector 的主要功能是对 I/O 模型和应用层协议的封装。I/O 模型方面，最新的 Jetty 9 版本只支持 NIO，因此 Jetty 的 Connector 设计有明显的 Java NIO 通信模型的痕迹。至于应用层协议方面，跟 Tomcat 的 Processor 一样，Jetty 抽象出了 Connection 组件来封装应用层协议的差异。\n\n服务端在 NIO 通信上主要完成了三件事情：监听连接、I/O 事件查询以及数据读写。因此 Jetty 设计了Acceptor、SelectorManager 和 Connection 来分别做这三件事情\n\n# Acceptor\n\nAcceptor 用于接受请求。跟 Tomcat 一样，Jetty 也有独立的 Acceptor 线程组用于处理连接请求。在 Connector 的实现类 ServerConnector 中，有一个 _acceptors 的数组，在 Connector 启动的时候, 会根据 _acceptors 数组的长度创建对应数量的 Acceptor，而 Acceptor 的个数可以配置。\n\nfor (int i = 0; i < _acceptors.length; i++)\n{\n  Acceptor a = new Acceptor(i);\n  getExecutor().execute(a);\n}\n\n\nAcceptor 是 ServerConnector 中的一个内部类，同时也是一个 Runnable，Acceptor 线程是通过 getExecutor() 得到的线程池来执行的，前面提到这是一个全局的线程池。\n\nAcceptor 通过阻塞的方式来接受连接，这一点跟 Tomcat 也是一样的。\n\npublic void accept(int acceptorID) throws IOException\n{\n  ServerSocketChannel serverChannel = _acceptChannel;\n  if (serverChannel != null && serverChannel.isOpen())\n  {\n    // 这里是阻塞的\n    SocketChannel channel = serverChannel.accept();\n    // 执行到这里时说明有请求进来了\n    accepted(channel);\n  }\n}\n\n\n接受连接成功后会调用 accepted() 函数，accepted() 函数中会将 SocketChannel 设置为非阻塞模式，然后交给 Selector 去处理，因此这也就到了 Selector 的地界了。\n\nprivate void accepted(SocketChannel channel) throws IOException\n{\n    channel.configureBlocking(false);\n    Socket socket = channel.socket();\n    configure(socket);\n    // _manager 是 SelectorManager 实例，里面管理了所有的 Selector 实例\n    _manager.accept(channel);\n}\n\n\nSelectorManager\n\nJetty 的 Selector 由 SelectorManager 类管理，而被管理的 Selector 叫作 ManagedSelector。SelectorManager 内部有一个 ManagedSelector 数组，真正干活的是 ManagedSelector。咱们接着上面分析，看看在 SelectorManager 在 accept 方法里做了什么。\n\npublic void accept(SelectableChannel channel, Object attachment)\n{\n  // 选择一个 ManagedSelector 来处理 Channel\n  final ManagedSelector selector = chooseSelector();\n  // 提交一个任务 Accept 给 ManagedSelector\n  selector.submit(selector.new Accept(channel, attachment));\n}\n\n\nSelectorManager 从本身的 Selector 数组中选择一个 Selector 来处理这个 Channel，并创建一个任务 Accept 交给 ManagedSelector，ManagedSelector 在处理这个任务主要做了两步：\n\n第一步，调用 Selector 的 register 方法把 Channel 注册到 Selector 上，拿到一个 SelectionKey。\n\n _key = _channel.register(selector, SelectionKey.OP_ACCEPT, this);\n\n\n第二步，创建一个 EndPoint 和 Connection，并跟这个 SelectionKey（Channel）绑在一起：\n\nprivate void createEndPoint(SelectableChannel channel, SelectionKey selectionKey) throws IOException\n{\n    //1. 创建 Endpoint\n    EndPoint endPoint = _selectorManager.newEndPoint(channel, this, selectionKey);\n\n    //2. 创建 Connection\n    Connection connection = _selectorManager.newConnection(channel, endPoint, selectionKey.attachment());\n\n    //3. 把 Endpoint、Connection 和 SelectionKey 绑在一起\n    endPoint.setConnection(connection);\n    selectionKey.attach(endPoint);\n\n}\n\n\n这里需要你特别注意的是，ManagedSelector 并没有直接调用 EndPoint 的方法去处理数据，而是通过调用 EndPoint 的方法返回一个 Runnable，然后把这个 Runnable 扔给线程池执行，所以你能猜到，这个 Runnable 才会去真正读数据和处理请求。\n\nConnection\n\n这个 Runnable 是 EndPoint 的一个内部类，它会调用 Connection 的回调方法来处理请求。Jetty 的 Connection 组件类比就是 Tomcat 的 Processor，负责具体协议的解析，得到 Request 对象，并调用 Handler 容器进行处理。下面我简单介绍一下它的具体实现类 HttpConnection 对请求和响应的处理过程。\n\n请求处理：HttpConnection 并不会主动向 EndPoint 读取数据，而是向在 EndPoint 中注册一堆回调方法：\n\ngetEndPoint().fillInterested(_readCallback);\n\n\n这段代码就是告诉 EndPoint，数据到了你就调我这些回调方法 _readCallback 吧，有点异步 I/O 的感觉，也就是说 Jetty 在应用层面模拟了异步 I/O 模型。\n\n而在回调方法 _readCallback 里，会调用 EndPoint 的接口去读数据，读完后让 HTTP 解析器去解析字节流，HTTP 解析器会将解析后的数据，包括请求行、请求头相关信息存到 Request 对象里。\n\n响应处理：Connection 调用 Handler 进行业务处理，Handler 会通过 Response 对象来操作响应流，向流里面写入数据，HttpConnection 再通过 EndPoint 把数据写到 Channel，这样一次响应就完成了。\n\n到此你应该了解了 Connector 的工作原理，下面我画张图再来回顾一下 Connector 的工作流程。\n\n\n\n 1. Acceptor 监听连接请求，当有连接请求到达时就接受连接，一个连接对应一个 Channel，Acceptor 将 Channel 交给 ManagedSelector 来处理。\n\n 2. ManagedSelector 把 Channel 注册到 Selector 上，并创建一个 EndPoint 和 Connection 跟这个 Channel 绑定，接着就不断地检测 I/O 事件。\n\n 3. I/O 事件到了就调用 EndPoint 的方法拿到一个 Runnable，并扔给线程池执行。\n\n 4. 线程池中调度某个线程执行 Runnable。\n\n 5. Runnable 执行时，调用回调函数，这个回调函数是 Connection 注册到 EndPoint 中的。\n\n 6. 回调函数内部实现，其实就是调用 EndPoint 的接口方法来读数据。\n\n 7. Connection 解析读到的数据，生成请求对象并交给 Handler 组件去处理。\n\n\n# Handler 组件\n\nJetty 的 Handler 设计是它的一大特色，Jetty 本质就是一个 Handler 管理器，Jetty 本身就提供了一些默认 Handler 来实现 Servlet 容器的功能，你也可以定义自己的 Handler 来添加到 Jetty 中，这体现了“微内核 + 插件”的设计思想。\n\nHandler 就是一个接口，它有一堆实现类，Jetty 的 Connector 组件调用这些接口来处理 Servlet 请求。\n\npublic interface Handler extends LifeCycle, Destroyable\n{\n    // 处理请求的方法\n    public void handle(String target, Request baseRequest, HttpServletRequest request, HttpServletResponse response)\n        throws IOException, ServletException;\n\n    // 每个 Handler 都关联一个 Server 组件，被 Server 管理\n    public void setServer(Server server);\n    public Server getServer();\n\n    // 销毁方法相关的资源\n    public void destroy();\n}\n\n\n方法说明：\n\n * Handler 的 handle 方法跟 Tomcat 容器组件的 service 方法一样，它有 ServletRequest 和 ServeletResponse 两个参数。\n * 因为任何一个 Handler 都需要关联一个 Server 组件，Handler 需要被 Server 组件来管理。Handler 通过 setServer 和 getServer 方法绑定 Server。\n * Handler 会加载一些资源到内存，因此通过设置 destroy 方法来销毁。\n\n# Handler 继承关系\n\nHandler 只是一个接口，完成具体功能的还是它的子类。那么 Handler 有哪些子类呢？它们的继承关系又是怎样的？这些子类是如何实现 Servlet 容器功能的呢？\n\n\n\n在 AbstractHandler 之下有 AbstractHandlerContainer，为什么需要这个类呢？这其实是个过渡，为了实现链式调用，一个 Handler 内部必然要有其他 Handler 的引用，所以这个类的名字里才有 Container，意思就是这样的 Handler 里包含了其他 Handler 的引用。\n\nHandlerWrapper 和 HandlerCollection 都是 Handler，但是这些 Handler 里还包括其他 Handler 的引用。不同的是，HandlerWrapper 只包含一个其他 Handler 的引用，而 HandlerCollection 中有一个 Handler 数组的引用。\n\nHandlerWrapper 有两个子类：Server 和 ScopedHandler。\n\n * Server 比较好理解，它本身是 Handler 模块的入口，必然要将请求传递给其他 Handler 来处理，为了触发其他 Handler 的调用，所以它是一个 HandlerWrapper。\n * ScopedHandler 也是一个比较重要的 Handler，实现了“具有上下文信息”的责任链调用。为什么我要强调“具有上下文信息”呢？那是因为 Servlet 规范规定 Servlet 在执行过程中是有上下文的。那么这些 Handler 在执行过程中如何访问这个上下文呢？这个上下文又存在什么地方呢？答案就是通过 ScopedHandler 来实现的。\n\nHandlerCollection 其实维护了一个 Handler 数组。这是为了同时支持多个 Web 应用，如果每个 Web 应用有一个 Handler 入口，那么多个 Web 应用的 Handler 就成了一个数组，比如 Server 中就有一个 HandlerCollection，Server 会根据用户请求的 URL 从数组中选取相应的 Handler 来处理，就是选择特定的 Web 应用来处理请求。\n\nHandler 可以分成三种类型：\n\n * 第一种是协调 Handler，这种 Handler 负责将请求路由到一组 Handler 中去，比如 HandlerCollection，它内部持有一个 Handler 数组，当请求到来时，它负责将请求转发到数组中的某一个 Handler。\n * 第二种是过滤器 Handler，这种 Handler 自己会处理请求，处理完了后再把请求转发到下一个 Handler，比如图上的 HandlerWrapper，它内部持有下一个 Handler 的引用。需要注意的是，所有继承了 HandlerWrapper 的 Handler 都具有了过滤器 Handler 的特征，比如 ContextHandler、SessionHandler 和 WebAppContext 等。\n * 第三种是内容 Handler，说白了就是这些 Handler 会真正调用 Servlet 来处理请求，生成响应的内容，比如 ServletHandler。如果浏览器请求的是一个静态资源，也有相应的 ResourceHandler 来处理这个请求，返回静态页面。\n\n# 实现 Servlet 规范\n\nServletHandler、ContextHandler 以及 WebAppContext 等，它们实现了 Servlet 规范。\n\nServlet 规范中有 Context、Servlet、Filter、Listener 和 Session 等，Jetty 要支持 Servlet 规范，就需要有相应的 Handler 来分别实现这些功能。因此，Jetty 设计了 3 个组件：ContextHandler、ServletHandler 和 SessionHandler 来实现 Servle 规范中规定的功能，而WebAppContext 本身就是一个 ContextHandler，另外它还负责管理 ServletHandler 和 SessionHandler。\n\nContextHandler 会创建并初始化 Servlet 规范里的 ServletContext 对象，同时 ContextHandler 还包含了一组能够让你的 Web 应用运行起来的 Handler，可以这样理解，Context 本身也是一种 Handler，它里面包含了其他的 Handler，这些 Handler 能处理某个特定 URL 下的请求。比如，ContextHandler 包含了一个或者多个 ServletHandler。\n\nServletHandler 实现了 Servlet 规范中的 Servlet、Filter 和 Listener 的功能。ServletHandler 依赖 FilterHolder、ServletHolder、ServletMapping、FilterMapping 这四大组件。FilterHolder 和 ServletHolder 分别是 Filter 和 Servlet 的包装类，每一个 Servlet 与路径的映射会被封装成 ServletMapping，而 Filter 与拦截 URL 的映射会被封装成 FilterMapping。\n\nSessionHandler 用来管理 Session。除此之外 WebAppContext 还有一些通用功能的 Handler，比如 SecurityHandler 和 GzipHandler，同样从名字可以知道这些 Handler 的功能分别是安全控制和压缩 / 解压缩。\n\nWebAppContext 会将这些 Handler 构建成一个执行链，通过这个链会最终调用到我们的业务 Servlet。\n\n\n# Jetty 的线程策略\n\n\n# 传统 Selector 编程模型\n\n常规的 NIO 编程思路是，将 I/O 事件的侦测和请求的处理分别用不同的线程处理。具体过程是：\n\n启动一个线程，在一个死循环里不断地调用 select 方法，检测 Channel 的 I/O 状态，一旦 I/O 事件达到，比如数据就绪，就把该 I/O 事件以及一些数据包装成一个 Runnable，将 Runnable 放到新线程中去处理。\n\n在这个过程中按照职责划分，有两个线程在干活，一个是 I/O 事件检测线程，另一个是 I/O 事件处理线程。这样的好处是它们互不干扰和阻塞对方。\n\n\n# Jetty 的 Selector 编程模型\n\n将 I/O 事件检测和业务处理这两种工作分开的思路也有缺点：当 Selector 检测读就绪事件时，数据已经被拷贝到内核中的缓存了，同时 CPU 的缓存中也有这些数据了，我们知道 CPU 本身的缓存比内存快多了，这时当应用程序去读取这些数据时，如果用另一个线程去读，很有可能这个读线程使用另一个 CPU 核，而不是之前那个检测数据就绪的 CPU 核，这样 CPU 缓存中的数据就用不上了，并且线程切换也需要开销。\n\n因此 Jetty 的 Connector 做了一个大胆尝试，那就是把 I/O 事件的生产和消费放到同一个线程来处理，如果这两个任务由同一个线程来执行，如果执行过程中线程不阻塞，操作系统会用同一个 CPU 核来执行这两个任务，这样就能利用 CPU 缓存了。\n\n# ManagedSelector\n\nManagedSelector 的本质就是一个 Selector，负责 I/O 事件的检测和分发。为了方便使用，Jetty 在 Java 原生的 Selector 上做了一些扩展，就变成了 ManagedSelector，我们先来看看它有哪些成员变量：\n\npublic class ManagedSelector extends ContainerLifeCycle implements Dumpable\n{\n    // 原子变量，表明当前的 ManagedSelector 是否已经启动\n    private final AtomicBoolean _started = new AtomicBoolean(false);\n\n    // 表明是否阻塞在 select 调用上\n    private boolean _selecting = false;\n\n    // 管理器的引用，SelectorManager 管理若干 ManagedSelector 的生命周期\n    private final SelectorManager _selectorManager;\n\n    //ManagedSelector 不止一个，为它们每人分配一个 id\n    private final int _id;\n\n    // 关键的执行策略，生产者和消费者是否在同一个线程处理由它决定\n    private final ExecutionStrategy _strategy;\n\n    //Java 原生的 Selector\n    private Selector _selector;\n\n    //"Selector 更新任务 " 队列\n    private Deque<SelectorUpdate> _updates = new ArrayDeque<>();\n    private Deque<SelectorUpdate> _updateable = new ArrayDeque<>();\n\n    ...\n}\n\n\n这些成员变量中其他的都好理解，就是“Selector 更新任务”队列_updates和执行策略_strategy可能不是很直观。\n\n# SelectorUpdate 接口\n\n为什么需要一个“Selector 更新任务”队列呢，对于 Selector 的用户来说，我们对 Selector 的操作无非是将 Channel 注册到 Selector 或者告诉 Selector 我对什么 I/O 事件感兴趣，那么这些操作其实就是对 Selector 状态的更新，Jetty 把这些操作抽象成 SelectorUpdate 接口。\n\n/**\n * A selector update to be done when the selector has been woken.\n */\npublic interface SelectorUpdate\n{\n    void update(Selector selector);\n}\n\n\n这意味着如果你不能直接操作 ManageSelector 中的 Selector，而是需要向 ManagedSelector 提交一个任务类，这个类需要实现 SelectorUpdate 接口 update 方法，在 update 方法里定义你想要对 ManagedSelector 做的操作。\n\n比如 Connector 中 Endpoint 组件对读就绪事件感兴趣，它就向 ManagedSelector 提交了一个内部任务类 ManagedSelector.SelectorUpdate：\n\n_selector.submit(_updateKeyAction);\n\n\n这个_updateKeyAction就是一个 SelectorUpdate 实例，它的 update 方法实现如下：\n\nprivate final ManagedSelector.SelectorUpdate _updateKeyAction = new ManagedSelector.SelectorUpdate()\n{\n    @Override\n    public void update(Selector selector)\n    {\n        // 这里的 updateKey 其实就是调用了 SelectionKey.interestOps(OP_READ);\n        updateKey();\n    }\n};\n\n\n我们看到在 update 方法里，调用了 SelectionKey 类的 interestOps 方法，传入的参数是OP_READ，意思是现在我对这个 Channel 上的读就绪事件感兴趣了。\n\n那谁来负责执行这些 update 方法呢，答案是 ManagedSelector 自己，它在一个死循环里拉取这些 SelectorUpdate 任务类逐个执行。\n\n# Selectable 接口\n\n那 I/O 事件到达时，ManagedSelector 怎么知道应该调哪个函数来处理呢？其实也是通过一个任务类接口，这个接口就是 Selectable，它返回一个 Runnable，这个 Runnable 其实就是 I/O 事件就绪时相应的处理逻辑。\n\npublic interface Selectable\n{\n    // 当某一个 Channel 的 I/O 事件就绪后，ManagedSelector 会调用的回调函数\n    Runnable onSelected();\n\n    // 当所有事件处理完了之后 ManagedSelector 会调的回调函数，我们先忽略。\n    void updateKey();\n}\n\n\nManagedSelector 在检测到某个 Channel 上的 I/O 事件就绪时，也就是说这个 Channel 被选中了，ManagedSelector 调用这个 Channel 所绑定的附件类的 onSelected 方法来拿到一个 Runnable。\n\n这句话有点绕，其实就是 ManagedSelector 的使用者，比如 Endpoint 组件在向 ManagedSelector 注册读就绪事件时，同时也要告诉 ManagedSelector 在事件就绪时执行什么任务，具体来说就是传入一个附件类，这个附件类需要实现 Selectable 接口。ManagedSelector 通过调用这个 onSelected 拿到一个 Runnable，然后把 Runnable 扔给线程池去执行。\n\n那 Endpoint 的 onSelected 是如何实现的呢？\n\n@Override\npublic Runnable onSelected()\n{\n    int readyOps = _key.readyOps();\n\n    boolean fillable = (readyOps & SelectionKey.OP_READ) != 0;\n    boolean flushable = (readyOps & SelectionKey.OP_WRITE) != 0;\n\n    // return task to complete the job\n    Runnable task= fillable\n            ? (flushable\n                    ? _runCompleteWriteFillable\n                    : _runFillable)\n            : (flushable\n                    ? _runCompleteWrite\n                    : null);\n\n    return task;\n}\n\n\n上面的代码逻辑很简单，就是读事件到了就读，写事件到了就写。\n\n# ExecutionStrategy\n\n铺垫了这么多，终于要上主菜了。前面我主要介绍了 ManagedSelector 的使用者如何跟 ManagedSelector 交互，也就是如何注册 Channel 以及 I/O 事件，提供什么样的处理类来处理 I/O 事件，接下来我们来看看 ManagedSelector 是如何统一管理和维护用户注册的 Channel 集合。再回到今天开始的讨论，ManagedSelector 将 I/O 事件的生产和消费看作是生产者消费者模式，为了充分利用 CPU 缓存，生产和消费尽量放到同一个线程处理，那这是如何实现的呢？Jetty 定义了 ExecutionStrategy 接口：\n\npublic interface ExecutionStrategy\n{\n    // 只在 HTTP2 中用到，简单起见，我们先忽略这个方法。\n    public void dispatch();\n\n    // 实现具体执行策略，任务生产出来后可能由当前线程执行，也可能由新线程来执行\n    public void produce();\n\n    // 任务的生产委托给 Producer 内部接口，\n    public interface Producer\n    {\n        // 生产一个 Runnable(任务)\n        Runnable produce();\n    }\n}\n\n\n我们看到 ExecutionStrategy 接口比较简单，它将具体任务的生产委托内部接口 Producer，而在自己的 produce 方法里来实现具体执行逻辑，也就是生产出来的任务要么由当前线程执行，要么放到新线程中执行。Jetty 提供了一些具体策略实现类：ProduceConsume、ProduceExecuteConsume、ExecuteProduceConsume 和 EatWhatYouKill。它们的区别是：\n\n * ProduceConsume：任务生产者自己依次生产和执行任务，对应到 NIO 通信模型就是用一个线程来侦测和处理一个 ManagedSelector 上所有的 I/O 事件，后面的 I/O 事件要等待前面的 I/O 事件处理完，效率明显不高。通过图来理解，图中绿色表示生产一个任务，蓝色表示执行这个任务。\n\n\n\n * ProduceExecuteConsume：任务生产者开启新线程来运行任务，这是典型的 I/O 事件侦测和处理用不同的线程来处理，缺点是不能利用 CPU 缓存，并且线程切换成本高。同样我们通过一张图来理解，图中的棕色表示线程切换。\n\n\n\n * ExecuteProduceConsume：任务生产者自己运行任务，但是该策略可能会新建一个新线程以继续生产和执行任务。这种策略也被称为“吃掉你杀的猎物”，它来自狩猎伦理，认为一个人不应该杀死他不吃掉的东西，对应线程来说，不应该生成自己不打算运行的任务。它的优点是能利用 CPU 缓存，但是潜在的问题是如果处理 I/O 事件的业务代码执行时间过长，会导致线程大量阻塞和线程饥饿。\n\n\n\n * EatWhatYouKill：这是 Jetty 对 ExecuteProduceConsume 策略的改良，在线程池线程充足的情况下等同于 ExecuteProduceConsume；当系统比较忙线程不够时，切换成 ProduceExecuteConsume 策略。为什么要这么做呢，原因是 ExecuteProduceConsume 是在同一线程执行 I/O 事件的生产和消费，它使用的线程来自 Jetty 全局的线程池，这些线程有可能被业务代码阻塞，如果阻塞得多了，全局线程池中的线程自然就不够用了，最坏的情况是连 I/O 事件的侦测都没有线程可用了，会导致 Connector 拒绝浏览器请求。于是 Jetty 做了一个优化，在低线程情况下，就执行 ProduceExecuteConsume 策略，I/O 侦测用专门的线程处理，I/O 事件的处理扔给线程池处理，其实就是放到线程池的队列里慢慢处理。\n\n分析了这几种线程策略，我们再来看看 Jetty 是如何实现 ExecutionStrategy 接口的。答案其实就是实现 produce 接口生产任务，一旦任务生产出来，ExecutionStrategy 会负责执行这个任务。\n\nprivate class SelectorProducer implements ExecutionStrategy.Producer\n{\n    private Set<SelectionKey> _keys = Collections.emptySet();\n    private Iterator<SelectionKey> _cursor = Collections.emptyIterator();\n\n    @Override\n    public Runnable produce()\n    {\n        while (true)\n        {\n            // 如何 Channel 集合中有 I/O 事件就绪，调用前面提到的 Selectable 接口获取 Runnable, 直接返回给 ExecutionStrategy 去处理\n            Runnable task = processSelected();\n            if (task != null)\n                return task;\n\n           // 如果没有 I/O 事件就绪，就干点杂活，看看有没有客户提交了更新 Selector 的任务，就是上面提到的 SelectorUpdate 任务类。\n            processUpdates();\n            updateKeys();\n\n           // 继续执行 select 方法，侦测 I/O 就绪事件\n            if (!select())\n                return null;\n        }\n    }\n }\n\n\nSelectorProducer 是 ManagedSelector 的内部类，SelectorProducer 实现了 ExecutionStrategy 中的 Producer 接口中的 produce 方法，需要向 ExecutionStrategy 返回一个 Runnable。在这个方法里 SelectorProducer 主要干了三件事情\n\n 1. 如果 Channel 集合中有 I/O 事件就绪，调用前面提到的 Selectable 接口获取 Runnable，直接返回给 ExecutionStrategy 去处理。\n 2. 如果没有 I/O 事件就绪，就干点杂活，看看有没有客户提交了更新 Selector 上事件注册的任务，也就是上面提到的 SelectorUpdate 任务类。\n 3. 干完杂活继续执行 select 方法，侦测 I/O 就绪事件。\n\n\n# 参考资料\n\n * Jetty 官方网址\n * Jetty Github\n * Jetty wiki',normalizedContent:'# jetty 快速入门\n\n\n# jetty 简介\n\njetty 是什么？\n\njetty 是轻量级的 web 服务器和 servlet 引擎。\n\n它的最大特点是：可以很方便的作为嵌入式服务器。\n\n它是 eclipse 的一个开源项目。不用怀疑，就是你常用的那个 eclipse。\n\n它是使用 java 开发的，所以天然对 java 支持良好。\n\n官方网址\n\ngithub 源码地址\n\n什么是嵌入式服务器？\n\n以 jetty 来说明，就是只要引入 jetty 的 jar 包，可以通过直接调用其 api 的方式来启动 web 服务。\n\n用过 tomcat、resin 等服务器的朋友想必不会陌生那一套安装、配置、部署的流程吧，还是挺繁琐的。使用 jetty，就不需要这些过程了。\n\njetty 非常适用于项目的开发、测试，因为非常快捷。如果想用于生产环境，则需要谨慎考虑，它不一定能像成熟的 tomcat、resin 等服务器一样支持企业级 java ee 的需要。\n\n\n# jetty 的使用\n\n我觉得嵌入式启动方式的一个好处在于：可以直接运行项目，无需每次部署都得再配置服务器。\n\njetty 的嵌入式启动使用有两种方式：\n\napi 方式\n\nmaven 插件方式\n\n\n# api 方式\n\n添加 maven 依赖\n\n<dependency>\n  <groupid>org.eclipse.jetty</groupid>\n  <artifactid>jetty-webapp</artifactid>\n  <version>9.3.2.v20150730</version>\n  <scope>test</scope>\n</dependency>\n<dependency>\n  <groupid>org.eclipse.jetty</groupid>\n  <artifactid>jetty-annotations</artifactid>\n  <version>9.3.2.v20150730</version>\n  <scope>test</scope>\n</dependency>\n<dependency>\n  <groupid>org.eclipse.jetty</groupid>\n  <artifactid>apache-jsp</artifactid>\n  <version>9.3.2.v20150730</version>\n  <scope>test</scope>\n</dependency>\n<dependency>\n  <groupid>org.eclipse.jetty</groupid>\n  <artifactid>apache-jstl</artifactid>\n  <version>9.3.2.v20150730</version>\n  <scope>test</scope>\n</dependency>\n\n\n官方的启动代码\n\npublic class splitfileserver\n{\n    public static void main( string[] args ) throws exception\n    {\n        // 创建server对象，并绑定端口\n        server server = new server();\n        serverconnector connector = new serverconnector(server);\n        connector.setport(8090);\n        server.setconnectors(new connector[] { connector });\n\n        // 创建上下文句柄，绑定上下文路径。这样启动后的url就会是:http://host:port/context\n        resourcehandler rh0 = new resourcehandler();\n        contexthandler context0 = new contexthandler();\n        context0.setcontextpath("/");\n\n        // 绑定测试资源目录（在本例的配置目录dir0的路径是src/test/resources/dir0）\n        file dir0 = maventestingutils.gettestresourcedir("dir0");\n        context0.setbaseresource(resource.newresource(dir0));\n        context0.sethandler(rh0);\n\n        // 和上面的例子一样\n        resourcehandler rh1 = new resourcehandler();\n        contexthandler context1 = new contexthandler();\n        context1.setcontextpath("/");\n        file dir1 = maventestingutils.gettestresourcedir("dir1");\n        context1.setbaseresource(resource.newresource(dir1));\n        context1.sethandler(rh1);\n\n        // 绑定两个资源句柄\n        contexthandlercollection contexts = new contexthandlercollection();\n        contexts.sethandlers(new handler[] { context0, context1 });\n        server.sethandler(contexts);\n\n        // 启动\n        server.start();\n\n        // 打印dump时的信息\n        system.out.println(server.dump());\n\n        // join当前线程\n        server.join();\n    }\n}\n\n\n直接运行 main 方法，就可以启动 web 服务。\n\n注：以上代码在 eclipse 中运行没有问题，如果想在 intellij 中运行还需要为它指定配置文件。\n\n如果想了解在 eclipse 和 intellij 都能运行的通用方法可以参考我的 github 代码示例。\n\n我的实现也是参考 springside 的方式。\n\n代码行数有点多，不在这里贴代码了。\n\n完整参考代码\n\n\n# maven 插件方式\n\n如果你熟悉 maven，那么实在太简单了\n\n注： maven 版本必须在 3.3 及以上版本。\n\n(1) 添加 maven 插件\n\n<plugin>\n  <groupid>org.eclipse.jetty</groupid>\n  <artifactid>jetty-maven-plugin</artifactid>\n  <version>9.3.12.v20160915</version>\n</plugin>\n\n\n(2) 执行 maven 命令：\n\nmvn jetty:run\n\n\n讲真，就是这么简单。jetty 默认会为你创建一个 web 服务，地址为 127.0.0.1:8080。\n\n当然，你也可以在插件中配置你的 webapp 环境\n\n<plugin>\n  <groupid>org.eclipse.jetty</groupid>\n  <artifactid>jetty-maven-plugin</artifactid>\n  <version>9.3.12.v20160915</version>\n\n  <configuration>\n <webappsourcedirectory>${project.basedir}/src/staticfiles</webappsourcedirectory>\n\n    \x3c!-- 配置webapp --\x3e\n <webapp>\n   <contextpath>/</contextpath>\n   <descriptor>${project.basedir}/src/over/here/web.xml</descriptor>\n   <jettyenvxml>${project.basedir}/src/over/here/jetty-env.xml</jettyenvxml>\n </webapp>\n\n    \x3c!-- 配置classes --\x3e\n <classesdirectory>${project.basedir}/somewhere/else</classesdirectory>\n <scanclassespattern>\n   <excludes>\n  <exclude>**/foo.class</exclude>\n   </excludes>\n </scanclassespattern>\n <scantargets>\n   <scantarget>src/mydir</scantarget>\n   <scantarget>src/myfile.txt</scantarget>\n </scantargets>\n\n    \x3c!-- 扫描target目录下的资源文件 --\x3e\n <scantargetpatterns>\n   <scantargetpattern>\n <directory>src/other-resources</directory>\n <includes>\n   <include>**/*.xml</include>\n   <include>**/*.properties</include>\n </includes>\n <excludes>\n   <exclude>**/myspecial.xml</exclude>\n   <exclude>**/myspecial.properties</exclude>\n </excludes>\n   </scantargetpattern>\n </scantargetpatterns>\n  </configuration>\n</plugin>\n\n\n官方给的 jetty-env.xml 范例\n\n <?xml version="1.0"?>\n <!doctype configure public "-//mort bay consulting//dtd configure//en" "http://jetty.mortbay.org/configure.dtd">\n\n <configure class="org.eclipse.jetty.webapp.webappcontext">\n\n   \x3c!-- add an enventry only valid for this webapp               --\x3e\n   <new id="gargle"  class="org.eclipse.jetty.plus.jndi.enventry">\n     <arg>gargle</arg>\n     <arg type="java.lang.double">100</arg>\n     <arg type="boolean">true</arg>\n   </new>\n\n  \x3c!-- add an override for a global enventry                           --\x3e\n   <new id="wiggle"  class="org.eclipse.jetty.plus.jndi.enventry">\n     <arg>wiggle</arg>\n     <arg type="java.lang.double">55.0</arg>\n     <arg type="boolean">true</arg>\n   </new>\n\n   \x3c!-- an xadatasource                                                --\x3e\n   <new id="mydatasource99" class="org.eclipse.jetty.plus.jndi.resource">\n     <arg>jdbc/mydatasource99</arg>\n     <arg>\n       <new class="com.atomikos.jdbc.simpledatasourcebean">\n         <set name="xadatasourceclassname">org.apache.derby.jdbc.embeddedxadatasource</set>\n         <set name="xadatasourceproperties">databasename=testdb99;createdatabase=create</set>\n         <set name="uniqueresourcename">mydatasource99</set>\n       </new>\n     </arg>\n   </new>\n\n </configure>\n\n\n\n# jetty 的架构\n\n\n# jetty 架构简介\n\n\n\njetty server 就是由多个 connector（连接器）、多个 handler（处理器），以及一个线程池组成。\n\n跟 tomcat 一样，jetty 也有 http 服务器和 servlet 容器的功能，因此 jetty 中的 connector 组件和 handler 组件分别来实现这两个功能，而这两个组件工作时所需要的线程资源都直接从一个全局线程池 threadpool 中获取。\n\njetty server 可以有多个 connector 在不同的端口上监听客户请求，而对于请求处理的 handler 组件，也可以根据具体场景使用不同的 handler。这样的设计提高了 jetty 的灵活性，需要支持 servlet，则可以使用 servlethandler；需要支持 session，则再增加一个 sessionhandler。也就是说我们可以不使用 servlet 或者 session，只要不配置这个 handler 就行了。\n\n为了启动和协调上面的核心组件工作，jetty 提供了一个 server 类来做这个事情，它负责创建并初始化 connector、handler、threadpool 组件，然后调用 start 方法启动它们。\n\n\n# jetty 和 tomcat 架构区别\n\n对比一下 tomcat 的整体架构图，你会发现 tomcat 在整体上跟 jetty 很相似，它们的第一个区别是 jetty 中没有 service 的概念，tomcat 中的 service 包装了多个连接器和一个容器组件，一个 tomcat 实例可以配置多个 service，不同的 service 通过不同的连接器监听不同的端口；而 jetty 中 connector 是被所有 handler 共享的。\n\n第二个区别是，在 tomcat 中每个连接器都有自己的线程池，而在 jetty 中所有的 connector 共享一个全局的线程池。\n\n\n# connector 组件\n\n跟 tomcat 一样，connector 的主要功能是对 i/o 模型和应用层协议的封装。i/o 模型方面，最新的 jetty 9 版本只支持 nio，因此 jetty 的 connector 设计有明显的 java nio 通信模型的痕迹。至于应用层协议方面，跟 tomcat 的 processor 一样，jetty 抽象出了 connection 组件来封装应用层协议的差异。\n\n服务端在 nio 通信上主要完成了三件事情：监听连接、i/o 事件查询以及数据读写。因此 jetty 设计了acceptor、selectormanager 和 connection 来分别做这三件事情\n\n# acceptor\n\nacceptor 用于接受请求。跟 tomcat 一样，jetty 也有独立的 acceptor 线程组用于处理连接请求。在 connector 的实现类 serverconnector 中，有一个 _acceptors 的数组，在 connector 启动的时候, 会根据 _acceptors 数组的长度创建对应数量的 acceptor，而 acceptor 的个数可以配置。\n\nfor (int i = 0; i < _acceptors.length; i++)\n{\n  acceptor a = new acceptor(i);\n  getexecutor().execute(a);\n}\n\n\nacceptor 是 serverconnector 中的一个内部类，同时也是一个 runnable，acceptor 线程是通过 getexecutor() 得到的线程池来执行的，前面提到这是一个全局的线程池。\n\nacceptor 通过阻塞的方式来接受连接，这一点跟 tomcat 也是一样的。\n\npublic void accept(int acceptorid) throws ioexception\n{\n  serversocketchannel serverchannel = _acceptchannel;\n  if (serverchannel != null && serverchannel.isopen())\n  {\n    // 这里是阻塞的\n    socketchannel channel = serverchannel.accept();\n    // 执行到这里时说明有请求进来了\n    accepted(channel);\n  }\n}\n\n\n接受连接成功后会调用 accepted() 函数，accepted() 函数中会将 socketchannel 设置为非阻塞模式，然后交给 selector 去处理，因此这也就到了 selector 的地界了。\n\nprivate void accepted(socketchannel channel) throws ioexception\n{\n    channel.configureblocking(false);\n    socket socket = channel.socket();\n    configure(socket);\n    // _manager 是 selectormanager 实例，里面管理了所有的 selector 实例\n    _manager.accept(channel);\n}\n\n\nselectormanager\n\njetty 的 selector 由 selectormanager 类管理，而被管理的 selector 叫作 managedselector。selectormanager 内部有一个 managedselector 数组，真正干活的是 managedselector。咱们接着上面分析，看看在 selectormanager 在 accept 方法里做了什么。\n\npublic void accept(selectablechannel channel, object attachment)\n{\n  // 选择一个 managedselector 来处理 channel\n  final managedselector selector = chooseselector();\n  // 提交一个任务 accept 给 managedselector\n  selector.submit(selector.new accept(channel, attachment));\n}\n\n\nselectormanager 从本身的 selector 数组中选择一个 selector 来处理这个 channel，并创建一个任务 accept 交给 managedselector，managedselector 在处理这个任务主要做了两步：\n\n第一步，调用 selector 的 register 方法把 channel 注册到 selector 上，拿到一个 selectionkey。\n\n _key = _channel.register(selector, selectionkey.op_accept, this);\n\n\n第二步，创建一个 endpoint 和 connection，并跟这个 selectionkey（channel）绑在一起：\n\nprivate void createendpoint(selectablechannel channel, selectionkey selectionkey) throws ioexception\n{\n    //1. 创建 endpoint\n    endpoint endpoint = _selectormanager.newendpoint(channel, this, selectionkey);\n\n    //2. 创建 connection\n    connection connection = _selectormanager.newconnection(channel, endpoint, selectionkey.attachment());\n\n    //3. 把 endpoint、connection 和 selectionkey 绑在一起\n    endpoint.setconnection(connection);\n    selectionkey.attach(endpoint);\n\n}\n\n\n这里需要你特别注意的是，managedselector 并没有直接调用 endpoint 的方法去处理数据，而是通过调用 endpoint 的方法返回一个 runnable，然后把这个 runnable 扔给线程池执行，所以你能猜到，这个 runnable 才会去真正读数据和处理请求。\n\nconnection\n\n这个 runnable 是 endpoint 的一个内部类，它会调用 connection 的回调方法来处理请求。jetty 的 connection 组件类比就是 tomcat 的 processor，负责具体协议的解析，得到 request 对象，并调用 handler 容器进行处理。下面我简单介绍一下它的具体实现类 httpconnection 对请求和响应的处理过程。\n\n请求处理：httpconnection 并不会主动向 endpoint 读取数据，而是向在 endpoint 中注册一堆回调方法：\n\ngetendpoint().fillinterested(_readcallback);\n\n\n这段代码就是告诉 endpoint，数据到了你就调我这些回调方法 _readcallback 吧，有点异步 i/o 的感觉，也就是说 jetty 在应用层面模拟了异步 i/o 模型。\n\n而在回调方法 _readcallback 里，会调用 endpoint 的接口去读数据，读完后让 http 解析器去解析字节流，http 解析器会将解析后的数据，包括请求行、请求头相关信息存到 request 对象里。\n\n响应处理：connection 调用 handler 进行业务处理，handler 会通过 response 对象来操作响应流，向流里面写入数据，httpconnection 再通过 endpoint 把数据写到 channel，这样一次响应就完成了。\n\n到此你应该了解了 connector 的工作原理，下面我画张图再来回顾一下 connector 的工作流程。\n\n\n\n 1. acceptor 监听连接请求，当有连接请求到达时就接受连接，一个连接对应一个 channel，acceptor 将 channel 交给 managedselector 来处理。\n\n 2. managedselector 把 channel 注册到 selector 上，并创建一个 endpoint 和 connection 跟这个 channel 绑定，接着就不断地检测 i/o 事件。\n\n 3. i/o 事件到了就调用 endpoint 的方法拿到一个 runnable，并扔给线程池执行。\n\n 4. 线程池中调度某个线程执行 runnable。\n\n 5. runnable 执行时，调用回调函数，这个回调函数是 connection 注册到 endpoint 中的。\n\n 6. 回调函数内部实现，其实就是调用 endpoint 的接口方法来读数据。\n\n 7. connection 解析读到的数据，生成请求对象并交给 handler 组件去处理。\n\n\n# handler 组件\n\njetty 的 handler 设计是它的一大特色，jetty 本质就是一个 handler 管理器，jetty 本身就提供了一些默认 handler 来实现 servlet 容器的功能，你也可以定义自己的 handler 来添加到 jetty 中，这体现了“微内核 + 插件”的设计思想。\n\nhandler 就是一个接口，它有一堆实现类，jetty 的 connector 组件调用这些接口来处理 servlet 请求。\n\npublic interface handler extends lifecycle, destroyable\n{\n    // 处理请求的方法\n    public void handle(string target, request baserequest, httpservletrequest request, httpservletresponse response)\n        throws ioexception, servletexception;\n\n    // 每个 handler 都关联一个 server 组件，被 server 管理\n    public void setserver(server server);\n    public server getserver();\n\n    // 销毁方法相关的资源\n    public void destroy();\n}\n\n\n方法说明：\n\n * handler 的 handle 方法跟 tomcat 容器组件的 service 方法一样，它有 servletrequest 和 serveletresponse 两个参数。\n * 因为任何一个 handler 都需要关联一个 server 组件，handler 需要被 server 组件来管理。handler 通过 setserver 和 getserver 方法绑定 server。\n * handler 会加载一些资源到内存，因此通过设置 destroy 方法来销毁。\n\n# handler 继承关系\n\nhandler 只是一个接口，完成具体功能的还是它的子类。那么 handler 有哪些子类呢？它们的继承关系又是怎样的？这些子类是如何实现 servlet 容器功能的呢？\n\n\n\n在 abstracthandler 之下有 abstracthandlercontainer，为什么需要这个类呢？这其实是个过渡，为了实现链式调用，一个 handler 内部必然要有其他 handler 的引用，所以这个类的名字里才有 container，意思就是这样的 handler 里包含了其他 handler 的引用。\n\nhandlerwrapper 和 handlercollection 都是 handler，但是这些 handler 里还包括其他 handler 的引用。不同的是，handlerwrapper 只包含一个其他 handler 的引用，而 handlercollection 中有一个 handler 数组的引用。\n\nhandlerwrapper 有两个子类：server 和 scopedhandler。\n\n * server 比较好理解，它本身是 handler 模块的入口，必然要将请求传递给其他 handler 来处理，为了触发其他 handler 的调用，所以它是一个 handlerwrapper。\n * scopedhandler 也是一个比较重要的 handler，实现了“具有上下文信息”的责任链调用。为什么我要强调“具有上下文信息”呢？那是因为 servlet 规范规定 servlet 在执行过程中是有上下文的。那么这些 handler 在执行过程中如何访问这个上下文呢？这个上下文又存在什么地方呢？答案就是通过 scopedhandler 来实现的。\n\nhandlercollection 其实维护了一个 handler 数组。这是为了同时支持多个 web 应用，如果每个 web 应用有一个 handler 入口，那么多个 web 应用的 handler 就成了一个数组，比如 server 中就有一个 handlercollection，server 会根据用户请求的 url 从数组中选取相应的 handler 来处理，就是选择特定的 web 应用来处理请求。\n\nhandler 可以分成三种类型：\n\n * 第一种是协调 handler，这种 handler 负责将请求路由到一组 handler 中去，比如 handlercollection，它内部持有一个 handler 数组，当请求到来时，它负责将请求转发到数组中的某一个 handler。\n * 第二种是过滤器 handler，这种 handler 自己会处理请求，处理完了后再把请求转发到下一个 handler，比如图上的 handlerwrapper，它内部持有下一个 handler 的引用。需要注意的是，所有继承了 handlerwrapper 的 handler 都具有了过滤器 handler 的特征，比如 contexthandler、sessionhandler 和 webappcontext 等。\n * 第三种是内容 handler，说白了就是这些 handler 会真正调用 servlet 来处理请求，生成响应的内容，比如 servlethandler。如果浏览器请求的是一个静态资源，也有相应的 resourcehandler 来处理这个请求，返回静态页面。\n\n# 实现 servlet 规范\n\nservlethandler、contexthandler 以及 webappcontext 等，它们实现了 servlet 规范。\n\nservlet 规范中有 context、servlet、filter、listener 和 session 等，jetty 要支持 servlet 规范，就需要有相应的 handler 来分别实现这些功能。因此，jetty 设计了 3 个组件：contexthandler、servlethandler 和 sessionhandler 来实现 servle 规范中规定的功能，而webappcontext 本身就是一个 contexthandler，另外它还负责管理 servlethandler 和 sessionhandler。\n\ncontexthandler 会创建并初始化 servlet 规范里的 servletcontext 对象，同时 contexthandler 还包含了一组能够让你的 web 应用运行起来的 handler，可以这样理解，context 本身也是一种 handler，它里面包含了其他的 handler，这些 handler 能处理某个特定 url 下的请求。比如，contexthandler 包含了一个或者多个 servlethandler。\n\nservlethandler 实现了 servlet 规范中的 servlet、filter 和 listener 的功能。servlethandler 依赖 filterholder、servletholder、servletmapping、filtermapping 这四大组件。filterholder 和 servletholder 分别是 filter 和 servlet 的包装类，每一个 servlet 与路径的映射会被封装成 servletmapping，而 filter 与拦截 url 的映射会被封装成 filtermapping。\n\nsessionhandler 用来管理 session。除此之外 webappcontext 还有一些通用功能的 handler，比如 securityhandler 和 gziphandler，同样从名字可以知道这些 handler 的功能分别是安全控制和压缩 / 解压缩。\n\nwebappcontext 会将这些 handler 构建成一个执行链，通过这个链会最终调用到我们的业务 servlet。\n\n\n# jetty 的线程策略\n\n\n# 传统 selector 编程模型\n\n常规的 nio 编程思路是，将 i/o 事件的侦测和请求的处理分别用不同的线程处理。具体过程是：\n\n启动一个线程，在一个死循环里不断地调用 select 方法，检测 channel 的 i/o 状态，一旦 i/o 事件达到，比如数据就绪，就把该 i/o 事件以及一些数据包装成一个 runnable，将 runnable 放到新线程中去处理。\n\n在这个过程中按照职责划分，有两个线程在干活，一个是 i/o 事件检测线程，另一个是 i/o 事件处理线程。这样的好处是它们互不干扰和阻塞对方。\n\n\n# jetty 的 selector 编程模型\n\n将 i/o 事件检测和业务处理这两种工作分开的思路也有缺点：当 selector 检测读就绪事件时，数据已经被拷贝到内核中的缓存了，同时 cpu 的缓存中也有这些数据了，我们知道 cpu 本身的缓存比内存快多了，这时当应用程序去读取这些数据时，如果用另一个线程去读，很有可能这个读线程使用另一个 cpu 核，而不是之前那个检测数据就绪的 cpu 核，这样 cpu 缓存中的数据就用不上了，并且线程切换也需要开销。\n\n因此 jetty 的 connector 做了一个大胆尝试，那就是把 i/o 事件的生产和消费放到同一个线程来处理，如果这两个任务由同一个线程来执行，如果执行过程中线程不阻塞，操作系统会用同一个 cpu 核来执行这两个任务，这样就能利用 cpu 缓存了。\n\n# managedselector\n\nmanagedselector 的本质就是一个 selector，负责 i/o 事件的检测和分发。为了方便使用，jetty 在 java 原生的 selector 上做了一些扩展，就变成了 managedselector，我们先来看看它有哪些成员变量：\n\npublic class managedselector extends containerlifecycle implements dumpable\n{\n    // 原子变量，表明当前的 managedselector 是否已经启动\n    private final atomicboolean _started = new atomicboolean(false);\n\n    // 表明是否阻塞在 select 调用上\n    private boolean _selecting = false;\n\n    // 管理器的引用，selectormanager 管理若干 managedselector 的生命周期\n    private final selectormanager _selectormanager;\n\n    //managedselector 不止一个，为它们每人分配一个 id\n    private final int _id;\n\n    // 关键的执行策略，生产者和消费者是否在同一个线程处理由它决定\n    private final executionstrategy _strategy;\n\n    //java 原生的 selector\n    private selector _selector;\n\n    //"selector 更新任务 " 队列\n    private deque<selectorupdate> _updates = new arraydeque<>();\n    private deque<selectorupdate> _updateable = new arraydeque<>();\n\n    ...\n}\n\n\n这些成员变量中其他的都好理解，就是“selector 更新任务”队列_updates和执行策略_strategy可能不是很直观。\n\n# selectorupdate 接口\n\n为什么需要一个“selector 更新任务”队列呢，对于 selector 的用户来说，我们对 selector 的操作无非是将 channel 注册到 selector 或者告诉 selector 我对什么 i/o 事件感兴趣，那么这些操作其实就是对 selector 状态的更新，jetty 把这些操作抽象成 selectorupdate 接口。\n\n/**\n * a selector update to be done when the selector has been woken.\n */\npublic interface selectorupdate\n{\n    void update(selector selector);\n}\n\n\n这意味着如果你不能直接操作 manageselector 中的 selector，而是需要向 managedselector 提交一个任务类，这个类需要实现 selectorupdate 接口 update 方法，在 update 方法里定义你想要对 managedselector 做的操作。\n\n比如 connector 中 endpoint 组件对读就绪事件感兴趣，它就向 managedselector 提交了一个内部任务类 managedselector.selectorupdate：\n\n_selector.submit(_updatekeyaction);\n\n\n这个_updatekeyaction就是一个 selectorupdate 实例，它的 update 方法实现如下：\n\nprivate final managedselector.selectorupdate _updatekeyaction = new managedselector.selectorupdate()\n{\n    @override\n    public void update(selector selector)\n    {\n        // 这里的 updatekey 其实就是调用了 selectionkey.interestops(op_read);\n        updatekey();\n    }\n};\n\n\n我们看到在 update 方法里，调用了 selectionkey 类的 interestops 方法，传入的参数是op_read，意思是现在我对这个 channel 上的读就绪事件感兴趣了。\n\n那谁来负责执行这些 update 方法呢，答案是 managedselector 自己，它在一个死循环里拉取这些 selectorupdate 任务类逐个执行。\n\n# selectable 接口\n\n那 i/o 事件到达时，managedselector 怎么知道应该调哪个函数来处理呢？其实也是通过一个任务类接口，这个接口就是 selectable，它返回一个 runnable，这个 runnable 其实就是 i/o 事件就绪时相应的处理逻辑。\n\npublic interface selectable\n{\n    // 当某一个 channel 的 i/o 事件就绪后，managedselector 会调用的回调函数\n    runnable onselected();\n\n    // 当所有事件处理完了之后 managedselector 会调的回调函数，我们先忽略。\n    void updatekey();\n}\n\n\nmanagedselector 在检测到某个 channel 上的 i/o 事件就绪时，也就是说这个 channel 被选中了，managedselector 调用这个 channel 所绑定的附件类的 onselected 方法来拿到一个 runnable。\n\n这句话有点绕，其实就是 managedselector 的使用者，比如 endpoint 组件在向 managedselector 注册读就绪事件时，同时也要告诉 managedselector 在事件就绪时执行什么任务，具体来说就是传入一个附件类，这个附件类需要实现 selectable 接口。managedselector 通过调用这个 onselected 拿到一个 runnable，然后把 runnable 扔给线程池去执行。\n\n那 endpoint 的 onselected 是如何实现的呢？\n\n@override\npublic runnable onselected()\n{\n    int readyops = _key.readyops();\n\n    boolean fillable = (readyops & selectionkey.op_read) != 0;\n    boolean flushable = (readyops & selectionkey.op_write) != 0;\n\n    // return task to complete the job\n    runnable task= fillable\n            ? (flushable\n                    ? _runcompletewritefillable\n                    : _runfillable)\n            : (flushable\n                    ? _runcompletewrite\n                    : null);\n\n    return task;\n}\n\n\n上面的代码逻辑很简单，就是读事件到了就读，写事件到了就写。\n\n# executionstrategy\n\n铺垫了这么多，终于要上主菜了。前面我主要介绍了 managedselector 的使用者如何跟 managedselector 交互，也就是如何注册 channel 以及 i/o 事件，提供什么样的处理类来处理 i/o 事件，接下来我们来看看 managedselector 是如何统一管理和维护用户注册的 channel 集合。再回到今天开始的讨论，managedselector 将 i/o 事件的生产和消费看作是生产者消费者模式，为了充分利用 cpu 缓存，生产和消费尽量放到同一个线程处理，那这是如何实现的呢？jetty 定义了 executionstrategy 接口：\n\npublic interface executionstrategy\n{\n    // 只在 http2 中用到，简单起见，我们先忽略这个方法。\n    public void dispatch();\n\n    // 实现具体执行策略，任务生产出来后可能由当前线程执行，也可能由新线程来执行\n    public void produce();\n\n    // 任务的生产委托给 producer 内部接口，\n    public interface producer\n    {\n        // 生产一个 runnable(任务)\n        runnable produce();\n    }\n}\n\n\n我们看到 executionstrategy 接口比较简单，它将具体任务的生产委托内部接口 producer，而在自己的 produce 方法里来实现具体执行逻辑，也就是生产出来的任务要么由当前线程执行，要么放到新线程中执行。jetty 提供了一些具体策略实现类：produceconsume、produceexecuteconsume、executeproduceconsume 和 eatwhatyoukill。它们的区别是：\n\n * produceconsume：任务生产者自己依次生产和执行任务，对应到 nio 通信模型就是用一个线程来侦测和处理一个 managedselector 上所有的 i/o 事件，后面的 i/o 事件要等待前面的 i/o 事件处理完，效率明显不高。通过图来理解，图中绿色表示生产一个任务，蓝色表示执行这个任务。\n\n\n\n * produceexecuteconsume：任务生产者开启新线程来运行任务，这是典型的 i/o 事件侦测和处理用不同的线程来处理，缺点是不能利用 cpu 缓存，并且线程切换成本高。同样我们通过一张图来理解，图中的棕色表示线程切换。\n\n\n\n * executeproduceconsume：任务生产者自己运行任务，但是该策略可能会新建一个新线程以继续生产和执行任务。这种策略也被称为“吃掉你杀的猎物”，它来自狩猎伦理，认为一个人不应该杀死他不吃掉的东西，对应线程来说，不应该生成自己不打算运行的任务。它的优点是能利用 cpu 缓存，但是潜在的问题是如果处理 i/o 事件的业务代码执行时间过长，会导致线程大量阻塞和线程饥饿。\n\n\n\n * eatwhatyoukill：这是 jetty 对 executeproduceconsume 策略的改良，在线程池线程充足的情况下等同于 executeproduceconsume；当系统比较忙线程不够时，切换成 produceexecuteconsume 策略。为什么要这么做呢，原因是 executeproduceconsume 是在同一线程执行 i/o 事件的生产和消费，它使用的线程来自 jetty 全局的线程池，这些线程有可能被业务代码阻塞，如果阻塞得多了，全局线程池中的线程自然就不够用了，最坏的情况是连 i/o 事件的侦测都没有线程可用了，会导致 connector 拒绝浏览器请求。于是 jetty 做了一个优化，在低线程情况下，就执行 produceexecuteconsume 策略，i/o 侦测用专门的线程处理，i/o 事件的处理扔给线程池处理，其实就是放到线程池的队列里慢慢处理。\n\n分析了这几种线程策略，我们再来看看 jetty 是如何实现 executionstrategy 接口的。答案其实就是实现 produce 接口生产任务，一旦任务生产出来，executionstrategy 会负责执行这个任务。\n\nprivate class selectorproducer implements executionstrategy.producer\n{\n    private set<selectionkey> _keys = collections.emptyset();\n    private iterator<selectionkey> _cursor = collections.emptyiterator();\n\n    @override\n    public runnable produce()\n    {\n        while (true)\n        {\n            // 如何 channel 集合中有 i/o 事件就绪，调用前面提到的 selectable 接口获取 runnable, 直接返回给 executionstrategy 去处理\n            runnable task = processselected();\n            if (task != null)\n                return task;\n\n           // 如果没有 i/o 事件就绪，就干点杂活，看看有没有客户提交了更新 selector 的任务，就是上面提到的 selectorupdate 任务类。\n            processupdates();\n            updatekeys();\n\n           // 继续执行 select 方法，侦测 i/o 就绪事件\n            if (!select())\n                return null;\n        }\n    }\n }\n\n\nselectorproducer 是 managedselector 的内部类，selectorproducer 实现了 executionstrategy 中的 producer 接口中的 produce 方法，需要向 executionstrategy 返回一个 runnable。在这个方法里 selectorproducer 主要干了三件事情\n\n 1. 如果 channel 集合中有 i/o 事件就绪，调用前面提到的 selectable 接口获取 runnable，直接返回给 executionstrategy 去处理。\n 2. 如果没有 i/o 事件就绪，就干点杂活，看看有没有客户提交了更新 selector 上事件注册的任务，也就是上面提到的 selectorupdate 任务类。\n 3. 干完杂活继续执行 select 方法，侦测 i/o 就绪事件。\n\n\n# 参考资料\n\n * jetty 官方网址\n * jetty github\n * jetty wiki',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 服务器",frontmatter:{title:"Java 服务器",categories:["编程","Java","服务器"],tags:["Java","JavaWeb","服务器"],hidden:!0,abbrlink:"c34dbf07",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/9d17ce/"},regularPath:"/02.JavaEE/02.%E6%9C%8D%E5%8A%A1%E5%99%A8/",relativePath:"02.JavaEE/02.服务器/README.md",key:"v-b09ed4f4",path:"/pages/9d17ce/",headers:[{level:2,title:"📖 内容",slug:"📖-内容",normalizedTitle:"📖 内容",charIndex:15},{level:2,title:"📚 资料",slug:"📚-资料",normalizedTitle:"📚 资料",charIndex:108},{level:2,title:"🚪 传送",slug:"🚪-传送",normalizedTitle:"🚪 传送",charIndex:210}],headersStr:"📖 内容 📚 资料 🚪 传送",content:"# Java 服务器\n\n\n# 📖 内容\n\n * Tomcat 快速入门\n * Tomcat 连接器\n * Tomcat 容器\n * Tomcat 优化\n * Tomcat 和 Jetty\n * Jetty\n\n\n# 📚 资料\n\n * Tomcat 官网\n * Jetty 官网\n * Jetty Github\n * Nginx 官网\n * Nginx 的中文维基\n * 深入拆解 Tomcat & Jetty\n\n\n# 🚪 传送\n\n◾ 🏠 JAVA-TUTORIAL 首页 ◾ 🎯 我的博客 ◾",normalizedContent:"# java 服务器\n\n\n# 📖 内容\n\n * tomcat 快速入门\n * tomcat 连接器\n * tomcat 容器\n * tomcat 优化\n * tomcat 和 jetty\n * jetty\n\n\n# 📚 资料\n\n * tomcat 官网\n * jetty 官网\n * jetty github\n * nginx 官网\n * nginx 的中文维基\n * 深入拆解 tomcat & jetty\n\n\n# 🚪 传送\n\n◾ 🏠 java-tutorial 首页 ◾ 🎯 我的博客 ◾",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"JavaEE",frontmatter:{title:"JavaEE",categories:["编程","Java","JavaEE"],tags:["Java","JavaEE"],hidden:!0,abbrlink:"37aa865c",date:"2022-02-18T08:53:11.000Z",permalink:"/pages/ca58e7/"},regularPath:"/02.JavaEE/",relativePath:"02.JavaEE/README.md",key:"v-08c5e54c",path:"/pages/ca58e7/",headers:[{level:2,title:"📖 内容",slug:"📖-内容",normalizedTitle:"📖 内容",charIndex:13},{level:3,title:"JavaWeb",slug:"javaweb",normalizedTitle:"javaweb",charIndex:23},{level:3,title:"Java 服务器",slug:"java-服务器",normalizedTitle:"java 服务器",charIndex:155},{level:2,title:"📚 资料",slug:"📚-资料",normalizedTitle:"📚 资料",charIndex:326},{level:2,title:"🚪 传送",slug:"🚪-传送",normalizedTitle:"🚪 传送",charIndex:619}],headersStr:"📖 内容 JavaWeb Java 服务器 📚 资料 🚪 传送",content:"# JavaEE\n\n\n# 📖 内容\n\n\n# JavaWeb\n\n * JavaWeb 面经\n * JavaWeb 之 Servlet 指南\n * JavaWeb 之 Jsp 指南\n * JavaWeb 之 Filter 和 Listener\n * JavaWeb 之 Cookie 和 Session\n\n\n# Java 服务器\n\n> Tomcat 和 Jetty 都是 Java 比较流行的轻量级服务器。\n> \n> Nginx 是目前最流行的反向代理服务器，也常用于负载均衡。\n\n * Tomcat 快速入门\n * Tomcat 连接器\n * Tomcat 容器\n * Tomcat 优化\n * Tomcat 和 Jetty\n * Jetty\n\n\n# 📚 资料\n\n * JavaWeb\n   * 书籍\n     * Java Web 整合开发王者归来\n     * Head First Servlets & JSP\n   * 教程\n     * 深入拆解 Tomcat & Jetty\n     * Servlet 教程\n     * 博客园孤傲苍狼 JavaWeb 学习总结\n     * JSP 教程\n * 服务器\n   * Tomcat 官网\n   * Jetty 官网\n   * Jetty Github\n   * Nginx 官网\n   * Nginx 的中文维基\n   * 深入拆解 Tomcat & Jetty\n\n\n# 🚪 传送\n\n◾ 🏠 JAVA-TUTORIAL 首页 ◾ 🎯 我的博客 ◾",normalizedContent:"# javaee\n\n\n# 📖 内容\n\n\n# javaweb\n\n * javaweb 面经\n * javaweb 之 servlet 指南\n * javaweb 之 jsp 指南\n * javaweb 之 filter 和 listener\n * javaweb 之 cookie 和 session\n\n\n# java 服务器\n\n> tomcat 和 jetty 都是 java 比较流行的轻量级服务器。\n> \n> nginx 是目前最流行的反向代理服务器，也常用于负载均衡。\n\n * tomcat 快速入门\n * tomcat 连接器\n * tomcat 容器\n * tomcat 优化\n * tomcat 和 jetty\n * jetty\n\n\n# 📚 资料\n\n * javaweb\n   * 书籍\n     * java web 整合开发王者归来\n     * head first servlets & jsp\n   * 教程\n     * 深入拆解 tomcat & jetty\n     * servlet 教程\n     * 博客园孤傲苍狼 javaweb 学习总结\n     * jsp 教程\n * 服务器\n   * tomcat 官网\n   * jetty 官网\n   * jetty github\n   * nginx 官网\n   * nginx 的中文维基\n   * 深入拆解 tomcat & jetty\n\n\n# 🚪 传送\n\n◾ 🏠 java-tutorial 首页 ◾ 🎯 我的博客 ◾",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Maven 快速入门",frontmatter:{title:"Maven 快速入门",categories:["编程","Java","软件","构建"],tags:["Java","构建","Maven"],abbrlink:"ad26e4b1",date:"2020-02-07T23:04:47.000Z",permalink:"/pages/6b8149/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/01.%E6%9E%84%E5%BB%BA/01.Maven/01.Maven%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8.html",relativePath:"11.软件/01.构建/01.Maven/01.Maven快速入门.md",key:"v-8b222c70",path:"/pages/6b8149/",headers:[{level:2,title:"Maven 简介",slug:"maven-简介",normalizedTitle:"maven 简介",charIndex:17},{level:3,title:"Maven 是什么",slug:"maven-是什么",normalizedTitle:"maven 是什么",charIndex:30},{level:3,title:"Maven 的生命周期",slug:"maven-的生命周期",normalizedTitle:"maven 的生命周期",charIndex:448},{level:3,title:"Maven 的标准工程结构",slug:"maven-的标准工程结构",normalizedTitle:"maven 的标准工程结构",charIndex:704},{level:3,title:'Maven 的"约定优于配置"',slug:"maven-的-约定优于配置",normalizedTitle:"maven 的&quot;约定优于配置&quot;",charIndex:null},{level:3,title:"Maven 的版本规范",slug:"maven-的版本规范",normalizedTitle:"maven 的版本规范",charIndex:1212},{level:2,title:"Maven 安装",slug:"maven-安装",normalizedTitle:"maven 安装",charIndex:2183},{level:3,title:"环境准备",slug:"环境准备",normalizedTitle:"环境准备",charIndex:2304},{level:3,title:"下载解压",slug:"下载解压",normalizedTitle:"下载解压",charIndex:2542},{level:3,title:"环境变量",slug:"环境变量",normalizedTitle:"环境变量",charIndex:2686},{level:4,title:"配置 Unix 系统环境变量",slug:"配置-unix-系统环境变量",normalizedTitle:"配置 unix 系统环境变量",charIndex:2729},{level:4,title:"配置 Windows 系统环境变量",slug:"配置-windows-系统环境变量",normalizedTitle:"配置 windows 系统环境变量",charIndex:2906},{level:3,title:"检测安装成功",slug:"检测安装成功",normalizedTitle:"检测安装成功",charIndex:2994},{level:3,title:"Maven 配置文件",slug:"maven-配置文件",normalizedTitle:"maven 配置文件",charIndex:3419},{level:2,title:"快速入门",slug:"快速入门",normalizedTitle:"快速入门",charIndex:8},{level:3,title:"创建 Maven 工程",slug:"创建-maven-工程",normalizedTitle:"创建 maven 工程",charIndex:3925},{level:4,title:"初始化工程",slug:"初始化工程",normalizedTitle:"初始化工程",charIndex:3940},{level:4,title:"POM 配置",slug:"pom-配置",normalizedTitle:"pom 配置",charIndex:4580},{level:4,title:"构建项目",slug:"构建项目",normalizedTitle:"构建项目",charIndex:5361},{level:3,title:"在 Intellij 中创建 Maven 工程",slug:"在-intellij-中创建-maven-工程",normalizedTitle:"在 intellij 中创建 maven 工程",charIndex:5940},{level:3,title:"在 Eclipse 中创建 Maven 工程",slug:"在-eclipse-中创建-maven-工程",normalizedTitle:"在 eclipse 中创建 maven 工程",charIndex:6117},{level:2,title:"使用说明",slug:"使用说明",normalizedTitle:"使用说明",charIndex:6884},{level:3,title:"如何添加依赖",slug:"如何添加依赖",normalizedTitle:"如何添加依赖",charIndex:6893},{level:3,title:"如何寻找 jar 包",slug:"如何寻找-jar-包",normalizedTitle:"如何寻找 jar 包",charIndex:8222},{level:3,title:"如何使用 Maven 插件(Plugin)",slug:"如何使用-maven-插件-plugin",normalizedTitle:"如何使用 maven 插件(plugin)",charIndex:8350},{level:3,title:"如何一次编译多个工程",slug:"如何一次编译多个工程",normalizedTitle:"如何一次编译多个工程",charIndex:8761},{level:3,title:"常用 Maven 插件",slug:"常用-maven-插件",normalizedTitle:"常用 maven 插件",charIndex:9542},{level:4,title:"maven-antrun-plugin",slug:"maven-antrun-plugin",normalizedTitle:"maven-antrun-plugin",charIndex:9602},{level:4,title:"maven-archetype-plugin",slug:"maven-archetype-plugin",normalizedTitle:"maven-archetype-plugin",charIndex:9854},{level:4,title:"maven-assembly-plugin",slug:"maven-assembly-plugin",normalizedTitle:"maven-assembly-plugin",charIndex:10211},{level:4,title:"maven-dependency-plugin",slug:"maven-dependency-plugin",normalizedTitle:"maven-dependency-plugin",charIndex:10531},{level:4,title:"maven-enforcer-plugin",slug:"maven-enforcer-plugin",normalizedTitle:"maven-enforcer-plugin",charIndex:10822},{level:4,title:"maven-help-plugin",slug:"maven-help-plugin",normalizedTitle:"maven-help-plugin",charIndex:11211},{level:4,title:"maven-release-plugin",slug:"maven-release-plugin",normalizedTitle:"maven-release-plugin",charIndex:11643},{level:4,title:"maven-resources-plugin",slug:"maven-resources-plugin",normalizedTitle:"maven-resources-plugin",charIndex:12020},{level:4,title:"maven-surefire-plugin",slug:"maven-surefire-plugin",normalizedTitle:"maven-surefire-plugin",charIndex:12391},{level:4,title:"build-helper-maven-plugin",slug:"build-helper-maven-plugin",normalizedTitle:"build-helper-maven-plugin",charIndex:12747},{level:4,title:"exec-maven-plugin",slug:"exec-maven-plugin",normalizedTitle:"exec-maven-plugin",charIndex:13167},{level:4,title:"jetty-maven-plugin",slug:"jetty-maven-plugin",normalizedTitle:"jetty-maven-plugin",charIndex:13532},{level:4,title:"versions-maven-plugin",slug:"versions-maven-plugin",normalizedTitle:"versions-maven-plugin",charIndex:14047},{level:3,title:"Maven 命令",slug:"maven-命令",normalizedTitle:"maven 命令",charIndex:6810},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:16004}],headersStr:'Maven 简介 Maven 是什么 Maven 的生命周期 Maven 的标准工程结构 Maven 的"约定优于配置" Maven 的版本规范 Maven 安装 环境准备 下载解压 环境变量 配置 Unix 系统环境变量 配置 Windows 系统环境变量 检测安装成功 Maven 配置文件 快速入门 创建 Maven 工程 初始化工程 POM 配置 构建项目 在 Intellij 中创建 Maven 工程 在 Eclipse 中创建 Maven 工程 使用说明 如何添加依赖 如何寻找 jar 包 如何使用 Maven 插件(Plugin) 如何一次编译多个工程 常用 Maven 插件 maven-antrun-plugin maven-archetype-plugin maven-assembly-plugin maven-dependency-plugin maven-enforcer-plugin maven-help-plugin maven-release-plugin maven-resources-plugin maven-surefire-plugin build-helper-maven-plugin exec-maven-plugin jetty-maven-plugin versions-maven-plugin Maven 命令 参考资料',content:'# Maven 快速入门\n\n\n# Maven 简介\n\n\n# Maven 是什么\n\nMaven 是一个项目管理工具。它负责管理项目开发过程中的几乎所有的东西。\n\n * 版本 - maven 有自己的版本定义和规则。\n * 构建 - maven 支持许多种的应用程序类型，对于每一种支持的应用程序类型都定义好了一组构建规则和工具集。\n * 输出物管理 - maven 可以管理项目构建的产物，并将其加入到用户库中。这个功能可以用于项目组和其他部门之间的交付行为。\n * 依赖关系 - maven 对依赖关系的特性进行细致的分析和划分，避免开发过程中的依赖混乱和相互污染行为\n * 文档和构建结果 - maven 的 site 命令支持各种文档信息的发布，包括构建过程的各种输出，javadoc，产品文档等。\n * 项目关系 - 一个大型的项目通常有几个小项目或者模块组成，用 maven 可以很方便地管理。\n * 移植性管理 - maven 可以针对不同的开发场景，输出不同种类的输出结果。\n\n\n# Maven 的生命周期\n\nmaven 把项目的构建划分为不同的生命周期(lifecycle)。粗略一点的话，它这个过程(phase)包括：编译、测试、打包、集成测试、验证、部署。maven 中所有的执行动作(goal)都需要指明自己在这个过程中的执行位置，然后 maven 执行的时候，就依照过程的发展依次调用这些 goal 进行各种处理。\n\n这个也是 maven 的一个基本调度机制。一般来说，位置稍后的过程都会依赖于之前的过程。当然，maven 同样提供了配置文件，可以依照用户要求，跳过某些阶段。\n\n\n# Maven 的标准工程结构\n\nMaven 的标准工程结构如下：\n\n|-- pom.xml(maven的核心配置文件)\n|-- src\n|-- main\n  |-- java(java源代码目录)\n  |-- resources(资源文件目录)\n|-- test\n    |-- java(单元测试代码目录)\n|-- target(输出目录，所有的输出物都存放在这个目录下)\n    |-- classes(编译后的class文件存放处)\n\n\n\n# Maven 的"约定优于配置"\n\n所谓的"约定优于配置"，在 maven 中并不是完全不可以修改的，他们只是一些配置的默认值而已。但是除非必要，并不需要去修改那些约定内容。maven 默认的文件存放结构如下：\n\n每一个阶段的任务都知道怎么正确完成自己的工作，比如 compile 任务就知道从 src/main/java 下编译所有的 java 文件，并把它的输出 class 文件存放到 target/classes 中。\n\n对 maven 来说，采用"约定优于配置"的策略可以减少修改配置的工作量，也可以降低学习成本，更重要的是，给项目引入了统一的规范。\n\n\n# Maven 的版本规范\n\nmaven 使用如下几个要素来唯一定位某一个输出物：\n\n * groupId - 团体、组织的标识符。团体标识的约定是，它以创建这个项目的组织名称的逆向域名(reverse domain name)开头。一般对应着 JAVA 的包的结构。例如 org.apache\n * artifactId - 单独项目的唯一标识符。比如我们的 tomcat, commons 等。不要在 artifactId 中包含点号(.)。\n * version - 一个项目的特定版本。\n * packaging - 项目的类型，默认是 jar，描述了项目打包后的输出。类型为 jar 的项目产生一个 JAR 文件，类型为 war 的项目产生一个 web 应用。\n\n例如：想在 maven 工程中引入 4.12 版本的 junit 包，添加如下依赖即可。\n\n<dependency>\n  <groupId>junit</groupId>\n  <artifactId>junit</artifactId>\n  <version>4.12</version>\n  <scope>compile</scope>\n</dependency>\n\n\nmaven 有自己的版本规范，一般是如下定义 <major version>、<minor version>、<incremental version>-<qualifier> ，比如 1.2.3-beta-01。要说明的是，maven 自己判断版本的算法是 major,minor,incremental 部分用数字比 较，qualifier 部分用字符串比较，所以要小心 alpha-2 和 alpha-15 的比较关系，最好用 alpha-02 的格式。\n\nmaven 在版本管理时候可以使用几个特殊的字符串 SNAPSHOT，LATEST，RELEASE。比如"1.0-SNAPSHOT"。各个部分的含义和处理逻辑如下说明：\n\n * SNAPSHOT - 这个版本一般用于开发过程中，表示不稳定的版本。\n * LATEST - 指某个特定构件的最新发布，这个发布可能是一个发布版，也可能是一个 snapshot 版，具体看哪个时间最后。\n * RELEASE - 指最后一个发布版。\n\n\n# Maven 安装\n\n> Linux 环境安装可以使用我写一键安装脚本：https://github.com/dunwu/linux-tutorial/tree/master/codes/linux/ops/service/maven\n\n\n# 环境准备\n\nMaven 依赖于 Java，所以本地必须安装 JDK。\n\n打开控制台，执行 java -version 确认本地已安装 JDK。\n\n$ java -version\njava version "1.8.0_191"\nJava(TM) SE Runtime Environment (build 1.8.0_191-b12)\nJava HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)\n\n\n\n# 下载解压\n\n进入 官网下载地址，选择合适版本，下载并解压到本地。解压命令如下：\n\n# 以下解压命令分别针对 zip 包和 tar 包\nunzip apache-maven-3.6.3-bin.zip\ntar xzvf apache-maven-3.6.3-bin.tar.gz\n\n\n\n# 环境变量\n\n添加环境变量 MAVEN_HOME，值为 Maven 的安装路径。\n\n# 配置 Unix 系统环境变量\n\n输入 vi /etc/profile ，添加环境变量如下：\n\n# MAVEN 的根路径\nexport MAVEN_HOME=/opt/maven/apache-maven-3.5.2\nexport PATH=$MAVEN_HOME/bin:$PATH\n\n\n执行 source /etc/profile ，立即生效。\n\n# 配置 Windows 系统环境变量\n\n右键 "计算机"，选择 "属性"，之后点击 "高级系统设置"，点击"环境变量"，来设置环境变量，有以下系统变量需要配置：\n\n\n\n\n\n\n# 检测安装成功\n\n检验是否安装成功，执行 mvn -v 命令，如果输出类似下面的 maven 版本信息，说明配置成功。\n\n$ mvn -v\nApache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-18T02:33:14+08:00)\nMaven home: /opt/maven/apache-maven-3.5.4\nJava version: 1.8.0_191, vendor: Oracle Corporation, runtime: /mnt/disk1/jdk1.8.0_191/jre\nDefault locale: zh_CN, platform encoding: UTF-8\nOS name: "linux", version: "3.10.0-327.el7.x86_64", arch: "amd64", family: "unix"\n\n\n\n# Maven 配置文件\n\nsetting.xml 文件是 Maven 的默认配置文件，其默认路径为：<Maven 安装目录>/conf/settings.xml。\n\n如果需要修改 Maven 配置，直接修改 setting.xml 并保持即可。\n\n例如：想要修改本地仓库位置可以按如下配置，这样，所有通过 Maven 下载打包的 jar 包都会存储在 D:\\maven\\repo 路径下。\n\n<settings xmlns="http://maven.apache.org/SETTINGS/1.1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.1.0 http://maven.apache.org/xsd/settings-1.1.0.xsd">\n  <localRepository>D:\\maven\\repo<localRepository/>\n  \x3c!-- 略 --\x3e\n</settings>\n\n\n\n# 快速入门\n\n\n# 创建 Maven 工程\n\n# 初始化工程\n\n执行指令：\n\nmvn archetype:generate -DgroupId=com.mycompany.app -DartifactId=my-app -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.4 -DinteractiveMode=false\n\n\n会在当前路径新建一个名为 my-app 的 Maven 工程，其目录结构如下：\n\nmy-app\n|-- pom.xml\n`-- src\n    |-- main\n    |   `-- java\n    |       `-- com\n    |           `-- mycompany\n    |               `-- app\n    |                   `-- App.java\n    `-- test\n        `-- java\n            `-- com\n                `-- mycompany\n                    `-- app\n                        `-- AppTest.java\n\n\n其中， src/main/java 目录包含 java 源码， src/test/java 目录包含 java 测试源码，而 pom.xml 文件是 maven 工程的配置文件。\n\n# POM 配置\n\npom.xml 是 maven 工程的配置文件，它描述了 maven 工程的构建方式，其配置信息是很复杂的，这里给一个最简单的配置示例：\n\nproject xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>com.mycompany.app</groupId>\n  <artifactId>my-app</artifactId>\n  <version>1.0-SNAPSHOT</version>\n\n  <properties>\n    <maven.compiler.source>1.7</maven.compiler.source>\n    <maven.compiler.target>1.7</maven.compiler.target>\n  </properties>\n\n  <dependencies>\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>4.12</version>\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n</project>\n\n\n# 构建项目\n\n执行以下命令，即可构建项目：\n\nmvn clean package -Dmaven.test.skip=true -B -U\n\n\n构建成功后，会输出类似下面的信息：\n\n...\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  2.953 s\n[INFO] Finished at: 2019-11-24T13:05:10+01:00\n[INFO] ------------------------------------------------------------------------\n\n\n这时，在当前路径下会产生一个 target 目录，其中包含了构建的输出物，如：jar 包、class 文件等。\n\n这时，我们可以执行以下命令启动 jar 包：\n\njava -cp target/my-app-1.0-SNAPSHOT.jar com.mycompany.app.App\n\n\n\n# 在 Intellij 中创建 Maven 工程\n\n（1）创建 Maven 工程\n\n依次点击 File -> New -> Project 打开创建工程对话框，选择 Maven 工程。\n\n\n\n（2）输入项目信息\n\n\n\n（3）点击 Intellij 侧边栏中的 Maven 工具界面，有几个可以直接使用的 maven 命令，可以帮助你进行构建。\n\n\n\n\n# 在 Eclipse 中创建 Maven 工程\n\n（1）Maven 插件\n\n在 Eclipse 中创建 Maven 工程，需要安装 Maven 插件。\n\n一般较新版本的 Eclipse 都会带有 Maven 插件，如果你的 Eclipse 中已经有 Maven 插件，可以跳过这一步骤。\n\n点击 Help -> Eclipse Marketplace，搜索 maven 关键字，选择安装红框对应的 Maven 插件。\n\n\n\n（2）Maven 环境配置\n\n点击 Window -> Preferences\n\n如下图所示，配置 settings.xml 文件的位置\n\n\n\n（3）创建 Maven 工程\n\nFile -> New -> Maven Project -> Next，在接下来的窗口中会看到一大堆的项目模板，选择合适的模板。\n\n接下来设置项目的参数，如下：\n\n\n\ngroupId是项目组织唯一的标识符，实际对应 JAVA 的包的结构，是 main 目录里 java 的目录结构。\n\nartifactId就是项目的唯一的标识符，实际对应项目的名称，就是项目根目录的名称。\n\n点击 Finish，Eclipse 会创建一个 Maven 工程。\n\n（4）使用 Maven 进行构建\n\nEclipse 中构建方式：\n\n在 Elipse 项目上右击 -> Run As 就能看到很多 Maven 操作。这些操作和 maven 命令是等效的。例如 Maven clean，等同于 mvn clean 命令。\n\n\n\n你也可以点击 Maven build，输入组合命令，并保存下来。如下图：\n\n\n\nMaven 命令构建方式：\n\n当然，你也可以直接使用 maven 命令进行构建。\n\n进入工程所在目录，输入 maven 命令就可以了。\n\n\n\n\n# 使用说明\n\n\n# 如何添加依赖\n\n在 Maven 工程中添加依赖 jar 包，很简单，只要在 POM 文件中引入对应的<dependency>标签即可。\n\n参考下例：\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">\n\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>com.zp.maven</groupId>\n  <artifactId>MavenDemo</artifactId>\n  <version>0.0.1-SNAPSHOT</version>\n  <packaging>jar</packaging>\n  <name>MavenDemo</name>\n  <url>http://maven.apache.org</url>\n\n  <properties>\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <junit.version>3.8.1</junit.version>\n  </properties>\n\n  <dependencies>\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>${junit.version}</version>\n      <scope>test</scope>\n    </dependency>\n\n    <dependency>\n      <groupId>log4j</groupId>\n      <artifactId>log4j</artifactId>\n      <version>1.2.12</version>\n      <scope>compile</scope>\n    </dependency>\n  </dependencies>\n</project>\n\n\n<dependency> 标签最常用的四个属性标签：\n\n * <groupId> - 项目组织唯一的标识符，实际对应 JAVA 的包的结构。\n * <artifactId> - 项目唯一的标识符，实际对应项目的名称，就是项目根目录的名称。\n * <version> - jar 包的版本号。可以直接填版本数字，也可以在 properties 标签中设置属性值。\n * <scope> - jar 包的作用范围。可以填写 compile、runtime、test、system 和 provided。用来在编译、测试等场景下选择对应的 classpath。\n\n\n# 如何寻找 jar 包\n\n可以在 http://mvnrepository.com/ 站点搜寻你想要的 jar 包版本\n\n例如，想要使用 log4j，可以找到需要的版本号，然后拷贝对应的 maven 标签信息，将其添加到 pom .xml 文件中。\n\n\n# 如何使用 Maven 插件(Plugin)\n\n要添加 Maven 插件，可以在 pom.xml 文件中添加 <plugin> 标签。\n\n<build>\n  <plugins>\n    <plugin>\n      <groupId>org.apache.maven.plugins</groupId>\n      <artifactId>maven-compiler-plugin</artifactId>\n      <version>3.3</version>\n      <configuration>\n        <source>1.7</source>\n        <target>1.7</target>\n      </configuration>\n    </plugin>\n  </plugins>\n</build>\n\n\n<configuration> 标签用来配置插件的一些使用参数。\n\n\n# 如何一次编译多个工程\n\n假设要创建一个父 maven 工程，它有两个子工程：my-app 和 my-webapp：\n\n+- pom.xml\n+- my-app\n| +- pom.xml\n| +- src\n|   +- main\n|     +- java\n+- my-webapp\n| +- pom.xml\n| +- src\n|   +- main\n|     +- webapp\n\n\napp 工程的 pom.xml 如下，重点在于在 modules 中引入两个子 module：\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>com.mycompany.app</groupId>\n  <artifactId>app</artifactId>\n  <version>1.0-SNAPSHOT</version>\n  <packaging>pom</packaging>\n\n  <modules>\n    <module>my-app</module>\n    <module>my-webapp</module>\n  </modules>\n</project>\n\n\n选择编译 XXX 时，会依次对它的所有 Module 执行相同操作。\n\n\n# 常用 Maven 插件\n\n> 更多详情请参考：https://maven.apache.org/plugins/\n\n# maven-antrun-plugin\n\nmaven-antrun-plugin 能让用户在 Maven 项目中运行 Ant 任务。用户可以直接在该插件的配置以 Ant 的方式编写 Target， 然后交给该插件的 run 目标去执行。在一些由 Ant 往 Maven 迁移的项目中，该插件尤其有用。此外当你发现需要编写一些自定义程度很高的任务，同时又觉 得 Maven 不够灵活时，也可以以 Ant 的方式实现之。maven-antrun-plugin 的 run 目标通常与生命周期绑定运行。\n\n# maven-archetype-plugin\n\nArchtype 指项目的骨架，Maven 初学者最开始执行的 Maven 命令可能就是mvn archetype:generate，这实际上就是让 maven-archetype-plugin 生成一个很简单的项目骨架，帮助开发者快速上手。可能也有人看到一些文档写了mvn archetype:create， 但实际上 create 目标已经被弃用了，取而代之的是 generate 目标，该目标使用交互式的方式提示用户输入必要的信息以创建项目，体验更好。 maven-archetype-plugin 还有一些其他目标帮助用户自己定义项目原型，例如你由一个产品需要交付给很多客户进行二次开发，你就可以为 他们提供一个 Archtype，帮助他们快速上手。\n\n# maven-assembly-plugin\n\nmaven-assembly-plugin 的用途是将项目打包，该包可能包含了项目的可执行文件、源代码、readme、平台脚本等等。 maven-assembly-plugin 支持各种主流的格式如 zip、tar.gz、jar 和 war 等，具体打包哪些文件是高度可控的，例如用户可以 按文件级别的粒度、文件集级别的粒度、模块级别的粒度、以及依赖级别的粒度控制打包，此外，包含和排除配置也是支持的。maven-assembly- plugin 要求用户使用一个名为assembly.xml的元数据文件来表述打包，它的 single 目标可以直接在命令行调用，也可以被绑定至生命周期。\n\n# maven-dependency-plugin\n\nmaven-dependency-plugin 最大的用途是帮助分析项目依赖，dependency:list能够列出项目最终解析到的依赖列表，dependency:tree能进一步的描绘项目依赖树，dependency:analyze可以告诉你项目依赖潜在的问题，如果你有直接使用到的却未声明的依赖，该目标就会发出警告。maven-dependency-plugin 还有很多目标帮助你操作依赖文件，例如dependency:copy-dependencies能将项目依赖从本地 Maven 仓库复制到某个特定的文件夹下面。\n\n# maven-enforcer-plugin\n\n在一个稍大一点的组织或团队中，你无法保证所有成员都熟悉 Maven，那他们做一些比较愚蠢的事情就会变得很正常，例如给项目引入了外部的 SNAPSHOT 依赖而导致构建不稳定，使用了一个与大家不一致的 Maven 版本而经常抱怨构建出现诡异问题。maven-enforcer- plugin 能够帮助你避免之类问题，它允许你创建一系列规则强制大家遵守，包括设定 Java 版本、设定 Maven 版本、禁止某些依赖、禁止 SNAPSHOT 依赖。只要在一个父 POM 配置规则，然后让大家继承，当规则遭到破坏的时候，Maven 就会报错。除了标准的规则之外，你还可以扩展该插 件，编写自己的规则。maven-enforcer-plugin 的 enforce 目标负责检查规则，它默认绑定到生命周期的 validate 阶段。\n\n# maven-help-plugin\n\nmaven-help-plugin 是一个小巧的辅助工具，最简单的help:system可以打印所有可用的环境变量和 Java 系统属性。help:effective-pom和help:effective-settings最 为有用，它们分别打印项目的有效 POM 和有效 settings，有效 POM 是指合并了所有父 POM（包括 Super POM）后的 XML，当你不确定 POM 的某些信息从何而来时，就可以查看有效 POM。有效 settings 同理，特别是当你发现自己配置的 settings.xml 没有生效时，就可以用help:effective-settings来验证。此外，maven-help-plugin 的 describe 目标可以帮助你描述任何一个 Maven 插件的信息，还有 all-profiles 目标和 active-profiles 目标帮助查看项目的 Profile。\n\n# maven-release-plugin\n\nmaven-release-plugin 的用途是帮助自动化项目版本发布，它依赖于 POM 中的 SCM 信息。release:prepare用来准备版本发布，具体的工作包括检查是否有未提交代码、检查是否有 SNAPSHOT 依赖、升级项目的 SNAPSHOT 版本至 RELEASE 版本、为项目打标签等等。release:perform则 是签出标签中的 RELEASE 源码，构建并发布。版本发布是非常琐碎的工作，它涉及了各种检查，而且由于该工作仅仅是偶尔需要，因此手动操作很容易遗漏一 些细节，maven-release-plugin 让该工作变得非常快速简便，不易出错。maven-release-plugin 的各种目标通常直接在 命令行调用，因为版本发布显然不是日常构建生命周期的一部分。\n\n# maven-resources-plugin\n\n为了使项目结构更为清晰，Maven 区别对待 Java 代码文件和资源文件，maven-compiler-plugin 用来编译 Java 代码，maven-resources-plugin 则用来处理资源文件。默认的主资源文件目录是src/main/resources，很多用户会需要添加额外的资源文件目录，这个时候就可以通过配置 maven-resources-plugin 来实现。此外，资源文件过滤也是 Maven 的一大特性，你可以在资源文件中使用*${propertyName}*形式的 Maven 属性，然后配置 maven-resources-plugin 开启对资源文件的过滤，之后就可以针对不同环境通过命令行或者 Profile 传入属性的值，以实现更为灵活的构建。\n\n# maven-surefire-plugin\n\n可能是由于历史的原因，Maven 2.3 中用于执行测试的插件不是 maven-test-plugin，而是 maven-surefire-plugin。其实大部分时间内，只要你的测试 类遵循通用的命令约定（以 Test 结尾、以 TestCase 结尾、或者以 Test 开头），就几乎不用知晓该插件的存在。然而在当你想要跳过测试、排除某些 测试类、或者使用一些 TestNG 特性的时候，了解 maven-surefire-plugin 的一些配置选项就很有用了。例如 mvn test -Dtest=FooTest 这样一条命令的效果是仅运行 FooTest 测试类，这是通过控制 maven-surefire-plugin 的 test 参数实现的。\n\n# build-helper-maven-plugin\n\nMaven 默认只允许指定一个主 Java 代码目录和一个测试 Java 代码目录，虽然这其实是个应当尽量遵守的约定，但偶尔你还是会希望能够指定多个 源码目录（例如为了应对遗留项目），build-helper-maven-plugin 的 add-source 目标就是服务于这个目的，通常它被绑定到 默认生命周期的 generate-sources 阶段以添加额外的源码目录。需要强调的是，这种做法还是不推荐的，因为它破坏了 Maven 的约定，而且可能会遇到其他严格遵守约定的插件工具无法正确识别额外的源码目录。\n\nbuild-helper-maven-plugin 的另一个非常有用的目标是 attach-artifact，使用该目标你可以以 classifier 的形式选取部分项目文件生成附属构件，并同时 install 到本地仓库，也可以 deploy 到远程仓库。\n\n# exec-maven-plugin\n\nexec-maven-plugin 很好理解，顾名思义，它能让你运行任何本地的系统程序，在某些特定情况下，运行一个 Maven 外部的程序可能就是最简单的问题解决方案，这就是exec:exec的 用途，当然，该插件还允许你配置相关的程序运行参数。除了 exec 目标之外，exec-maven-plugin 还提供了一个 java 目标，该目标要求你 提供一个 mainClass 参数，然后它能够利用当前项目的依赖作为 classpath，在同一个 JVM 中运行该 mainClass。有时候，为了简单的 演示一个命令行 Java 程序，你可以在 POM 中配置好 exec-maven-plugin 的相关运行参数，然后直接在命令运行mvn exec:java 以查看运行效果。\n\n# jetty-maven-plugin\n\n在进行 Web 开发的时候，打开浏览器对应用进行手动的测试几乎是无法避免的，这种测试方法通常就是将项目打包成 war 文件，然后部署到 Web 容器 中，再启动容器进行验证，这显然十分耗时。为了帮助开发者节省时间，jetty-maven-plugin 应运而生，它完全兼容 Maven 项目的目录结构，能够周期性地检查源文件，一旦发现变更后自动更新到内置的 Jetty Web 容器中。做一些基本配置后（例如 Web 应用的 contextPath 和自动扫描变更的时间间隔），你只要执行 mvn jetty:run ，然后在 IDE 中修改代码，代码经 IDE 自动编译后产生变更，再由 jetty-maven-plugin 侦测到后更新至 Jetty 容器，这时你就可以直接 测试 Web 页面了。需要注意的是，jetty-maven-plugin 并不是宿主于 Apache 或 Codehaus 的官方插件，因此使用的时候需要额外 的配置settings.xml的 pluginGroups 元素，将 org.mortbay.jetty 这个 pluginGroup 加入。\n\n# versions-maven-plugin\n\n很多 Maven 用户遇到过这样一个问题，当项目包含大量模块的时候，为他们集体更新版本就变成一件烦人的事情，到底有没有自动化工具能帮助完成这件 事情呢？（当然你可以使用 sed 之类的文本操作工具，不过不在本文讨论范围）答案是肯定的，versions-maven- plugin 提供了很多目标帮助你管理 Maven 项目的各种版本信息。例如最常用的，命令 mvn versions:set -DnewVersion=1.1-SNAPSHOT 就能帮助你把所有模块的版本更新到 1.1-SNAPSHOT。该插件还提供了其他一些很有用的目标，display-dependency- updates 能告诉你项目依赖有哪些可用的更新；类似的 display-plugin-updates 能告诉你可用的插件更新；然后 use- latest-versions 能自动帮你将所有依赖升级到最新版本。最后，如果你对所做的更改满意，则可以使用 mvn versions:commit 提交，不满意的话也可以使用 mvn versions:revert 进行撤销。\n\n\n# Maven 命令\n\n常用 maven 命令清单：\n\n生命周期                          阶段描述\nmvn validate                  验证项目是否正确，以及所有为了完整构建必要的信息是否可用\nmvn generate-sources          生成所有需要包含在编译过程中的源代码\nmvn process-sources           处理源代码，比如过滤一些值\nmvn generate-resources        生成所有需要包含在打包过程中的资源文件\nmvn process-resources         复制并处理资源文件至目标目录，准备打包\nmvn compile                   编译项目的源代码\nmvn process-classes           后处理编译生成的文件，例如对 Java 类进行字节码增强（bytecode enhancement）\nmvn generate-test-sources     生成所有包含在测试编译过程中的测试源码\nmvn process-test-sources      处理测试源码，比如过滤一些值\nmvn generate-test-resources   生成测试需要的资源文件\nmvn process-test-resources    复制并处理测试资源文件至测试目标目录\nmvn test-compile              编译测试源码至测试目标目录\nmvn test                      使用合适的单元测试框架运行测试。这些测试应该不需要代码被打包或发布\nmvn prepare-package           在真正的打包之前，执行一些准备打包必要的操作。这通常会产生一个包的展开的处理过的版本（将会在 Maven\n                              2.1+中实现）\nmvn package                   将编译好的代码打包成可分发的格式，如 JAR，WAR，或者 EAR\nmvn pre-integration-test      执行一些在集成测试运行之前需要的动作。如建立集成测试需要的环境\nmvn integration-test          如果有必要的话，处理包并发布至集成测试可以运行的环境\nmvn post-integration-test     执行一些在集成测试运行之后需要的动作。如清理集成测试环境。\nmvn verify                    执行所有检查，验证包是有效的，符合质量规范\nmvn install                   安装包至本地仓库，以备本地的其它项目作为依赖使用\nmvn deploy                    复制最终的包至远程仓库，共享给其它开发人员和项目（通常和一次正式的发布相关）\n\n示例：最常用的 maven 构建命令\n\nmvn clean install -Dmaven.test.skip=true -B -U\n\n\n清理本地输出物，并构建 maven 项目，最后将输出物归档在本地仓库。\n\n> 💡 想了解更多 maven 命令行细节可以参考官方文档：\n> \n>  * Maven 构建生命周期说明\n>  * Maven 命令行参数说明\n\n\n# 参考资料\n\n * Maven Github\n * Maven 官方文档\n * Maven in 5 Minutes\n * Maven Getting Started Guide\n * maven 常见问题问答\n * 常用 Maven 插件介绍',normalizedContent:'# maven 快速入门\n\n\n# maven 简介\n\n\n# maven 是什么\n\nmaven 是一个项目管理工具。它负责管理项目开发过程中的几乎所有的东西。\n\n * 版本 - maven 有自己的版本定义和规则。\n * 构建 - maven 支持许多种的应用程序类型，对于每一种支持的应用程序类型都定义好了一组构建规则和工具集。\n * 输出物管理 - maven 可以管理项目构建的产物，并将其加入到用户库中。这个功能可以用于项目组和其他部门之间的交付行为。\n * 依赖关系 - maven 对依赖关系的特性进行细致的分析和划分，避免开发过程中的依赖混乱和相互污染行为\n * 文档和构建结果 - maven 的 site 命令支持各种文档信息的发布，包括构建过程的各种输出，javadoc，产品文档等。\n * 项目关系 - 一个大型的项目通常有几个小项目或者模块组成，用 maven 可以很方便地管理。\n * 移植性管理 - maven 可以针对不同的开发场景，输出不同种类的输出结果。\n\n\n# maven 的生命周期\n\nmaven 把项目的构建划分为不同的生命周期(lifecycle)。粗略一点的话，它这个过程(phase)包括：编译、测试、打包、集成测试、验证、部署。maven 中所有的执行动作(goal)都需要指明自己在这个过程中的执行位置，然后 maven 执行的时候，就依照过程的发展依次调用这些 goal 进行各种处理。\n\n这个也是 maven 的一个基本调度机制。一般来说，位置稍后的过程都会依赖于之前的过程。当然，maven 同样提供了配置文件，可以依照用户要求，跳过某些阶段。\n\n\n# maven 的标准工程结构\n\nmaven 的标准工程结构如下：\n\n|-- pom.xml(maven的核心配置文件)\n|-- src\n|-- main\n  |-- java(java源代码目录)\n  |-- resources(资源文件目录)\n|-- test\n    |-- java(单元测试代码目录)\n|-- target(输出目录，所有的输出物都存放在这个目录下)\n    |-- classes(编译后的class文件存放处)\n\n\n\n# maven 的"约定优于配置"\n\n所谓的"约定优于配置"，在 maven 中并不是完全不可以修改的，他们只是一些配置的默认值而已。但是除非必要，并不需要去修改那些约定内容。maven 默认的文件存放结构如下：\n\n每一个阶段的任务都知道怎么正确完成自己的工作，比如 compile 任务就知道从 src/main/java 下编译所有的 java 文件，并把它的输出 class 文件存放到 target/classes 中。\n\n对 maven 来说，采用"约定优于配置"的策略可以减少修改配置的工作量，也可以降低学习成本，更重要的是，给项目引入了统一的规范。\n\n\n# maven 的版本规范\n\nmaven 使用如下几个要素来唯一定位某一个输出物：\n\n * groupid - 团体、组织的标识符。团体标识的约定是，它以创建这个项目的组织名称的逆向域名(reverse domain name)开头。一般对应着 java 的包的结构。例如 org.apache\n * artifactid - 单独项目的唯一标识符。比如我们的 tomcat, commons 等。不要在 artifactid 中包含点号(.)。\n * version - 一个项目的特定版本。\n * packaging - 项目的类型，默认是 jar，描述了项目打包后的输出。类型为 jar 的项目产生一个 jar 文件，类型为 war 的项目产生一个 web 应用。\n\n例如：想在 maven 工程中引入 4.12 版本的 junit 包，添加如下依赖即可。\n\n<dependency>\n  <groupid>junit</groupid>\n  <artifactid>junit</artifactid>\n  <version>4.12</version>\n  <scope>compile</scope>\n</dependency>\n\n\nmaven 有自己的版本规范，一般是如下定义 <major version>、<minor version>、<incremental version>-<qualifier> ，比如 1.2.3-beta-01。要说明的是，maven 自己判断版本的算法是 major,minor,incremental 部分用数字比 较，qualifier 部分用字符串比较，所以要小心 alpha-2 和 alpha-15 的比较关系，最好用 alpha-02 的格式。\n\nmaven 在版本管理时候可以使用几个特殊的字符串 snapshot，latest，release。比如"1.0-snapshot"。各个部分的含义和处理逻辑如下说明：\n\n * snapshot - 这个版本一般用于开发过程中，表示不稳定的版本。\n * latest - 指某个特定构件的最新发布，这个发布可能是一个发布版，也可能是一个 snapshot 版，具体看哪个时间最后。\n * release - 指最后一个发布版。\n\n\n# maven 安装\n\n> linux 环境安装可以使用我写一键安装脚本：https://github.com/dunwu/linux-tutorial/tree/master/codes/linux/ops/service/maven\n\n\n# 环境准备\n\nmaven 依赖于 java，所以本地必须安装 jdk。\n\n打开控制台，执行 java -version 确认本地已安装 jdk。\n\n$ java -version\njava version "1.8.0_191"\njava(tm) se runtime environment (build 1.8.0_191-b12)\njava hotspot(tm) 64-bit server vm (build 25.191-b12, mixed mode)\n\n\n\n# 下载解压\n\n进入 官网下载地址，选择合适版本，下载并解压到本地。解压命令如下：\n\n# 以下解压命令分别针对 zip 包和 tar 包\nunzip apache-maven-3.6.3-bin.zip\ntar xzvf apache-maven-3.6.3-bin.tar.gz\n\n\n\n# 环境变量\n\n添加环境变量 maven_home，值为 maven 的安装路径。\n\n# 配置 unix 系统环境变量\n\n输入 vi /etc/profile ，添加环境变量如下：\n\n# maven 的根路径\nexport maven_home=/opt/maven/apache-maven-3.5.2\nexport path=$maven_home/bin:$path\n\n\n执行 source /etc/profile ，立即生效。\n\n# 配置 windows 系统环境变量\n\n右键 "计算机"，选择 "属性"，之后点击 "高级系统设置"，点击"环境变量"，来设置环境变量，有以下系统变量需要配置：\n\n\n\n\n\n\n# 检测安装成功\n\n检验是否安装成功，执行 mvn -v 命令，如果输出类似下面的 maven 版本信息，说明配置成功。\n\n$ mvn -v\napache maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-18t02:33:14+08:00)\nmaven home: /opt/maven/apache-maven-3.5.4\njava version: 1.8.0_191, vendor: oracle corporation, runtime: /mnt/disk1/jdk1.8.0_191/jre\ndefault locale: zh_cn, platform encoding: utf-8\nos name: "linux", version: "3.10.0-327.el7.x86_64", arch: "amd64", family: "unix"\n\n\n\n# maven 配置文件\n\nsetting.xml 文件是 maven 的默认配置文件，其默认路径为：<maven 安装目录>/conf/settings.xml。\n\n如果需要修改 maven 配置，直接修改 setting.xml 并保持即可。\n\n例如：想要修改本地仓库位置可以按如下配置，这样，所有通过 maven 下载打包的 jar 包都会存储在 d:\\maven\\repo 路径下。\n\n<settings xmlns="http://maven.apache.org/settings/1.1.0" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/settings/1.1.0 http://maven.apache.org/xsd/settings-1.1.0.xsd">\n  <localrepository>d:\\maven\\repo<localrepository/>\n  \x3c!-- 略 --\x3e\n</settings>\n\n\n\n# 快速入门\n\n\n# 创建 maven 工程\n\n# 初始化工程\n\n执行指令：\n\nmvn archetype:generate -dgroupid=com.mycompany.app -dartifactid=my-app -darchetypeartifactid=maven-archetype-quickstart -darchetypeversion=1.4 -dinteractivemode=false\n\n\n会在当前路径新建一个名为 my-app 的 maven 工程，其目录结构如下：\n\nmy-app\n|-- pom.xml\n`-- src\n    |-- main\n    |   `-- java\n    |       `-- com\n    |           `-- mycompany\n    |               `-- app\n    |                   `-- app.java\n    `-- test\n        `-- java\n            `-- com\n                `-- mycompany\n                    `-- app\n                        `-- apptest.java\n\n\n其中， src/main/java 目录包含 java 源码， src/test/java 目录包含 java 测试源码，而 pom.xml 文件是 maven 工程的配置文件。\n\n# pom 配置\n\npom.xml 是 maven 工程的配置文件，它描述了 maven 工程的构建方式，其配置信息是很复杂的，这里给一个最简单的配置示例：\n\nproject xmlns="http://maven.apache.org/pom/4.0.0" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <modelversion>4.0.0</modelversion>\n\n  <groupid>com.mycompany.app</groupid>\n  <artifactid>my-app</artifactid>\n  <version>1.0-snapshot</version>\n\n  <properties>\n    <maven.compiler.source>1.7</maven.compiler.source>\n    <maven.compiler.target>1.7</maven.compiler.target>\n  </properties>\n\n  <dependencies>\n    <dependency>\n      <groupid>junit</groupid>\n      <artifactid>junit</artifactid>\n      <version>4.12</version>\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n</project>\n\n\n# 构建项目\n\n执行以下命令，即可构建项目：\n\nmvn clean package -dmaven.test.skip=true -b -u\n\n\n构建成功后，会输出类似下面的信息：\n\n...\n[info] ------------------------------------------------------------------------\n[info] build success\n[info] ------------------------------------------------------------------------\n[info] total time:  2.953 s\n[info] finished at: 2019-11-24t13:05:10+01:00\n[info] ------------------------------------------------------------------------\n\n\n这时，在当前路径下会产生一个 target 目录，其中包含了构建的输出物，如：jar 包、class 文件等。\n\n这时，我们可以执行以下命令启动 jar 包：\n\njava -cp target/my-app-1.0-snapshot.jar com.mycompany.app.app\n\n\n\n# 在 intellij 中创建 maven 工程\n\n（1）创建 maven 工程\n\n依次点击 file -> new -> project 打开创建工程对话框，选择 maven 工程。\n\n\n\n（2）输入项目信息\n\n\n\n（3）点击 intellij 侧边栏中的 maven 工具界面，有几个可以直接使用的 maven 命令，可以帮助你进行构建。\n\n\n\n\n# 在 eclipse 中创建 maven 工程\n\n（1）maven 插件\n\n在 eclipse 中创建 maven 工程，需要安装 maven 插件。\n\n一般较新版本的 eclipse 都会带有 maven 插件，如果你的 eclipse 中已经有 maven 插件，可以跳过这一步骤。\n\n点击 help -> eclipse marketplace，搜索 maven 关键字，选择安装红框对应的 maven 插件。\n\n\n\n（2）maven 环境配置\n\n点击 window -> preferences\n\n如下图所示，配置 settings.xml 文件的位置\n\n\n\n（3）创建 maven 工程\n\nfile -> new -> maven project -> next，在接下来的窗口中会看到一大堆的项目模板，选择合适的模板。\n\n接下来设置项目的参数，如下：\n\n\n\ngroupid是项目组织唯一的标识符，实际对应 java 的包的结构，是 main 目录里 java 的目录结构。\n\nartifactid就是项目的唯一的标识符，实际对应项目的名称，就是项目根目录的名称。\n\n点击 finish，eclipse 会创建一个 maven 工程。\n\n（4）使用 maven 进行构建\n\neclipse 中构建方式：\n\n在 elipse 项目上右击 -> run as 就能看到很多 maven 操作。这些操作和 maven 命令是等效的。例如 maven clean，等同于 mvn clean 命令。\n\n\n\n你也可以点击 maven build，输入组合命令，并保存下来。如下图：\n\n\n\nmaven 命令构建方式：\n\n当然，你也可以直接使用 maven 命令进行构建。\n\n进入工程所在目录，输入 maven 命令就可以了。\n\n\n\n\n# 使用说明\n\n\n# 如何添加依赖\n\n在 maven 工程中添加依赖 jar 包，很简单，只要在 pom 文件中引入对应的<dependency>标签即可。\n\n参考下例：\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">\n\n  <modelversion>4.0.0</modelversion>\n  <groupid>com.zp.maven</groupid>\n  <artifactid>mavendemo</artifactid>\n  <version>0.0.1-snapshot</version>\n  <packaging>jar</packaging>\n  <name>mavendemo</name>\n  <url>http://maven.apache.org</url>\n\n  <properties>\n    <project.build.sourceencoding>utf-8</project.build.sourceencoding>\n    <junit.version>3.8.1</junit.version>\n  </properties>\n\n  <dependencies>\n    <dependency>\n      <groupid>junit</groupid>\n      <artifactid>junit</artifactid>\n      <version>${junit.version}</version>\n      <scope>test</scope>\n    </dependency>\n\n    <dependency>\n      <groupid>log4j</groupid>\n      <artifactid>log4j</artifactid>\n      <version>1.2.12</version>\n      <scope>compile</scope>\n    </dependency>\n  </dependencies>\n</project>\n\n\n<dependency> 标签最常用的四个属性标签：\n\n * <groupid> - 项目组织唯一的标识符，实际对应 java 的包的结构。\n * <artifactid> - 项目唯一的标识符，实际对应项目的名称，就是项目根目录的名称。\n * <version> - jar 包的版本号。可以直接填版本数字，也可以在 properties 标签中设置属性值。\n * <scope> - jar 包的作用范围。可以填写 compile、runtime、test、system 和 provided。用来在编译、测试等场景下选择对应的 classpath。\n\n\n# 如何寻找 jar 包\n\n可以在 http://mvnrepository.com/ 站点搜寻你想要的 jar 包版本\n\n例如，想要使用 log4j，可以找到需要的版本号，然后拷贝对应的 maven 标签信息，将其添加到 pom .xml 文件中。\n\n\n# 如何使用 maven 插件(plugin)\n\n要添加 maven 插件，可以在 pom.xml 文件中添加 <plugin> 标签。\n\n<build>\n  <plugins>\n    <plugin>\n      <groupid>org.apache.maven.plugins</groupid>\n      <artifactid>maven-compiler-plugin</artifactid>\n      <version>3.3</version>\n      <configuration>\n        <source>1.7</source>\n        <target>1.7</target>\n      </configuration>\n    </plugin>\n  </plugins>\n</build>\n\n\n<configuration> 标签用来配置插件的一些使用参数。\n\n\n# 如何一次编译多个工程\n\n假设要创建一个父 maven 工程，它有两个子工程：my-app 和 my-webapp：\n\n+- pom.xml\n+- my-app\n| +- pom.xml\n| +- src\n|   +- main\n|     +- java\n+- my-webapp\n| +- pom.xml\n| +- src\n|   +- main\n|     +- webapp\n\n\napp 工程的 pom.xml 如下，重点在于在 modules 中引入两个子 module：\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <modelversion>4.0.0</modelversion>\n\n  <groupid>com.mycompany.app</groupid>\n  <artifactid>app</artifactid>\n  <version>1.0-snapshot</version>\n  <packaging>pom</packaging>\n\n  <modules>\n    <module>my-app</module>\n    <module>my-webapp</module>\n  </modules>\n</project>\n\n\n选择编译 xxx 时，会依次对它的所有 module 执行相同操作。\n\n\n# 常用 maven 插件\n\n> 更多详情请参考：https://maven.apache.org/plugins/\n\n# maven-antrun-plugin\n\nmaven-antrun-plugin 能让用户在 maven 项目中运行 ant 任务。用户可以直接在该插件的配置以 ant 的方式编写 target， 然后交给该插件的 run 目标去执行。在一些由 ant 往 maven 迁移的项目中，该插件尤其有用。此外当你发现需要编写一些自定义程度很高的任务，同时又觉 得 maven 不够灵活时，也可以以 ant 的方式实现之。maven-antrun-plugin 的 run 目标通常与生命周期绑定运行。\n\n# maven-archetype-plugin\n\narchtype 指项目的骨架，maven 初学者最开始执行的 maven 命令可能就是mvn archetype:generate，这实际上就是让 maven-archetype-plugin 生成一个很简单的项目骨架，帮助开发者快速上手。可能也有人看到一些文档写了mvn archetype:create， 但实际上 create 目标已经被弃用了，取而代之的是 generate 目标，该目标使用交互式的方式提示用户输入必要的信息以创建项目，体验更好。 maven-archetype-plugin 还有一些其他目标帮助用户自己定义项目原型，例如你由一个产品需要交付给很多客户进行二次开发，你就可以为 他们提供一个 archtype，帮助他们快速上手。\n\n# maven-assembly-plugin\n\nmaven-assembly-plugin 的用途是将项目打包，该包可能包含了项目的可执行文件、源代码、readme、平台脚本等等。 maven-assembly-plugin 支持各种主流的格式如 zip、tar.gz、jar 和 war 等，具体打包哪些文件是高度可控的，例如用户可以 按文件级别的粒度、文件集级别的粒度、模块级别的粒度、以及依赖级别的粒度控制打包，此外，包含和排除配置也是支持的。maven-assembly- plugin 要求用户使用一个名为assembly.xml的元数据文件来表述打包，它的 single 目标可以直接在命令行调用，也可以被绑定至生命周期。\n\n# maven-dependency-plugin\n\nmaven-dependency-plugin 最大的用途是帮助分析项目依赖，dependency:list能够列出项目最终解析到的依赖列表，dependency:tree能进一步的描绘项目依赖树，dependency:analyze可以告诉你项目依赖潜在的问题，如果你有直接使用到的却未声明的依赖，该目标就会发出警告。maven-dependency-plugin 还有很多目标帮助你操作依赖文件，例如dependency:copy-dependencies能将项目依赖从本地 maven 仓库复制到某个特定的文件夹下面。\n\n# maven-enforcer-plugin\n\n在一个稍大一点的组织或团队中，你无法保证所有成员都熟悉 maven，那他们做一些比较愚蠢的事情就会变得很正常，例如给项目引入了外部的 snapshot 依赖而导致构建不稳定，使用了一个与大家不一致的 maven 版本而经常抱怨构建出现诡异问题。maven-enforcer- plugin 能够帮助你避免之类问题，它允许你创建一系列规则强制大家遵守，包括设定 java 版本、设定 maven 版本、禁止某些依赖、禁止 snapshot 依赖。只要在一个父 pom 配置规则，然后让大家继承，当规则遭到破坏的时候，maven 就会报错。除了标准的规则之外，你还可以扩展该插 件，编写自己的规则。maven-enforcer-plugin 的 enforce 目标负责检查规则，它默认绑定到生命周期的 validate 阶段。\n\n# maven-help-plugin\n\nmaven-help-plugin 是一个小巧的辅助工具，最简单的help:system可以打印所有可用的环境变量和 java 系统属性。help:effective-pom和help:effective-settings最 为有用，它们分别打印项目的有效 pom 和有效 settings，有效 pom 是指合并了所有父 pom（包括 super pom）后的 xml，当你不确定 pom 的某些信息从何而来时，就可以查看有效 pom。有效 settings 同理，特别是当你发现自己配置的 settings.xml 没有生效时，就可以用help:effective-settings来验证。此外，maven-help-plugin 的 describe 目标可以帮助你描述任何一个 maven 插件的信息，还有 all-profiles 目标和 active-profiles 目标帮助查看项目的 profile。\n\n# maven-release-plugin\n\nmaven-release-plugin 的用途是帮助自动化项目版本发布，它依赖于 pom 中的 scm 信息。release:prepare用来准备版本发布，具体的工作包括检查是否有未提交代码、检查是否有 snapshot 依赖、升级项目的 snapshot 版本至 release 版本、为项目打标签等等。release:perform则 是签出标签中的 release 源码，构建并发布。版本发布是非常琐碎的工作，它涉及了各种检查，而且由于该工作仅仅是偶尔需要，因此手动操作很容易遗漏一 些细节，maven-release-plugin 让该工作变得非常快速简便，不易出错。maven-release-plugin 的各种目标通常直接在 命令行调用，因为版本发布显然不是日常构建生命周期的一部分。\n\n# maven-resources-plugin\n\n为了使项目结构更为清晰，maven 区别对待 java 代码文件和资源文件，maven-compiler-plugin 用来编译 java 代码，maven-resources-plugin 则用来处理资源文件。默认的主资源文件目录是src/main/resources，很多用户会需要添加额外的资源文件目录，这个时候就可以通过配置 maven-resources-plugin 来实现。此外，资源文件过滤也是 maven 的一大特性，你可以在资源文件中使用*${propertyname}*形式的 maven 属性，然后配置 maven-resources-plugin 开启对资源文件的过滤，之后就可以针对不同环境通过命令行或者 profile 传入属性的值，以实现更为灵活的构建。\n\n# maven-surefire-plugin\n\n可能是由于历史的原因，maven 2.3 中用于执行测试的插件不是 maven-test-plugin，而是 maven-surefire-plugin。其实大部分时间内，只要你的测试 类遵循通用的命令约定（以 test 结尾、以 testcase 结尾、或者以 test 开头），就几乎不用知晓该插件的存在。然而在当你想要跳过测试、排除某些 测试类、或者使用一些 testng 特性的时候，了解 maven-surefire-plugin 的一些配置选项就很有用了。例如 mvn test -dtest=footest 这样一条命令的效果是仅运行 footest 测试类，这是通过控制 maven-surefire-plugin 的 test 参数实现的。\n\n# build-helper-maven-plugin\n\nmaven 默认只允许指定一个主 java 代码目录和一个测试 java 代码目录，虽然这其实是个应当尽量遵守的约定，但偶尔你还是会希望能够指定多个 源码目录（例如为了应对遗留项目），build-helper-maven-plugin 的 add-source 目标就是服务于这个目的，通常它被绑定到 默认生命周期的 generate-sources 阶段以添加额外的源码目录。需要强调的是，这种做法还是不推荐的，因为它破坏了 maven 的约定，而且可能会遇到其他严格遵守约定的插件工具无法正确识别额外的源码目录。\n\nbuild-helper-maven-plugin 的另一个非常有用的目标是 attach-artifact，使用该目标你可以以 classifier 的形式选取部分项目文件生成附属构件，并同时 install 到本地仓库，也可以 deploy 到远程仓库。\n\n# exec-maven-plugin\n\nexec-maven-plugin 很好理解，顾名思义，它能让你运行任何本地的系统程序，在某些特定情况下，运行一个 maven 外部的程序可能就是最简单的问题解决方案，这就是exec:exec的 用途，当然，该插件还允许你配置相关的程序运行参数。除了 exec 目标之外，exec-maven-plugin 还提供了一个 java 目标，该目标要求你 提供一个 mainclass 参数，然后它能够利用当前项目的依赖作为 classpath，在同一个 jvm 中运行该 mainclass。有时候，为了简单的 演示一个命令行 java 程序，你可以在 pom 中配置好 exec-maven-plugin 的相关运行参数，然后直接在命令运行mvn exec:java 以查看运行效果。\n\n# jetty-maven-plugin\n\n在进行 web 开发的时候，打开浏览器对应用进行手动的测试几乎是无法避免的，这种测试方法通常就是将项目打包成 war 文件，然后部署到 web 容器 中，再启动容器进行验证，这显然十分耗时。为了帮助开发者节省时间，jetty-maven-plugin 应运而生，它完全兼容 maven 项目的目录结构，能够周期性地检查源文件，一旦发现变更后自动更新到内置的 jetty web 容器中。做一些基本配置后（例如 web 应用的 contextpath 和自动扫描变更的时间间隔），你只要执行 mvn jetty:run ，然后在 ide 中修改代码，代码经 ide 自动编译后产生变更，再由 jetty-maven-plugin 侦测到后更新至 jetty 容器，这时你就可以直接 测试 web 页面了。需要注意的是，jetty-maven-plugin 并不是宿主于 apache 或 codehaus 的官方插件，因此使用的时候需要额外 的配置settings.xml的 plugingroups 元素，将 org.mortbay.jetty 这个 plugingroup 加入。\n\n# versions-maven-plugin\n\n很多 maven 用户遇到过这样一个问题，当项目包含大量模块的时候，为他们集体更新版本就变成一件烦人的事情，到底有没有自动化工具能帮助完成这件 事情呢？（当然你可以使用 sed 之类的文本操作工具，不过不在本文讨论范围）答案是肯定的，versions-maven- plugin 提供了很多目标帮助你管理 maven 项目的各种版本信息。例如最常用的，命令 mvn versions:set -dnewversion=1.1-snapshot 就能帮助你把所有模块的版本更新到 1.1-snapshot。该插件还提供了其他一些很有用的目标，display-dependency- updates 能告诉你项目依赖有哪些可用的更新；类似的 display-plugin-updates 能告诉你可用的插件更新；然后 use- latest-versions 能自动帮你将所有依赖升级到最新版本。最后，如果你对所做的更改满意，则可以使用 mvn versions:commit 提交，不满意的话也可以使用 mvn versions:revert 进行撤销。\n\n\n# maven 命令\n\n常用 maven 命令清单：\n\n生命周期                          阶段描述\nmvn validate                  验证项目是否正确，以及所有为了完整构建必要的信息是否可用\nmvn generate-sources          生成所有需要包含在编译过程中的源代码\nmvn process-sources           处理源代码，比如过滤一些值\nmvn generate-resources        生成所有需要包含在打包过程中的资源文件\nmvn process-resources         复制并处理资源文件至目标目录，准备打包\nmvn compile                   编译项目的源代码\nmvn process-classes           后处理编译生成的文件，例如对 java 类进行字节码增强（bytecode enhancement）\nmvn generate-test-sources     生成所有包含在测试编译过程中的测试源码\nmvn process-test-sources      处理测试源码，比如过滤一些值\nmvn generate-test-resources   生成测试需要的资源文件\nmvn process-test-resources    复制并处理测试资源文件至测试目标目录\nmvn test-compile              编译测试源码至测试目标目录\nmvn test                      使用合适的单元测试框架运行测试。这些测试应该不需要代码被打包或发布\nmvn prepare-package           在真正的打包之前，执行一些准备打包必要的操作。这通常会产生一个包的展开的处理过的版本（将会在 maven\n                              2.1+中实现）\nmvn package                   将编译好的代码打包成可分发的格式，如 jar，war，或者 ear\nmvn pre-integration-test      执行一些在集成测试运行之前需要的动作。如建立集成测试需要的环境\nmvn integration-test          如果有必要的话，处理包并发布至集成测试可以运行的环境\nmvn post-integration-test     执行一些在集成测试运行之后需要的动作。如清理集成测试环境。\nmvn verify                    执行所有检查，验证包是有效的，符合质量规范\nmvn install                   安装包至本地仓库，以备本地的其它项目作为依赖使用\nmvn deploy                    复制最终的包至远程仓库，共享给其它开发人员和项目（通常和一次正式的发布相关）\n\n示例：最常用的 maven 构建命令\n\nmvn clean install -dmaven.test.skip=true -b -u\n\n\n清理本地输出物，并构建 maven 项目，最后将输出物归档在本地仓库。\n\n> 💡 想了解更多 maven 命令行细节可以参考官方文档：\n> \n>  * maven 构建生命周期说明\n>  * maven 命令行参数说明\n\n\n# 参考资料\n\n * maven github\n * maven 官方文档\n * maven in 5 minutes\n * maven getting started guide\n * maven 常见问题问答\n * 常用 maven 插件介绍',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Maven 教程之 pom.xml 详解",frontmatter:{title:"Maven 教程之 pom.xml 详解",categories:["编程","Java","软件","构建"],tags:["Java","构建","Maven"],abbrlink:"15944f49",date:"2019-05-14T14:57:33.000Z",permalink:"/pages/f594fa/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/01.%E6%9E%84%E5%BB%BA/01.Maven/02.Maven%E6%95%99%E7%A8%8B%E4%B9%8Bpom.xml%E8%AF%A6%E8%A7%A3.html",relativePath:"11.软件/01.构建/01.Maven/02.Maven教程之pom.xml详解.md",key:"v-101ee2a2",path:"/pages/f594fa/",headers:[{level:2,title:"pom.xml 简介",slug:"pom-xml-简介",normalizedTitle:"pom.xml 简介",charIndex:27},{level:3,title:"什么是 pom",slug:"什么是-pom",normalizedTitle:"什么是 pom",charIndex:42},{level:3,title:"pom 配置一览",slug:"pom-配置一览",normalizedTitle:"pom 配置一览",charIndex:132},{level:2,title:"基本配置",slug:"基本配置",normalizedTitle:"基本配置",charIndex:1434},{level:3,title:"maven 坐标",slug:"maven-坐标",normalizedTitle:"maven 坐标",charIndex:2019},{level:2,title:"依赖配置",slug:"依赖配置",normalizedTitle:"依赖配置",charIndex:2864},{level:3,title:"dependencies",slug:"dependencies",normalizedTitle:"dependencies",charIndex:546},{level:3,title:"parent",slug:"parent",normalizedTitle:"parent",charIndex:581},{level:3,title:"dependencyManagement",slug:"dependencymanagement",normalizedTitle:"dependencymanagement",charIndex:604},{level:3,title:"modules",slug:"modules",normalizedTitle:"modules",charIndex:655},{level:3,title:"properties",slug:"properties",normalizedTitle:"properties",charIndex:680},{level:2,title:"构建配置",slug:"构建配置",normalizedTitle:"构建配置",charIndex:6541},{level:3,title:"build",slug:"build",normalizedTitle:"build",charIndex:738},{level:4,title:"resources",slug:"resources",normalizedTitle:"resources",charIndex:7639},{level:4,title:"plugins",slug:"plugins",normalizedTitle:"plugins",charIndex:5540},{level:4,title:"pluginManagement",slug:"pluginmanagement",normalizedTitle:"pluginmanagement",charIndex:5548},{level:4,title:"directories",slug:"directories",normalizedTitle:"directories",charIndex:11477},{level:4,title:"extensions",slug:"extensions",normalizedTitle:"extensions",charIndex:9500},{level:3,title:"reporting",slug:"reporting",normalizedTitle:"reporting",charIndex:759},{level:2,title:"项目信息",slug:"项目信息",normalizedTitle:"项目信息",charIndex:14128},{level:2,title:"环境配置",slug:"环境配置",normalizedTitle:"环境配置",charIndex:15966},{level:3,title:"issueManagement",slug:"issuemanagement",normalizedTitle:"issuemanagement",charIndex:1092},{level:3,title:"ciManagement",slug:"cimanagement",normalizedTitle:"cimanagement",charIndex:1133},{level:3,title:"mailingLists",slug:"mailinglists",normalizedTitle:"mailinglists",charIndex:1168},{level:3,title:"scm",slug:"scm",normalizedTitle:"scm",charIndex:1203},{level:3,title:"prerequisites",slug:"prerequisites",normalizedTitle:"prerequisites",charIndex:1220},{level:3,title:"repositories",slug:"repositories",normalizedTitle:"repositories",charIndex:1257},{level:3,title:"pluginRepositories",slug:"pluginrepositories",normalizedTitle:"pluginrepositories",charIndex:1292},{level:3,title:"distributionManagement",slug:"distributionmanagement",normalizedTitle:"distributionmanagement",charIndex:1339},{level:3,title:"profiles",slug:"profiles",normalizedTitle:"profiles",charIndex:1394},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:21784}],headersStr:"pom.xml 简介 什么是 pom pom 配置一览 基本配置 maven 坐标 依赖配置 dependencies parent dependencyManagement modules properties 构建配置 build resources plugins pluginManagement directories extensions reporting 项目信息 环境配置 issueManagement ciManagement mailingLists scm prerequisites repositories pluginRepositories distributionManagement profiles 参考资料",content:'# Maven 教程之 pom.xml 详解\n\n\n# pom.xml 简介\n\n\n# 什么是 pom\n\nPOM 是 Project Object Model 的缩写，即项目对象模型。\n\npom.xml 就是 maven 的配置文件，用以描述项目的各种信息。\n\n\n# pom 配置一览\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <modelVersion>4.0.0</modelVersion>\n\n  \x3c!-- The Basics --\x3e\n  <groupId>...</groupId>\n  <artifactId>...</artifactId>\n  <version>...</version>\n  <packaging>...</packaging>\n  <dependencies>...</dependencies>\n  <parent>...</parent>\n  <dependencyManagement>...</dependencyManagement>\n  <modules>...</modules>\n  <properties>...</properties>\n\n  \x3c!-- Build Settings --\x3e\n  <build>...</build>\n  <reporting>...</reporting>\n\n  \x3c!-- More Project Information --\x3e\n  <name>...</name>\n  <description>...</description>\n  <url>...</url>\n  <inceptionYear>...</inceptionYear>\n  <licenses>...</licenses>\n  <organization>...</organization>\n  <developers>...</developers>\n  <contributors>...</contributors>\n\n  \x3c!-- Environment Settings --\x3e\n  <issueManagement>...</issueManagement>\n  <ciManagement>...</ciManagement>\n  <mailingLists>...</mailingLists>\n  <scm>...</scm>\n  <prerequisites>...</prerequisites>\n  <repositories>...</repositories>\n  <pluginRepositories>...</pluginRepositories>\n  <distributionManagement>...</distributionManagement>\n  <profiles>...</profiles>\n</project>\n\n\n\n# 基本配置\n\n * project - project 是 pom.xml 中描述符的根。\n * modelVersion - modelVersion 指定 pom.xml 符合哪个版本的描述符。maven 2 和 3 只能为 4.0.0。\n\n一般 jar 包被识别为： groupId:artifactId:version 的形式。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>org.codehaus.mojo</groupId>\n  <artifactId>my-project</artifactId>\n  <version>1.0</version>\n  <packaging>war</packaging>\n</project>\n\n\n\n# maven 坐标\n\n在 maven 中，根据 groupId、artifactId、version 组合成 groupId:artifactId:version 来唯一识别一个 jar 包。\n\n * groupId - 团体、组织的标识符。团体标识的约定是，它以创建这个项目的组织名称的逆向域名(reverse domain name)开头。一般对应着 java 的包结构。\n * artifactId - 单独项目的唯一标识符。比如我们的 tomcat、commons 等。不要在 artifactId 中包含点号(.)。\n * version - 一个项目的特定版本。\n   * maven 有自己的版本规范，一般是如下定义 major version、minor version、incremental version-qualifier ，比如 1.2.3-beta-01。要说明的是，maven 自己判断版本的算法是 major、minor、incremental 部分用数字比较，qualifier 部分用字符串比较，所以要小心 alpha-2 和 alpha-15 的比较关系，最好用 alpha-02 的格式。\n   * maven 在版本管理时候可以使用几个特殊的字符串 SNAPSHOT、LATEST、RELEASE。比如 1.0-SNAPSHOT。各个部分的含义和处理逻辑如下说明：\n     * SNAPSHOT - 这个版本一般用于开发过程中，表示不稳定的版本。\n     * LATEST - 指某个特定构件的最新发布，这个发布可能是一个发布版，也可能是一个 snapshot 版，具体看哪个时间最后。\n     * RELEASE ：指最后一个发布版。\n * packaging - 项目的类型，描述了项目打包后的输出，默认是 jar。常见的输出类型为：pom, jar, maven-plugin, ejb, war, ear, rar, par。\n\n\n# 依赖配置\n\n\n# dependencies\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <dependencies>\n    <dependency>\n     <groupId>org.apache.maven</groupId>\n      <artifactId>maven-embedder</artifactId>\n      <version>2.0</version>\n      <type>jar</type>\n      <scope>test</scope>\n      <optional>true</optional>\n      <exclusions>\n        <exclusion>\n          <groupId>org.apache.maven</groupId>\n          <artifactId>maven-core</artifactId>\n        </exclusion>\n      </exclusions>\n    </dependency>\n    ...\n  </dependencies>\n  ...\n</project>\n\n\n * groupId, artifactId, version - 和基本配置中的 groupId、artifactId、version 意义相同。\n * type - 对应 packaging 的类型，如果不使用 type 标签，maven 默认为 jar。\n * scope - 此元素指的是任务的类路径（编译和运行时，测试等）以及如何限制依赖关系的传递性。有 5 种可用的限定范围：\n   * compile - 如果没有指定 scope 标签，maven 默认为这个范围。编译依赖关系在所有 classpath 中都可用。此外，这些依赖关系被传播到依赖项目。\n   * provided - 与 compile 类似，但是表示您希望 jdk 或容器在运行时提供它。它只适用于编译和测试 classpath，不可传递。\n   * runtime - 此范围表示编译不需要依赖关系，而是用于执行。它是在运行时和测试 classpath，但不是编译 classpath。\n   * test - 此范围表示正常使用应用程序不需要依赖关系，仅适用于测试编译和执行阶段。它不是传递的。\n   * system - 此范围与 provided 类似，除了您必须提供明确包含它的 jar。该 artifact 始终可用，并且不是在仓库中查找。\n * systemPath - 仅当依赖范围是系统时才使用。否则，如果设置此元素，构建将失败。该路径必须是绝对路径，因此建议使用 propertie 来指定特定的路径，如$ {java.home} / lib。由于假定先前安装了系统范围依赖关系，maven 将不会检查项目的仓库，而是检查库文件是否存在。如果没有，maven 将会失败，并建议您手动下载安装。\n * optional - optional 让其他项目知道，当您使用此项目时，您不需要这种依赖性才能正常工作。\n * exclusions - 包含一个或多个排除元素，每个排除元素都包含一个表示要排除的依赖关系的 groupId 和 artifactId。与可选项不同，可能或可能不会安装和使用，排除主动从依赖关系树中删除自己。\n\n\n# parent\n\nmaven 支持继承功能。子 POM 可以使用 parent 指定父 POM ，然后继承其配置。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <modelVersion>4.0.0</modelVersion>\n\n  <parent>\n    <groupId>org.codehaus.mojo</groupId>\n    <artifactId>my-parent</artifactId>\n    <version>2.0</version>\n    <relativePath>../my-parent</relativePath>\n  </parent>\n\n  <artifactId>my-project</artifactId>\n</project>\n\n\n * relativePath - 注意 relativePath 元素。在搜索本地和远程存储库之前，它不是必需的，但可以用作 maven 的指示符，以首先搜索给定该项目父级的路径。\n\n\n# dependencyManagement\n\ndependencyManagement 是表示依赖 jar 包的声明。即你在项目中的 dependencyManagement 下声明了依赖，maven 不会加载该依赖，dependencyManagement 声明可以被子 POM 继承。\n\ndependencyManagement 的一个使用案例是当有父子项目的时候，父项目中可以利用 dependencyManagement 声明子项目中需要用到的依赖 jar 包，之后，当某个或者某几个子项目需要加载该依赖的时候，就可以在子项目中 dependencies 节点只配置 groupId 和 artifactId 就可以完成依赖的引用。\n\ndependencyManagement 主要是为了统一管理依赖包的版本，确保所有子项目使用的版本一致，类似的还有plugins和pluginManagement。\n\n\n# modules\n\n子模块列表。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>org.codehaus.mojo</groupId>\n  <artifactId>my-parent</artifactId>\n  <version>2.0</version>\n  <packaging>pom</packaging>\n\n  <modules>\n    <module>my-project</module>\n    <module>another-project</module>\n    <module>third-project/pom-example.xml</module>\n  </modules>\n</project>\n\n\n\n# properties\n\n属性列表。定义的属性可以在 pom.xml 文件中任意处使用。使用方式为 ${propertie} 。\n\n<project>\n  ...\n  <properties>\n    <maven.compiler.source>1.7<maven.compiler.source>\n    <maven.compiler.target>1.7<maven.compiler.target>\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>\n  </properties>\n  ...\n</project>\n\n\n\n# 构建配置\n\n\n# build\n\nbuild 可以分为 "project build" 和 "profile build"。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  \x3c!-- "Project Build" contains more elements than just the BaseBuild set --\x3e\n  <build>...</build>\n\n  <profiles>\n    <profile>\n      \x3c!-- "Profile Build" contains a subset of "Project Build"s elements --\x3e\n      <build>...</build>\n    </profile>\n  </profiles>\n</project>\n\n\n基本构建配置：\n\n<build>\n  <defaultGoal>install</defaultGoal>\n  <directory>${basedir}/target</directory>\n  <finalName>${artifactId}-${version}</finalName>\n  <filters>\n    <filter>filters/filter1.properties</filter>\n  </filters>\n  ...\n</build>\n\n\ndefaultGoal : 默认执行目标或阶段。如果给出了一个目标，它应该被定义为它在命令行中（如 jar：jar）。如果定义了一个阶段（如安装），也是如此。\n\ndirectory ：构建时的输出路径。默认为：${basedir}/target 。\n\nfinalName ：这是项目的最终构建名称（不包括文件扩展名，例如：my-project-1.0.jar）\n\nfilter ：定义 * .properties 文件，其中包含适用于接受其设置的资源的属性列表（如下所述）。换句话说，过滤器文件中定义的“name = value”对在代码中替换$ {name}字符串。\n\n# resources\n\n资源的配置。资源文件通常不是代码，不需要编译，而是在项目需要捆绑使用的内容。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <build>\n    ...\n    <resources>\n      <resource>\n        <targetPath>META-INF/plexus</targetPath>\n        <filtering>false</filtering>\n        <directory>${basedir}/src/main/plexus</directory>\n        <includes>\n          <include>configuration.xml</include>\n        </includes>\n        <excludes>\n          <exclude>**/*.properties</exclude>\n        </excludes>\n      </resource>\n    </resources>\n    <testResources>\n      ...\n    </testResources>\n    ...\n  </build>\n</project>\n\n\n * resources: 资源元素的列表，每个资源元素描述与此项目关联的文件和何处包含文件。\n * targetPath: 指定从构建中放置资源集的目录结构。目标路径默认为基本目录。将要包装在 jar 中的资源的通常指定的目标路径是 META-INF。\n * filtering: 值为 true 或 false。表示是否要为此资源启用过滤。请注意，该过滤器 * .properties 文件不必定义为进行过滤 - 资源还可以使用默认情况下在 POM 中定义的属性（例如$ {project.version}），并将其传递到命令行中“-D”标志（例如，“-Dname = value”）或由 properties 元素显式定义。过滤文件覆盖上面。\n * directory: 值定义了资源的路径。构建的默认目录是${basedir}/src/main/resources。\n * includes: 一组文件匹配模式，指定目录中要包括的文件，使用*作为通配符。\n * excludes: 与 includes 类似，指定目录中要排除的文件，使用*作为通配符。注意：如果 include 和 exclude 发生冲突，maven 会以 exclude 作为有效项。\n * testResources: testResources 与 resources 功能类似，区别仅在于：testResources 指定的资源仅用于 test 阶段，并且其默认资源目录为：${basedir}/src/test/resources 。\n\n# plugins\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <build>\n    ...\n    <plugins>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-jar-plugin</artifactId>\n        <version>2.6</version>\n        <extensions>false</extensions>\n        <inherited>true</inherited>\n        <configuration>\n          <classifier>test</classifier>\n        </configuration>\n        <dependencies>...</dependencies>\n        <executions>...</executions>\n      </plugin>\n    </plugins>\n  </build>\n</project>\n\n\n * groupId, artifactId, version ：和基本配置中的 groupId、artifactId、version 意义相同。\n\n * extensions ：值为 true 或 false。是否加载此插件的扩展名。默认为 false。\n\n * inherited ：值为 true 或 false。这个插件配置是否应该适用于继承自这个插件的 POM。默认值为 true。\n\n * configuration - 这是针对个人插件的配置，这里不扩散讲解。\n\n * dependencies ：这里的 dependencies 是插件本身所需要的依赖。\n\n * executions ：需要记住的是，插件可能有多个目标。每个目标可能有一个单独的配置，甚至可能将插件的目标完全绑定到不同的阶段。执行配置插件的目标的执行。\n   \n   * id: 执行目标的标识。\n   * goals: 像所有多元化的 POM 元素一样，它包含单个元素的列表。在这种情况下，这个执行块指定的插件目标列表。\n   * phase: 这是执行目标列表的阶段。这是一个非常强大的选项，允许将任何目标绑定到构建生命周期中的任何阶段，从而改变 maven 的默认行为。\n   * inherited: 像上面的继承元素一样，设置这个 false 会阻止 maven 将这个执行传递给它的子代。此元素仅对父 POM 有意义。\n   * configuration: 与上述相同，但将配置限制在此特定目标列表中，而不是插件下的所有目标。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <build>\n    <plugins>\n      <plugin>\n        <artifactId>maven-antrun-plugin</artifactId>\n        <version>1.1</version>\n        <executions>\n          <execution>\n            <id>echodir</id>\n            <goals>\n              <goal>run</goal>\n            </goals>\n            <phase>verify</phase>\n            <inherited>false</inherited>\n            <configuration>\n              <tasks>\n                <echo>Build Dir: ${project.build.directory}</echo>\n              </tasks>\n            </configuration>\n          </execution>\n        </executions>\n\n      </plugin>\n    </plugins>\n  </build>\n</project>\n\n\n# pluginManagement\n\n与 dependencyManagement 很相似，在当前 POM 中仅声明插件，而不是实际引入插件。子 POM 中只配置 groupId 和 artifactId 就可以完成插件的引用，且子 POM 有权重写 pluginManagement 定义。\n\n它的目的在于统一所有子 POM 的插件版本。\n\n# directories\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <build>\n    <sourceDirectory>${basedir}/src/main/java</sourceDirectory>\n    <scriptSourceDirectory>${basedir}/src/main/scripts</scriptSourceDirectory>\n    <testSourceDirectory>${basedir}/src/test/java</testSourceDirectory>\n    <outputDirectory>${basedir}/target/classes</outputDirectory>\n    <testOutputDirectory>${basedir}/target/test-classes</testOutputDirectory>\n    ...\n  </build>\n</project>\n\n\n目录元素集合存在于 build 元素中，它为整个 POM 设置了各种目录结构。由于它们在配置文件构建中不存在，所以这些不能由配置文件更改。\n\n如果上述目录元素的值设置为绝对路径（扩展属性时），则使用该目录。否则，它是相对于基础构建目录：${basedir}。\n\n# extensions\n\n扩展是在此构建中使用的 artifacts 的列表。它们将被包含在运行构建的 classpath 中。它们可以启用对构建过程的扩展（例如为 Wagon 传输机制添加一个 ftp 提供程序），并使活动的插件能够对构建生命周期进行更改。简而言之，扩展是在构建期间激活的 artifacts。扩展不需要实际执行任何操作，也不包含 Mojo。因此，扩展对于指定普通插件接口的多个实现中的一个是非常好的。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <build>\n    ...\n    <extensions>\n      <extension>\n        <groupId>org.apache.maven.wagon</groupId>\n        <artifactId>wagon-ftp</artifactId>\n        <version>1.0-alpha-3</version>\n      </extension>\n    </extensions>\n    ...\n  </build>\n</project>\n\n\n\n# reporting\n\n报告包含特定针对 site 生成阶段的元素。某些 maven 插件可以生成 reporting 元素下配置的报告，例如：生成 javadoc 报告。reporting 与 build 元素配置插件的能力相似。明显的区别在于：在执行块中插件目标的控制不是细粒度的，报表通过配置 reportSet 元素来精细控制。而微妙的区别在于 reporting 元素下的 configuration 元素可以用作 build 下的 configuration ，尽管相反的情况并非如此（ build 下的 configuration 不影响 reporting 元素下的 configuration ）。\n\n另一个区别就是 plugin 下的 outputDirectory 元素。在报告的情况下，默认输出目录为 ${basedir}/target/site。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <reporting>\n    <plugins>\n      <plugin>\n        ...\n        <reportSets>\n          <reportSet>\n            <id>sunlink</id>\n            <reports>\n              <report>javadoc</report>\n            </reports>\n            <inherited>true</inherited>\n            <configuration>\n              <links>\n                <link>http://java.sun.com/j2se/1.5.0/docs/api/</link>\n              </links>\n            </configuration>\n          </reportSet>\n        </reportSets>\n      </plugin>\n    </plugins>\n  </reporting>\n  ...\n</project>\n\n\n\n# 项目信息\n\n项目信息相关的这部分标签都不是必要的，也就是说完全可以不填写。\n\n它的作用仅限于描述项目的详细信息。\n\n下面的示例是项目信息相关标签的清单：\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n\n  \x3c!-- 项目信息 begin --\x3e\n\n  \x3c!--项目名--\x3e\n  <name>maven-notes</name>\n\n  \x3c!--项目描述--\x3e\n  <description>maven 学习笔记</description>\n\n  \x3c!--项目url--\x3e\n  <url>https://github.com/dunwu/maven-notes</url>\n\n  \x3c!--项目开发年份--\x3e\n  <inceptionYear>2017</inceptionYear>\n\n  \x3c!--开源协议--\x3e\n  <licenses>\n    <license>\n      <name>Apache License, Version 2.0</name>\n      <url>https://www.apache.org/licenses/LICENSE-2.0.txt</url>\n      <distribution>repo</distribution>\n      <comments>A business-friendly OSS license</comments>\n    </license>\n  </licenses>\n\n  \x3c!--组织信息(如公司、开源组织等)--\x3e\n  <organization>\n    <name>...</name>\n    <url>...</url>\n  </organization>\n\n  \x3c!--开发者列表--\x3e\n  <developers>\n    <developer>\n      <id>victor</id>\n      <name>Zhang Peng</name>\n      <email>forbreak at 163.com</email>\n      <url>https://github.com/dunwu</url>\n      <organization>...</organization>\n      <organizationUrl>...</organizationUrl>\n      <roles>\n        <role>architect</role>\n        <role>developer</role>\n      </roles>\n      <timezone>+8</timezone>\n      <properties>...</properties>\n    </developer>\n  </developers>\n\n  \x3c!--代码贡献者列表--\x3e\n   <contributors>\n    <contributor>\n      \x3c!--标签内容和<developer>相同--\x3e\n    </contributor>\n  </contributors>\n\n  \x3c!-- 项目信息 end --\x3e\n\n  ...\n</project>\n\n\n这部分标签都非常简单，基本都能做到顾名思义，且都属于可有可无的标签，所以这里仅简单介绍一下：\n\n * name - 项目完整名称\n\n * description - 项目描述\n\n * url - 一般为项目仓库的 host\n\n * inceptionYear - 开发年份\n\n * licenses - 开源协议\n\n * organization - 项目所属组织信息\n\n * developers - 项目开发者列表\n\n * contributors - 项目贡献者列表，<contributor> 的子标签和 <developer> 的完全相同。\n\n\n# 环境配置\n\n\n# issueManagement\n\n这定义了所使用的缺陷跟踪系统（Bugzilla，TestTrack，ClearQuest 等）。虽然没有什么可以阻止插件使用这些信息的东西，但它主要用于生成项目文档。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <issueManagement>\n    <system>Bugzilla</system>\n    <url>http://127.0.0.1/bugzilla/</url>\n  </issueManagement>\n  ...\n</project>\n\n\n\n# ciManagement\n\nCI 构建系统配置，主要是指定通知机制以及被通知的邮箱。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <ciManagement>\n    <system>continuum</system>\n    <url>http://127.0.0.1:8080/continuum</url>\n    <notifiers>\n      <notifier>\n        <type>mail</type>\n        <sendOnError>true</sendOnError>\n        <sendOnFailure>true</sendOnFailure>\n        <sendOnSuccess>false</sendOnSuccess>\n        <sendOnWarning>false</sendOnWarning>\n        <configuration><address>continuum@127.0.0.1</address></configuration>\n      </notifier>\n    </notifiers>\n  </ciManagement>\n  ...\n</project>\n\n\n\n# mailingLists\n\n邮件列表\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <mailingLists>\n    <mailingList>\n      <name>User List</name>\n      <subscribe>user-subscribe@127.0.0.1</subscribe>\n      <unsubscribe>user-unsubscribe@127.0.0.1</unsubscribe>\n      <post>user@127.0.0.1</post>\n      <archive>http://127.0.0.1/user/</archive>\n      <otherArchives>\n        <otherArchive>http://base.google.com/base/1/127.0.0.1</otherArchive>\n      </otherArchives>\n    </mailingList>\n  </mailingLists>\n  ...\n</project>\n\n\n\n# scm\n\nSCM（软件配置管理，也称为源代码/控制管理或简洁的版本控制）。常见的 scm 有 svn 和 git 。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <scm>\n    <connection>scm:svn:http://127.0.0.1/svn/my-project</connection>\n    <developerConnection>scm:svn:https://127.0.0.1/svn/my-project</developerConnection>\n    <tag>HEAD</tag>\n    <url>http://127.0.0.1/websvn/my-project</url>\n  </scm>\n  ...\n</project>\n\n\n\n# prerequisites\n\nPOM 执行的预设条件。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <prerequisites>\n    <maven>2.0.6</maven>\n  </prerequisites>\n  ...\n</project>\n\n\n\n# repositories\n\nrepositories 是遵循 Maven 存储库目录布局的 artifacts 集合。默认的 Maven 中央存储库位于https://repo.maven.apache.org/maven2/上。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <repositories>\n    <repository>\n      <releases>\n        <enabled>false</enabled>\n        <updatePolicy>always</updatePolicy>\n        <checksumPolicy>warn</checksumPolicy>\n      </releases>\n      <snapshots>\n        <enabled>true</enabled>\n        <updatePolicy>never</updatePolicy>\n        <checksumPolicy>fail</checksumPolicy>\n      </snapshots>\n      <id>codehausSnapshots</id>\n      <name>Codehaus Snapshots</name>\n      <url>http://snapshots.maven.codehaus.org/maven2</url>\n      <layout>default</layout>\n    </repository>\n  </repositories>\n  <pluginRepositories>\n    ...\n  </pluginRepositories>\n  ...\n</project>\n\n\n\n# pluginRepositories\n\n与 repositories 差不多。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <distributionManagement>\n    ...\n    <downloadUrl>http://mojo.codehaus.org/my-project</downloadUrl>\n    <status>deployed</status>\n  </distributionManagement>\n  ...\n</project>\n\n\n\n# distributionManagement\n\n它管理在整个构建过程中生成的 artifact 和支持文件的分布。从最后的元素开始：\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <distributionManagement>\n    ...\n    <downloadUrl>http://mojo.codehaus.org/my-project</downloadUrl>\n    <status>deployed</status>\n  </distributionManagement>\n  ...\n</project>\n\n\n * repository - 与 repositories 相似\n\n * site - 站点信息\n\n * relocation - 项目迁移位置\n\n\n# profiles\n\nactivation 是一个 profile 的关键。配置文件的功能来自于在某些情况下仅修改基本 POM 的功能。这些情况通过 activation 元素指定。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <profiles>\n    <profile>\n      <id>test</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n        <jdk>1.5</jdk>\n        <os>\n          <name>Windows XP</name>\n          <family>Windows</family>\n          <arch>x86</arch>\n          <version>5.1.2600</version>\n        </os>\n        <property>\n          <name>sparrow-type</name>\n          <value>African</value>\n        </property>\n        <file>\n          <exists>${basedir}/file2.properties</exists>\n          <missing>${basedir}/file1.properties</missing>\n        </file>\n      </activation>\n      ...\n    </profile>\n  </profiles>\n</project>\n\n\n\n# 参考资料\n\n * maven 官方文档之 pom',normalizedContent:'# maven 教程之 pom.xml 详解\n\n\n# pom.xml 简介\n\n\n# 什么是 pom\n\npom 是 project object model 的缩写，即项目对象模型。\n\npom.xml 就是 maven 的配置文件，用以描述项目的各种信息。\n\n\n# pom 配置一览\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <modelversion>4.0.0</modelversion>\n\n  \x3c!-- the basics --\x3e\n  <groupid>...</groupid>\n  <artifactid>...</artifactid>\n  <version>...</version>\n  <packaging>...</packaging>\n  <dependencies>...</dependencies>\n  <parent>...</parent>\n  <dependencymanagement>...</dependencymanagement>\n  <modules>...</modules>\n  <properties>...</properties>\n\n  \x3c!-- build settings --\x3e\n  <build>...</build>\n  <reporting>...</reporting>\n\n  \x3c!-- more project information --\x3e\n  <name>...</name>\n  <description>...</description>\n  <url>...</url>\n  <inceptionyear>...</inceptionyear>\n  <licenses>...</licenses>\n  <organization>...</organization>\n  <developers>...</developers>\n  <contributors>...</contributors>\n\n  \x3c!-- environment settings --\x3e\n  <issuemanagement>...</issuemanagement>\n  <cimanagement>...</cimanagement>\n  <mailinglists>...</mailinglists>\n  <scm>...</scm>\n  <prerequisites>...</prerequisites>\n  <repositories>...</repositories>\n  <pluginrepositories>...</pluginrepositories>\n  <distributionmanagement>...</distributionmanagement>\n  <profiles>...</profiles>\n</project>\n\n\n\n# 基本配置\n\n * project - project 是 pom.xml 中描述符的根。\n * modelversion - modelversion 指定 pom.xml 符合哪个版本的描述符。maven 2 和 3 只能为 4.0.0。\n\n一般 jar 包被识别为： groupid:artifactid:version 的形式。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      http://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <modelversion>4.0.0</modelversion>\n\n  <groupid>org.codehaus.mojo</groupid>\n  <artifactid>my-project</artifactid>\n  <version>1.0</version>\n  <packaging>war</packaging>\n</project>\n\n\n\n# maven 坐标\n\n在 maven 中，根据 groupid、artifactid、version 组合成 groupid:artifactid:version 来唯一识别一个 jar 包。\n\n * groupid - 团体、组织的标识符。团体标识的约定是，它以创建这个项目的组织名称的逆向域名(reverse domain name)开头。一般对应着 java 的包结构。\n * artifactid - 单独项目的唯一标识符。比如我们的 tomcat、commons 等。不要在 artifactid 中包含点号(.)。\n * version - 一个项目的特定版本。\n   * maven 有自己的版本规范，一般是如下定义 major version、minor version、incremental version-qualifier ，比如 1.2.3-beta-01。要说明的是，maven 自己判断版本的算法是 major、minor、incremental 部分用数字比较，qualifier 部分用字符串比较，所以要小心 alpha-2 和 alpha-15 的比较关系，最好用 alpha-02 的格式。\n   * maven 在版本管理时候可以使用几个特殊的字符串 snapshot、latest、release。比如 1.0-snapshot。各个部分的含义和处理逻辑如下说明：\n     * snapshot - 这个版本一般用于开发过程中，表示不稳定的版本。\n     * latest - 指某个特定构件的最新发布，这个发布可能是一个发布版，也可能是一个 snapshot 版，具体看哪个时间最后。\n     * release ：指最后一个发布版。\n * packaging - 项目的类型，描述了项目打包后的输出，默认是 jar。常见的输出类型为：pom, jar, maven-plugin, ejb, war, ear, rar, par。\n\n\n# 依赖配置\n\n\n# dependencies\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <dependencies>\n    <dependency>\n     <groupid>org.apache.maven</groupid>\n      <artifactid>maven-embedder</artifactid>\n      <version>2.0</version>\n      <type>jar</type>\n      <scope>test</scope>\n      <optional>true</optional>\n      <exclusions>\n        <exclusion>\n          <groupid>org.apache.maven</groupid>\n          <artifactid>maven-core</artifactid>\n        </exclusion>\n      </exclusions>\n    </dependency>\n    ...\n  </dependencies>\n  ...\n</project>\n\n\n * groupid, artifactid, version - 和基本配置中的 groupid、artifactid、version 意义相同。\n * type - 对应 packaging 的类型，如果不使用 type 标签，maven 默认为 jar。\n * scope - 此元素指的是任务的类路径（编译和运行时，测试等）以及如何限制依赖关系的传递性。有 5 种可用的限定范围：\n   * compile - 如果没有指定 scope 标签，maven 默认为这个范围。编译依赖关系在所有 classpath 中都可用。此外，这些依赖关系被传播到依赖项目。\n   * provided - 与 compile 类似，但是表示您希望 jdk 或容器在运行时提供它。它只适用于编译和测试 classpath，不可传递。\n   * runtime - 此范围表示编译不需要依赖关系，而是用于执行。它是在运行时和测试 classpath，但不是编译 classpath。\n   * test - 此范围表示正常使用应用程序不需要依赖关系，仅适用于测试编译和执行阶段。它不是传递的。\n   * system - 此范围与 provided 类似，除了您必须提供明确包含它的 jar。该 artifact 始终可用，并且不是在仓库中查找。\n * systempath - 仅当依赖范围是系统时才使用。否则，如果设置此元素，构建将失败。该路径必须是绝对路径，因此建议使用 propertie 来指定特定的路径，如$ {java.home} / lib。由于假定先前安装了系统范围依赖关系，maven 将不会检查项目的仓库，而是检查库文件是否存在。如果没有，maven 将会失败，并建议您手动下载安装。\n * optional - optional 让其他项目知道，当您使用此项目时，您不需要这种依赖性才能正常工作。\n * exclusions - 包含一个或多个排除元素，每个排除元素都包含一个表示要排除的依赖关系的 groupid 和 artifactid。与可选项不同，可能或可能不会安装和使用，排除主动从依赖关系树中删除自己。\n\n\n# parent\n\nmaven 支持继承功能。子 pom 可以使用 parent 指定父 pom ，然后继承其配置。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <modelversion>4.0.0</modelversion>\n\n  <parent>\n    <groupid>org.codehaus.mojo</groupid>\n    <artifactid>my-parent</artifactid>\n    <version>2.0</version>\n    <relativepath>../my-parent</relativepath>\n  </parent>\n\n  <artifactid>my-project</artifactid>\n</project>\n\n\n * relativepath - 注意 relativepath 元素。在搜索本地和远程存储库之前，它不是必需的，但可以用作 maven 的指示符，以首先搜索给定该项目父级的路径。\n\n\n# dependencymanagement\n\ndependencymanagement 是表示依赖 jar 包的声明。即你在项目中的 dependencymanagement 下声明了依赖，maven 不会加载该依赖，dependencymanagement 声明可以被子 pom 继承。\n\ndependencymanagement 的一个使用案例是当有父子项目的时候，父项目中可以利用 dependencymanagement 声明子项目中需要用到的依赖 jar 包，之后，当某个或者某几个子项目需要加载该依赖的时候，就可以在子项目中 dependencies 节点只配置 groupid 和 artifactid 就可以完成依赖的引用。\n\ndependencymanagement 主要是为了统一管理依赖包的版本，确保所有子项目使用的版本一致，类似的还有plugins和pluginmanagement。\n\n\n# modules\n\n子模块列表。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <modelversion>4.0.0</modelversion>\n\n  <groupid>org.codehaus.mojo</groupid>\n  <artifactid>my-parent</artifactid>\n  <version>2.0</version>\n  <packaging>pom</packaging>\n\n  <modules>\n    <module>my-project</module>\n    <module>another-project</module>\n    <module>third-project/pom-example.xml</module>\n  </modules>\n</project>\n\n\n\n# properties\n\n属性列表。定义的属性可以在 pom.xml 文件中任意处使用。使用方式为 ${propertie} 。\n\n<project>\n  ...\n  <properties>\n    <maven.compiler.source>1.7<maven.compiler.source>\n    <maven.compiler.target>1.7<maven.compiler.target>\n    <project.build.sourceencoding>utf-8</project.build.sourceencoding>\n    <project.reporting.outputencoding>utf-8</project.reporting.outputencoding>\n  </properties>\n  ...\n</project>\n\n\n\n# 构建配置\n\n\n# build\n\nbuild 可以分为 "project build" 和 "profile build"。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  \x3c!-- "project build" contains more elements than just the basebuild set --\x3e\n  <build>...</build>\n\n  <profiles>\n    <profile>\n      \x3c!-- "profile build" contains a subset of "project build"s elements --\x3e\n      <build>...</build>\n    </profile>\n  </profiles>\n</project>\n\n\n基本构建配置：\n\n<build>\n  <defaultgoal>install</defaultgoal>\n  <directory>${basedir}/target</directory>\n  <finalname>${artifactid}-${version}</finalname>\n  <filters>\n    <filter>filters/filter1.properties</filter>\n  </filters>\n  ...\n</build>\n\n\ndefaultgoal : 默认执行目标或阶段。如果给出了一个目标，它应该被定义为它在命令行中（如 jar：jar）。如果定义了一个阶段（如安装），也是如此。\n\ndirectory ：构建时的输出路径。默认为：${basedir}/target 。\n\nfinalname ：这是项目的最终构建名称（不包括文件扩展名，例如：my-project-1.0.jar）\n\nfilter ：定义 * .properties 文件，其中包含适用于接受其设置的资源的属性列表（如下所述）。换句话说，过滤器文件中定义的“name = value”对在代码中替换$ {name}字符串。\n\n# resources\n\n资源的配置。资源文件通常不是代码，不需要编译，而是在项目需要捆绑使用的内容。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <build>\n    ...\n    <resources>\n      <resource>\n        <targetpath>meta-inf/plexus</targetpath>\n        <filtering>false</filtering>\n        <directory>${basedir}/src/main/plexus</directory>\n        <includes>\n          <include>configuration.xml</include>\n        </includes>\n        <excludes>\n          <exclude>**/*.properties</exclude>\n        </excludes>\n      </resource>\n    </resources>\n    <testresources>\n      ...\n    </testresources>\n    ...\n  </build>\n</project>\n\n\n * resources: 资源元素的列表，每个资源元素描述与此项目关联的文件和何处包含文件。\n * targetpath: 指定从构建中放置资源集的目录结构。目标路径默认为基本目录。将要包装在 jar 中的资源的通常指定的目标路径是 meta-inf。\n * filtering: 值为 true 或 false。表示是否要为此资源启用过滤。请注意，该过滤器 * .properties 文件不必定义为进行过滤 - 资源还可以使用默认情况下在 pom 中定义的属性（例如$ {project.version}），并将其传递到命令行中“-d”标志（例如，“-dname = value”）或由 properties 元素显式定义。过滤文件覆盖上面。\n * directory: 值定义了资源的路径。构建的默认目录是${basedir}/src/main/resources。\n * includes: 一组文件匹配模式，指定目录中要包括的文件，使用*作为通配符。\n * excludes: 与 includes 类似，指定目录中要排除的文件，使用*作为通配符。注意：如果 include 和 exclude 发生冲突，maven 会以 exclude 作为有效项。\n * testresources: testresources 与 resources 功能类似，区别仅在于：testresources 指定的资源仅用于 test 阶段，并且其默认资源目录为：${basedir}/src/test/resources 。\n\n# plugins\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  <build>\n    ...\n    <plugins>\n      <plugin>\n        <groupid>org.apache.maven.plugins</groupid>\n        <artifactid>maven-jar-plugin</artifactid>\n        <version>2.6</version>\n        <extensions>false</extensions>\n        <inherited>true</inherited>\n        <configuration>\n          <classifier>test</classifier>\n        </configuration>\n        <dependencies>...</dependencies>\n        <executions>...</executions>\n      </plugin>\n    </plugins>\n  </build>\n</project>\n\n\n * groupid, artifactid, version ：和基本配置中的 groupid、artifactid、version 意义相同。\n\n * extensions ：值为 true 或 false。是否加载此插件的扩展名。默认为 false。\n\n * inherited ：值为 true 或 false。这个插件配置是否应该适用于继承自这个插件的 pom。默认值为 true。\n\n * configuration - 这是针对个人插件的配置，这里不扩散讲解。\n\n * dependencies ：这里的 dependencies 是插件本身所需要的依赖。\n\n * executions ：需要记住的是，插件可能有多个目标。每个目标可能有一个单独的配置，甚至可能将插件的目标完全绑定到不同的阶段。执行配置插件的目标的执行。\n   \n   * id: 执行目标的标识。\n   * goals: 像所有多元化的 pom 元素一样，它包含单个元素的列表。在这种情况下，这个执行块指定的插件目标列表。\n   * phase: 这是执行目标列表的阶段。这是一个非常强大的选项，允许将任何目标绑定到构建生命周期中的任何阶段，从而改变 maven 的默认行为。\n   * inherited: 像上面的继承元素一样，设置这个 false 会阻止 maven 将这个执行传递给它的子代。此元素仅对父 pom 有意义。\n   * configuration: 与上述相同，但将配置限制在此特定目标列表中，而不是插件下的所有目标。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <build>\n    <plugins>\n      <plugin>\n        <artifactid>maven-antrun-plugin</artifactid>\n        <version>1.1</version>\n        <executions>\n          <execution>\n            <id>echodir</id>\n            <goals>\n              <goal>run</goal>\n            </goals>\n            <phase>verify</phase>\n            <inherited>false</inherited>\n            <configuration>\n              <tasks>\n                <echo>build dir: ${project.build.directory}</echo>\n              </tasks>\n            </configuration>\n          </execution>\n        </executions>\n\n      </plugin>\n    </plugins>\n  </build>\n</project>\n\n\n# pluginmanagement\n\n与 dependencymanagement 很相似，在当前 pom 中仅声明插件，而不是实际引入插件。子 pom 中只配置 groupid 和 artifactid 就可以完成插件的引用，且子 pom 有权重写 pluginmanagement 定义。\n\n它的目的在于统一所有子 pom 的插件版本。\n\n# directories\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <build>\n    <sourcedirectory>${basedir}/src/main/java</sourcedirectory>\n    <scriptsourcedirectory>${basedir}/src/main/scripts</scriptsourcedirectory>\n    <testsourcedirectory>${basedir}/src/test/java</testsourcedirectory>\n    <outputdirectory>${basedir}/target/classes</outputdirectory>\n    <testoutputdirectory>${basedir}/target/test-classes</testoutputdirectory>\n    ...\n  </build>\n</project>\n\n\n目录元素集合存在于 build 元素中，它为整个 pom 设置了各种目录结构。由于它们在配置文件构建中不存在，所以这些不能由配置文件更改。\n\n如果上述目录元素的值设置为绝对路径（扩展属性时），则使用该目录。否则，它是相对于基础构建目录：${basedir}。\n\n# extensions\n\n扩展是在此构建中使用的 artifacts 的列表。它们将被包含在运行构建的 classpath 中。它们可以启用对构建过程的扩展（例如为 wagon 传输机制添加一个 ftp 提供程序），并使活动的插件能够对构建生命周期进行更改。简而言之，扩展是在构建期间激活的 artifacts。扩展不需要实际执行任何操作，也不包含 mojo。因此，扩展对于指定普通插件接口的多个实现中的一个是非常好的。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <build>\n    ...\n    <extensions>\n      <extension>\n        <groupid>org.apache.maven.wagon</groupid>\n        <artifactid>wagon-ftp</artifactid>\n        <version>1.0-alpha-3</version>\n      </extension>\n    </extensions>\n    ...\n  </build>\n</project>\n\n\n\n# reporting\n\n报告包含特定针对 site 生成阶段的元素。某些 maven 插件可以生成 reporting 元素下配置的报告，例如：生成 javadoc 报告。reporting 与 build 元素配置插件的能力相似。明显的区别在于：在执行块中插件目标的控制不是细粒度的，报表通过配置 reportset 元素来精细控制。而微妙的区别在于 reporting 元素下的 configuration 元素可以用作 build 下的 configuration ，尽管相反的情况并非如此（ build 下的 configuration 不影响 reporting 元素下的 configuration ）。\n\n另一个区别就是 plugin 下的 outputdirectory 元素。在报告的情况下，默认输出目录为 ${basedir}/target/site。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <reporting>\n    <plugins>\n      <plugin>\n        ...\n        <reportsets>\n          <reportset>\n            <id>sunlink</id>\n            <reports>\n              <report>javadoc</report>\n            </reports>\n            <inherited>true</inherited>\n            <configuration>\n              <links>\n                <link>http://java.sun.com/j2se/1.5.0/docs/api/</link>\n              </links>\n            </configuration>\n          </reportset>\n        </reportsets>\n      </plugin>\n    </plugins>\n  </reporting>\n  ...\n</project>\n\n\n\n# 项目信息\n\n项目信息相关的这部分标签都不是必要的，也就是说完全可以不填写。\n\n它的作用仅限于描述项目的详细信息。\n\n下面的示例是项目信息相关标签的清单：\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n\n  \x3c!-- 项目信息 begin --\x3e\n\n  \x3c!--项目名--\x3e\n  <name>maven-notes</name>\n\n  \x3c!--项目描述--\x3e\n  <description>maven 学习笔记</description>\n\n  \x3c!--项目url--\x3e\n  <url>https://github.com/dunwu/maven-notes</url>\n\n  \x3c!--项目开发年份--\x3e\n  <inceptionyear>2017</inceptionyear>\n\n  \x3c!--开源协议--\x3e\n  <licenses>\n    <license>\n      <name>apache license, version 2.0</name>\n      <url>https://www.apache.org/licenses/license-2.0.txt</url>\n      <distribution>repo</distribution>\n      <comments>a business-friendly oss license</comments>\n    </license>\n  </licenses>\n\n  \x3c!--组织信息(如公司、开源组织等)--\x3e\n  <organization>\n    <name>...</name>\n    <url>...</url>\n  </organization>\n\n  \x3c!--开发者列表--\x3e\n  <developers>\n    <developer>\n      <id>victor</id>\n      <name>zhang peng</name>\n      <email>forbreak at 163.com</email>\n      <url>https://github.com/dunwu</url>\n      <organization>...</organization>\n      <organizationurl>...</organizationurl>\n      <roles>\n        <role>architect</role>\n        <role>developer</role>\n      </roles>\n      <timezone>+8</timezone>\n      <properties>...</properties>\n    </developer>\n  </developers>\n\n  \x3c!--代码贡献者列表--\x3e\n   <contributors>\n    <contributor>\n      \x3c!--标签内容和<developer>相同--\x3e\n    </contributor>\n  </contributors>\n\n  \x3c!-- 项目信息 end --\x3e\n\n  ...\n</project>\n\n\n这部分标签都非常简单，基本都能做到顾名思义，且都属于可有可无的标签，所以这里仅简单介绍一下：\n\n * name - 项目完整名称\n\n * description - 项目描述\n\n * url - 一般为项目仓库的 host\n\n * inceptionyear - 开发年份\n\n * licenses - 开源协议\n\n * organization - 项目所属组织信息\n\n * developers - 项目开发者列表\n\n * contributors - 项目贡献者列表，<contributor> 的子标签和 <developer> 的完全相同。\n\n\n# 环境配置\n\n\n# issuemanagement\n\n这定义了所使用的缺陷跟踪系统（bugzilla，testtrack，clearquest 等）。虽然没有什么可以阻止插件使用这些信息的东西，但它主要用于生成项目文档。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <issuemanagement>\n    <system>bugzilla</system>\n    <url>http://127.0.0.1/bugzilla/</url>\n  </issuemanagement>\n  ...\n</project>\n\n\n\n# cimanagement\n\nci 构建系统配置，主要是指定通知机制以及被通知的邮箱。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <cimanagement>\n    <system>continuum</system>\n    <url>http://127.0.0.1:8080/continuum</url>\n    <notifiers>\n      <notifier>\n        <type>mail</type>\n        <sendonerror>true</sendonerror>\n        <sendonfailure>true</sendonfailure>\n        <sendonsuccess>false</sendonsuccess>\n        <sendonwarning>false</sendonwarning>\n        <configuration><address>continuum@127.0.0.1</address></configuration>\n      </notifier>\n    </notifiers>\n  </cimanagement>\n  ...\n</project>\n\n\n\n# mailinglists\n\n邮件列表\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <mailinglists>\n    <mailinglist>\n      <name>user list</name>\n      <subscribe>user-subscribe@127.0.0.1</subscribe>\n      <unsubscribe>user-unsubscribe@127.0.0.1</unsubscribe>\n      <post>user@127.0.0.1</post>\n      <archive>http://127.0.0.1/user/</archive>\n      <otherarchives>\n        <otherarchive>http://base.google.com/base/1/127.0.0.1</otherarchive>\n      </otherarchives>\n    </mailinglist>\n  </mailinglists>\n  ...\n</project>\n\n\n\n# scm\n\nscm（软件配置管理，也称为源代码/控制管理或简洁的版本控制）。常见的 scm 有 svn 和 git 。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <scm>\n    <connection>scm:svn:http://127.0.0.1/svn/my-project</connection>\n    <developerconnection>scm:svn:https://127.0.0.1/svn/my-project</developerconnection>\n    <tag>head</tag>\n    <url>http://127.0.0.1/websvn/my-project</url>\n  </scm>\n  ...\n</project>\n\n\n\n# prerequisites\n\npom 执行的预设条件。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <prerequisites>\n    <maven>2.0.6</maven>\n  </prerequisites>\n  ...\n</project>\n\n\n\n# repositories\n\nrepositories 是遵循 maven 存储库目录布局的 artifacts 集合。默认的 maven 中央存储库位于https://repo.maven.apache.org/maven2/上。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <repositories>\n    <repository>\n      <releases>\n        <enabled>false</enabled>\n        <updatepolicy>always</updatepolicy>\n        <checksumpolicy>warn</checksumpolicy>\n      </releases>\n      <snapshots>\n        <enabled>true</enabled>\n        <updatepolicy>never</updatepolicy>\n        <checksumpolicy>fail</checksumpolicy>\n      </snapshots>\n      <id>codehaussnapshots</id>\n      <name>codehaus snapshots</name>\n      <url>http://snapshots.maven.codehaus.org/maven2</url>\n      <layout>default</layout>\n    </repository>\n  </repositories>\n  <pluginrepositories>\n    ...\n  </pluginrepositories>\n  ...\n</project>\n\n\n\n# pluginrepositories\n\n与 repositories 差不多。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <distributionmanagement>\n    ...\n    <downloadurl>http://mojo.codehaus.org/my-project</downloadurl>\n    <status>deployed</status>\n  </distributionmanagement>\n  ...\n</project>\n\n\n\n# distributionmanagement\n\n它管理在整个构建过程中生成的 artifact 和支持文件的分布。从最后的元素开始：\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <distributionmanagement>\n    ...\n    <downloadurl>http://mojo.codehaus.org/my-project</downloadurl>\n    <status>deployed</status>\n  </distributionmanagement>\n  ...\n</project>\n\n\n * repository - 与 repositories 相似\n\n * site - 站点信息\n\n * relocation - 项目迁移位置\n\n\n# profiles\n\nactivation 是一个 profile 的关键。配置文件的功能来自于在某些情况下仅修改基本 pom 的功能。这些情况通过 activation 元素指定。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0\n                      https://maven.apache.org/xsd/maven-4.0.0.xsd">\n  ...\n  <profiles>\n    <profile>\n      <id>test</id>\n      <activation>\n        <activebydefault>false</activebydefault>\n        <jdk>1.5</jdk>\n        <os>\n          <name>windows xp</name>\n          <family>windows</family>\n          <arch>x86</arch>\n          <version>5.1.2600</version>\n        </os>\n        <property>\n          <name>sparrow-type</name>\n          <value>african</value>\n        </property>\n        <file>\n          <exists>${basedir}/file2.properties</exists>\n          <missing>${basedir}/file1.properties</missing>\n        </file>\n      </activation>\n      ...\n    </profile>\n  </profiles>\n</project>\n\n\n\n# 参考资料\n\n * maven 官方文档之 pom',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Maven 教程之 settings.xml 详解",frontmatter:{title:"Maven 教程之 settings.xml 详解",categories:["编程","Java","软件","构建"],tags:["Java","构建","Maven"],abbrlink:"e9105404",date:"2019-05-14T14:57:33.000Z",permalink:"/pages/d05c38/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/01.%E6%9E%84%E5%BB%BA/01.Maven/03.Maven%E6%95%99%E7%A8%8B%E4%B9%8Bsettings.xml%E8%AF%A6%E8%A7%A3.html",relativePath:"11.软件/01.构建/01.Maven/03.Maven教程之settings.xml详解.md",key:"v-6441b580",path:"/pages/d05c38/",headers:[{level:2,title:"settings.xml 简介",slug:"settings-xml-简介",normalizedTitle:"settings.xml 简介",charIndex:32},{level:3,title:"settings.xml 有什么用",slug:"settings-xml-有什么用",normalizedTitle:"settings.xml 有什么用",charIndex:52},{level:3,title:"settings.xml 文件位置",slug:"settings-xml-文件位置",normalizedTitle:"settings.xml 文件位置",charIndex:223},{level:3,title:"配置优先级",slug:"配置优先级",normalizedTitle:"配置优先级",charIndex:442},{level:2,title:"settings.xml 元素详解",slug:"settings-xml-元素详解",normalizedTitle:"settings.xml 元素详解",charIndex:578},{level:3,title:"顶级元素概览",slug:"顶级元素概览",normalizedTitle:"顶级元素概览",charIndex:600},{level:3,title:"LocalRepository",slug:"localrepository",normalizedTitle:"localrepository",charIndex:1077},{level:3,title:"InteractiveMode",slug:"interactivemode",normalizedTitle:"interactivemode",charIndex:1207},{level:3,title:"UsePluginRegistry",slug:"usepluginregistry",normalizedTitle:"usepluginregistry",charIndex:1353},{level:3,title:"Offline",slug:"offline",normalizedTitle:"offline",charIndex:1541},{level:3,title:"PluginGroups",slug:"plugingroups",normalizedTitle:"plugingroups",charIndex:1688},{level:3,title:"Servers",slug:"servers",normalizedTitle:"servers",charIndex:2311},{level:3,title:"Mirrors",slug:"mirrors",normalizedTitle:"mirrors",charIndex:3754},{level:3,title:"Proxies",slug:"proxies",normalizedTitle:"proxies",charIndex:4554},{level:3,title:"Profiles",slug:"profiles",normalizedTitle:"profiles",charIndex:1049},{level:4,title:"Activation",slug:"activation",normalizedTitle:"activation",charIndex:6504},{level:4,title:"properties",slug:"properties",normalizedTitle:"properties",charIndex:5766},{level:4,title:"Repositories",slug:"repositories",normalizedTitle:"repositories",charIndex:5751},{level:4,title:"pluginRepositories",slug:"pluginrepositories",normalizedTitle:"pluginrepositories",charIndex:5745},{level:3,title:"ActiveProfiles",slug:"activeprofiles",normalizedTitle:"activeprofiles",charIndex:10568},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:11334}],headersStr:"settings.xml 简介 settings.xml 有什么用 settings.xml 文件位置 配置优先级 settings.xml 元素详解 顶级元素概览 LocalRepository InteractiveMode UsePluginRegistry Offline PluginGroups Servers Mirrors Proxies Profiles Activation properties Repositories pluginRepositories ActiveProfiles 参考资料",content:'# Maven 教程之 settings.xml 详解\n\n\n# settings.xml 简介\n\n\n# settings.xml 有什么用\n\n从 settings.xml 的文件名就可以看出，它是用来设置 maven 参数的配置文件。settings.xml 中包含类似本地仓储位置、修改远程仓储服务器、认证信息等配置。\n\n * settings.xml 是 maven 的全局配置文件。\n * pom.xml 文件是本地项目配置文件。\n\n\n# settings.xml 文件位置\n\nsettings.xml 文件一般存在于两个位置：\n\n * 全局配置 - ${maven.home}/conf/settings.xml\n * 用户配置 - ${user.home}/.m2/settings.xml\n\n> 🔔 注意：用户配置优先于全局配置。${user.home} 和和所有其他系统属性只能在 3.0+版本上使用。请注意 windows 和 Linux 使用变量的区别。\n\n\n# 配置优先级\n\n> 重要：局部配置优先于全局配置。\n\n配置优先级从高到低：pom.xml > user settings > global settings\n\n如果这些文件同时存在，在应用配置时，会合并它们的内容，如果有重复的配置，优先级高的配置会覆盖优先级低的。\n\n\n# settings.xml 元素详解\n\n\n# 顶级元素概览\n\n下面列举了settings.xml中的顶级元素\n\n<settings xmlns="http://maven.apache.org/SETTINGS/1.0.0"\n      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n      xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0\n                          https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  <localRepository/>\n  <interactiveMode/>\n  <usePluginRegistry/>\n  <offline/>\n  <pluginGroups/>\n  <servers/>\n  <mirrors/>\n  <proxies/>\n  <profiles/>\n  <activeProfiles/>\n</settings>\n\n\n\n# LocalRepository\n\n作用：该值表示构建系统本地仓库的路径。\n\n其默认值：~/.m2/repository。\n\n<localRepository>${user.home}/.m2/repository</localRepository>\n\n\n\n# InteractiveMode\n\n作用：表示 maven 是否需要和用户交互以获得输入。\n\n如果 maven 需要和用户交互以获得输入，则设置成 true，反之则应为 false。默认为 true。\n\n<interactiveMode>true</interactiveMode>\n\n\n\n# UsePluginRegistry\n\n作用：maven 是否需要使用 plugin-registry.xml 文件来管理插件版本。\n\n如果需要让 maven 使用文件~/.m2/plugin-registry.xml 来管理插件版本，则设为 true。默认为 false。\n\n<usePluginRegistry>false</usePluginRegistry>\n\n\n\n# Offline\n\n作用：表示 maven 是否需要在离线模式下运行。\n\n如果构建系统需要在离线模式下运行，则为 true，默认为 false。\n\n当由于网络设置原因或者安全因素，构建服务器不能连接远程仓库的时候，该配置就十分有用。\n\n<offline>false</offline>\n\n\n\n# PluginGroups\n\n作用：当插件的组织 id（groupId）没有显式提供时，供搜寻插件组织 Id（groupId）的列表。\n\n该元素包含一个 pluginGroup 元素列表，每个子元素包含了一个组织 Id（groupId）。\n\n当我们使用某个插件，并且没有在命令行为其提供组织 Id（groupId）的时候，Maven 就会使用该列表。默认情况下该列表包含了 org.apache.maven.plugins 和 org.codehaus.mojo。\n\n<settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0\n                      https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  ...\n  <pluginGroups>\n    \x3c!--plugin的组织Id（groupId） --\x3e\n    <pluginGroup>org.codehaus.mojo</pluginGroup>\n  </pluginGroups>\n  ...\n</settings>\n\n\n\n# Servers\n\n作用：一般，仓库的下载和部署是在 pom.xml 文件中的 repositories 和 distributionManagement 元素中定义的。然而，一般类似用户名、密码（有些仓库访问是需要安全认证的）等信息不应该在 pom.xml 文件中配置，这些信息可以配置在 settings.xml 中。\n\n<settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0\n                      https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  ...\n  \x3c!--配置服务端的一些设置。一些设置如安全证书不应该和pom.xml一起分发。这种类型的信息应该存在于构建服务器上的settings.xml文件中。 --\x3e\n  <servers>\n    \x3c!--服务器元素包含配置服务器时需要的信息 --\x3e\n    <server>\n      \x3c!--这是server的id（注意不是用户登陆的id），该id与distributionManagement中repository元素的id相匹配。 --\x3e\n      <id>server001</id>\n      \x3c!--鉴权用户名。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。 --\x3e\n      <username>my_login</username>\n      \x3c!--鉴权密码 。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。密码加密功能已被添加到2.1.0 +。详情请访问密码加密页面 --\x3e\n      <password>my_password</password>\n      \x3c!--鉴权时使用的私钥位置。和前两个元素类似，私钥位置和私钥密码指定了一个私钥的路径（默认是${user.home}/.ssh/id_dsa）以及如果需要的话，一个密语。将来passphrase和password元素可能会被提取到外部，但目前它们必须在settings.xml文件以纯文本的形式声明。 --\x3e\n      <privateKey>${usr.home}/.ssh/id_dsa</privateKey>\n      \x3c!--鉴权时使用的私钥密码。 --\x3e\n      <passphrase>some_passphrase</passphrase>\n      \x3c!--文件被创建时的权限。如果在部署的时候会创建一个仓库文件或者目录，这时候就可以使用权限（permission）。这两个元素合法的值是一个三位数字，其对应了unix文件系统的权限，如664，或者775。 --\x3e\n      <filePermissions>664</filePermissions>\n      \x3c!--目录被创建时的权限。 --\x3e\n      <directoryPermissions>775</directoryPermissions>\n    </server>\n  </servers>\n  ...\n</settings>\n\n\n\n# Mirrors\n\n作用：为仓库列表配置的下载镜像列表。\n\n<settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0\n                      https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  ...\n  <mirrors>\n    \x3c!-- 给定仓库的下载镜像。 --\x3e\n    <mirror>\n      \x3c!-- 该镜像的唯一标识符。id用来区分不同的mirror元素。 --\x3e\n      <id>planetmirror.com</id>\n      \x3c!-- 镜像名称 --\x3e\n      <name>PlanetMirror Australia</name>\n      \x3c!-- 该镜像的URL。构建系统会优先考虑使用该URL，而非使用默认的服务器URL。 --\x3e\n      <url>http://downloads.planetmirror.com/pub/maven2</url>\n      \x3c!-- 被镜像的服务器的id。例如，如果我们要设置了一个Maven中央仓库（http://repo.maven.apache.org/maven2/）的镜像，就需要将该元素设置成central。这必须和中央仓库的id central完全一致。 --\x3e\n      <mirrorOf>central</mirrorOf>\n    </mirror>\n  </mirrors>\n  ...\n</settings>\n\n\n\n# Proxies\n\n作用：用来配置不同的代理。\n\n<settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0\n                      https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  ...\n  <proxies>\n    \x3c!--代理元素包含配置代理时需要的信息 --\x3e\n    <proxy>\n      \x3c!--代理的唯一定义符，用来区分不同的代理元素。 --\x3e\n      <id>myproxy</id>\n      \x3c!--该代理是否是激活的那个。true则激活代理。当我们声明了一组代理，而某个时候只需要激活一个代理的时候，该元素就可以派上用处。 --\x3e\n      <active>true</active>\n      \x3c!--代理的协议。 协议://主机名:端口，分隔成离散的元素以方便配置。 --\x3e\n      <protocol>http</protocol>\n      \x3c!--代理的主机名。协议://主机名:端口，分隔成离散的元素以方便配置。 --\x3e\n      <host>proxy.somewhere.com</host>\n      \x3c!--代理的端口。协议://主机名:端口，分隔成离散的元素以方便配置。 --\x3e\n      <port>8080</port>\n      \x3c!--代理的用户名，用户名和密码表示代理服务器认证的登录名和密码。 --\x3e\n      <username>proxyuser</username>\n      \x3c!--代理的密码，用户名和密码表示代理服务器认证的登录名和密码。 --\x3e\n      <password>somepassword</password>\n      \x3c!--不该被代理的主机名列表。该列表的分隔符由代理服务器指定；例子中使用了竖线分隔符，使用逗号分隔也很常见。 --\x3e\n      <nonProxyHosts>*.google.com|ibiblio.org</nonProxyHosts>\n    </proxy>\n  </proxies>\n  ...\n</settings>\n\n\n\n# Profiles\n\n作用：根据环境参数来调整构建配置的列表。\n\nsettings.xml 中的 profile 元素是 pom.xml 中 profile 元素的裁剪版本。\n\n它包含了id、activation、repositories、pluginRepositories 和 properties 元素。这里的 profile 元素只包含这五个子元素是因为这里只关心构建系统这个整体（这正是 settings.xml 文件的角色定位），而非单独的项目对象模型设置。如果一个 settings.xml 中的 profile 被激活，它的值会覆盖任何其它定义在 pom.xml 中带有相同 id 的 profile。\n\n<settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0\n                      https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  ...\n  <profiles>\n    <profile>\n      \x3c!-- profile的唯一标识 --\x3e\n      <id>test</id>\n      \x3c!-- 自动触发profile的条件逻辑 --\x3e\n      <activation />\n      \x3c!-- 扩展属性列表 --\x3e\n      <properties />\n      \x3c!-- 远程仓库列表 --\x3e\n      <repositories />\n      \x3c!-- 插件仓库列表 --\x3e\n      <pluginRepositories />\n    </profile>\n  </profiles>\n  ...\n</settings>\n\n\n# Activation\n\n作用：自动触发 profile 的条件逻辑。\n\n如 pom.xml 中的 profile 一样，profile 的作用在于它能够在某些特定的环境中自动使用某些特定的值；这些环境通过 activation 元素指定。 activation 元素并不是激活 profile 的唯一方式。settings.xml 文件中的 activeProfile 元素可以包含 profile 的 id。profile 也可以通过在命令行，使用 -P 标记和逗号分隔的列表来显式的激活（如，-P test）。\n\n<activation>\n  \x3c!--profile默认是否激活的标识 --\x3e\n  <activeByDefault>false</activeByDefault>\n  \x3c!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。 --\x3e\n  <jdk>1.5</jdk>\n  \x3c!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。 --\x3e\n  <os>\n    \x3c!--激活profile的操作系统的名字 --\x3e\n    <name>Windows XP</name>\n    \x3c!--激活profile的操作系统所属家族(如 \'windows\') --\x3e\n    <family>Windows</family>\n    \x3c!--激活profile的操作系统体系结构 --\x3e\n    <arch>x86</arch>\n    \x3c!--激活profile的操作系统版本 --\x3e\n    <version>5.1.2600</version>\n  </os>\n  \x3c!--如果Maven检测到某一个属性（其值可以在POM中通过${name}引用），其拥有对应的name = 值，Profile就会被激活。如果值字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段 --\x3e\n  <property>\n    \x3c!--激活profile的属性的名称 --\x3e\n    <name>mavenVersion</name>\n    \x3c!--激活profile的属性的值 --\x3e\n    <value>2.0.3</value>\n  </property>\n  \x3c!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。 --\x3e\n  <file>\n    \x3c!--如果指定的文件存在，则激活profile。 --\x3e\n    <exists>${basedir}/file2.properties</exists>\n    \x3c!--如果指定的文件不存在，则激活profile。 --\x3e\n    <missing>${basedir}/file1.properties</missing>\n  </file>\n</activation>\n\n\n> 注：在 maven 工程的 pom.xml 所在目录下执行 mvn help:active-profiles 命令可以查看中央仓储的 profile 是否在工程中生效。\n\n# properties\n\n作用：对应profile的扩展属性列表。\n\nmaven 属性和 ant 中的属性一样，可以用来存放一些值。这些值可以在 pom.xml 中的任何地方使用标记${X}来使用，这里 X 是指属性的名称。属性有五种不同的形式，并且都能在 settings.xml 文件中访问。\n\n\x3c!--\n  1. env.X: 在一个变量前加上"env."的前缀，会返回一个shell环境变量。例如,"env.PATH"指代了$path环境变量（在Windows上是%PATH%）。\n  2. project.x：指代了POM中对应的元素值。例如: <project><version>1.0</version></project>通过${project.version}获得version的值。\n  3. settings.x: 指代了settings.xml中对应元素的值。例如：<settings><offline>false</offline></settings>通过 ${settings.offline}获得offline的值。\n  4. Java System Properties: 所有可通过java.lang.System.getProperties()访问的属性都能在POM中使用该形式访问，例如 ${java.home}。\n  5. x: 在<properties/>元素中，或者外部文件中设置，以${someVar}的形式使用。\n --\x3e\n<properties>\n  <user.install>${user.home}/our-project</user.install>\n</properties>\n\n\n> 注：如果该 profile 被激活，则可以在pom.xml中使用${user.install}。\n\n# Repositories\n\n作用：远程仓库列表，它是 maven 用来填充构建系统本地仓库所使用的一组远程仓库。\n\n<repositories>\n  \x3c!--包含需要连接到远程仓库的信息 --\x3e\n  <repository>\n    \x3c!--远程仓库唯一标识 --\x3e\n    <id>codehausSnapshots</id>\n    \x3c!--远程仓库名称 --\x3e\n    <name>Codehaus Snapshots</name>\n    \x3c!--如何处理远程仓库里发布版本的下载 --\x3e\n    <releases>\n      \x3c!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --\x3e\n      <enabled>false</enabled>\n      \x3c!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --\x3e\n      <updatePolicy>always</updatePolicy>\n      \x3c!--当Maven验证构件校验文件失败时该怎么做-ignore（忽略），fail（失败），或者warn（警告）。 --\x3e\n      <checksumPolicy>warn</checksumPolicy>\n    </releases>\n    \x3c!--如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --\x3e\n    <snapshots>\n      <enabled />\n      <updatePolicy />\n      <checksumPolicy />\n    </snapshots>\n    \x3c!--远程仓库URL，按protocol://hostname/path形式 --\x3e\n    <url>http://snapshots.maven.codehaus.org/maven2</url>\n    \x3c!--用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --\x3e\n    <layout>default</layout>\n  </repository>\n</repositories>\n\n\n# pluginRepositories\n\n作用：发现插件的远程仓库列表。\n\n和 repository 类似，只是 repository 是管理 jar 包依赖的仓库，pluginRepositories 则是管理插件的仓库。 maven 插件是一种特殊类型的构件。由于这个原因，插件仓库独立于其它仓库。pluginRepositories 元素的结构和 repositories 元素的结构类似。每个 pluginRepository 元素指定一个 Maven 可以用来寻找新插件的远程地址。\n\n<pluginRepositories>\n  \x3c!-- 包含需要连接到远程插件仓库的信息.参见profiles/profile/repositories/repository元素的说明 --\x3e\n  <pluginRepository>\n    <releases>\n      <enabled />\n      <updatePolicy />\n      <checksumPolicy />\n    </releases>\n    <snapshots>\n      <enabled />\n      <updatePolicy />\n      <checksumPolicy />\n    </snapshots>\n    <id />\n    <name />\n    <url />\n    <layout />\n  </pluginRepository>\n</pluginRepositories>\n\n\n\n# ActiveProfiles\n\n作用：手动激活 profiles 的列表，按照profile被应用的顺序定义activeProfile。\n\n该元素包含了一组 activeProfile 元素，每个 activeProfile 都含有一个 profile id。任何在 activeProfile 中定义的 profile id，不论环境设置如何，其对应的 profile 都会被激活。如果没有匹配的 profile，则什么都不会发生。\n\n例如，env-test 是一个 activeProfile，则在 pom.xml（或者 profile.xml）中对应 id 的 profile 会被激活。如果运行过程中找不到这样一个 profile，Maven 则会像往常一样运行。\n\n<settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0\n                      https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  ...\n  <activeProfiles>\n    \x3c!-- 要激活的profile id --\x3e\n    <activeProfile>env-test</activeProfile>\n  </activeProfiles>\n  ...\n</settings>\n\n\n至此，maven settings.xml 中的标签都讲解完毕，希望对大家有所帮助。\n\n\n# 参考资料\n\n * maven 官方文档之 settings',normalizedContent:'# maven 教程之 settings.xml 详解\n\n\n# settings.xml 简介\n\n\n# settings.xml 有什么用\n\n从 settings.xml 的文件名就可以看出，它是用来设置 maven 参数的配置文件。settings.xml 中包含类似本地仓储位置、修改远程仓储服务器、认证信息等配置。\n\n * settings.xml 是 maven 的全局配置文件。\n * pom.xml 文件是本地项目配置文件。\n\n\n# settings.xml 文件位置\n\nsettings.xml 文件一般存在于两个位置：\n\n * 全局配置 - ${maven.home}/conf/settings.xml\n * 用户配置 - ${user.home}/.m2/settings.xml\n\n> 🔔 注意：用户配置优先于全局配置。${user.home} 和和所有其他系统属性只能在 3.0+版本上使用。请注意 windows 和 linux 使用变量的区别。\n\n\n# 配置优先级\n\n> 重要：局部配置优先于全局配置。\n\n配置优先级从高到低：pom.xml > user settings > global settings\n\n如果这些文件同时存在，在应用配置时，会合并它们的内容，如果有重复的配置，优先级高的配置会覆盖优先级低的。\n\n\n# settings.xml 元素详解\n\n\n# 顶级元素概览\n\n下面列举了settings.xml中的顶级元素\n\n<settings xmlns="http://maven.apache.org/settings/1.0.0"\n      xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n      xsi:schemalocation="http://maven.apache.org/settings/1.0.0\n                          https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  <localrepository/>\n  <interactivemode/>\n  <usepluginregistry/>\n  <offline/>\n  <plugingroups/>\n  <servers/>\n  <mirrors/>\n  <proxies/>\n  <profiles/>\n  <activeprofiles/>\n</settings>\n\n\n\n# localrepository\n\n作用：该值表示构建系统本地仓库的路径。\n\n其默认值：~/.m2/repository。\n\n<localrepository>${user.home}/.m2/repository</localrepository>\n\n\n\n# interactivemode\n\n作用：表示 maven 是否需要和用户交互以获得输入。\n\n如果 maven 需要和用户交互以获得输入，则设置成 true，反之则应为 false。默认为 true。\n\n<interactivemode>true</interactivemode>\n\n\n\n# usepluginregistry\n\n作用：maven 是否需要使用 plugin-registry.xml 文件来管理插件版本。\n\n如果需要让 maven 使用文件~/.m2/plugin-registry.xml 来管理插件版本，则设为 true。默认为 false。\n\n<usepluginregistry>false</usepluginregistry>\n\n\n\n# offline\n\n作用：表示 maven 是否需要在离线模式下运行。\n\n如果构建系统需要在离线模式下运行，则为 true，默认为 false。\n\n当由于网络设置原因或者安全因素，构建服务器不能连接远程仓库的时候，该配置就十分有用。\n\n<offline>false</offline>\n\n\n\n# plugingroups\n\n作用：当插件的组织 id（groupid）没有显式提供时，供搜寻插件组织 id（groupid）的列表。\n\n该元素包含一个 plugingroup 元素列表，每个子元素包含了一个组织 id（groupid）。\n\n当我们使用某个插件，并且没有在命令行为其提供组织 id（groupid）的时候，maven 就会使用该列表。默认情况下该列表包含了 org.apache.maven.plugins 和 org.codehaus.mojo。\n\n<settings xmlns="http://maven.apache.org/settings/1.0.0" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/settings/1.0.0\n                      https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  ...\n  <plugingroups>\n    \x3c!--plugin的组织id（groupid） --\x3e\n    <plugingroup>org.codehaus.mojo</plugingroup>\n  </plugingroups>\n  ...\n</settings>\n\n\n\n# servers\n\n作用：一般，仓库的下载和部署是在 pom.xml 文件中的 repositories 和 distributionmanagement 元素中定义的。然而，一般类似用户名、密码（有些仓库访问是需要安全认证的）等信息不应该在 pom.xml 文件中配置，这些信息可以配置在 settings.xml 中。\n\n<settings xmlns="http://maven.apache.org/settings/1.0.0" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/settings/1.0.0\n                      https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  ...\n  \x3c!--配置服务端的一些设置。一些设置如安全证书不应该和pom.xml一起分发。这种类型的信息应该存在于构建服务器上的settings.xml文件中。 --\x3e\n  <servers>\n    \x3c!--服务器元素包含配置服务器时需要的信息 --\x3e\n    <server>\n      \x3c!--这是server的id（注意不是用户登陆的id），该id与distributionmanagement中repository元素的id相匹配。 --\x3e\n      <id>server001</id>\n      \x3c!--鉴权用户名。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。 --\x3e\n      <username>my_login</username>\n      \x3c!--鉴权密码 。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。密码加密功能已被添加到2.1.0 +。详情请访问密码加密页面 --\x3e\n      <password>my_password</password>\n      \x3c!--鉴权时使用的私钥位置。和前两个元素类似，私钥位置和私钥密码指定了一个私钥的路径（默认是${user.home}/.ssh/id_dsa）以及如果需要的话，一个密语。将来passphrase和password元素可能会被提取到外部，但目前它们必须在settings.xml文件以纯文本的形式声明。 --\x3e\n      <privatekey>${usr.home}/.ssh/id_dsa</privatekey>\n      \x3c!--鉴权时使用的私钥密码。 --\x3e\n      <passphrase>some_passphrase</passphrase>\n      \x3c!--文件被创建时的权限。如果在部署的时候会创建一个仓库文件或者目录，这时候就可以使用权限（permission）。这两个元素合法的值是一个三位数字，其对应了unix文件系统的权限，如664，或者775。 --\x3e\n      <filepermissions>664</filepermissions>\n      \x3c!--目录被创建时的权限。 --\x3e\n      <directorypermissions>775</directorypermissions>\n    </server>\n  </servers>\n  ...\n</settings>\n\n\n\n# mirrors\n\n作用：为仓库列表配置的下载镜像列表。\n\n<settings xmlns="http://maven.apache.org/settings/1.0.0" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/settings/1.0.0\n                      https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  ...\n  <mirrors>\n    \x3c!-- 给定仓库的下载镜像。 --\x3e\n    <mirror>\n      \x3c!-- 该镜像的唯一标识符。id用来区分不同的mirror元素。 --\x3e\n      <id>planetmirror.com</id>\n      \x3c!-- 镜像名称 --\x3e\n      <name>planetmirror australia</name>\n      \x3c!-- 该镜像的url。构建系统会优先考虑使用该url，而非使用默认的服务器url。 --\x3e\n      <url>http://downloads.planetmirror.com/pub/maven2</url>\n      \x3c!-- 被镜像的服务器的id。例如，如果我们要设置了一个maven中央仓库（http://repo.maven.apache.org/maven2/）的镜像，就需要将该元素设置成central。这必须和中央仓库的id central完全一致。 --\x3e\n      <mirrorof>central</mirrorof>\n    </mirror>\n  </mirrors>\n  ...\n</settings>\n\n\n\n# proxies\n\n作用：用来配置不同的代理。\n\n<settings xmlns="http://maven.apache.org/settings/1.0.0" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/settings/1.0.0\n                      https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  ...\n  <proxies>\n    \x3c!--代理元素包含配置代理时需要的信息 --\x3e\n    <proxy>\n      \x3c!--代理的唯一定义符，用来区分不同的代理元素。 --\x3e\n      <id>myproxy</id>\n      \x3c!--该代理是否是激活的那个。true则激活代理。当我们声明了一组代理，而某个时候只需要激活一个代理的时候，该元素就可以派上用处。 --\x3e\n      <active>true</active>\n      \x3c!--代理的协议。 协议://主机名:端口，分隔成离散的元素以方便配置。 --\x3e\n      <protocol>http</protocol>\n      \x3c!--代理的主机名。协议://主机名:端口，分隔成离散的元素以方便配置。 --\x3e\n      <host>proxy.somewhere.com</host>\n      \x3c!--代理的端口。协议://主机名:端口，分隔成离散的元素以方便配置。 --\x3e\n      <port>8080</port>\n      \x3c!--代理的用户名，用户名和密码表示代理服务器认证的登录名和密码。 --\x3e\n      <username>proxyuser</username>\n      \x3c!--代理的密码，用户名和密码表示代理服务器认证的登录名和密码。 --\x3e\n      <password>somepassword</password>\n      \x3c!--不该被代理的主机名列表。该列表的分隔符由代理服务器指定；例子中使用了竖线分隔符，使用逗号分隔也很常见。 --\x3e\n      <nonproxyhosts>*.google.com|ibiblio.org</nonproxyhosts>\n    </proxy>\n  </proxies>\n  ...\n</settings>\n\n\n\n# profiles\n\n作用：根据环境参数来调整构建配置的列表。\n\nsettings.xml 中的 profile 元素是 pom.xml 中 profile 元素的裁剪版本。\n\n它包含了id、activation、repositories、pluginrepositories 和 properties 元素。这里的 profile 元素只包含这五个子元素是因为这里只关心构建系统这个整体（这正是 settings.xml 文件的角色定位），而非单独的项目对象模型设置。如果一个 settings.xml 中的 profile 被激活，它的值会覆盖任何其它定义在 pom.xml 中带有相同 id 的 profile。\n\n<settings xmlns="http://maven.apache.org/settings/1.0.0" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/settings/1.0.0\n                      https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  ...\n  <profiles>\n    <profile>\n      \x3c!-- profile的唯一标识 --\x3e\n      <id>test</id>\n      \x3c!-- 自动触发profile的条件逻辑 --\x3e\n      <activation />\n      \x3c!-- 扩展属性列表 --\x3e\n      <properties />\n      \x3c!-- 远程仓库列表 --\x3e\n      <repositories />\n      \x3c!-- 插件仓库列表 --\x3e\n      <pluginrepositories />\n    </profile>\n  </profiles>\n  ...\n</settings>\n\n\n# activation\n\n作用：自动触发 profile 的条件逻辑。\n\n如 pom.xml 中的 profile 一样，profile 的作用在于它能够在某些特定的环境中自动使用某些特定的值；这些环境通过 activation 元素指定。 activation 元素并不是激活 profile 的唯一方式。settings.xml 文件中的 activeprofile 元素可以包含 profile 的 id。profile 也可以通过在命令行，使用 -p 标记和逗号分隔的列表来显式的激活（如，-p test）。\n\n<activation>\n  \x3c!--profile默认是否激活的标识 --\x3e\n  <activebydefault>false</activebydefault>\n  \x3c!--当匹配的jdk被检测到，profile被激活。例如，1.4激活jdk1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的jdk。 --\x3e\n  <jdk>1.5</jdk>\n  \x3c!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。 --\x3e\n  <os>\n    \x3c!--激活profile的操作系统的名字 --\x3e\n    <name>windows xp</name>\n    \x3c!--激活profile的操作系统所属家族(如 \'windows\') --\x3e\n    <family>windows</family>\n    \x3c!--激活profile的操作系统体系结构 --\x3e\n    <arch>x86</arch>\n    \x3c!--激活profile的操作系统版本 --\x3e\n    <version>5.1.2600</version>\n  </os>\n  \x3c!--如果maven检测到某一个属性（其值可以在pom中通过${name}引用），其拥有对应的name = 值，profile就会被激活。如果值字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段 --\x3e\n  <property>\n    \x3c!--激活profile的属性的名称 --\x3e\n    <name>mavenversion</name>\n    \x3c!--激活profile的属性的值 --\x3e\n    <value>2.0.3</value>\n  </property>\n  \x3c!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。 --\x3e\n  <file>\n    \x3c!--如果指定的文件存在，则激活profile。 --\x3e\n    <exists>${basedir}/file2.properties</exists>\n    \x3c!--如果指定的文件不存在，则激活profile。 --\x3e\n    <missing>${basedir}/file1.properties</missing>\n  </file>\n</activation>\n\n\n> 注：在 maven 工程的 pom.xml 所在目录下执行 mvn help:active-profiles 命令可以查看中央仓储的 profile 是否在工程中生效。\n\n# properties\n\n作用：对应profile的扩展属性列表。\n\nmaven 属性和 ant 中的属性一样，可以用来存放一些值。这些值可以在 pom.xml 中的任何地方使用标记${x}来使用，这里 x 是指属性的名称。属性有五种不同的形式，并且都能在 settings.xml 文件中访问。\n\n\x3c!--\n  1. env.x: 在一个变量前加上"env."的前缀，会返回一个shell环境变量。例如,"env.path"指代了$path环境变量（在windows上是%path%）。\n  2. project.x：指代了pom中对应的元素值。例如: <project><version>1.0</version></project>通过${project.version}获得version的值。\n  3. settings.x: 指代了settings.xml中对应元素的值。例如：<settings><offline>false</offline></settings>通过 ${settings.offline}获得offline的值。\n  4. java system properties: 所有可通过java.lang.system.getproperties()访问的属性都能在pom中使用该形式访问，例如 ${java.home}。\n  5. x: 在<properties/>元素中，或者外部文件中设置，以${somevar}的形式使用。\n --\x3e\n<properties>\n  <user.install>${user.home}/our-project</user.install>\n</properties>\n\n\n> 注：如果该 profile 被激活，则可以在pom.xml中使用${user.install}。\n\n# repositories\n\n作用：远程仓库列表，它是 maven 用来填充构建系统本地仓库所使用的一组远程仓库。\n\n<repositories>\n  \x3c!--包含需要连接到远程仓库的信息 --\x3e\n  <repository>\n    \x3c!--远程仓库唯一标识 --\x3e\n    <id>codehaussnapshots</id>\n    \x3c!--远程仓库名称 --\x3e\n    <name>codehaus snapshots</name>\n    \x3c!--如何处理远程仓库里发布版本的下载 --\x3e\n    <releases>\n      \x3c!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --\x3e\n      <enabled>false</enabled>\n      \x3c!--该元素指定更新发生的频率。maven会比较本地pom和远程pom的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：x（这里x是以分钟为单位的时间间隔），或者never（从不）。 --\x3e\n      <updatepolicy>always</updatepolicy>\n      \x3c!--当maven验证构件校验文件失败时该怎么做-ignore（忽略），fail（失败），或者warn（警告）。 --\x3e\n      <checksumpolicy>warn</checksumpolicy>\n    </releases>\n    \x3c!--如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，pom就可以在每个单独的仓库中，为每种类型的构件采取不同的策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --\x3e\n    <snapshots>\n      <enabled />\n      <updatepolicy />\n      <checksumpolicy />\n    </snapshots>\n    \x3c!--远程仓库url，按protocol://hostname/path形式 --\x3e\n    <url>http://snapshots.maven.codehaus.org/maven2</url>\n    \x3c!--用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。maven 2为其仓库提供了一个默认的布局；然而，maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --\x3e\n    <layout>default</layout>\n  </repository>\n</repositories>\n\n\n# pluginrepositories\n\n作用：发现插件的远程仓库列表。\n\n和 repository 类似，只是 repository 是管理 jar 包依赖的仓库，pluginrepositories 则是管理插件的仓库。 maven 插件是一种特殊类型的构件。由于这个原因，插件仓库独立于其它仓库。pluginrepositories 元素的结构和 repositories 元素的结构类似。每个 pluginrepository 元素指定一个 maven 可以用来寻找新插件的远程地址。\n\n<pluginrepositories>\n  \x3c!-- 包含需要连接到远程插件仓库的信息.参见profiles/profile/repositories/repository元素的说明 --\x3e\n  <pluginrepository>\n    <releases>\n      <enabled />\n      <updatepolicy />\n      <checksumpolicy />\n    </releases>\n    <snapshots>\n      <enabled />\n      <updatepolicy />\n      <checksumpolicy />\n    </snapshots>\n    <id />\n    <name />\n    <url />\n    <layout />\n  </pluginrepository>\n</pluginrepositories>\n\n\n\n# activeprofiles\n\n作用：手动激活 profiles 的列表，按照profile被应用的顺序定义activeprofile。\n\n该元素包含了一组 activeprofile 元素，每个 activeprofile 都含有一个 profile id。任何在 activeprofile 中定义的 profile id，不论环境设置如何，其对应的 profile 都会被激活。如果没有匹配的 profile，则什么都不会发生。\n\n例如，env-test 是一个 activeprofile，则在 pom.xml（或者 profile.xml）中对应 id 的 profile 会被激活。如果运行过程中找不到这样一个 profile，maven 则会像往常一样运行。\n\n<settings xmlns="http://maven.apache.org/settings/1.0.0" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/settings/1.0.0\n                      https://maven.apache.org/xsd/settings-1.0.0.xsd">\n  ...\n  <activeprofiles>\n    \x3c!-- 要激活的profile id --\x3e\n    <activeprofile>env-test</activeprofile>\n  </activeprofiles>\n  ...\n</settings>\n\n\n至此，maven settings.xml 中的标签都讲解完毕，希望对大家有所帮助。\n\n\n# 参考资料\n\n * maven 官方文档之 settings',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Maven 实战问题和最佳实践",frontmatter:{title:"Maven 实战问题和最佳实践",categories:["编程","Java","软件","构建"],tags:["Java","构建","Maven"],abbrlink:"684ab4a9",date:"2018-11-28T09:29:22.000Z",permalink:"/pages/7908f2/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/01.%E6%9E%84%E5%BB%BA/01.Maven/04.Maven%E5%AE%9E%E6%88%98%E9%97%AE%E9%A2%98%E5%92%8C%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html",relativePath:"11.软件/01.构建/01.Maven/04.Maven实战问题和最佳实践.md",key:"v-7d156502",path:"/pages/7908f2/",headers:[{level:2,title:"Maven 常见问题",slug:"maven-常见问题",normalizedTitle:"maven 常见问题",charIndex:22},{level:3,title:"dependencies 和 dependencyManagement，plugins 和 pluginManagement 有什么区别",slug:"dependencies-和-dependencymanagement-plugins-和-pluginmanagement-有什么区别",normalizedTitle:"dependencies 和 dependencymanagement，plugins 和 pluginmanagement 有什么区别",charIndex:37},{level:3,title:"IDEA 修改 JDK 版本后编译报错",slug:"idea-修改-jdk-版本后编译报错",normalizedTitle:"idea 修改 jdk 版本后编译报错",charIndex:490},{level:3,title:"重复引入依赖",slug:"重复引入依赖",normalizedTitle:"重复引入依赖",charIndex:975},{level:3,title:"如何打包一个可以直接运行的 Spring Boot jar 包",slug:"如何打包一个可以直接运行的-spring-boot-jar-包",normalizedTitle:"如何打包一个可以直接运行的 spring boot jar 包",charIndex:1067},{level:3,title:"去哪儿找 maven dependency",slug:"去哪儿找-maven-dependency",normalizedTitle:"去哪儿找 maven dependency",charIndex:2213},{level:3,title:"如何指定编码",slug:"如何指定编码",normalizedTitle:"如何指定编码",charIndex:2401},{level:3,title:"如何指定 JDK 版本",slug:"如何指定-jdk-版本",normalizedTitle:"如何指定 jdk 版本",charIndex:2619},{level:3,title:"如何避免将 dependency 打包到构件中",slug:"如何避免将-dependency-打包到构件中",normalizedTitle:"如何避免将 dependency 打包到构件中",charIndex:3234},{level:3,title:"如何跳过单元测试",slug:"如何跳过单元测试",normalizedTitle:"如何跳过单元测试",charIndex:3381},{level:3,title:"如何引入本地 jar",slug:"如何引入本地-jar",normalizedTitle:"如何引入本地 jar",charIndex:3534},{level:3,title:"如何排除依赖",slug:"如何排除依赖",normalizedTitle:"如何排除依赖",charIndex:3991},{level:2,title:"Maven 最佳实践",slug:"maven-最佳实践",normalizedTitle:"maven 最佳实践",charIndex:4462},{level:3,title:"通过 bom 统一管理版本",slug:"通过-bom-统一管理版本",normalizedTitle:"通过 bom 统一管理版本",charIndex:4477}],headersStr:"Maven 常见问题 dependencies 和 dependencyManagement，plugins 和 pluginManagement 有什么区别 IDEA 修改 JDK 版本后编译报错 重复引入依赖 如何打包一个可以直接运行的 Spring Boot jar 包 去哪儿找 maven dependency 如何指定编码 如何指定 JDK 版本 如何避免将 dependency 打包到构件中 如何跳过单元测试 如何引入本地 jar 如何排除依赖 Maven 最佳实践 通过 bom 统一管理版本",content:'# Maven 实战问题和最佳实践\n\n\n# Maven 常见问题\n\n\n# dependencies 和 dependencyManagement，plugins 和 pluginManagement 有什么区别\n\ndependencyManagement 是表示依赖 jar 包的声明，即你在项目中的 dependencyManagement 下声明了依赖，maven 不会加载该依赖，dependencyManagement 声明可以被继承。\n\ndependencyManagement 的一个使用案例是当有父子项目的时候，父项目中可以利用 dependencyManagement 声明子项目中需要用到的依赖 jar 包，之后，当某个或者某几个子项目需要加载该插件的时候，就可以在子项目中 dependencies 节点只配置 groupId 和 artifactId 就可以完成插件的引用。\n\ndependencyManagement 主要是为了统一管理插件，确保所有子项目使用的插件版本保持一致，类似的还有 plugins 和 pluginManagement。\n\n\n# IDEA 修改 JDK 版本后编译报错\n\n错误现象：\n\n修改 JDK 版本，指定 maven-compiler-plugin 的 source 和 target 为 1.8 。\n\n然后，在 Intellij IDEA 中执行 maven 指令，报错：\n\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.0:compile (default-compile) on project apollo-common: Fatal error compiling: 无效的目标版本： 1.8 -> [Help 1]\n\n\n错误原因：\n\nmaven 的 JDK 源与指定的 JDK 编译版本不符。\n\n排错手段：\n\n * 查看 Project Settings\n\nProject SDK 是否正确\n\n\n\nSDK 路径是否正确\n\n\n\n * 查看 Settings > Maven 的配置\n\nJDK for importer 是否正确\n\n\n\nRunner 是否正确\n\n\n\n\n# 重复引入依赖\n\n在 Idea 中，选中 Module，使用 Ctrl+Alt+Shift+U，打开依赖图，检索是否存在重复引用的情况。如果存在重复引用，可以将多余的引用删除。\n\n\n# 如何打包一个可以直接运行的 Spring Boot jar 包\n\n可以使用 spring-boot-maven-plugin 插件\n\n<build>\n  <plugins>\n    <plugin>\n      <groupId>org.springframework.boot</groupId>\n      <artifactId>spring-boot-maven-plugin</artifactId>\n      <executions>\n        <execution>\n          <goals>\n            <goal>repackage</goal>\n          </goals>\n        </execution>\n      </executions>\n    </plugin>\n  </plugins>\n</build>\n\n\n如果引入了第三方 jar 包，如何打包？\n\n首先，要添加依赖\n\n<dependency>\n  <groupId>io.github.dunwu</groupId>\n  <artifactId>dunwu-common</artifactId>\n  <version>1.0.0</version>\n  <scope>system</scope>\n  <systemPath>${project.basedir}/src/main/resources/lib/dunwu-common-1.0.0.jar</systemPath>\n</dependency>\n\n\n接着，需要配置 spring-boot-maven-plugin 插件：\n\n<build>\n  <plugins>\n    <plugin>\n      <groupId>org.springframework.boot</groupId>\n      <artifactId>spring-boot-maven-plugin</artifactId>\n      <executions>\n        <execution>\n          <goals>\n            <goal>repackage</goal>\n          </goals>\n        </execution>\n      </executions>\n      <configuration>\n        <includeSystemScope>true</includeSystemScope>\n      </configuration>\n    </plugin>\n  </plugins>\n</build>\n\n\n\n# 去哪儿找 maven dependency\n\n问：刚接触 maven 的新手，往往会有这样的疑问，我该去哪儿找 jar？\n\n答：官方推荐的搜索 maven dependency 网址：\n\n * https://search.maven.org\n * https://repository.apache.org\n * https://mvnrepository.com\n\n\n# 如何指定编码\n\n问：众所周知，不同编码格式常常会产生意想不到的诡异问题，那么 maven 构建时如何指定 maven 构建时的编码？\n\n答：在 properties 中指定 project.build.sourceEncoding\n\n<properties>\n  <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n</properties>\n\n\n\n# 如何指定 JDK 版本\n\n问：如何指定 maven 构建时的 JDK 版本\n\n答：有两种方法：\n\n（1）properties 方式\n\n<project>\n  ...\n  <properties>\n    <maven.compiler.source>1.7</maven.compiler.source>\n    <maven.compiler.target>1.7</maven.compiler.target>\n  </properties>\n  ...\n</project>\n\n\n（2）使用 maven-compiler-plugin 插件，并指定 source 和 target 版本\n\n<build>\n...\n  <plugins>\n    <plugin>\n      <groupId>org.apache.maven.plugins</groupId>\n      <artifactId>maven-compiler-plugin</artifactId>\n      <version>3.3</version>\n      <configuration>\n        <source>1.7</source>\n        <target>1.7</target>\n      </configuration>\n    </plugin>\n  </plugins>\n...\n</build>\n\n\n\n# 如何避免将 dependency 打包到构件中\n\n答：指定 maven dependency 的 scope 为 provided，这意味着：依赖关系将在运行时由其容器或 JDK 提供。 具有此范围的依赖关系不会传递，也不会捆绑在诸如 WAR 之类的包中，也不会包含在运行时类路径中。\n\n\n# 如何跳过单元测试\n\n问：执行 mvn package 或 mvn install 时，会自动编译所有单元测试(src/test/java 目录下的代码)，如何跳过这一步？\n\n答：在执行命令的后面，添加命令行参数 -Dmaven.test.skip=true 或者 -DskipTests=true\n\n\n# 如何引入本地 jar\n\n问：有时候，需要引入在中央仓库找不到的 jar，但又想通过 maven 进行管理，那么应该如何做到呢？ 答：可以通过设置 dependency 的 scope 为 system 来引入本地 jar。 例：\n\n * 将私有 jar 放置在 resouces/lib 下，然后以如下方式添加依赖：\n * groupId 和 artifactId 可以按照 jar 包中的 package 设置，只要和其他 jar 不冲突即可。\n\n<dependency>\n    <groupId>xxx</groupId>\n    <artifactId>xxx</artifactId>\n    <version>1.0.0</version>\n    <scope>system</scope>\n    <systemPath>${project.basedir}/src/main/resources/lib/xxx-6.0.0.jar</systemPath>\n</dependency>\n\n\n\n# 如何排除依赖\n\n问：如何排除依赖一个依赖关系？比方项目中使用的 libA 依赖某个库的 1.0 版。libB 以来某个库的 2.0 版，如今想统一使用 2.0 版，怎样去掉 1.0 版的依赖？\n\n答：通过 exclusion 排除指定依赖即可。\n\n例：\n\n<dependency>\n    <groupId>org.apache.zookeeper</groupId>\n    <artifactId>zookeeper</artifactId>\n    <version>3.4.12</version>\n    <optional>true</optional>\n    <exclusions>\n        <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-log4j12</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n\n\n\n# Maven 最佳实践\n\n\n# 通过 bom 统一管理版本\n\n采用类似 spring-boot-dependencies 的方式统一管理依赖版本。\n\nspring-boot-dependencies 的 pom.xml 形式：\n\n<?xml version="1.0" encoding="UTF-8"?>\n<project xmlns="http://maven.apache.org/POM/4.0.0" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">\n<modelVersion>4.0.0</modelVersion>\n<groupId>org.springframework.boot</groupId>\n<artifactId>spring-boot-dependencies</artifactId>\n<version>2.1.9.RELEASE</version>\n<packaging>pom</packaging>\n\n\x3c!-- 省略 --\x3e\n\n\x3c!-- 依赖包版本管理 --\x3e\n<dependencyManagement>\n    <dependencies>\n    \x3c!-- 省略 --\x3e\n    </dependencies>\n</dependencyManagement>\n\n<build>\n\x3c!-- 插件版本管理 --\x3e\n<pluginManagement>\n    <plugins>\n    \x3c!-- 省略 --\x3e\n    </plugins>\n</pluginManagement>\n</build>\n</project>\n\n\n其他项目引入 spring-boot-dependencies 来管理依赖版本的方式：\n\n <dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-dependencies</artifactId>\n            <version>${spring-boot.version}</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n',normalizedContent:'# maven 实战问题和最佳实践\n\n\n# maven 常见问题\n\n\n# dependencies 和 dependencymanagement，plugins 和 pluginmanagement 有什么区别\n\ndependencymanagement 是表示依赖 jar 包的声明，即你在项目中的 dependencymanagement 下声明了依赖，maven 不会加载该依赖，dependencymanagement 声明可以被继承。\n\ndependencymanagement 的一个使用案例是当有父子项目的时候，父项目中可以利用 dependencymanagement 声明子项目中需要用到的依赖 jar 包，之后，当某个或者某几个子项目需要加载该插件的时候，就可以在子项目中 dependencies 节点只配置 groupid 和 artifactid 就可以完成插件的引用。\n\ndependencymanagement 主要是为了统一管理插件，确保所有子项目使用的插件版本保持一致，类似的还有 plugins 和 pluginmanagement。\n\n\n# idea 修改 jdk 版本后编译报错\n\n错误现象：\n\n修改 jdk 版本，指定 maven-compiler-plugin 的 source 和 target 为 1.8 。\n\n然后，在 intellij idea 中执行 maven 指令，报错：\n\n[error] failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.0:compile (default-compile) on project apollo-common: fatal error compiling: 无效的目标版本： 1.8 -> [help 1]\n\n\n错误原因：\n\nmaven 的 jdk 源与指定的 jdk 编译版本不符。\n\n排错手段：\n\n * 查看 project settings\n\nproject sdk 是否正确\n\n\n\nsdk 路径是否正确\n\n\n\n * 查看 settings > maven 的配置\n\njdk for importer 是否正确\n\n\n\nrunner 是否正确\n\n\n\n\n# 重复引入依赖\n\n在 idea 中，选中 module，使用 ctrl+alt+shift+u，打开依赖图，检索是否存在重复引用的情况。如果存在重复引用，可以将多余的引用删除。\n\n\n# 如何打包一个可以直接运行的 spring boot jar 包\n\n可以使用 spring-boot-maven-plugin 插件\n\n<build>\n  <plugins>\n    <plugin>\n      <groupid>org.springframework.boot</groupid>\n      <artifactid>spring-boot-maven-plugin</artifactid>\n      <executions>\n        <execution>\n          <goals>\n            <goal>repackage</goal>\n          </goals>\n        </execution>\n      </executions>\n    </plugin>\n  </plugins>\n</build>\n\n\n如果引入了第三方 jar 包，如何打包？\n\n首先，要添加依赖\n\n<dependency>\n  <groupid>io.github.dunwu</groupid>\n  <artifactid>dunwu-common</artifactid>\n  <version>1.0.0</version>\n  <scope>system</scope>\n  <systempath>${project.basedir}/src/main/resources/lib/dunwu-common-1.0.0.jar</systempath>\n</dependency>\n\n\n接着，需要配置 spring-boot-maven-plugin 插件：\n\n<build>\n  <plugins>\n    <plugin>\n      <groupid>org.springframework.boot</groupid>\n      <artifactid>spring-boot-maven-plugin</artifactid>\n      <executions>\n        <execution>\n          <goals>\n            <goal>repackage</goal>\n          </goals>\n        </execution>\n      </executions>\n      <configuration>\n        <includesystemscope>true</includesystemscope>\n      </configuration>\n    </plugin>\n  </plugins>\n</build>\n\n\n\n# 去哪儿找 maven dependency\n\n问：刚接触 maven 的新手，往往会有这样的疑问，我该去哪儿找 jar？\n\n答：官方推荐的搜索 maven dependency 网址：\n\n * https://search.maven.org\n * https://repository.apache.org\n * https://mvnrepository.com\n\n\n# 如何指定编码\n\n问：众所周知，不同编码格式常常会产生意想不到的诡异问题，那么 maven 构建时如何指定 maven 构建时的编码？\n\n答：在 properties 中指定 project.build.sourceencoding\n\n<properties>\n  <project.build.sourceencoding>utf-8</project.build.sourceencoding>\n</properties>\n\n\n\n# 如何指定 jdk 版本\n\n问：如何指定 maven 构建时的 jdk 版本\n\n答：有两种方法：\n\n（1）properties 方式\n\n<project>\n  ...\n  <properties>\n    <maven.compiler.source>1.7</maven.compiler.source>\n    <maven.compiler.target>1.7</maven.compiler.target>\n  </properties>\n  ...\n</project>\n\n\n（2）使用 maven-compiler-plugin 插件，并指定 source 和 target 版本\n\n<build>\n...\n  <plugins>\n    <plugin>\n      <groupid>org.apache.maven.plugins</groupid>\n      <artifactid>maven-compiler-plugin</artifactid>\n      <version>3.3</version>\n      <configuration>\n        <source>1.7</source>\n        <target>1.7</target>\n      </configuration>\n    </plugin>\n  </plugins>\n...\n</build>\n\n\n\n# 如何避免将 dependency 打包到构件中\n\n答：指定 maven dependency 的 scope 为 provided，这意味着：依赖关系将在运行时由其容器或 jdk 提供。 具有此范围的依赖关系不会传递，也不会捆绑在诸如 war 之类的包中，也不会包含在运行时类路径中。\n\n\n# 如何跳过单元测试\n\n问：执行 mvn package 或 mvn install 时，会自动编译所有单元测试(src/test/java 目录下的代码)，如何跳过这一步？\n\n答：在执行命令的后面，添加命令行参数 -dmaven.test.skip=true 或者 -dskiptests=true\n\n\n# 如何引入本地 jar\n\n问：有时候，需要引入在中央仓库找不到的 jar，但又想通过 maven 进行管理，那么应该如何做到呢？ 答：可以通过设置 dependency 的 scope 为 system 来引入本地 jar。 例：\n\n * 将私有 jar 放置在 resouces/lib 下，然后以如下方式添加依赖：\n * groupid 和 artifactid 可以按照 jar 包中的 package 设置，只要和其他 jar 不冲突即可。\n\n<dependency>\n    <groupid>xxx</groupid>\n    <artifactid>xxx</artifactid>\n    <version>1.0.0</version>\n    <scope>system</scope>\n    <systempath>${project.basedir}/src/main/resources/lib/xxx-6.0.0.jar</systempath>\n</dependency>\n\n\n\n# 如何排除依赖\n\n问：如何排除依赖一个依赖关系？比方项目中使用的 liba 依赖某个库的 1.0 版。libb 以来某个库的 2.0 版，如今想统一使用 2.0 版，怎样去掉 1.0 版的依赖？\n\n答：通过 exclusion 排除指定依赖即可。\n\n例：\n\n<dependency>\n    <groupid>org.apache.zookeeper</groupid>\n    <artifactid>zookeeper</artifactid>\n    <version>3.4.12</version>\n    <optional>true</optional>\n    <exclusions>\n        <exclusion>\n            <groupid>org.slf4j</groupid>\n            <artifactid>slf4j-log4j12</artifactid>\n        </exclusion>\n    </exclusions>\n</dependency>\n\n\n\n# maven 最佳实践\n\n\n# 通过 bom 统一管理版本\n\n采用类似 spring-boot-dependencies 的方式统一管理依赖版本。\n\nspring-boot-dependencies 的 pom.xml 形式：\n\n<?xml version="1.0" encoding="utf-8"?>\n<project xmlns="http://maven.apache.org/pom/4.0.0" xsi:schemalocation="http://maven.apache.org/pom/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance">\n<modelversion>4.0.0</modelversion>\n<groupid>org.springframework.boot</groupid>\n<artifactid>spring-boot-dependencies</artifactid>\n<version>2.1.9.release</version>\n<packaging>pom</packaging>\n\n\x3c!-- 省略 --\x3e\n\n\x3c!-- 依赖包版本管理 --\x3e\n<dependencymanagement>\n    <dependencies>\n    \x3c!-- 省略 --\x3e\n    </dependencies>\n</dependencymanagement>\n\n<build>\n\x3c!-- 插件版本管理 --\x3e\n<pluginmanagement>\n    <plugins>\n    \x3c!-- 省略 --\x3e\n    </plugins>\n</pluginmanagement>\n</build>\n</project>\n\n\n其他项目引入 spring-boot-dependencies 来管理依赖版本的方式：\n\n <dependencymanagement>\n    <dependencies>\n        <dependency>\n            <groupid>org.springframework.boot</groupid>\n            <artifactid>spring-boot-dependencies</artifactid>\n            <version>${spring-boot.version}</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencymanagement>\n',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Maven 教程之发布 jar 到私服或中央仓库",frontmatter:{title:"Maven 教程之发布 jar 到私服或中央仓库",categories:["编程","Java","软件","构建"],tags:["Java","构建","Maven"],abbrlink:"b88f29ef",date:"2019-05-14T14:57:33.000Z",permalink:"/pages/2ddf04/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/01.%E6%9E%84%E5%BB%BA/01.Maven/05.Maven%E6%95%99%E7%A8%8B%E4%B9%8B%E5%8F%91%E5%B8%83jar%E5%88%B0%E7%A7%81%E6%9C%8D%E6%88%96%E4%B8%AD%E5%A4%AE%E4%BB%93%E5%BA%93.html",relativePath:"11.软件/01.构建/01.Maven/05.Maven教程之发布jar到私服或中央仓库.md",key:"v-ae223d88",path:"/pages/2ddf04/",headers:[{level:2,title:"发布 jar 包到中央仓库",slug:"发布-jar-包到中央仓库",normalizedTitle:"发布 jar 包到中央仓库",charIndex:31},{level:3,title:"在 Sonatype 创建 Issue",slug:"在-sonatype-创建-issue",normalizedTitle:"在 sonatype 创建 issue",charIndex:140},{level:3,title:"使用 GPG 生成公私钥对",slug:"使用-gpg-生成公私钥对",normalizedTitle:"使用 gpg 生成公私钥对",charIndex:605},{level:3,title:"Maven 配置",slug:"maven-配置",normalizedTitle:"maven 配置",charIndex:3332},{level:4,title:"settings.xml 配置",slug:"settings-xml-配置",normalizedTitle:"settings.xml 配置",charIndex:3401},{level:4,title:"pom.xml 配置",slug:"pom-xml-配置",normalizedTitle:"pom.xml 配置",charIndex:4723},{level:3,title:"部署和发布",slug:"部署和发布",normalizedTitle:"部署和发布",charIndex:7380},{level:2,title:"部署 maven 私服",slug:"部署-maven-私服",normalizedTitle:"部署 maven 私服",charIndex:7542},{level:3,title:"下载安装 Nexus",slug:"下载安装-nexus",normalizedTitle:"下载安装 nexus",charIndex:7672},{level:3,title:"启动停止 Nexus",slug:"启动停止-nexus",normalizedTitle:"启动停止 nexus",charIndex:8084},{level:3,title:"使用 Nexus",slug:"使用-nexus",normalizedTitle:"使用 nexus",charIndex:8738},{level:4,title:"配置 settings.xml",slug:"配置-settings-xml",normalizedTitle:"配置 settings.xml",charIndex:8713},{level:4,title:"配置 pom.xml",slug:"配置-pom-xml",normalizedTitle:"配置 pom.xml",charIndex:10530},{level:4,title:"执行 maven 构建",slug:"执行-maven-构建",normalizedTitle:"执行 maven 构建",charIndex:11092},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:11310}],headersStr:"发布 jar 包到中央仓库 在 Sonatype 创建 Issue 使用 GPG 生成公私钥对 Maven 配置 settings.xml 配置 pom.xml 配置 部署和发布 部署 maven 私服 下载安装 Nexus 启动停止 Nexus 使用 Nexus 配置 settings.xml 配置 pom.xml 执行 maven 构建 参考资料",content:'# Maven 教程之发布 jar 到私服或中央仓库\n\n\n# 发布 jar 包到中央仓库\n\n> 为了避免重复造轮子，相信每个 Java 程序员都想打造自己的脚手架或工具包（自己定制的往往才是最适合自己的）。那么如何将自己的脚手架发布到中央仓库呢？下面我们将一步步来实现。\n\n\n# 在 Sonatype 创建 Issue\n\n（1）注册 Sonatype 账号\n\n发布 Java 包到 Maven 中央仓库，首先需要在 Sonatype 网站创建一个工单(Issues)。\n\n第一次使用这个网站的时候需要注册自己的帐号（这个帐号和密码需要记住，后面会用到）。\n\n（2）创建 Issue\n\n注册账号成功后，根据你 Java 包的功能分别写上Summary、Description、Group Id、SCM url以及Project URL等必要信息，可以参见我之前创建的 Issue：OSSRH-36187。\n\n\n\n创建完之后需要等待 Sonatype 的工作人员审核处理，审核时间还是很快的，我的审核差不多等待了两小时。当 Issue 的 Status 变为RESOLVED后，就可以进行下一步操作了。\n\n> 说明：如果你的 Group Id 填写的是自己的网站（我的就是这种情况），Sonatype 的工作人员会询问你那个 Group Id 是不是你的域名，你只需要在上面回答是就行，然后就会通过审核。\n\n\n# 使用 GPG 生成公私钥对\n\n（1）安装 Gpg4win\n\nWindows 系统，可以下载 Gpg4win 软件来生成密钥对。\n\nGpg4win 下载地址\n\n安装后，执行命令 gpg --version 检查是否安装成功。\n\nC:\\Program Files (x86)\\GnuPG\\bin>gpg --version\ngpg (GnuPG) 2.2.10\nlibgcrypt 1.8.3\nCopyright (C) 2018 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <https://gnu.org/licenses/gpl.html>\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the exdunwu permitted by law.\n\nHome: C:/Users/Administrator/AppData/Roaming/gnupg\nSupported algorithms:\nPubkey: RSA, ELG, DSA, ECDH, ECDSA, EDDSA\nCipher: IDEA, 3DES, CAST5, BLOWFISH, AES, AES192, AES256, TWOFISH,\n        CAMELLIA128, CAMELLIA192, CAMELLIA256\nHash: SHA1, RIPEMD160, SHA256, SHA384, SHA512, SHA224\nCompression: Uncompressed, ZIP, ZLIB, BZIP2\n\n\n（2）生成密钥对\n\n执行命令 gpg --gen-key\n\nC:\\Program Files (x86)\\GnuPG\\bin>gpg --gen-key\ngpg (GnuPG) 2.2.10; Copyright (C) 2018 Free Software Foundation, Inc.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the exdunwu permitted by law.\n\nNote: Use "gpg --full-generate-key" for a full featured key generation dialog.\n\nGnuPG needs to construct a user ID to identify your key.\n\nReal name: Zhang Peng\nEmail address: forbreak@163.com\nYou selected this USER-ID:\n    "Zhang Peng <forbreak@163.com>"\n\nChange (N)ame, (E)mail, or (O)kay/(Q)uit? O\n\n\n说明：按照提示，依次输入用户名、邮箱。\n\n（3）查看公钥\n\nC:\\Program Files (x86)\\GnuPG\\bin>gpg --list-keys\n\ngpg: checking the trustdb\ngpg: marginals needed: 3  completes needed: 1  trust model: pgp\ngpg: depth: 0  valid:   2  signed:   0  trust: 0-, 0q, 0n, 0m, 0f, 2u\ngpg: next trustdb check due at 2020-11-05\nC:/Users/Administrator/AppData/Roaming/gnupg/pubring.kbx\n--------------------------------------------------------\npub   rsa2048 2018-11-06 [SC] [expires: 2020-11-06]\n      E4CE537A3803D49C35332221A306519BAFF57F60\nuid           [ultimate] forbreak <forbreak@163.com>\nsub   rsa2048 2018-11-06 [E] [expires: 2020-11-06]\n\n\n> 说明：其中，E4CE537A3803D49C35332221A306519BAFF57F60 就是公钥\n\n（4）将公钥发布到 PGP 密钥服务器\n\n执行 gpg --keyserver hkp://pool.sks-keyservers.net --send-keys 发布公钥：\n\nC:\\Program Files (x86)\\GnuPG\\bin>gpg --keyserver hkp://pool.sks-keyservers.net --send-keys E4CE537A3803D49C35332221A306519BAFF57F60\ngpg: sending key A306519BAFF57F60 to hkp://pool.sks-keyservers.net\n\n\n> 🔔 注意：有可能出现 gpg: keyserver receive failed: No dat 错误，等大约 30 分钟后再执行就不会报错了。\n\n（5）查看公钥是否发布成功\n\n执行 gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys 查看公钥是否发布成功。\n\nC:\\Program Files (x86)\\GnuPG\\bin>gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys E4CE537A3803D49C35332221A306519BAFF57F60\ngpg: key A306519BAFF57F60: "forbreak <forbreak@163.com>" not changed\ngpg: Total number processed: 1\ngpg:              unchanged: 1\n\n\n\n# Maven 配置\n\n完成了前两个章节的准备工作，就可以将 jar 包上传到中央仓库了。当然了，我们还要对 maven 做一些配置。\n\n# settings.xml 配置\n\n一份完整的 settings.xml 配置示例如下：\n\n<?xml version="1.0" encoding="UTF-8"?>\n\n<settings xmlns="http://maven.apache.org/SETTINGS/1.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd">\n\n  <pluginGroups>\n    <pluginGroup>org.sonatype.plugins</pluginGroup>\n  </pluginGroups>\n\n  \x3c!-- 用户名、密码就是 Sonatype 账号、密码 --\x3e\n  <servers>\n    <server>\n      <id>sonatype-snapshots</id>\n      <username>xxxxxx</username>\n      <password>xxxxxx</password>\n    </server>\n    <server>\n      <id>sonatype-staging</id>\n      <username>xxxxxx</username>\n      <password>xxxxxx</password>\n    </server>\n  </servers>\n\n  \x3c!-- 使用 aliyun maven 仓库加速下载 --\x3e\n  <mirrors>\n    <mirror>\n      <id>nexus-aliyun</id>\n      <mirrorOf>*</mirrorOf>\n      <name>Aliyun</name>\n      <url>http://maven.aliyun.com/nexus/groups/public</url>\n    </mirror>\n  </mirrors>\n\n  \x3c!-- gpg 的密码，注意，这里不是指公钥 --\x3e\n  <profiles>\n    <profile>\n      <id>sonatype</id>\n      <properties>\n        <gpg.executable>C:/Program Files (x86)/GnuPG/bin/gpg.exe</gpg.executable>\n        <gpg.passphrase>xxxxxx</gpg.passphrase>\n      </properties>\n    </profile>\n  </profiles>\n\n  <activeProfiles>\n    <activeProfile>sonatype</activeProfile>\n  </activeProfiles>\n</settings>\n\n\n# pom.xml 配置\n\n（1）添加 licenses、scm、developers 配置：\n\n<licenses>\n  <license>\n    <name>The Apache Software License, Version 2.0</name>\n    <url>http://www.apache.org/licenses/LICENSE-2.0.txt</url>\n    <distribution>repo</distribution>\n  </license>\n</licenses>\n\n<developers>\n  <developer>\n    <name>xxxxxx</name>\n    <email>forbreak@163.com</email>\n    <url>https://github.com/dunwu</url>\n  </developer>\n</developers>\n\n<scm>\n  <url>https://github.com/dunwu/dunwu</url>\n  <connection>git@github.com:dunwu/dunwu.git</connection>\n  <developerConnection>https://github.com/dunwu</developerConnection>\n</scm>\n\n\n（2）添加 distributionManagement 配置\n\n<distributionManagement>\n  <snapshotRepository>\n    <id>sonatype-snapshots</id>\n    <url>https://oss.sonatype.org/content/repositories/snapshots</url>\n  </snapshotRepository>\n  <repository>\n    <id>sonatype-staging</id>\n    <url>https://oss.sonatype.org/service/local/staging/deploy/maven2</url>\n  </repository>\n</distributionManagement>\n\n\n> 说明：<snapshotRepository> 指定的是 snapshot 仓库地址；<repository> 指定的是 staging （正式版）仓库地址。需要留意的是，这里的 id 需要和 settings.xml 中的 <server> 的 id 保持一致。\n\n（3）添加 profiles 配置\n\n <profiles>\n  <profile>\n    <id>sonatype</id>\n    <build>\n      <plugins>\n        <plugin>\n          <groupId>org.sonatype.plugins</groupId>\n          <artifactId>nexus-staging-maven-plugin</artifactId>\n          <version>1.6.7</version>\n          <extensions>true</extensions>\n          <configuration>\n            <serverId>sonatype-snapshots</serverId>\n            <nexusUrl>https://oss.sonatype.org/</nexusUrl>\n            <autoReleaseAfterClose>true</autoReleaseAfterClose>\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-javadoc-plugin</artifactId>\n          <version>3.0.1</version>\n          <configuration>\n            <failOnError>false</failOnError>\n            <quiet>true</quiet>\n          </configuration>\n          <executions>\n            <execution>\n              <id>attach-javadocs</id>\n              <goals>\n                <goal>jar</goal>\n              </goals>\n            </execution>\n          </executions>\n        </plugin>\n\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-gpg-plugin</artifactId>\n          <version>1.6</version>\n          <executions>\n            <execution>\n              <id>sign-artifacts</id>\n              <phase>verify</phase>\n              <goals>\n                <goal>sign</goal>\n              </goals>\n            </execution>\n          </executions>\n        </plugin>\n      </plugins>\n    </build>\n  </profile>\n</profiles>\n\n\n\n# 部署和发布\n\n按照上面的步骤配置完后，一切都已经 OK。\n\n此时，使用 mvn clean deploy -P sonatype 命令就可以发布 jar 包到中央仓库了：\n\n> 说明：-P 参数后面的 sonatype 需要和 pom.xml 中 <profile> 的 id 保持一致，才能激活 profile。\n\n\n# 部署 maven 私服\n\n> 工作中，Java 程序员开发的商用 Java 项目，一般不想发布到中央仓库，使得人人尽知。这时，我们就需要搭建私服，将 maven 服务器部署在公司内部网络，从而避免 jar 包流传出去。怎么做呢，让我们来一步步学习吧。\n\n\n# 下载安装 Nexus\n\n进入官方下载地址，选择合适版本下载。\n\n\n\n本人希望将 Nexus 部署在 Linux 机器，所以选用的是 Unix 版本。\n\n这里，如果想通过命令方式直接下载（比如用脚本安装），可以在官方历史发布版本页面中找到合适版本，然后执行以下命令：\n\nwget -O /opt/maven/nexus-unix.tar.gz http://download.sonatype.com/nexus/3/nexus-3.13.0-01-unix.tar.gz\ntar -zxf nexus-unix.tar.gz\n\n\n解压后，有两个目录：\n\n * nexus-3.13.0-01 - 包含了 Nexus 运行所需要的文件。是 Nexus 运行必须的。\n * sonatype-work - 包含了 Nexus 生成的配置文件、日志文件、仓库文件等。当我们需要备份 Nexus 的时候默认备份此目录即可。\n\n\n# 启动停止 Nexus\n\n进入 nexus-3.13.0-01/bin 目录，有一个可执行脚本 nexus。\n\n执行 ./nexus，可以查看允许执行的参数，如下所示，含义可谓一目了然：\n\n$ ./nexus\nUsage: ./nexus {start|stop|run|run-redirect|status|restart|force-reload}\n\n\n * 启动 nexus - ./nexus start\n * 停止 nexus -\n\n启动成功后，在浏览器中访问 http://<ip>:8081，欢迎页面如下图所示：\n\n\n\n点击右上角 Sign in 登录，默认用户名/密码为：admin/admin123。\n\n有必要提一下的是，在 Nexus 的 Repositories 管理页面，展示了可用的 maven 仓库，如下图所示：\n\n\n\n> 说明：\n> \n>  * maven-central - maven 中央库（如果没有配置 mirror，默认就从这里下载 jar 包），从 https://repo1.maven.org/maven2/ 获取资源\n>  * maven-releases - 存储私有仓库的发行版 jar 包\n>  * maven-snapshots - 存储私有仓库的快照版（调试版本） jar 包\n>  * maven-public - 私有仓库的公共空间，把上面三个仓库组合在一起对外提供服务，在本地 maven 基础配置 settings.xml 中使用。\n\n\n# 使用 Nexus\n\n如果要使用 Nexus，还必须在 settings.xml 和 pom.xml 中配置认证信息。\n\n# 配置 settings.xml\n\n一份完整的 settings.xml：\n\n<?xml version="1.0" encoding="UTF-8"?>\n\n<settings xmlns="http://maven.apache.org/SETTINGS/1.0.0"\n  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd">\n  <pluginGroups>\n    <pluginGroup>org.sonatype.plugins</pluginGroup>\n  </pluginGroups>\n\n  \x3c!-- Maven 私服账号信息 --\x3e\n  <servers>\n    <server>\n      <id>releases</id>\n      <username>admin</username>\n      <password>admin123</password>\n    </server>\n    <server>\n      <id>snapshots</id>\n      <username>admin</username>\n      <password>admin123</password>\n    </server>\n  </servers>\n\n  \x3c!-- jar 包下载地址 --\x3e\n  <mirrors>\n    <mirror>\n      <id>public</id>\n      <mirrorOf>*</mirrorOf>\n      <url>http://10.255.255.224:8081/repository/maven-public/</url>\n    </mirror>\n  </mirrors>\n\n  <profiles>\n    <profile>\n      <id>zp</id>\n      <repositories>\n        <repository>\n          <id>central</id>\n          <url>http://central</url>\n          <releases>\n            <enabled>true</enabled>\n          </releases>\n          <snapshots>\n            <enabled>true</enabled>\n          </snapshots>\n        </repository>\n      </repositories>\n      <pluginRepositories>\n        <pluginRepository>\n          <id>central</id>\n          <url>http://central</url>\n          <releases>\n            <enabled>true</enabled>\n          </releases>\n          <snapshots>\n            <enabled>true</enabled>\n            <updatePolicy>always</updatePolicy>\n          </snapshots>\n        </pluginRepository>\n      </pluginRepositories>\n    </profile>\n  </profiles>\n\n  <activeProfiles>\n    <activeProfile>zp</activeProfile>\n  </activeProfiles>\n</settings>\n\n\n# 配置 pom.xml\n\n在 pom.xml 中添加如下配置：\n\n  <distributionManagement>\n    <repository>\n      <id>releases</id>\n      <name>Releases</name>\n      <url>http://10.255.255.224:8081/repository/maven-releases</url>\n    </repository>\n    <snapshotRepository>\n      <id>snapshots</id>\n      <name>Snapshot</name>\n      <url>http://10.255.255.224:8081/repository/maven-snapshots</url>\n    </snapshotRepository>\n  </distributionManagement>\n\n\n> 🔔 注意：\n> \n>  * <repository> 和 <snapshotRepository> 的 id 必须和 settings.xml 配置文件中的 <server> 标签中的 id 匹配。\n>  * <url> 标签的地址需要和 maven 私服的地址匹配。\n\n# 执行 maven 构建\n\n如果要使用 settings.xml 中的私服配置，必须通过指定 -P zp 来激活 profile。\n\n示例：\n\n## 编译并打包 maven 项目\n$ mvn clean package -Dmaven.skip.test=true -P zp\n\n## 编译并上传 maven 交付件（jar 包）\n$ mvn clean deploy -Dmaven.skip.test=true -P zp\n\n\n\n# 参考资料\n\n * https://www.jianshu.com/p/8c3d7fb09bce\n * http://www.ruanyifeng.com/blog/2013/07/gpg.html\n * https://www.cnblogs.com/hoobey/p/6102382.html\n * https://blog.csdn.net/wzygis/article/details/49276779\n * https://blog.csdn.net/clj198606061111/article/details/52200928',normalizedContent:'# maven 教程之发布 jar 到私服或中央仓库\n\n\n# 发布 jar 包到中央仓库\n\n> 为了避免重复造轮子，相信每个 java 程序员都想打造自己的脚手架或工具包（自己定制的往往才是最适合自己的）。那么如何将自己的脚手架发布到中央仓库呢？下面我们将一步步来实现。\n\n\n# 在 sonatype 创建 issue\n\n（1）注册 sonatype 账号\n\n发布 java 包到 maven 中央仓库，首先需要在 sonatype 网站创建一个工单(issues)。\n\n第一次使用这个网站的时候需要注册自己的帐号（这个帐号和密码需要记住，后面会用到）。\n\n（2）创建 issue\n\n注册账号成功后，根据你 java 包的功能分别写上summary、description、group id、scm url以及project url等必要信息，可以参见我之前创建的 issue：ossrh-36187。\n\n\n\n创建完之后需要等待 sonatype 的工作人员审核处理，审核时间还是很快的，我的审核差不多等待了两小时。当 issue 的 status 变为resolved后，就可以进行下一步操作了。\n\n> 说明：如果你的 group id 填写的是自己的网站（我的就是这种情况），sonatype 的工作人员会询问你那个 group id 是不是你的域名，你只需要在上面回答是就行，然后就会通过审核。\n\n\n# 使用 gpg 生成公私钥对\n\n（1）安装 gpg4win\n\nwindows 系统，可以下载 gpg4win 软件来生成密钥对。\n\ngpg4win 下载地址\n\n安装后，执行命令 gpg --version 检查是否安装成功。\n\nc:\\program files (x86)\\gnupg\\bin>gpg --version\ngpg (gnupg) 2.2.10\nlibgcrypt 1.8.3\ncopyright (c) 2018 free software foundation, inc.\nlicense gplv3+: gnu gpl version 3 or later <https://gnu.org/licenses/gpl.html>\nthis is free software: you are free to change and redistribute it.\nthere is no warranty, to the exdunwu permitted by law.\n\nhome: c:/users/administrator/appdata/roaming/gnupg\nsupported algorithms:\npubkey: rsa, elg, dsa, ecdh, ecdsa, eddsa\ncipher: idea, 3des, cast5, blowfish, aes, aes192, aes256, twofish,\n        camellia128, camellia192, camellia256\nhash: sha1, ripemd160, sha256, sha384, sha512, sha224\ncompression: uncompressed, zip, zlib, bzip2\n\n\n（2）生成密钥对\n\n执行命令 gpg --gen-key\n\nc:\\program files (x86)\\gnupg\\bin>gpg --gen-key\ngpg (gnupg) 2.2.10; copyright (c) 2018 free software foundation, inc.\nthis is free software: you are free to change and redistribute it.\nthere is no warranty, to the exdunwu permitted by law.\n\nnote: use "gpg --full-generate-key" for a full featured key generation dialog.\n\ngnupg needs to construct a user id to identify your key.\n\nreal name: zhang peng\nemail address: forbreak@163.com\nyou selected this user-id:\n    "zhang peng <forbreak@163.com>"\n\nchange (n)ame, (e)mail, or (o)kay/(q)uit? o\n\n\n说明：按照提示，依次输入用户名、邮箱。\n\n（3）查看公钥\n\nc:\\program files (x86)\\gnupg\\bin>gpg --list-keys\n\ngpg: checking the trustdb\ngpg: marginals needed: 3  completes needed: 1  trust model: pgp\ngpg: depth: 0  valid:   2  signed:   0  trust: 0-, 0q, 0n, 0m, 0f, 2u\ngpg: next trustdb check due at 2020-11-05\nc:/users/administrator/appdata/roaming/gnupg/pubring.kbx\n--------------------------------------------------------\npub   rsa2048 2018-11-06 [sc] [expires: 2020-11-06]\n      e4ce537a3803d49c35332221a306519baff57f60\nuid           [ultimate] forbreak <forbreak@163.com>\nsub   rsa2048 2018-11-06 [e] [expires: 2020-11-06]\n\n\n> 说明：其中，e4ce537a3803d49c35332221a306519baff57f60 就是公钥\n\n（4）将公钥发布到 pgp 密钥服务器\n\n执行 gpg --keyserver hkp://pool.sks-keyservers.net --send-keys 发布公钥：\n\nc:\\program files (x86)\\gnupg\\bin>gpg --keyserver hkp://pool.sks-keyservers.net --send-keys e4ce537a3803d49c35332221a306519baff57f60\ngpg: sending key a306519baff57f60 to hkp://pool.sks-keyservers.net\n\n\n> 🔔 注意：有可能出现 gpg: keyserver receive failed: no dat 错误，等大约 30 分钟后再执行就不会报错了。\n\n（5）查看公钥是否发布成功\n\n执行 gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys 查看公钥是否发布成功。\n\nc:\\program files (x86)\\gnupg\\bin>gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys e4ce537a3803d49c35332221a306519baff57f60\ngpg: key a306519baff57f60: "forbreak <forbreak@163.com>" not changed\ngpg: total number processed: 1\ngpg:              unchanged: 1\n\n\n\n# maven 配置\n\n完成了前两个章节的准备工作，就可以将 jar 包上传到中央仓库了。当然了，我们还要对 maven 做一些配置。\n\n# settings.xml 配置\n\n一份完整的 settings.xml 配置示例如下：\n\n<?xml version="1.0" encoding="utf-8"?>\n\n<settings xmlns="http://maven.apache.org/settings/1.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance" xsi:schemalocation="http://maven.apache.org/settings/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd">\n\n  <plugingroups>\n    <plugingroup>org.sonatype.plugins</plugingroup>\n  </plugingroups>\n\n  \x3c!-- 用户名、密码就是 sonatype 账号、密码 --\x3e\n  <servers>\n    <server>\n      <id>sonatype-snapshots</id>\n      <username>xxxxxx</username>\n      <password>xxxxxx</password>\n    </server>\n    <server>\n      <id>sonatype-staging</id>\n      <username>xxxxxx</username>\n      <password>xxxxxx</password>\n    </server>\n  </servers>\n\n  \x3c!-- 使用 aliyun maven 仓库加速下载 --\x3e\n  <mirrors>\n    <mirror>\n      <id>nexus-aliyun</id>\n      <mirrorof>*</mirrorof>\n      <name>aliyun</name>\n      <url>http://maven.aliyun.com/nexus/groups/public</url>\n    </mirror>\n  </mirrors>\n\n  \x3c!-- gpg 的密码，注意，这里不是指公钥 --\x3e\n  <profiles>\n    <profile>\n      <id>sonatype</id>\n      <properties>\n        <gpg.executable>c:/program files (x86)/gnupg/bin/gpg.exe</gpg.executable>\n        <gpg.passphrase>xxxxxx</gpg.passphrase>\n      </properties>\n    </profile>\n  </profiles>\n\n  <activeprofiles>\n    <activeprofile>sonatype</activeprofile>\n  </activeprofiles>\n</settings>\n\n\n# pom.xml 配置\n\n（1）添加 licenses、scm、developers 配置：\n\n<licenses>\n  <license>\n    <name>the apache software license, version 2.0</name>\n    <url>http://www.apache.org/licenses/license-2.0.txt</url>\n    <distribution>repo</distribution>\n  </license>\n</licenses>\n\n<developers>\n  <developer>\n    <name>xxxxxx</name>\n    <email>forbreak@163.com</email>\n    <url>https://github.com/dunwu</url>\n  </developer>\n</developers>\n\n<scm>\n  <url>https://github.com/dunwu/dunwu</url>\n  <connection>git@github.com:dunwu/dunwu.git</connection>\n  <developerconnection>https://github.com/dunwu</developerconnection>\n</scm>\n\n\n（2）添加 distributionmanagement 配置\n\n<distributionmanagement>\n  <snapshotrepository>\n    <id>sonatype-snapshots</id>\n    <url>https://oss.sonatype.org/content/repositories/snapshots</url>\n  </snapshotrepository>\n  <repository>\n    <id>sonatype-staging</id>\n    <url>https://oss.sonatype.org/service/local/staging/deploy/maven2</url>\n  </repository>\n</distributionmanagement>\n\n\n> 说明：<snapshotrepository> 指定的是 snapshot 仓库地址；<repository> 指定的是 staging （正式版）仓库地址。需要留意的是，这里的 id 需要和 settings.xml 中的 <server> 的 id 保持一致。\n\n（3）添加 profiles 配置\n\n <profiles>\n  <profile>\n    <id>sonatype</id>\n    <build>\n      <plugins>\n        <plugin>\n          <groupid>org.sonatype.plugins</groupid>\n          <artifactid>nexus-staging-maven-plugin</artifactid>\n          <version>1.6.7</version>\n          <extensions>true</extensions>\n          <configuration>\n            <serverid>sonatype-snapshots</serverid>\n            <nexusurl>https://oss.sonatype.org/</nexusurl>\n            <autoreleaseafterclose>true</autoreleaseafterclose>\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupid>org.apache.maven.plugins</groupid>\n          <artifactid>maven-javadoc-plugin</artifactid>\n          <version>3.0.1</version>\n          <configuration>\n            <failonerror>false</failonerror>\n            <quiet>true</quiet>\n          </configuration>\n          <executions>\n            <execution>\n              <id>attach-javadocs</id>\n              <goals>\n                <goal>jar</goal>\n              </goals>\n            </execution>\n          </executions>\n        </plugin>\n\n        <plugin>\n          <groupid>org.apache.maven.plugins</groupid>\n          <artifactid>maven-gpg-plugin</artifactid>\n          <version>1.6</version>\n          <executions>\n            <execution>\n              <id>sign-artifacts</id>\n              <phase>verify</phase>\n              <goals>\n                <goal>sign</goal>\n              </goals>\n            </execution>\n          </executions>\n        </plugin>\n      </plugins>\n    </build>\n  </profile>\n</profiles>\n\n\n\n# 部署和发布\n\n按照上面的步骤配置完后，一切都已经 ok。\n\n此时，使用 mvn clean deploy -p sonatype 命令就可以发布 jar 包到中央仓库了：\n\n> 说明：-p 参数后面的 sonatype 需要和 pom.xml 中 <profile> 的 id 保持一致，才能激活 profile。\n\n\n# 部署 maven 私服\n\n> 工作中，java 程序员开发的商用 java 项目，一般不想发布到中央仓库，使得人人尽知。这时，我们就需要搭建私服，将 maven 服务器部署在公司内部网络，从而避免 jar 包流传出去。怎么做呢，让我们来一步步学习吧。\n\n\n# 下载安装 nexus\n\n进入官方下载地址，选择合适版本下载。\n\n\n\n本人希望将 nexus 部署在 linux 机器，所以选用的是 unix 版本。\n\n这里，如果想通过命令方式直接下载（比如用脚本安装），可以在官方历史发布版本页面中找到合适版本，然后执行以下命令：\n\nwget -o /opt/maven/nexus-unix.tar.gz http://download.sonatype.com/nexus/3/nexus-3.13.0-01-unix.tar.gz\ntar -zxf nexus-unix.tar.gz\n\n\n解压后，有两个目录：\n\n * nexus-3.13.0-01 - 包含了 nexus 运行所需要的文件。是 nexus 运行必须的。\n * sonatype-work - 包含了 nexus 生成的配置文件、日志文件、仓库文件等。当我们需要备份 nexus 的时候默认备份此目录即可。\n\n\n# 启动停止 nexus\n\n进入 nexus-3.13.0-01/bin 目录，有一个可执行脚本 nexus。\n\n执行 ./nexus，可以查看允许执行的参数，如下所示，含义可谓一目了然：\n\n$ ./nexus\nusage: ./nexus {start|stop|run|run-redirect|status|restart|force-reload}\n\n\n * 启动 nexus - ./nexus start\n * 停止 nexus -\n\n启动成功后，在浏览器中访问 http://<ip>:8081，欢迎页面如下图所示：\n\n\n\n点击右上角 sign in 登录，默认用户名/密码为：admin/admin123。\n\n有必要提一下的是，在 nexus 的 repositories 管理页面，展示了可用的 maven 仓库，如下图所示：\n\n\n\n> 说明：\n> \n>  * maven-central - maven 中央库（如果没有配置 mirror，默认就从这里下载 jar 包），从 https://repo1.maven.org/maven2/ 获取资源\n>  * maven-releases - 存储私有仓库的发行版 jar 包\n>  * maven-snapshots - 存储私有仓库的快照版（调试版本） jar 包\n>  * maven-public - 私有仓库的公共空间，把上面三个仓库组合在一起对外提供服务，在本地 maven 基础配置 settings.xml 中使用。\n\n\n# 使用 nexus\n\n如果要使用 nexus，还必须在 settings.xml 和 pom.xml 中配置认证信息。\n\n# 配置 settings.xml\n\n一份完整的 settings.xml：\n\n<?xml version="1.0" encoding="utf-8"?>\n\n<settings xmlns="http://maven.apache.org/settings/1.0.0"\n  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance" xsi:schemalocation="http://maven.apache.org/settings/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd">\n  <plugingroups>\n    <plugingroup>org.sonatype.plugins</plugingroup>\n  </plugingroups>\n\n  \x3c!-- maven 私服账号信息 --\x3e\n  <servers>\n    <server>\n      <id>releases</id>\n      <username>admin</username>\n      <password>admin123</password>\n    </server>\n    <server>\n      <id>snapshots</id>\n      <username>admin</username>\n      <password>admin123</password>\n    </server>\n  </servers>\n\n  \x3c!-- jar 包下载地址 --\x3e\n  <mirrors>\n    <mirror>\n      <id>public</id>\n      <mirrorof>*</mirrorof>\n      <url>http://10.255.255.224:8081/repository/maven-public/</url>\n    </mirror>\n  </mirrors>\n\n  <profiles>\n    <profile>\n      <id>zp</id>\n      <repositories>\n        <repository>\n          <id>central</id>\n          <url>http://central</url>\n          <releases>\n            <enabled>true</enabled>\n          </releases>\n          <snapshots>\n            <enabled>true</enabled>\n          </snapshots>\n        </repository>\n      </repositories>\n      <pluginrepositories>\n        <pluginrepository>\n          <id>central</id>\n          <url>http://central</url>\n          <releases>\n            <enabled>true</enabled>\n          </releases>\n          <snapshots>\n            <enabled>true</enabled>\n            <updatepolicy>always</updatepolicy>\n          </snapshots>\n        </pluginrepository>\n      </pluginrepositories>\n    </profile>\n  </profiles>\n\n  <activeprofiles>\n    <activeprofile>zp</activeprofile>\n  </activeprofiles>\n</settings>\n\n\n# 配置 pom.xml\n\n在 pom.xml 中添加如下配置：\n\n  <distributionmanagement>\n    <repository>\n      <id>releases</id>\n      <name>releases</name>\n      <url>http://10.255.255.224:8081/repository/maven-releases</url>\n    </repository>\n    <snapshotrepository>\n      <id>snapshots</id>\n      <name>snapshot</name>\n      <url>http://10.255.255.224:8081/repository/maven-snapshots</url>\n    </snapshotrepository>\n  </distributionmanagement>\n\n\n> 🔔 注意：\n> \n>  * <repository> 和 <snapshotrepository> 的 id 必须和 settings.xml 配置文件中的 <server> 标签中的 id 匹配。\n>  * <url> 标签的地址需要和 maven 私服的地址匹配。\n\n# 执行 maven 构建\n\n如果要使用 settings.xml 中的私服配置，必须通过指定 -p zp 来激活 profile。\n\n示例：\n\n## 编译并打包 maven 项目\n$ mvn clean package -dmaven.skip.test=true -p zp\n\n## 编译并上传 maven 交付件（jar 包）\n$ mvn clean deploy -dmaven.skip.test=true -p zp\n\n\n\n# 参考资料\n\n * https://www.jianshu.com/p/8c3d7fb09bce\n * http://www.ruanyifeng.com/blog/2013/07/gpg.html\n * https://www.cnblogs.com/hoobey/p/6102382.html\n * https://blog.csdn.net/wzygis/article/details/49276779\n * https://blog.csdn.net/clj198606061111/article/details/52200928',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Maven 插件之代码检查",frontmatter:{title:"Maven 插件之代码检查",categories:["编程","Java","软件","构建"],tags:["Java","构建","Maven"],abbrlink:"7b76d24a",date:"2019-12-16T17:09:26.000Z",permalink:"/pages/149013/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/01.%E6%9E%84%E5%BB%BA/01.Maven/06.Maven%E6%8F%92%E4%BB%B6%E4%B9%8B%E4%BB%A3%E7%A0%81%E6%A3%80%E6%9F%A5.html",relativePath:"11.软件/01.构建/01.Maven/06.Maven插件之代码检查.md",key:"v-d649585e",path:"/pages/149013/",headers:[{level:2,title:"maven-checkstyle-plugin",slug:"maven-checkstyle-plugin",normalizedTitle:"maven-checkstyle-plugin",charIndex:20},{level:3,title:"定义 checkstyle.xml",slug:"定义-checkstyle-xml",normalizedTitle:"定义 checkstyle.xml",charIndex:92},{level:2,title:"maven-pmd-plugin",slug:"maven-pmd-plugin",normalizedTitle:"maven-pmd-plugin",charIndex:13707},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:15422}],headersStr:"maven-checkstyle-plugin 定义 checkstyle.xml maven-pmd-plugin 参考资料",content:'# Maven 插件之代码检查\n\n\n# maven-checkstyle-plugin\n\n> maven-checkstyle-plugin，用于检测代码中不符合规范的地方。\n\n\n# 定义 checkstyle.xml\n\n<!DOCTYPE module PUBLIC\n  "-//Checkstyle//DTD Checkstyle Configuration 1.3//EN"\n  "https://checkstyle.org/dtds/configuration_1_3.dtd">\n\n\x3c!-- Generated by RHY @will_awoke --\x3e\n\n<module name="Checker">\n\n  <property name="charset" value="UTF-8"/>\n  <property name="severity" value="warning"/>\n\n  \x3c!-- Checks for Size Violations.  --\x3e\n  \x3c!-- 检查文件的长度（行） default max=2000 --\x3e\n  <module name="FileLength">\n    <property name="max" value="2500"/>\n  </module>\n\n  \x3c!-- Checks that property files contain the same keys. --\x3e\n  \x3c!-- 检查**.properties配置文件 是否有相同的key\n  <module name="Translation">\n  </module>\n  --\x3e\n\n  <module name="TreeWalker">\n\n    \x3c!-- Checks for imports    --\x3e\n    \x3c!-- 必须导入类的完整路径，即不能使用*导入所需的类 --\x3e\n    <module name="AvoidStarImport"/>\n\n    \x3c!-- 检查是否从非法的包中导入了类 illegalPkgs: 定义非法的包名称--\x3e\n    <module name="IllegalImport"/> \x3c!-- defaults to sun.* packages --\x3e\n\n    \x3c!-- 检查是否导入了不必显示导入的类--\x3e\n    <module name="RedundantImport"/>\n\n    \x3c!-- 检查是否导入的包没有使用--\x3e\n    <module name="UnusedImports"/>\n\n    \x3c!-- Checks for whitespace\n    <module name="EmptyForIteratorPad"/>\n    <module name="MethodParamPad"/>\n    <module name="NoWhitespaceAfter"/>\n    <module name="NoWhitespaceBefore"/>\n    <module name="OperatorWrap"/>\n    <module name="ParenPad"/>\n    <module name="TypecastParenPad"/>\n    <module name="WhitespaceAfter"/>\n    <module name="WhitespaceAround"/>\n    --\x3e\n\n    \x3c!-- 检查类和接口的javadoc 默认不检查author 和version tags\n      authorFormat: 检查author标签的格式\n            versionFormat: 检查version标签的格式\n            scope: 可以检查的类的范围，例如：public只能检查public修饰的类，private可以检查所有的类\n            excludeScope: 不能检查的类的范围，例如：public，public的类将不被检查，但访问权限小于public的类仍然会检查，其他的权限以此类推\n            tokens: 该属性适用的类型，例如：CLASS_DEF,INTERFACE_DEF --\x3e\n    <module name="JavadocType">\n      <property name="authorFormat" value="\\S"/>\n      <property name="scope" value="protected"/>\n      <property name="tokens" value="CLASS_DEF,INTERFACE_DEF"/>\n    </module>\n\n    \x3c!-- 检查方法的javadoc的注释\n            scope: 可以检查的方法的范围，例如：public只能检查public修饰的方法，private可以检查所有的方法\n            allowMissingParamTags: 是否忽略对参数注释的检查\n            allowMissingThrowsTags: 是否忽略对throws注释的检查\n            allowMissingReturnTag: 是否忽略对return注释的检查 --\x3e\n    <module name="JavadocMethod">\n      <property name="scope" value="private"/>\n      <property name="allowMissingParamTags" value="false"/>\n      <property name="allowMissingThrowsTags" value="false"/>\n      <property name="allowMissingReturnTag" value="false"/>\n      <property name="tokens" value="METHOD_DEF"/>\n      <property name="allowUndeclaredRTE" value="true"/>\n      <property name="allowThrowsTagsForSubclasses" value="true"/>\n      \x3c!--允许get set 方法没有注释--\x3e\n      <property name="allowMissingPropertyJavadoc" value="true"/>\n    </module>\n\n    \x3c!-- 检查类变量的注释\n            scope: 检查变量的范围，例如：public只能检查public修饰的变量，private可以检查所有的变量 --\x3e\n    <module name="JavadocVariable">\n      <property name="scope" value="private"/>\n    </module>\n\n    \x3c!--option: 定义左大括号\'{\'显示位置，eol在同一行显示，nl在下一行显示\n      maxLineLength: 大括号\'{\'所在行行最多容纳的字符数\n      tokens: 该属性适用的类型，例：CLASS_DEF,INTERFACE_DEF,METHOD_DEF,CTOR_DEF --\x3e\n    <module name="LeftCurly">\n      <property name="option" value="nl"/>\n    </module>\n\n    \x3c!-- NeedBraces 检查是否应该使用括号的地方没有加括号\n      tokens: 定义检查的类型 --\x3e\n    <module name="NeedBraces"/>\n\n    \x3c!-- Checks the placement of right curly braces (\'}\') for  else, try, and catch tokens. The policy to verify is specified using property  option.\n      option: 右大括号是否单独一行显示\n      tokens: 定义检查的类型  --\x3e\n    <module name="RightCurly">\n      <property name="option" value="alone"/>\n    </module>\n\n    \x3c!-- 检查在重写了equals方法后是否重写了hashCode方法 --\x3e\n    <module name="EqualsHashCode"/>\n\n    \x3c!--  Checks for illegal instantiations where a factory method is preferred.\n      Rationale: Depending on the project, for some classes it might be preferable to create instances through factory methods rather than calling the constructor.\n      A simple example is the java.lang.Boolean class. In order to save memory and CPU cycles, it is preferable to use the predefined constants TRUE and FALSE. Constructor invocations should be replaced by calls to Boolean.valueOf().\n      Some extremely performance sensitive projects may require the use of factory methods for other classes as well, to enforce the usage of number caches or object pools. --\x3e\n    <module name="IllegalInstantiation">\n      <property name="classes" value="java.lang.Boolean"/>\n    </module>\n\n    \x3c!-- Checks for Naming Conventions.   命名规范   --\x3e\n    \x3c!-- local, final variables, including catch parameters --\x3e\n    <module name="LocalFinalVariableName"/>\n\n    \x3c!-- local, non-final variables, including catch parameters--\x3e\n    <module name="LocalVariableName"/>\n\n    \x3c!-- static, non-final fields --\x3e\n    <module name="StaticVariableName">\n      <property name="format" value="(^[A-Z0-9_]{0,19}$)"/>\n    </module>\n\n    \x3c!-- packages --\x3e\n    <module name="PackageName">\n      <property name="format" value="^[a-z]+(\\.[a-z][a-z0-9]*)*$"/>\n    </module>\n\n    \x3c!-- classes and interfaces --\x3e\n    <module name="TypeName">\n      <property name="format" value="(^[A-Z][a-zA-Z0-9]{0,19}$)"/>\n    </module>\n\n    \x3c!-- methods --\x3e\n    <module name="MethodName">\n      <property name="format" value="(^[a-z][a-zA-Z0-9]{0,19}$)"/>\n    </module>\n\n    \x3c!-- non-static fields --\x3e\n    <module name="MemberName">\n      <property name="format" value="(^[a-z][a-z0-9][a-zA-Z0-9]{0,19}$)"/>\n    </module>\n\n    \x3c!-- parameters --\x3e\n    <module name="ParameterName">\n      <property name="format" value="(^[a-z][a-zA-Z0-9_]{0,19}$)"/>\n    </module>\n\n    \x3c!-- constants (static,  final fields) --\x3e\n    <module name="ConstantName">\n      <property name="format" value="(^[A-Z0-9_]{0,19}$)"/>\n    </module>\n\n    \x3c!-- 代码缩进   --\x3e\n    <module name="Indentation">\n    </module>\n\n    \x3c!-- Checks for redundant exceptions declared in throws clause such as duplicates, unchecked exceptions or subclasses of another declared exception.\n      检查是否抛出了多余的异常\n    <module name="RedundantThrows">\n        <property name="logLoadErrors" value="true"/>\n        <property name="suppressLoadErrors" value="true"/>\n    </module>\n    --\x3e\n\n    \x3c!--  Checks for overly complicated boolean expressions. Currently finds code like  if (b == true), b || true, !false, etc.\n      检查boolean值是否冗余的地方\n      Rationale: Complex boolean logic makes code hard to understand and maintain. --\x3e\n    <module name="SimplifyBooleanExpression"/>\n\n    \x3c!--  Checks for overly complicated boolean return statements. For example the following code\n       检查是否存在过度复杂的boolean返回值\n       if (valid())\n          return false;\n       else\n          return true;\n       could be written as\n          return !valid();\n       The Idea for this Check has been shamelessly stolen from the equivalent PMD rule. --\x3e\n    <module name="SimplifyBooleanReturn"/>\n\n    \x3c!-- Checks that a class which has only private constructors is declared as final.只有私有构造器的类必须声明为final--\x3e\n    <module name="FinalClass"/>\n\n    \x3c!--  Make sure that utility classes (classes that contain only static methods or fields in their API) do not have a public constructor.\n      确保Utils类（只提供static方法和属性的类）没有public构造器。\n      Rationale: Instantiating utility classes does not make sense. Hence the constructors should either be private or (if you want to allow subclassing) protected. A common mistake is forgetting to hide the default constructor.\n      If you make the constructor protected you may want to consider the following constructor implementation technique to disallow instantiating subclasses:\n      public class StringUtils // not final to allow subclassing\n      {\n          protected StringUtils() {\n              throw new UnsupportedOperationException(); // prevents calls from subclass\n          }\n          public static int count(char c, String s) {\n              // ...\n          }\n      }\n   <module name="HideUtilityClassConstructor"/>\n   --\x3e\n\n    \x3c!--  Checks visibility of class members. Only static final members may be public; other class members must be private unless property protectedAllowed or packageAllowed is set.\n      检查class成员属性可见性。只有static final 修饰的成员是可以public的。其他的成员属性必需是private的，除非属性protectedAllowed或者packageAllowed设置了true.\n       Public members are not flagged if the name matches the public member regular expression (contains "^serialVersionUID$" by default). Note: Checkstyle 2 used to include "^f[A-Z][a-zA-Z0-9]*$" in the default pattern to allow CMP for EJB 1.1 with the default settings. With EJB 2.0 it is not longer necessary to have public access for persistent fields, hence the default has been changed.\n       Rationale: Enforce encapsulation. 强制封装 --\x3e\n    <module name="VisibilityModifier"/>\n\n    \x3c!-- 每一行只能定义一个变量 --\x3e\n    <module name="MultipleVariableDeclarations">\n    </module>\n\n    \x3c!-- Checks the style of array type definitions. Some like Java-style: public static void main(String[] args) and some like C-style: public static void main(String args[])\n      检查再定义数组时，采用java风格还是c风格，例如：int[] num是java风格，int num[]是c风格。默认是java风格--\x3e\n    <module name="ArrayTypeStyle">\n    </module>\n\n    \x3c!-- Checks that there are no "magic numbers", where a magic number is a numeric literal that is not defined as a constant. By default, -1, 0, 1, and 2 are not considered to be magic numbers.\n    <module name="MagicNumber">\n    </module>\n    --\x3e\n\n    \x3c!-- A check for TODO: comments. Actually it is a generic regular expression matcher on Java comments. To check for other patterns in Java comments, set property format.\n       检查是否存在TODO（待处理） TODO是javaIDE自动生成的。一般代码写完后要去掉。\n     --\x3e\n    <module name="TodoComment"/>\n\n    \x3c!--  Checks that long constants are defined with an upper ell. That is \' L\' and not \'l\'. This is in accordance to the Java Language Specification,  Section 3.10.1.\n      检查是否在long类型是否定义了大写的L.字母小写l和数字1（一）很相似。\n      looks a lot like 1. --\x3e\n    <module name="UpperEll"/>\n\n    \x3c!--  Checks that switch statement has "default" clause. 检查switch语句是否有‘default’从句\n       Rationale: It\'s usually a good idea to introduce a default case in every switch statement.\n       Even if the developer is sure that all currently possible cases are covered, this should be expressed in the default branch,\n        e.g. by using an assertion. This way the code is protected aginst later changes, e.g. introduction of new types in an enumeration type. --\x3e\n    <module name="MissingSwitchDefault"/>\n\n    \x3c!--检查switch中case后是否加入了跳出语句，例如：return、break、throw、continue --\x3e\n    <module name="FallThrough"/>\n\n    \x3c!-- Checks the number of parameters of a method or constructor. max default 7个. --\x3e\n    <module name="ParameterNumber">\n      <property name="max" value="5"/>\n    </module>\n\n    \x3c!-- 每行字符数 --\x3e\n    <module name="LineLength">\n      <property name="max" value="200"/>\n    </module>\n\n    \x3c!-- Checks for long methods and constructors. max default 150行. max=300 设置长度300 --\x3e\n    <module name="MethodLength">\n      <property name="max" value="300"/>\n    </module>\n\n    \x3c!-- ModifierOrder 检查修饰符的顺序，默认是 public,protected,private,abstract,static,final,transient,volatile,synchronized,native --\x3e\n    <module name="ModifierOrder">\n    </module>\n\n    \x3c!-- 检查是否有多余的修饰符，例如：接口中的方法不必使用public、abstract修饰  --\x3e\n    <module name="RedundantModifier">\n    </module>\n\n    \x3c!--- 字符串比较必须使用 equals() --\x3e\n    <module name="StringLiteralEquality">\n    </module>\n\n    \x3c!-- if-else嵌套语句个数 最多4层 --\x3e\n    <module name="NestedIfDepth">\n      <property name="max" value="3"/>\n    </module>\n\n    \x3c!-- try-catch 嵌套语句个数 最多2层 --\x3e\n    <module name="NestedTryDepth">\n      <property name="max" value="2"/>\n    </module>\n\n    \x3c!-- 返回个数 --\x3e\n    <module name="ReturnCount">\n      <property name="max" value="5"/>\n      <property name="format" value="^$"/>\n    </module>\n\n  </module>\n</module>\n\n\n配置 pom.xml：\n\n\n<project>\n    ...\n    <properties>\n        <checkstyle.config.location>config/maven_checks.xml</checkstyle.config.location>\n    </properties>\n    ...\n    <reporting>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-checkstyle-plugin</artifactId>\n                <version>3.0</version>\n                <executions>\n                    <execution>\n                        \x3c!-- 绑定pmd:pmd到validate生命周期，在validate时会自动进行代码规范检查 --\x3e\n                        <id>validate</id>\n                        <phase>validate</phase>\n                        <configuration>\n                            \x3c!-- 配置文件的路径，在style文件夹下 --\x3e\n                            <configLocation>style/checkstyle.xml</configLocation>\n                            <encoding>UTF-8</encoding>\n                            <consoleOutput>true</consoleOutput>\n                            <failsOnError>true</failsOnError>\n                            <includeTestSourceDirectory>false</includeTestSourceDirectory>\n                        </configuration>\n                        <goals>\n                            <goal>check</goal>\n                        </goals>\n                    </execution>\n                </executions>\n            </plugin>\n\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-jxr-plugin</artifactId>\n                <version>2.3</version>\n            </plugin>\n        </plugins>\n    </reporting>\n    ...\n</project>\n\n\n其中可以修改使用的检查规则文件路径，插件默认提供了四个规则文件可以直接使用，无需手动下载：\n\n * config/sun_checks.xml - Sun Microsystems Definition (default).\n * config/maven_checks.xml - Maven Development Definitions.\n * config/turbine_checks.xml - Turbine Development Definitions.\n * config/avalon_checks.xml - Avalon Development Definitions.\n\n配置好后，可以执行 mvn clean checkstyle:check 检查代码。\n\n\n# maven-pmd-plugin\n\n> maven-pmd-plugin 是阿里编程规范检查插件。\n\n配置 pom.xml：\n\n参考 https://github.com/alibaba/p3c/blob/master/p3c-pmd/pom.xml 配置\n\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-pmd-plugin</artifactId>\n        <version>3.11.0</version>\n        <configuration>\n          <sourceEncoding>${project.build.sourceEncoding}</sourceEncoding>\n          <targetJdk>${maven.compiler.target}</targetJdk>\n          <printFailingErrors>true</printFailingErrors>\n          <rulesets>\n            <ruleset>rulesets/java/ali-comment.xml</ruleset>\n            <ruleset>rulesets/java/ali-concurrent.xml</ruleset>\n            <ruleset>rulesets/java/ali-constant.xml</ruleset>\n            <ruleset>rulesets/java/ali-exception.xml</ruleset>\n            <ruleset>rulesets/java/ali-flowcontrol.xml</ruleset>\n            <ruleset>rulesets/java/ali-naming.xml</ruleset>\n            <ruleset>rulesets/java/ali-oop.xml</ruleset>\n            <ruleset>rulesets/java/ali-orm.xml</ruleset>\n            <ruleset>rulesets/java/ali-other.xml</ruleset>\n            <ruleset>rulesets/java/ali-set.xml</ruleset>\n          </rulesets>\n          <printFailingErrors>true</printFailingErrors>\n        </configuration>\n        <executions>\n          <execution>\n            <phase>verify</phase>\n            <goals>\n              <goal>check</goal>\n            </goals>\n          </execution>\n        </executions>\n        <dependencies>\n          <dependency>\n            <groupId>com.alibaba.p3c</groupId>\n            <artifactId>p3c-pmd</artifactId>\n            <version>2.0.0</version>\n          </dependency>\n        </dependencies>\n      </plugin>\n    </plugins>\n\n\n配置好后，可以执行 mvn clean pmd:check 检查代码。\n\n\n# 参考资料\n\n * https://maven.apache.org/plugins/maven-checkstyle-plugin/\n * https://maven.apache.org/jxr/maven-jxr-plugin/\n * https://www.jianshu.com/p/557b975ae40d\n * 阿里巴巴编程规范\n   * https://github.com/alibaba/p3c\n   * https://github.com/alibaba/p3c/blob/master/p3c-pmd/pom.xml',normalizedContent:'# maven 插件之代码检查\n\n\n# maven-checkstyle-plugin\n\n> maven-checkstyle-plugin，用于检测代码中不符合规范的地方。\n\n\n# 定义 checkstyle.xml\n\n<!doctype module public\n  "-//checkstyle//dtd checkstyle configuration 1.3//en"\n  "https://checkstyle.org/dtds/configuration_1_3.dtd">\n\n\x3c!-- generated by rhy @will_awoke --\x3e\n\n<module name="checker">\n\n  <property name="charset" value="utf-8"/>\n  <property name="severity" value="warning"/>\n\n  \x3c!-- checks for size violations.  --\x3e\n  \x3c!-- 检查文件的长度（行） default max=2000 --\x3e\n  <module name="filelength">\n    <property name="max" value="2500"/>\n  </module>\n\n  \x3c!-- checks that property files contain the same keys. --\x3e\n  \x3c!-- 检查**.properties配置文件 是否有相同的key\n  <module name="translation">\n  </module>\n  --\x3e\n\n  <module name="treewalker">\n\n    \x3c!-- checks for imports    --\x3e\n    \x3c!-- 必须导入类的完整路径，即不能使用*导入所需的类 --\x3e\n    <module name="avoidstarimport"/>\n\n    \x3c!-- 检查是否从非法的包中导入了类 illegalpkgs: 定义非法的包名称--\x3e\n    <module name="illegalimport"/> \x3c!-- defaults to sun.* packages --\x3e\n\n    \x3c!-- 检查是否导入了不必显示导入的类--\x3e\n    <module name="redundantimport"/>\n\n    \x3c!-- 检查是否导入的包没有使用--\x3e\n    <module name="unusedimports"/>\n\n    \x3c!-- checks for whitespace\n    <module name="emptyforiteratorpad"/>\n    <module name="methodparampad"/>\n    <module name="nowhitespaceafter"/>\n    <module name="nowhitespacebefore"/>\n    <module name="operatorwrap"/>\n    <module name="parenpad"/>\n    <module name="typecastparenpad"/>\n    <module name="whitespaceafter"/>\n    <module name="whitespacearound"/>\n    --\x3e\n\n    \x3c!-- 检查类和接口的javadoc 默认不检查author 和version tags\n      authorformat: 检查author标签的格式\n            versionformat: 检查version标签的格式\n            scope: 可以检查的类的范围，例如：public只能检查public修饰的类，private可以检查所有的类\n            excludescope: 不能检查的类的范围，例如：public，public的类将不被检查，但访问权限小于public的类仍然会检查，其他的权限以此类推\n            tokens: 该属性适用的类型，例如：class_def,interface_def --\x3e\n    <module name="javadoctype">\n      <property name="authorformat" value="\\s"/>\n      <property name="scope" value="protected"/>\n      <property name="tokens" value="class_def,interface_def"/>\n    </module>\n\n    \x3c!-- 检查方法的javadoc的注释\n            scope: 可以检查的方法的范围，例如：public只能检查public修饰的方法，private可以检查所有的方法\n            allowmissingparamtags: 是否忽略对参数注释的检查\n            allowmissingthrowstags: 是否忽略对throws注释的检查\n            allowmissingreturntag: 是否忽略对return注释的检查 --\x3e\n    <module name="javadocmethod">\n      <property name="scope" value="private"/>\n      <property name="allowmissingparamtags" value="false"/>\n      <property name="allowmissingthrowstags" value="false"/>\n      <property name="allowmissingreturntag" value="false"/>\n      <property name="tokens" value="method_def"/>\n      <property name="allowundeclaredrte" value="true"/>\n      <property name="allowthrowstagsforsubclasses" value="true"/>\n      \x3c!--允许get set 方法没有注释--\x3e\n      <property name="allowmissingpropertyjavadoc" value="true"/>\n    </module>\n\n    \x3c!-- 检查类变量的注释\n            scope: 检查变量的范围，例如：public只能检查public修饰的变量，private可以检查所有的变量 --\x3e\n    <module name="javadocvariable">\n      <property name="scope" value="private"/>\n    </module>\n\n    \x3c!--option: 定义左大括号\'{\'显示位置，eol在同一行显示，nl在下一行显示\n      maxlinelength: 大括号\'{\'所在行行最多容纳的字符数\n      tokens: 该属性适用的类型，例：class_def,interface_def,method_def,ctor_def --\x3e\n    <module name="leftcurly">\n      <property name="option" value="nl"/>\n    </module>\n\n    \x3c!-- needbraces 检查是否应该使用括号的地方没有加括号\n      tokens: 定义检查的类型 --\x3e\n    <module name="needbraces"/>\n\n    \x3c!-- checks the placement of right curly braces (\'}\') for  else, try, and catch tokens. the policy to verify is specified using property  option.\n      option: 右大括号是否单独一行显示\n      tokens: 定义检查的类型  --\x3e\n    <module name="rightcurly">\n      <property name="option" value="alone"/>\n    </module>\n\n    \x3c!-- 检查在重写了equals方法后是否重写了hashcode方法 --\x3e\n    <module name="equalshashcode"/>\n\n    \x3c!--  checks for illegal instantiations where a factory method is preferred.\n      rationale: depending on the project, for some classes it might be preferable to create instances through factory methods rather than calling the constructor.\n      a simple example is the java.lang.boolean class. in order to save memory and cpu cycles, it is preferable to use the predefined constants true and false. constructor invocations should be replaced by calls to boolean.valueof().\n      some extremely performance sensitive projects may require the use of factory methods for other classes as well, to enforce the usage of number caches or object pools. --\x3e\n    <module name="illegalinstantiation">\n      <property name="classes" value="java.lang.boolean"/>\n    </module>\n\n    \x3c!-- checks for naming conventions.   命名规范   --\x3e\n    \x3c!-- local, final variables, including catch parameters --\x3e\n    <module name="localfinalvariablename"/>\n\n    \x3c!-- local, non-final variables, including catch parameters--\x3e\n    <module name="localvariablename"/>\n\n    \x3c!-- static, non-final fields --\x3e\n    <module name="staticvariablename">\n      <property name="format" value="(^[a-z0-9_]{0,19}$)"/>\n    </module>\n\n    \x3c!-- packages --\x3e\n    <module name="packagename">\n      <property name="format" value="^[a-z]+(\\.[a-z][a-z0-9]*)*$"/>\n    </module>\n\n    \x3c!-- classes and interfaces --\x3e\n    <module name="typename">\n      <property name="format" value="(^[a-z][a-za-z0-9]{0,19}$)"/>\n    </module>\n\n    \x3c!-- methods --\x3e\n    <module name="methodname">\n      <property name="format" value="(^[a-z][a-za-z0-9]{0,19}$)"/>\n    </module>\n\n    \x3c!-- non-static fields --\x3e\n    <module name="membername">\n      <property name="format" value="(^[a-z][a-z0-9][a-za-z0-9]{0,19}$)"/>\n    </module>\n\n    \x3c!-- parameters --\x3e\n    <module name="parametername">\n      <property name="format" value="(^[a-z][a-za-z0-9_]{0,19}$)"/>\n    </module>\n\n    \x3c!-- constants (static,  final fields) --\x3e\n    <module name="constantname">\n      <property name="format" value="(^[a-z0-9_]{0,19}$)"/>\n    </module>\n\n    \x3c!-- 代码缩进   --\x3e\n    <module name="indentation">\n    </module>\n\n    \x3c!-- checks for redundant exceptions declared in throws clause such as duplicates, unchecked exceptions or subclasses of another declared exception.\n      检查是否抛出了多余的异常\n    <module name="redundantthrows">\n        <property name="logloaderrors" value="true"/>\n        <property name="suppressloaderrors" value="true"/>\n    </module>\n    --\x3e\n\n    \x3c!--  checks for overly complicated boolean expressions. currently finds code like  if (b == true), b || true, !false, etc.\n      检查boolean值是否冗余的地方\n      rationale: complex boolean logic makes code hard to understand and maintain. --\x3e\n    <module name="simplifybooleanexpression"/>\n\n    \x3c!--  checks for overly complicated boolean return statements. for example the following code\n       检查是否存在过度复杂的boolean返回值\n       if (valid())\n          return false;\n       else\n          return true;\n       could be written as\n          return !valid();\n       the idea for this check has been shamelessly stolen from the equivalent pmd rule. --\x3e\n    <module name="simplifybooleanreturn"/>\n\n    \x3c!-- checks that a class which has only private constructors is declared as final.只有私有构造器的类必须声明为final--\x3e\n    <module name="finalclass"/>\n\n    \x3c!--  make sure that utility classes (classes that contain only static methods or fields in their api) do not have a public constructor.\n      确保utils类（只提供static方法和属性的类）没有public构造器。\n      rationale: instantiating utility classes does not make sense. hence the constructors should either be private or (if you want to allow subclassing) protected. a common mistake is forgetting to hide the default constructor.\n      if you make the constructor protected you may want to consider the following constructor implementation technique to disallow instantiating subclasses:\n      public class stringutils // not final to allow subclassing\n      {\n          protected stringutils() {\n              throw new unsupportedoperationexception(); // prevents calls from subclass\n          }\n          public static int count(char c, string s) {\n              // ...\n          }\n      }\n   <module name="hideutilityclassconstructor"/>\n   --\x3e\n\n    \x3c!--  checks visibility of class members. only static final members may be public; other class members must be private unless property protectedallowed or packageallowed is set.\n      检查class成员属性可见性。只有static final 修饰的成员是可以public的。其他的成员属性必需是private的，除非属性protectedallowed或者packageallowed设置了true.\n       public members are not flagged if the name matches the public member regular expression (contains "^serialversionuid$" by default). note: checkstyle 2 used to include "^f[a-z][a-za-z0-9]*$" in the default pattern to allow cmp for ejb 1.1 with the default settings. with ejb 2.0 it is not longer necessary to have public access for persistent fields, hence the default has been changed.\n       rationale: enforce encapsulation. 强制封装 --\x3e\n    <module name="visibilitymodifier"/>\n\n    \x3c!-- 每一行只能定义一个变量 --\x3e\n    <module name="multiplevariabledeclarations">\n    </module>\n\n    \x3c!-- checks the style of array type definitions. some like java-style: public static void main(string[] args) and some like c-style: public static void main(string args[])\n      检查再定义数组时，采用java风格还是c风格，例如：int[] num是java风格，int num[]是c风格。默认是java风格--\x3e\n    <module name="arraytypestyle">\n    </module>\n\n    \x3c!-- checks that there are no "magic numbers", where a magic number is a numeric literal that is not defined as a constant. by default, -1, 0, 1, and 2 are not considered to be magic numbers.\n    <module name="magicnumber">\n    </module>\n    --\x3e\n\n    \x3c!-- a check for todo: comments. actually it is a generic regular expression matcher on java comments. to check for other patterns in java comments, set property format.\n       检查是否存在todo（待处理） todo是javaide自动生成的。一般代码写完后要去掉。\n     --\x3e\n    <module name="todocomment"/>\n\n    \x3c!--  checks that long constants are defined with an upper ell. that is \' l\' and not \'l\'. this is in accordance to the java language specification,  section 3.10.1.\n      检查是否在long类型是否定义了大写的l.字母小写l和数字1（一）很相似。\n      looks a lot like 1. --\x3e\n    <module name="upperell"/>\n\n    \x3c!--  checks that switch statement has "default" clause. 检查switch语句是否有‘default’从句\n       rationale: it\'s usually a good idea to introduce a default case in every switch statement.\n       even if the developer is sure that all currently possible cases are covered, this should be expressed in the default branch,\n        e.g. by using an assertion. this way the code is protected aginst later changes, e.g. introduction of new types in an enumeration type. --\x3e\n    <module name="missingswitchdefault"/>\n\n    \x3c!--检查switch中case后是否加入了跳出语句，例如：return、break、throw、continue --\x3e\n    <module name="fallthrough"/>\n\n    \x3c!-- checks the number of parameters of a method or constructor. max default 7个. --\x3e\n    <module name="parameternumber">\n      <property name="max" value="5"/>\n    </module>\n\n    \x3c!-- 每行字符数 --\x3e\n    <module name="linelength">\n      <property name="max" value="200"/>\n    </module>\n\n    \x3c!-- checks for long methods and constructors. max default 150行. max=300 设置长度300 --\x3e\n    <module name="methodlength">\n      <property name="max" value="300"/>\n    </module>\n\n    \x3c!-- modifierorder 检查修饰符的顺序，默认是 public,protected,private,abstract,static,final,transient,volatile,synchronized,native --\x3e\n    <module name="modifierorder">\n    </module>\n\n    \x3c!-- 检查是否有多余的修饰符，例如：接口中的方法不必使用public、abstract修饰  --\x3e\n    <module name="redundantmodifier">\n    </module>\n\n    \x3c!--- 字符串比较必须使用 equals() --\x3e\n    <module name="stringliteralequality">\n    </module>\n\n    \x3c!-- if-else嵌套语句个数 最多4层 --\x3e\n    <module name="nestedifdepth">\n      <property name="max" value="3"/>\n    </module>\n\n    \x3c!-- try-catch 嵌套语句个数 最多2层 --\x3e\n    <module name="nestedtrydepth">\n      <property name="max" value="2"/>\n    </module>\n\n    \x3c!-- 返回个数 --\x3e\n    <module name="returncount">\n      <property name="max" value="5"/>\n      <property name="format" value="^$"/>\n    </module>\n\n  </module>\n</module>\n\n\n配置 pom.xml：\n\n\n<project>\n    ...\n    <properties>\n        <checkstyle.config.location>config/maven_checks.xml</checkstyle.config.location>\n    </properties>\n    ...\n    <reporting>\n        <plugins>\n            <plugin>\n                <groupid>org.apache.maven.plugins</groupid>\n                <artifactid>maven-checkstyle-plugin</artifactid>\n                <version>3.0</version>\n                <executions>\n                    <execution>\n                        \x3c!-- 绑定pmd:pmd到validate生命周期，在validate时会自动进行代码规范检查 --\x3e\n                        <id>validate</id>\n                        <phase>validate</phase>\n                        <configuration>\n                            \x3c!-- 配置文件的路径，在style文件夹下 --\x3e\n                            <configlocation>style/checkstyle.xml</configlocation>\n                            <encoding>utf-8</encoding>\n                            <consoleoutput>true</consoleoutput>\n                            <failsonerror>true</failsonerror>\n                            <includetestsourcedirectory>false</includetestsourcedirectory>\n                        </configuration>\n                        <goals>\n                            <goal>check</goal>\n                        </goals>\n                    </execution>\n                </executions>\n            </plugin>\n\n            <plugin>\n                <groupid>org.apache.maven.plugins</groupid>\n                <artifactid>maven-jxr-plugin</artifactid>\n                <version>2.3</version>\n            </plugin>\n        </plugins>\n    </reporting>\n    ...\n</project>\n\n\n其中可以修改使用的检查规则文件路径，插件默认提供了四个规则文件可以直接使用，无需手动下载：\n\n * config/sun_checks.xml - sun microsystems definition (default).\n * config/maven_checks.xml - maven development definitions.\n * config/turbine_checks.xml - turbine development definitions.\n * config/avalon_checks.xml - avalon development definitions.\n\n配置好后，可以执行 mvn clean checkstyle:check 检查代码。\n\n\n# maven-pmd-plugin\n\n> maven-pmd-plugin 是阿里编程规范检查插件。\n\n配置 pom.xml：\n\n参考 https://github.com/alibaba/p3c/blob/master/p3c-pmd/pom.xml 配置\n\n      <plugin>\n        <groupid>org.apache.maven.plugins</groupid>\n        <artifactid>maven-pmd-plugin</artifactid>\n        <version>3.11.0</version>\n        <configuration>\n          <sourceencoding>${project.build.sourceencoding}</sourceencoding>\n          <targetjdk>${maven.compiler.target}</targetjdk>\n          <printfailingerrors>true</printfailingerrors>\n          <rulesets>\n            <ruleset>rulesets/java/ali-comment.xml</ruleset>\n            <ruleset>rulesets/java/ali-concurrent.xml</ruleset>\n            <ruleset>rulesets/java/ali-constant.xml</ruleset>\n            <ruleset>rulesets/java/ali-exception.xml</ruleset>\n            <ruleset>rulesets/java/ali-flowcontrol.xml</ruleset>\n            <ruleset>rulesets/java/ali-naming.xml</ruleset>\n            <ruleset>rulesets/java/ali-oop.xml</ruleset>\n            <ruleset>rulesets/java/ali-orm.xml</ruleset>\n            <ruleset>rulesets/java/ali-other.xml</ruleset>\n            <ruleset>rulesets/java/ali-set.xml</ruleset>\n          </rulesets>\n          <printfailingerrors>true</printfailingerrors>\n        </configuration>\n        <executions>\n          <execution>\n            <phase>verify</phase>\n            <goals>\n              <goal>check</goal>\n            </goals>\n          </execution>\n        </executions>\n        <dependencies>\n          <dependency>\n            <groupid>com.alibaba.p3c</groupid>\n            <artifactid>p3c-pmd</artifactid>\n            <version>2.0.0</version>\n          </dependency>\n        </dependencies>\n      </plugin>\n    </plugins>\n\n\n配置好后，可以执行 mvn clean pmd:check 检查代码。\n\n\n# 参考资料\n\n * https://maven.apache.org/plugins/maven-checkstyle-plugin/\n * https://maven.apache.org/jxr/maven-jxr-plugin/\n * https://www.jianshu.com/p/557b975ae40d\n * 阿里巴巴编程规范\n   * https://github.com/alibaba/p3c\n   * https://github.com/alibaba/p3c/blob/master/p3c-pmd/pom.xml',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Maven 教程",frontmatter:{title:"Maven 教程",categories:["编程","Java","软件","构建"],tags:["Java","构建","Maven"],hidden:!0,abbrlink:"a96d715",date:"2020-08-04T15:20:54.000Z",permalink:"/pages/14735b/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/01.%E6%9E%84%E5%BB%BA/01.Maven/",relativePath:"11.软件/01.构建/01.Maven/README.md",key:"v-6589cc90",path:"/pages/14735b/",headers:[{level:2,title:"📖 内容",slug:"📖-内容",normalizedTitle:"📖 内容",charIndex:437},{level:2,title:"📚 资料",slug:"📚-资料",normalizedTitle:"📚 资料",charIndex:579},{level:2,title:"🚪 传送",slug:"🚪-传送",normalizedTitle:"🚪 传送",charIndex:652}],headersStr:"📖 内容 📚 资料 🚪 传送",content:"# Maven 教程\n\n> Maven 是一个项目管理工具。它负责管理项目开发过程中的几乎所有的东西。\n> \n>  * 版本 - maven 有自己的版本定义和规则。\n>  * 构建 - maven 支持许多种的应用程序类型，对于每一种支持的应用程序类型都定义好了一组构建规则和工具集。\n>  * 输出物管理 - maven 可以管理项目构建的产物，并将其加入到用户库中。这个功能可以用于项目组和其他部门之间的交付行为。\n>  * 依赖关系 - maven 对依赖关系的特性进行细致的分析和划分，避免开发过程中的依赖混乱和相互污染行为\n>  * 文档和构建结果 - maven 的 site 命令支持各种文档信息的发布，包括构建过程的各种输出，javadoc，产品文档等。\n>  * 项目关系 - 一个大型的项目通常有几个小项目或者模块组成，用 maven 可以很方便地管理。\n>  * 移植性管理 - maven 可以针对不同的开发场景，输出不同种类的输出结果。\n\n\n# 📖 内容\n\n * Maven 快速入门\n * Maven 教程之 pom.xml 详解\n * Maven 教程之 settings.xml 详解\n * Maven 实战问题和最佳实践\n * Maven 教程之发布 jar 到私服或中央仓库\n * Maven 插件之代码检查\n\n\n# 📚 资料\n\n * 官网\n   * Maven Github\n   * Maven 官方文档\n * 书籍\n   * 《Maven 实战》\n\n\n# 🚪 传送\n\n◾ 🏠 JAVA-TUTORIAL 首页 ◾ 🎯 我的博客 ◾",normalizedContent:"# maven 教程\n\n> maven 是一个项目管理工具。它负责管理项目开发过程中的几乎所有的东西。\n> \n>  * 版本 - maven 有自己的版本定义和规则。\n>  * 构建 - maven 支持许多种的应用程序类型，对于每一种支持的应用程序类型都定义好了一组构建规则和工具集。\n>  * 输出物管理 - maven 可以管理项目构建的产物，并将其加入到用户库中。这个功能可以用于项目组和其他部门之间的交付行为。\n>  * 依赖关系 - maven 对依赖关系的特性进行细致的分析和划分，避免开发过程中的依赖混乱和相互污染行为\n>  * 文档和构建结果 - maven 的 site 命令支持各种文档信息的发布，包括构建过程的各种输出，javadoc，产品文档等。\n>  * 项目关系 - 一个大型的项目通常有几个小项目或者模块组成，用 maven 可以很方便地管理。\n>  * 移植性管理 - maven 可以针对不同的开发场景，输出不同种类的输出结果。\n\n\n# 📖 内容\n\n * maven 快速入门\n * maven 教程之 pom.xml 详解\n * maven 教程之 settings.xml 详解\n * maven 实战问题和最佳实践\n * maven 教程之发布 jar 到私服或中央仓库\n * maven 插件之代码检查\n\n\n# 📚 资料\n\n * 官网\n   * maven github\n   * maven 官方文档\n * 书籍\n   * 《maven 实战》\n\n\n# 🚪 传送\n\n◾ 🏠 java-tutorial 首页 ◾ 🎯 我的博客 ◾",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Ant 简易教程",frontmatter:{title:"Ant 简易教程",categories:["编程","Java","软件","构建"],tags:["Java","构建","Ant"],abbrlink:"389d1b12",date:"2017-12-06T09:46:28.000Z",permalink:"/pages/e2af3a/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/01.%E6%9E%84%E5%BB%BA/02.Ant.html",relativePath:"11.软件/01.构建/02.Ant.md",key:"v-cba3920e",path:"/pages/e2af3a/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:15},{level:2,title:"下载和安装",slug:"下载和安装",normalizedTitle:"下载和安装",charIndex:139},{level:3,title:"下载",slug:"下载",normalizedTitle:"下载",charIndex:139},{level:3,title:"配置环境变量",slug:"配置环境变量",normalizedTitle:"配置环境变量",charIndex:261},{level:3,title:"验证",slug:"验证",normalizedTitle:"验证",charIndex:429},{level:2,title:"例子",slug:"例子",normalizedTitle:"例子",charIndex:758},{level:2,title:"关键元素",slug:"关键元素",normalizedTitle:"关键元素",charIndex:2625},{level:3,title:"Project 元素",slug:"project-元素",normalizedTitle:"project 元素",charIndex:2716},{level:3,title:"Target 元素",slug:"target-元素",normalizedTitle:"target 元素",charIndex:3109},{level:3,title:"Task 元素",slug:"task-元素",normalizedTitle:"task 元素",charIndex:4413},{level:3,title:"Property 元素",slug:"property-元素",normalizedTitle:"property 元素",charIndex:6322},{level:3,title:"extension-point 元素",slug:"extension-point-元素",normalizedTitle:"extension-point 元素",charIndex:3776},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:6875}],headersStr:"简介 下载和安装 下载 配置环境变量 验证 例子 关键元素 Project 元素 Target 元素 Task 元素 Property 元素 extension-point 元素 参考资料",content:'# Ant 简易教程\n\n\n# 简介\n\nApache Ant 是一个将软件编译、测试、部署等步骤联系在一起加以自动化的一个工具，大多用于 Java 环境中的软件开发。由 Apache 软件基金会所提供。\n\nAnt 是纯 Java 语言编写的，所以具有很好的跨平台性。\n\n\n\n\n# 下载和安装\n\n\n# 下载\n\nant 的官方下载地址：http://ant.apache.org/bindownload.cgi\n\n进入页面后，在下图的红色方框中可以下载最新版本。笔者下载的版本是 apache-ant-1.9.4。\n\n\n\n\n# 配置环境变量\n\n配置环境变量（我的电脑 -> 属性 -> 高级 -> 环境变量）。\n\n设置 ant 环境变量：\n\nANT_HOME C:/ apache-ant-1.9.4\n\n\n\n**path ** C:/ apache-ant-1.9.4/bin\n\n\n\nclasspath C:/apache-ant-1.9.4/lib\n\n\n\n\n# 验证\n\n点击 开始 -> 运行 -> 输入 cmd\n\n执行构建文件\n\n输入如下命令：ant\n\n如果出现如下内容，说明安装成功：\n\n> Buildfile: build.xml does not exist! Build failed\n\n注意：因为 ant 默认运行 build.xml 文件，这个文件需要我们创建。\n\n如果不想命名为 build.xml，运行时可以使用 ant -buildfile test.xml 命令指明要运行的构建文件。\n\n查看版本信息\n\n输入 ant -version，可以查看版本信息。\n\n\n\n但如果出现 \'ant\' 不是内部或外部命令，也不是可运行的程序或批处理文件，说明安装失败：（可以重复前述步骤，直至安装成功。）\n\n\n# 例子\n\n在安装和配置成功后，我们就可以使用 ant 了。\n\n为了让读者对 ant 有一个直观的认识，首先以 Ant 官方手册上的一个简单例子做一个说明。\n\n以下是一个 build.xml 文件的内容：\n\n<project name="MyProject" default="dist" basedir=".">\n    <description>\n        simple example build file\n    </description>\n  \x3c!-- set global properties for this build --\x3e\n  <property name="src" location="src"/>\n  <property name="build" location="build"/>\n  <property name="dist"  location="dist"/>\n\n  <target name="init">\n    \x3c!-- Create the time stamp --\x3e\n    <tstamp/>\n    \x3c!-- Create the build directory structure used by compile --\x3e\n    <mkdir dir="${build}"/>\n  </target>\n\n  <target name="compile" depends="init"\n        description="compile the source " >\n    \x3c!-- Compile the java code from ${src} into ${build} --\x3e\n    <javac srcdir="${src}" destdir="${build}"/>\n  </target>\n\n  <target name="dist" depends="compile"\n        description="generate the distribution" >\n    \x3c!-- Create the distribution directory --\x3e\n    <mkdir dir="${dist}/lib"/>\n\n    \x3c!-- Put everything in ${build} into the MyProject-${DSTAMP}.jar file --\x3e\n    <jar jarfile="${dist}/lib/MyProject-${DSTAMP}.jar" basedir="${build}"/>\n  </target>\n\n  <target name="clean"\n        description="clean up" >\n    \x3c!-- Delete the ${build} and ${dist} directory trees --\x3e\n    <delete dir="${build}"/>\n    <delete dir="${dist}"/>\n  </target>\n</project>\n\n\n在这个 xml 文件中，有几个 target 标签，每个 target 对应一个执行目标。\n\n我们将这个 build.xml 放在 D:\\Temp\\ant_test 路径下，然后在 dos 界面下进行测试。\n\nant init\n\n\n\n在 D:\\Temp\\ant_test 路径下创建了一个 build 目录，执行成功。\n\nant compile\n\n\n\n提示错误，原来是在 build.xml 的所在目录下找不到 src 目录。好的，我们直接创建一个 src 目录，然后再次尝试。这次，执行成功。\n\n\n\n**ant dist **\n\n\n\n在 D:\\Temp\\ant_test 路径下创建了一个 dist 目录，执行成功。\n\nant clean\n\n\n\n清除创建的 build 和 dist 目录，执行成功。\n\n一个细节\n\n细心的读者，想必已经发现一个问题——在执行 ant compile 和 ant dist 命令的时候把前面的命令也执行了。这是为什么呢？\n\n请留意一下 build.xml 中的内容。有部分 target 标签中含有 depends 关键字。\n\n\n\n这表明，当前的 target 在执行时需要依赖其他的 target，必须先执行依赖的 target，然后再执行。\n\n\n# 关键元素\n\nAnt 的构件文件都是 XML 格式的。每个构件文件包含一个 project 元素和至少一个 target。\n\ntarget 元素可以包含多个 task 元素。\n\n\n# Project 元素\n\nproject 元素是构建文件的根元素。\n\n一个 project 元素可以有多个 target 元素，一个 target 元素可以有多个 task。\n\n在上节的例子中，project 标签里有三个属性。\n\n<project name="MyProject" default="dist" basedir=".">\n\n\nname 属性，指示 project 元素的名字。例子中的名字就是 MyProject。\n\ndefault 属性，指示这个 project 默认执行的 target。在本文的例子中，默认执行的 target 为 dist。\n\n如果我们输入命令 ant 时，不指定 target 参数，默认会执行 dist 这个 target。\n\nbasedir 属性，指定根路径的位置。该属性没有指定时，使用 Ant 的构件文件的所在目录作为根目录。\n\n\n# Target 元素\n\ntarget 元素是 task 的容器，也就是 Ant 的一个基本执行单元。\n\n以上节例子中的 compile 来举例。\n\n<target name="compile" depends="init" description="compile the source " >\n    \x3c!-- Compile the java code from ${src} into ${build} --\x3e\n    <javac srcdir="${src}" destdir="${build}"/>\n</target>\n\n\n这个 target 中出现了几个属性。\n\nname 属性，指示 target 元素的名称。\n\n这个属性在一个 project 元素中必须是唯一的。这很好理解，如果出现重复，Ant 就不知道具体该执行哪个 target 了。\n\ndepends 属性，指示依赖的 target，当前的 target 必须在依赖的 target 之后执行。\n\ndescription 属性，是关于 target 的简短说明。\n\n此外，还有其他几个未出现在构建文件中的属性。\n\nif 属性，验证指定的属性是否存在，若不存在，所在 target 将不会被执行。\n\nunless 属性，正好和 if 属性相反，验证指定的属性是否存在，若存在，所在 target 将不会被执行。****\n\nextensionOf 属性，添加当前 target 到 extension-point 依赖列表。——Ant1.8.0 新特性。\n\n> extension-point 元素和 target 元素十分类似，都可以指定依赖的 target。但是不同的是，extension-point 中不能包含任何 task。\n\n请看以下实例：\n\n<target name="create-directory-layout">\n   ...\n</target>\n<extension-point name="ready-to-compile" depends="create-directory-layout"/>\n<target name="compile" depends="ready-to-compile">\n   ...\n</target>\n\n\n调用 target 顺序: create-directory-layout --\x3e \'empty slot\' --\x3e compile\n\n<target name="generate-sources" extensionOf="ready-to-compile">\n   ...\n</target>\n\n\n调用 target 顺序: create-directory-layout --\x3e generate-sources --\x3e compile\n\nonMissingExtensionPoint 属性：当无法找到一个 extension-point 时，target 尝试去做的动作("fail", "warn", "ignore")。——Ant1.8.2 新特性\n\n\n# Task 元素\n\ntask 是一段可以被执行的代码。\n\n一个 task 可以有多个属性， 一个属性可以包含对一个 property 的引用。\n\ntask 的通常结构为\n\n<name attribute1="value1" attribute2="value2" ... />\n\n\n其中，name 是 task 的名字， attributeN 是属性名， valueN 是这个属性的值。\n\n还是以 compile 做为例子：\n\n<target name="compile" depends="init" description="compile the source " >\n    \x3c!-- Compile the java code from srcintosrcinto{build} --\x3e\n    <javac srcdir="${src}" destdir="${build}"/>\n</target>\n\n\n在 compile 这个 target 标签中包含了一个任务。\n\n这个任务的动作是：执行 JAVA 编译，编译 src 下的代码，并把编译生成的文件放在 build 目录中。\n\n**常用 task **\n\njavac：用于编译一个或者多个 Java 源文件，通常需要 srcdir 和 destdir 两个属性，用于指定 Java 源文件的位置和编译后 class 文件的保存位置。\n\n<javac srcdir="${src}" destdir="${build}" classpath="abc.jar" debug="on" source="1.7" />\n\n\njava：用于运行某个 Java 类，通常需要 classname 属性，用于指定需要运行哪个类。\n\n<java classname="test.Main">\n    <arg value="-h" />\n    <classpath>\n        <pathelement location="dist/test.jar" />\n    </classpath>\n</java>\n\n\njar：用于生成 JAR 包，通常需要指定 destfile 属性，用于指定所创建 JAR 包的文件名。除此之外，通常还应指定一个文件集，表明需要将哪些文件打包到 JAR 包里。\n\n<jar jarfile="dist/lib/MyProject−dist/lib/MyProject−{DSTAMP}.jar" basedir="${build}"/>\n\n\necho：输出某个字符串。\n\n<echo message="Building to ${builddir}"/>\n<echo>You are using version ${java.version} of Java! This message spans two lines.</echo>\n\n\ncopy：用于复制文件或路径。\n\n<copy todir="${builddir}/srccopy">\n    <fileset dir="${srcdir}">\n        <include name="**/*.java"/>\n    </fileset>\n    <filterset>\n        <filter token="VERSION" value="${app.version}"/>\n    </filterset>\n</copy>\n\n\ndelete：用于删除文件或路径。\n\n<copy todir="${builddir}/srccopy">\n    <fileset dir="${srcdir}">\n        <include name="**/*.java"/>\n    </fileset>\n    <filterset>\n        <filter token="VERSION" value="${app.version}"/>\n    </filterset>\n</copy>\n\n\nmkdir：用于创建文件夹。\n\n<mkdir dir="${dist}/lib" />\n\n\nmove：用户移动文件和路径。\n\n<move todir="some/new/dir">\n    <fileset dir="my/src/dir">\n        <include name="**/*.jar" />\n        <exclude name="**/ant.jar" />\n    </fileset>\n</move>\n\n\n\n# Property 元素\n\nProperty 是对参数的定义。\n\nproject 的属性可以通过 property 元素来设定，也可在 Ant 之外设定。若要在外部引入某文件，例如 build.properties 文件，可以通过如下内容将其引入：<property file=” build.properties”/>。\n\nproperty 元素可用作 task 的属性值。在 task 中是通过将属性名放在“${”和“}”之间，并放在 task 属性值的位置来实现的。\n\n例如 complile 例子中，使用了前面定义的 src 作为源目录。\n\n<javac srcdir="${src}" destdir="${build}"/>\n\n\nAnt 提供了一些内置的属性，它能得到的系统属性的列表与 Java 文档中 System.getPropertis()方法得到的属性一致，这些系统属性可参考 sun 网站的说明。\n\n\n# extension-point 元素\n\n和 target 元素十分类似，都可以指定依赖的 target。但是不同的是，extension-point 中不能包含任何 task。\n\n——Ant1.8.0 新增特性。\n\n在 target 元素中的例子里已提到过，不再赘述。\n\n\n# 参考资料\n\n * ant 官方手册\n * http://www.blogjava.net/amigoxie/archive/2007/11/09/159413.html',normalizedContent:'# ant 简易教程\n\n\n# 简介\n\napache ant 是一个将软件编译、测试、部署等步骤联系在一起加以自动化的一个工具，大多用于 java 环境中的软件开发。由 apache 软件基金会所提供。\n\nant 是纯 java 语言编写的，所以具有很好的跨平台性。\n\n\n\n\n# 下载和安装\n\n\n# 下载\n\nant 的官方下载地址：http://ant.apache.org/bindownload.cgi\n\n进入页面后，在下图的红色方框中可以下载最新版本。笔者下载的版本是 apache-ant-1.9.4。\n\n\n\n\n# 配置环境变量\n\n配置环境变量（我的电脑 -> 属性 -> 高级 -> 环境变量）。\n\n设置 ant 环境变量：\n\nant_home c:/ apache-ant-1.9.4\n\n\n\n**path ** c:/ apache-ant-1.9.4/bin\n\n\n\nclasspath c:/apache-ant-1.9.4/lib\n\n\n\n\n# 验证\n\n点击 开始 -> 运行 -> 输入 cmd\n\n执行构建文件\n\n输入如下命令：ant\n\n如果出现如下内容，说明安装成功：\n\n> buildfile: build.xml does not exist! build failed\n\n注意：因为 ant 默认运行 build.xml 文件，这个文件需要我们创建。\n\n如果不想命名为 build.xml，运行时可以使用 ant -buildfile test.xml 命令指明要运行的构建文件。\n\n查看版本信息\n\n输入 ant -version，可以查看版本信息。\n\n\n\n但如果出现 \'ant\' 不是内部或外部命令，也不是可运行的程序或批处理文件，说明安装失败：（可以重复前述步骤，直至安装成功。）\n\n\n# 例子\n\n在安装和配置成功后，我们就可以使用 ant 了。\n\n为了让读者对 ant 有一个直观的认识，首先以 ant 官方手册上的一个简单例子做一个说明。\n\n以下是一个 build.xml 文件的内容：\n\n<project name="myproject" default="dist" basedir=".">\n    <description>\n        simple example build file\n    </description>\n  \x3c!-- set global properties for this build --\x3e\n  <property name="src" location="src"/>\n  <property name="build" location="build"/>\n  <property name="dist"  location="dist"/>\n\n  <target name="init">\n    \x3c!-- create the time stamp --\x3e\n    <tstamp/>\n    \x3c!-- create the build directory structure used by compile --\x3e\n    <mkdir dir="${build}"/>\n  </target>\n\n  <target name="compile" depends="init"\n        description="compile the source " >\n    \x3c!-- compile the java code from ${src} into ${build} --\x3e\n    <javac srcdir="${src}" destdir="${build}"/>\n  </target>\n\n  <target name="dist" depends="compile"\n        description="generate the distribution" >\n    \x3c!-- create the distribution directory --\x3e\n    <mkdir dir="${dist}/lib"/>\n\n    \x3c!-- put everything in ${build} into the myproject-${dstamp}.jar file --\x3e\n    <jar jarfile="${dist}/lib/myproject-${dstamp}.jar" basedir="${build}"/>\n  </target>\n\n  <target name="clean"\n        description="clean up" >\n    \x3c!-- delete the ${build} and ${dist} directory trees --\x3e\n    <delete dir="${build}"/>\n    <delete dir="${dist}"/>\n  </target>\n</project>\n\n\n在这个 xml 文件中，有几个 target 标签，每个 target 对应一个执行目标。\n\n我们将这个 build.xml 放在 d:\\temp\\ant_test 路径下，然后在 dos 界面下进行测试。\n\nant init\n\n\n\n在 d:\\temp\\ant_test 路径下创建了一个 build 目录，执行成功。\n\nant compile\n\n\n\n提示错误，原来是在 build.xml 的所在目录下找不到 src 目录。好的，我们直接创建一个 src 目录，然后再次尝试。这次，执行成功。\n\n\n\n**ant dist **\n\n\n\n在 d:\\temp\\ant_test 路径下创建了一个 dist 目录，执行成功。\n\nant clean\n\n\n\n清除创建的 build 和 dist 目录，执行成功。\n\n一个细节\n\n细心的读者，想必已经发现一个问题——在执行 ant compile 和 ant dist 命令的时候把前面的命令也执行了。这是为什么呢？\n\n请留意一下 build.xml 中的内容。有部分 target 标签中含有 depends 关键字。\n\n\n\n这表明，当前的 target 在执行时需要依赖其他的 target，必须先执行依赖的 target，然后再执行。\n\n\n# 关键元素\n\nant 的构件文件都是 xml 格式的。每个构件文件包含一个 project 元素和至少一个 target。\n\ntarget 元素可以包含多个 task 元素。\n\n\n# project 元素\n\nproject 元素是构建文件的根元素。\n\n一个 project 元素可以有多个 target 元素，一个 target 元素可以有多个 task。\n\n在上节的例子中，project 标签里有三个属性。\n\n<project name="myproject" default="dist" basedir=".">\n\n\nname 属性，指示 project 元素的名字。例子中的名字就是 myproject。\n\ndefault 属性，指示这个 project 默认执行的 target。在本文的例子中，默认执行的 target 为 dist。\n\n如果我们输入命令 ant 时，不指定 target 参数，默认会执行 dist 这个 target。\n\nbasedir 属性，指定根路径的位置。该属性没有指定时，使用 ant 的构件文件的所在目录作为根目录。\n\n\n# target 元素\n\ntarget 元素是 task 的容器，也就是 ant 的一个基本执行单元。\n\n以上节例子中的 compile 来举例。\n\n<target name="compile" depends="init" description="compile the source " >\n    \x3c!-- compile the java code from ${src} into ${build} --\x3e\n    <javac srcdir="${src}" destdir="${build}"/>\n</target>\n\n\n这个 target 中出现了几个属性。\n\nname 属性，指示 target 元素的名称。\n\n这个属性在一个 project 元素中必须是唯一的。这很好理解，如果出现重复，ant 就不知道具体该执行哪个 target 了。\n\ndepends 属性，指示依赖的 target，当前的 target 必须在依赖的 target 之后执行。\n\ndescription 属性，是关于 target 的简短说明。\n\n此外，还有其他几个未出现在构建文件中的属性。\n\nif 属性，验证指定的属性是否存在，若不存在，所在 target 将不会被执行。\n\nunless 属性，正好和 if 属性相反，验证指定的属性是否存在，若存在，所在 target 将不会被执行。****\n\nextensionof 属性，添加当前 target 到 extension-point 依赖列表。——ant1.8.0 新特性。\n\n> extension-point 元素和 target 元素十分类似，都可以指定依赖的 target。但是不同的是，extension-point 中不能包含任何 task。\n\n请看以下实例：\n\n<target name="create-directory-layout">\n   ...\n</target>\n<extension-point name="ready-to-compile" depends="create-directory-layout"/>\n<target name="compile" depends="ready-to-compile">\n   ...\n</target>\n\n\n调用 target 顺序: create-directory-layout --\x3e \'empty slot\' --\x3e compile\n\n<target name="generate-sources" extensionof="ready-to-compile">\n   ...\n</target>\n\n\n调用 target 顺序: create-directory-layout --\x3e generate-sources --\x3e compile\n\nonmissingextensionpoint 属性：当无法找到一个 extension-point 时，target 尝试去做的动作("fail", "warn", "ignore")。——ant1.8.2 新特性\n\n\n# task 元素\n\ntask 是一段可以被执行的代码。\n\n一个 task 可以有多个属性， 一个属性可以包含对一个 property 的引用。\n\ntask 的通常结构为\n\n<name attribute1="value1" attribute2="value2" ... />\n\n\n其中，name 是 task 的名字， attributen 是属性名， valuen 是这个属性的值。\n\n还是以 compile 做为例子：\n\n<target name="compile" depends="init" description="compile the source " >\n    \x3c!-- compile the java code from srcintosrcinto{build} --\x3e\n    <javac srcdir="${src}" destdir="${build}"/>\n</target>\n\n\n在 compile 这个 target 标签中包含了一个任务。\n\n这个任务的动作是：执行 java 编译，编译 src 下的代码，并把编译生成的文件放在 build 目录中。\n\n**常用 task **\n\njavac：用于编译一个或者多个 java 源文件，通常需要 srcdir 和 destdir 两个属性，用于指定 java 源文件的位置和编译后 class 文件的保存位置。\n\n<javac srcdir="${src}" destdir="${build}" classpath="abc.jar" debug="on" source="1.7" />\n\n\njava：用于运行某个 java 类，通常需要 classname 属性，用于指定需要运行哪个类。\n\n<java classname="test.main">\n    <arg value="-h" />\n    <classpath>\n        <pathelement location="dist/test.jar" />\n    </classpath>\n</java>\n\n\njar：用于生成 jar 包，通常需要指定 destfile 属性，用于指定所创建 jar 包的文件名。除此之外，通常还应指定一个文件集，表明需要将哪些文件打包到 jar 包里。\n\n<jar jarfile="dist/lib/myproject−dist/lib/myproject−{dstamp}.jar" basedir="${build}"/>\n\n\necho：输出某个字符串。\n\n<echo message="building to ${builddir}"/>\n<echo>you are using version ${java.version} of java! this message spans two lines.</echo>\n\n\ncopy：用于复制文件或路径。\n\n<copy todir="${builddir}/srccopy">\n    <fileset dir="${srcdir}">\n        <include name="**/*.java"/>\n    </fileset>\n    <filterset>\n        <filter token="version" value="${app.version}"/>\n    </filterset>\n</copy>\n\n\ndelete：用于删除文件或路径。\n\n<copy todir="${builddir}/srccopy">\n    <fileset dir="${srcdir}">\n        <include name="**/*.java"/>\n    </fileset>\n    <filterset>\n        <filter token="version" value="${app.version}"/>\n    </filterset>\n</copy>\n\n\nmkdir：用于创建文件夹。\n\n<mkdir dir="${dist}/lib" />\n\n\nmove：用户移动文件和路径。\n\n<move todir="some/new/dir">\n    <fileset dir="my/src/dir">\n        <include name="**/*.jar" />\n        <exclude name="**/ant.jar" />\n    </fileset>\n</move>\n\n\n\n# property 元素\n\nproperty 是对参数的定义。\n\nproject 的属性可以通过 property 元素来设定，也可在 ant 之外设定。若要在外部引入某文件，例如 build.properties 文件，可以通过如下内容将其引入：<property file=” build.properties”/>。\n\nproperty 元素可用作 task 的属性值。在 task 中是通过将属性名放在“${”和“}”之间，并放在 task 属性值的位置来实现的。\n\n例如 complile 例子中，使用了前面定义的 src 作为源目录。\n\n<javac srcdir="${src}" destdir="${build}"/>\n\n\nant 提供了一些内置的属性，它能得到的系统属性的列表与 java 文档中 system.getpropertis()方法得到的属性一致，这些系统属性可参考 sun 网站的说明。\n\n\n# extension-point 元素\n\n和 target 元素十分类似，都可以指定依赖的 target。但是不同的是，extension-point 中不能包含任何 task。\n\n——ant1.8.0 新增特性。\n\n在 target 元素中的例子里已提到过，不再赘述。\n\n\n# 参考资料\n\n * ant 官方手册\n * http://www.blogjava.net/amigoxie/archive/2007/11/09/159413.html',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 构建",frontmatter:{title:"Java 构建",categories:["编程","Java","软件","构建"],tags:["Java","构建"],abbrlink:"7ebcc307",date:"2020-08-04T15:20:54.000Z",hidden:!0,permalink:"/pages/95388e/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/01.%E6%9E%84%E5%BB%BA/",relativePath:"11.软件/01.构建/README.md",key:"v-d7044cd0",path:"/pages/95388e/",headers:[{level:2,title:"📖 内容",slug:"📖-内容",normalizedTitle:"📖 内容",charIndex:245},{level:3,title:"Maven",slug:"maven",normalizedTitle:"maven",charIndex:85},{level:3,title:"Ant",slug:"ant",normalizedTitle:"ant",charIndex:177},{level:2,title:"📚 资料",slug:"📚-资料",normalizedTitle:"📚 资料",charIndex:418},{level:2,title:"🚪 传送",slug:"🚪-传送",normalizedTitle:"🚪 传送",charIndex:505}],headersStr:"📖 内容 Maven Ant 📚 资料 🚪 传送",content:"# Java 构建\n\n> Java 项目需要通过 构建工具 来管理项目依赖，完成编译、打包、发布、生成 JavaDoc 等任务。\n> \n>  * 目前最主流的构建工具是 Maven，它的功能非常强大。\n>  * Gradle 号称是要替代 Maven 等构件工具，它的版本管理确实简洁，但是需要学习 Groovy，学习成本比 Maven 高。\n>  * Ant 功能比 Maven 和 Gradle 要弱，现代 Java 项目基本不用了，但也有一些传统的 Java 项目还在使用。\n\n\n# 📖 内容\n\n\n# Maven\n\n * Maven 快速入门\n * Maven 教程之 pom.xml 详解\n * Maven 教程之 settings.xml 详解\n * Maven 实战问题和最佳实践\n * Maven 教程之发布 jar 到私服或中央仓库\n * Maven 插件之代码检查\n\n\n# Ant\n\n * Ant 简易教程\n\n\n# 📚 资料\n\n * 官网\n   * Maven Github\n   * Maven 官方文档\n   * Ant 官方手册\n * 书籍\n   * 《Maven 实战》\n\n\n# 🚪 传送\n\n◾ 🏠 JAVA-TUTORIAL 首页 ◾ 🎯 我的博客 ◾",normalizedContent:"# java 构建\n\n> java 项目需要通过 构建工具 来管理项目依赖，完成编译、打包、发布、生成 javadoc 等任务。\n> \n>  * 目前最主流的构建工具是 maven，它的功能非常强大。\n>  * gradle 号称是要替代 maven 等构件工具，它的版本管理确实简洁，但是需要学习 groovy，学习成本比 maven 高。\n>  * ant 功能比 maven 和 gradle 要弱，现代 java 项目基本不用了，但也有一些传统的 java 项目还在使用。\n\n\n# 📖 内容\n\n\n# maven\n\n * maven 快速入门\n * maven 教程之 pom.xml 详解\n * maven 教程之 settings.xml 详解\n * maven 实战问题和最佳实践\n * maven 教程之发布 jar 到私服或中央仓库\n * maven 插件之代码检查\n\n\n# ant\n\n * ant 简易教程\n\n\n# 📚 资料\n\n * 官网\n   * maven github\n   * maven 官方文档\n   * ant 官方手册\n * 书籍\n   * 《maven 实战》\n\n\n# 🚪 传送\n\n◾ 🏠 java-tutorial 首页 ◾ 🎯 我的博客 ◾",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Intellij IDEA 快速入门",frontmatter:{title:"Intellij IDEA 快速入门",categories:["编程","Java","软件","IDE"],tags:["Java","IDE"],abbrlink:"a688dbc5",date:"2019-11-29T18:10:14.000Z",permalink:"/pages/ea83ee/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/02.IDE/01.Intellij.html",relativePath:"11.软件/02.IDE/01.Intellij.md",key:"v-09c4ff2e",path:"/pages/ea83ee/",headers:[{level:2,title:"快捷键",slug:"快捷键",normalizedTitle:"快捷键",charIndex:25},{level:3,title:"核心快捷键",slug:"核心快捷键",normalizedTitle:"核心快捷键",charIndex:33},{level:3,title:"快捷键分类",slug:"快捷键分类",normalizedTitle:"快捷键分类",charIndex:1634},{level:4,title:"Tradition",slug:"tradition",normalizedTitle:"tradition",charIndex:1643},{level:4,title:"Editing",slug:"editing",normalizedTitle:"editing",charIndex:1902},{level:4,title:"Search/Replace",slug:"search-replace",normalizedTitle:"search/replace",charIndex:3944},{level:4,title:"Usage Search",slug:"usage-search",normalizedTitle:"usage search",charIndex:4269},{level:4,title:"Compile and Run",slug:"compile-and-run",normalizedTitle:"compile and run",charIndex:4452},{level:4,title:"Debugging",slug:"debugging",normalizedTitle:"debugging",charIndex:4691},{level:4,title:"Navigation",slug:"navigation",normalizedTitle:"navigation",charIndex:5272},{level:4,title:"Refactoring",slug:"refactoring",normalizedTitle:"refactoring",charIndex:6830},{level:4,title:"VCS/Local History",slug:"vcs-local-history",normalizedTitle:"vcs/local history",charIndex:6951},{level:4,title:"Live Templates",slug:"live-templates",normalizedTitle:"live templates",charIndex:7187},{level:4,title:"General",slug:"general",normalizedTitle:"general",charIndex:7299},{level:3,title:"Intellij IDEA 官方快捷键表",slug:"intellij-idea-官方快捷键表",normalizedTitle:"intellij idea 官方快捷键表",charIndex:7675},{level:2,title:"插件",slug:"插件",normalizedTitle:"插件",charIndex:7702},{level:2,title:"个性化",slug:"个性化",normalizedTitle:"个性化",charIndex:8137},{level:3,title:"颜色主题",slug:"颜色主题",normalizedTitle:"颜色主题",charIndex:8145},{level:2,title:"破解",slug:"破解",normalizedTitle:"破解",charIndex:8202},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:8753}],headersStr:"快捷键 核心快捷键 快捷键分类 Tradition Editing Search/Replace Usage Search Compile and Run Debugging Navigation Refactoring VCS/Local History Live Templates General Intellij IDEA 官方快捷键表 插件 个性化 颜色主题 破解 参考资料",content:"# Intellij IDEA 快速入门\n\n\n# 快捷键\n\n\n# 核心快捷键\n\nIntelliJ IDEA 作为一个以快捷键为中心的 IDE，为大多数操作建议了键盘快捷键。在这个主题中，您可以找到最不可缺少的列表，使 IntelliJ IDEA 轻松实现第一步。\n\n核心快捷键表：\n\n操作                                                    快捷键\n根据名称查找操作                                              Ctrl+Shift+A\n显示可用 意图操作 列表                                          Alt+Enter\n切换视图 (Project,Structure, etc.).                       Alt+F1\n切换工具窗口和在编辑器中打开的文件                                     Ctrl+Tab\n显示 导航栏.                                               Alt+Home\n插入代码模板.                                               Ctrl+J\n在周围插入代码模板.                                            Ctrl+Alt+J\nEdit an item from the Project or another tree view.   F4\n注释                                                    Ctrl+/ Ctrl+Shift+/\n根据名称查找类或文件.                                           Ctrl+N Ctrl+Shift+N\n拷贝当前行或指定的行.                                           Ctrl+D\n增加或减少选中的表达式.                                          Ctrl+W and Ctrl+Shift+W\n在当前文件查找或替换.                                           Ctrl+F Ctrl+R\n在项目中或指定的目录中查找或替换                                      Ctrl+Shift+F Ctrl+Shift+R\n全局搜索                                                  双击 Shift\n快速查看选中对象的引用.                                          Ctrl+Shift+F7\n展开或折叠编辑器中的代码块.                                        Ctrl+NumPad Plus Ctrl+NumPad -\n调用代码完成.                                               Ctrl+Space\n智能声明完成.                                               Ctrl+Shift+Enter\n智能补全代码                                                Ctrl+Shift+Space\n显示可用的重构方法列表                                           Ctrl+Shift+Alt+T\n\n\n# 快捷键分类\n\n# Tradition\n\n快捷键                介绍\nCtrl + Z           撤销\nCtrl + Shift + Z   取消撤销\nCtrl + X           剪切\nCtrl + C           复制\nCtrl + S           保存\nTab                缩进\nShift + Tab        取消缩进\nShift + Home/End   选中光标到当前行头位置/行尾位置\nCtrl + Home/End    跳到文件头/文件尾\n\n# Editing\n\n快捷键                      介绍\nCtrl + Space             基础代码补全，默认在 Windows 系统上被输入法占用，需要进行修改，建议修改为 Ctrl + 逗号（必备）\nCtrl + Alt + Space       类名自动完成\nCtrl + Shift + Enter     自动结束代码，行末自动添加分号（必备）\nCtrl + P                 方法参数提示显示\nCtrl + Q                 光标所在的变量/类名/方法名等上面（也可以在提示补充的时候按），显示文档内容\nShift + F1               如果有外部文档可以连接外部文档\nCtrl + F1                在光标所在的错误代码处显示错误信息（必备）\nAlt + Insert             代码自动生成，如生成对象的 set/get 方法，构造函数，toString() 等（必备）\nCtrl + O                 选择可重写的方法\nCtrl + I                 选择可继承的方法\nCtrl + Alt + T           对选中的代码弹出环绕选项弹出层（必备）\nCtrl + /                 注释光标所在行代码，会根据当前不同文件类型使用不同的注释符号（必备）\nCtrl + Shift + /         代码块注释（必备）\nCtrl + W                 递进式选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展选中范围（必备）\nCtrl + Shift + W         递进式取消选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展取消选中范围（必备）\nAlt + Q                  弹出一个提示，显示当前类的声明/上下文信息\nAlt + Enter              IntelliJ IDEA 根据光标所在问题，提供快速修复选择，光标放在的位置不同提示的结果也不同（必备）\nCtrl + Alt + L           格式化代码，可以对当前文件和整个包目录使用（必备）\nCtrl + Alt + O           优化导入的类，可以对当前文件和整个包目录使用（必备）\nCtrl + Alt + I           光标所在行 或 选中部分进行自动代码缩进，有点类似格式化\nCtrl + Shift + C         复制当前文件磁盘路径到剪贴板（必备）\nCtrl + Shift + V         弹出缓存的最近拷贝的内容管理器弹出层\nCtrl + Alt + Shift + C   复制参考信息\nCtrl + Alt + Shift + V   无格式黏贴（必备）\nCtrl + D                 复制光标所在行 或 复制选择内容，并把复制内容插入光标位置下面（必备）\nCtrl + Y                 删除光标所在行 或 删除选中的行（必备）\nCtrl + Shift + J         自动将下一行合并到当前行末尾（必备）\nShift + Enter            开始新一行。光标所在行下空出一行，光标定位到新行位置（必备）\nCtrl + Shift + U         对选中的代码进行大/小写轮流转换（必备）\nCtrl + Shift + ]/[       选中从光标所在位置到它的底部/顶部的中括号位置（必备）\nCtrl + Delete            删除光标后面的单词或是中文句（必备）\nCtrl + BackSpace         删除光标前面的单词或是中文句（必备）\nCtrl + +/-               展开/折叠代码块\nCtrl + Shift + +/-       展开/折叠所有代码（必备）\nCtrl + F4                关闭当前编辑文件\nCtrl + Shift + Up/Down   光标放在方法名上，将方法移动到上一个/下一个方法前面，调整方法排序（必备）\nAlt + Shift + Up/Down    移动光标所在行向上移动/向下移动（必备）\nCtrl + Shift + 左键单击      把光标放在某个类变量上，按此快捷键可以直接定位到该类中（必备）\nAlt + Shift + 左键双击       选择被双击的单词/中文句，按住不放，可以同时选择其他单词/中文句（必备）\nCtrl + Shift + T         对当前类生成单元测试类，如果已经存在的单元测试类则可以进行选择（必备）\n\n# Search/Replace\n\n快捷键                介绍\nDouble Shift       弹出 Search Everywhere 弹出层\nF3                 在查找模式下，定位到下一个匹配处\nShift + F3         在查找模式下，查找匹配上一个\nCtrl + F           在当前文件进行文本查找（必备）\nCtrl + R           在当前文件进行文本替换（必备）\nCtrl + Shift + F   根据输入内容查找整个项目 或 指定目录内文件（必备）\nCtrl + Shift + R   根据输入内容替换对应内容，范围为整个项目 或 指定目录内文件（必备）\n\n# Usage Search\n\n快捷键                 介绍\nAlt + F7            查找光标所在的方法/变量/类被调用的地方\nCtrl + Alt + F7     显示使用的地方。寻找被该类或是变量被调用的地方，用弹出框的方式找出来\nCtrl + Shift + F7   高亮显示所有该选中文本，按 Esc 高亮消失（必备）\n\n# Compile and Run\n\n快捷键                 介绍\nCtrl + F9           执行 Make Project 操作\nCtrl + Shift + F9   编译选中的文件/包/Module\nShift + F9          Debug\nShift + F10         Run\nAlt + Shift + F9    弹出 Debug 的可选择菜单\nAlt + Shift + F10   弹出 Run 的可选择菜单\n\n# Debugging\n\n快捷键                 介绍\nF7                  在 Debug\n                    模式下，进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则不会进入该内嵌的方法中\nF8                  在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则不进入当前方法体内\nShift + F7          在 Debug 模式下，智能步入。断点所在行上有多个方法调用，会弹出进入哪个方法\nShift + F8          在 Debug 模式下，跳出，表现出来的效果跟 F9 一样\nAlt + F8            在 Debug 模式下，选中对象，弹出可输入计算表达式调试框，查看该输入内容的调试结果\nAlt + F9            在 Debug 模式下，执行到光标处\nF9                  在 Debug 模式下，恢复程序运行，但是如果该断点下面代码还有断点则停在下一个断点上\nCtrl + F8           在 Debug 模式下，设置光标当前行为断点，如果当前已经是断点则去掉断点\nCtrl + Shift + F8   在 Debug 模式下，指定断点进入条件\n\n# Navigation\n\n快捷键                        介绍\nCtrl + N                   跳转到类（必备）\nCtrl + Shift + N           跳转到文件（必备）\nCtrl + Alt + Shift + N     跳转到符号（必备）\nAlt + Left/Right           切换当前已打开的窗口中的子视图，比如 Debug 窗口中有 Output、Debugger\n                           等子视图，用此快捷键就可以在子视图中切换（必备）\nF12                        回到前一个工具窗口（必备）\nESC                        从工具窗口进入代码文件窗口（必备）\nShift + ESC                隐藏当前 或 最后一个激活的工具窗口\nCtrl + G                   跳转到当前文件的指定行处\nCtrl + E                   显示最近打开的文件记录列表（必备）\nCtrl + Shift + E           显示最近编辑的文件记录列表（必备）\nCtrl + Alt + Left/Right    跳转到上一个/下一个操作的地方（必备）\nCtrl + Shift + Backspace   退回到上次修改的地方（必备）\nAlt + F1                   显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择（必备）\nCtrl + B/Ctrl + 左键单击       跳转到声明处\nCtrl + Alt + B             在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口\nCtrl + Shift + B           跳转到类型声明处（必备）\nCtrl + Shift + I           快速查看光标所在的方法 或 类的定义\nCtrl + U                   前往当前光标所在的方法的父类的方法/接口定义（必备）\nAlt + Up/Down              跳转到当前文件的前一个/后一个方法（必备）\nCtrl + ]/[                 跳转到当前所在代码的花括号结束位置/开始位置\nCtrl + F12                 弹出当前文件结构层，可以在弹出的层上直接输入，进行筛选\nCtrl + H                   显示当前类的层次结构\nCtrl + Shift + H           显示方法层次结构\nCtrl + Alt + H             调用层次\nF2/Shift + F2              跳转到下一个/上一个高亮错误 或 警告位置（必备）\nF4                         编辑源（必备）\nAlt + Home                 定位/显示到当前文件的 Navigation Bar\nF11                        添加书签（必备）\nCtrl + F11                 选中文件/文件夹，使用助记符设定/取消书签（必备）\nShift + F11                弹出书签显示层（必备）\nAlt + 1,2,3...9            显示对应数值的选项卡，其中 1 是 Project 用得最多（必备）\nCtrl + 1,2,3...9           定位到对应数值的书签位置（必备）\n\n# Refactoring\n\n快捷键                      介绍\nShift + F6               对文件/文件夹 重命名（必备）\nCtrl + Alt + Shift + T   打开重构菜单（必备）\n\n# VCS/Local History\n\n快捷键               介绍\nCtrl + K          版本控制提交项目，需要此项目有加入到版本控制才可用\nCtrl + T          版本控制更新项目，需要此项目有加入到版本控制才可用\nAlt + |           显示版本控制常用操作菜单弹出层（必备）\nAlt + Shift + C   查看最近操作项目的变化情况列表\nAlt + Shift + N   选择/添加 task（必备）\n\n# Live Templates\n\n快捷键              介绍\nCtrl + J         插入自定义动态代码模板（必备）\nCtrl + Alt + J   弹出模板选择窗口，将选定的代码加入动态模板中\n\n# General\n\n快捷键                      介绍\nCtrl + Tab               编辑窗口切换，如果在切换的过程又加按上 delete，则是关闭对应选中的窗口\nCtrl + Alt + Y           同步、刷新\nCtrl + Alt + S           打开 IntelliJ IDEA 系统设置（必备）\nCtrl + Alt + Shift + S   打开当前项目设置（必备）\nCtrl + Shift + A         查找动作/设置（必备）\nCtrl + Shift + F12       编辑器最大化（必备）\nAlt + Shift + F          显示添加到收藏夹弹出层/添加到收藏夹\nAlt + Shift + I          查看项目当前文件\n\n\n# Intellij IDEA 官方快捷键表\n\n\n\n\n# 插件\n\n推荐几个比较好用的插件\n\n * Key promoter 快捷键提示\n * CamelCase 驼峰式命名和下划线命名交替变化\n * CheckStyle-IDEA 代码规范检查\n * FindBugs-IDEA潜在 Bug 检查\n * MetricsReloaded 代码复杂度检查\n * Statistic 代码统计\n * JRebel Plugin 热部署\n * GsonFormat 把 JSON 字符串直接实例化成类\n * Eclipse Code Formatter 如果你以前用的是 IDE，并有自己的一套代码风格配置，可以通过此插件导入到 IDEA\n * Alibaba Java Coding Guidelines 阿里 Java 开发规范的静态检查工具\n * IDE Features Trainer 官方的新手训练插件\n * Markdown Navigator Markdown 插件，适用于喜欢用 markdown 写文档的人\n\n\n# 个性化\n\n\n# 颜色主题\n\nintellij-colors-solarized 个人觉得这种色彩搭配十分优雅\n\n下载地址\n\n\n# 破解\n\nIntellij 是一个收费的 IDE，坦白说有点小贵，买不起。\n\n所以，很惭愧，只好用下破解方法了。网上有很多使用注册码的网文，但是注册码不稳定，随时可能被封。还是自行搭建一个注册服务器比较稳定。我使用了 ilanyu 博文 IntelliJ IDEA License Server 本地搭建教程 的方法，亲测十分有效。\n\n我的备用地址：百度云盘\n\n下载并解压文中的压缩包到本地，选择适合操作系统的版本运行。\n\n如果是在 Linux 上运行，推荐创建一个脚本，代码如下：\n\n# 使用 nohup 创建守护进程，运行 IntelliJIDEALicenseServer_linux_amd64\n# 如果运行在其他 Linux 发行版本，替换执行的脚本即可\nnohup sh IntelliJIDEALicenseServer_linux_amd64 2>&1\n\n\n这样做是因为：大部分人使用 linux 是使用仿真器连接虚拟机，如果断开连接，进程也会被 kill，每次启动这个注册服务器很麻烦不是吗？而启动了守护进程，则不会出现这种情况，只有你主动 kill 进程才能将其干掉。\n\nWindows 版本是 exe 程序，将其设为开机自动启动即可，别告诉我你不知道怎么设置开机自动启动。\n\n\n# 参考资料\n\n * IntelliJ-IDEA-Tutorial\n * 极客学院 - Intellij IDEA 使用教程",normalizedContent:"# intellij idea 快速入门\n\n\n# 快捷键\n\n\n# 核心快捷键\n\nintellij idea 作为一个以快捷键为中心的 ide，为大多数操作建议了键盘快捷键。在这个主题中，您可以找到最不可缺少的列表，使 intellij idea 轻松实现第一步。\n\n核心快捷键表：\n\n操作                                                    快捷键\n根据名称查找操作                                              ctrl+shift+a\n显示可用 意图操作 列表                                          alt+enter\n切换视图 (project,structure, etc.).                       alt+f1\n切换工具窗口和在编辑器中打开的文件                                     ctrl+tab\n显示 导航栏.                                               alt+home\n插入代码模板.                                               ctrl+j\n在周围插入代码模板.                                            ctrl+alt+j\nedit an item from the project or another tree view.   f4\n注释                                                    ctrl+/ ctrl+shift+/\n根据名称查找类或文件.                                           ctrl+n ctrl+shift+n\n拷贝当前行或指定的行.                                           ctrl+d\n增加或减少选中的表达式.                                          ctrl+w and ctrl+shift+w\n在当前文件查找或替换.                                           ctrl+f ctrl+r\n在项目中或指定的目录中查找或替换                                      ctrl+shift+f ctrl+shift+r\n全局搜索                                                  双击 shift\n快速查看选中对象的引用.                                          ctrl+shift+f7\n展开或折叠编辑器中的代码块.                                        ctrl+numpad plus ctrl+numpad -\n调用代码完成.                                               ctrl+space\n智能声明完成.                                               ctrl+shift+enter\n智能补全代码                                                ctrl+shift+space\n显示可用的重构方法列表                                           ctrl+shift+alt+t\n\n\n# 快捷键分类\n\n# tradition\n\n快捷键                介绍\nctrl + z           撤销\nctrl + shift + z   取消撤销\nctrl + x           剪切\nctrl + c           复制\nctrl + s           保存\ntab                缩进\nshift + tab        取消缩进\nshift + home/end   选中光标到当前行头位置/行尾位置\nctrl + home/end    跳到文件头/文件尾\n\n# editing\n\n快捷键                      介绍\nctrl + space             基础代码补全，默认在 windows 系统上被输入法占用，需要进行修改，建议修改为 ctrl + 逗号（必备）\nctrl + alt + space       类名自动完成\nctrl + shift + enter     自动结束代码，行末自动添加分号（必备）\nctrl + p                 方法参数提示显示\nctrl + q                 光标所在的变量/类名/方法名等上面（也可以在提示补充的时候按），显示文档内容\nshift + f1               如果有外部文档可以连接外部文档\nctrl + f1                在光标所在的错误代码处显示错误信息（必备）\nalt + insert             代码自动生成，如生成对象的 set/get 方法，构造函数，tostring() 等（必备）\nctrl + o                 选择可重写的方法\nctrl + i                 选择可继承的方法\nctrl + alt + t           对选中的代码弹出环绕选项弹出层（必备）\nctrl + /                 注释光标所在行代码，会根据当前不同文件类型使用不同的注释符号（必备）\nctrl + shift + /         代码块注释（必备）\nctrl + w                 递进式选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展选中范围（必备）\nctrl + shift + w         递进式取消选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展取消选中范围（必备）\nalt + q                  弹出一个提示，显示当前类的声明/上下文信息\nalt + enter              intellij idea 根据光标所在问题，提供快速修复选择，光标放在的位置不同提示的结果也不同（必备）\nctrl + alt + l           格式化代码，可以对当前文件和整个包目录使用（必备）\nctrl + alt + o           优化导入的类，可以对当前文件和整个包目录使用（必备）\nctrl + alt + i           光标所在行 或 选中部分进行自动代码缩进，有点类似格式化\nctrl + shift + c         复制当前文件磁盘路径到剪贴板（必备）\nctrl + shift + v         弹出缓存的最近拷贝的内容管理器弹出层\nctrl + alt + shift + c   复制参考信息\nctrl + alt + shift + v   无格式黏贴（必备）\nctrl + d                 复制光标所在行 或 复制选择内容，并把复制内容插入光标位置下面（必备）\nctrl + y                 删除光标所在行 或 删除选中的行（必备）\nctrl + shift + j         自动将下一行合并到当前行末尾（必备）\nshift + enter            开始新一行。光标所在行下空出一行，光标定位到新行位置（必备）\nctrl + shift + u         对选中的代码进行大/小写轮流转换（必备）\nctrl + shift + ]/[       选中从光标所在位置到它的底部/顶部的中括号位置（必备）\nctrl + delete            删除光标后面的单词或是中文句（必备）\nctrl + backspace         删除光标前面的单词或是中文句（必备）\nctrl + +/-               展开/折叠代码块\nctrl + shift + +/-       展开/折叠所有代码（必备）\nctrl + f4                关闭当前编辑文件\nctrl + shift + up/down   光标放在方法名上，将方法移动到上一个/下一个方法前面，调整方法排序（必备）\nalt + shift + up/down    移动光标所在行向上移动/向下移动（必备）\nctrl + shift + 左键单击      把光标放在某个类变量上，按此快捷键可以直接定位到该类中（必备）\nalt + shift + 左键双击       选择被双击的单词/中文句，按住不放，可以同时选择其他单词/中文句（必备）\nctrl + shift + t         对当前类生成单元测试类，如果已经存在的单元测试类则可以进行选择（必备）\n\n# search/replace\n\n快捷键                介绍\ndouble shift       弹出 search everywhere 弹出层\nf3                 在查找模式下，定位到下一个匹配处\nshift + f3         在查找模式下，查找匹配上一个\nctrl + f           在当前文件进行文本查找（必备）\nctrl + r           在当前文件进行文本替换（必备）\nctrl + shift + f   根据输入内容查找整个项目 或 指定目录内文件（必备）\nctrl + shift + r   根据输入内容替换对应内容，范围为整个项目 或 指定目录内文件（必备）\n\n# usage search\n\n快捷键                 介绍\nalt + f7            查找光标所在的方法/变量/类被调用的地方\nctrl + alt + f7     显示使用的地方。寻找被该类或是变量被调用的地方，用弹出框的方式找出来\nctrl + shift + f7   高亮显示所有该选中文本，按 esc 高亮消失（必备）\n\n# compile and run\n\n快捷键                 介绍\nctrl + f9           执行 make project 操作\nctrl + shift + f9   编译选中的文件/包/module\nshift + f9          debug\nshift + f10         run\nalt + shift + f9    弹出 debug 的可选择菜单\nalt + shift + f10   弹出 run 的可选择菜单\n\n# debugging\n\n快捷键                 介绍\nf7                  在 debug\n                    模式下，进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则不会进入该内嵌的方法中\nf8                  在 debug 模式下，进入下一步，如果当前行断点是一个方法，则不进入当前方法体内\nshift + f7          在 debug 模式下，智能步入。断点所在行上有多个方法调用，会弹出进入哪个方法\nshift + f8          在 debug 模式下，跳出，表现出来的效果跟 f9 一样\nalt + f8            在 debug 模式下，选中对象，弹出可输入计算表达式调试框，查看该输入内容的调试结果\nalt + f9            在 debug 模式下，执行到光标处\nf9                  在 debug 模式下，恢复程序运行，但是如果该断点下面代码还有断点则停在下一个断点上\nctrl + f8           在 debug 模式下，设置光标当前行为断点，如果当前已经是断点则去掉断点\nctrl + shift + f8   在 debug 模式下，指定断点进入条件\n\n# navigation\n\n快捷键                        介绍\nctrl + n                   跳转到类（必备）\nctrl + shift + n           跳转到文件（必备）\nctrl + alt + shift + n     跳转到符号（必备）\nalt + left/right           切换当前已打开的窗口中的子视图，比如 debug 窗口中有 output、debugger\n                           等子视图，用此快捷键就可以在子视图中切换（必备）\nf12                        回到前一个工具窗口（必备）\nesc                        从工具窗口进入代码文件窗口（必备）\nshift + esc                隐藏当前 或 最后一个激活的工具窗口\nctrl + g                   跳转到当前文件的指定行处\nctrl + e                   显示最近打开的文件记录列表（必备）\nctrl + shift + e           显示最近编辑的文件记录列表（必备）\nctrl + alt + left/right    跳转到上一个/下一个操作的地方（必备）\nctrl + shift + backspace   退回到上次修改的地方（必备）\nalt + f1                   显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择（必备）\nctrl + b/ctrl + 左键单击       跳转到声明处\nctrl + alt + b             在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口\nctrl + shift + b           跳转到类型声明处（必备）\nctrl + shift + i           快速查看光标所在的方法 或 类的定义\nctrl + u                   前往当前光标所在的方法的父类的方法/接口定义（必备）\nalt + up/down              跳转到当前文件的前一个/后一个方法（必备）\nctrl + ]/[                 跳转到当前所在代码的花括号结束位置/开始位置\nctrl + f12                 弹出当前文件结构层，可以在弹出的层上直接输入，进行筛选\nctrl + h                   显示当前类的层次结构\nctrl + shift + h           显示方法层次结构\nctrl + alt + h             调用层次\nf2/shift + f2              跳转到下一个/上一个高亮错误 或 警告位置（必备）\nf4                         编辑源（必备）\nalt + home                 定位/显示到当前文件的 navigation bar\nf11                        添加书签（必备）\nctrl + f11                 选中文件/文件夹，使用助记符设定/取消书签（必备）\nshift + f11                弹出书签显示层（必备）\nalt + 1,2,3...9            显示对应数值的选项卡，其中 1 是 project 用得最多（必备）\nctrl + 1,2,3...9           定位到对应数值的书签位置（必备）\n\n# refactoring\n\n快捷键                      介绍\nshift + f6               对文件/文件夹 重命名（必备）\nctrl + alt + shift + t   打开重构菜单（必备）\n\n# vcs/local history\n\n快捷键               介绍\nctrl + k          版本控制提交项目，需要此项目有加入到版本控制才可用\nctrl + t          版本控制更新项目，需要此项目有加入到版本控制才可用\nalt + |           显示版本控制常用操作菜单弹出层（必备）\nalt + shift + c   查看最近操作项目的变化情况列表\nalt + shift + n   选择/添加 task（必备）\n\n# live templates\n\n快捷键              介绍\nctrl + j         插入自定义动态代码模板（必备）\nctrl + alt + j   弹出模板选择窗口，将选定的代码加入动态模板中\n\n# general\n\n快捷键                      介绍\nctrl + tab               编辑窗口切换，如果在切换的过程又加按上 delete，则是关闭对应选中的窗口\nctrl + alt + y           同步、刷新\nctrl + alt + s           打开 intellij idea 系统设置（必备）\nctrl + alt + shift + s   打开当前项目设置（必备）\nctrl + shift + a         查找动作/设置（必备）\nctrl + shift + f12       编辑器最大化（必备）\nalt + shift + f          显示添加到收藏夹弹出层/添加到收藏夹\nalt + shift + i          查看项目当前文件\n\n\n# intellij idea 官方快捷键表\n\n\n\n\n# 插件\n\n推荐几个比较好用的插件\n\n * key promoter 快捷键提示\n * camelcase 驼峰式命名和下划线命名交替变化\n * checkstyle-idea 代码规范检查\n * findbugs-idea潜在 bug 检查\n * metricsreloaded 代码复杂度检查\n * statistic 代码统计\n * jrebel plugin 热部署\n * gsonformat 把 json 字符串直接实例化成类\n * eclipse code formatter 如果你以前用的是 ide，并有自己的一套代码风格配置，可以通过此插件导入到 idea\n * alibaba java coding guidelines 阿里 java 开发规范的静态检查工具\n * ide features trainer 官方的新手训练插件\n * markdown navigator markdown 插件，适用于喜欢用 markdown 写文档的人\n\n\n# 个性化\n\n\n# 颜色主题\n\nintellij-colors-solarized 个人觉得这种色彩搭配十分优雅\n\n下载地址\n\n\n# 破解\n\nintellij 是一个收费的 ide，坦白说有点小贵，买不起。\n\n所以，很惭愧，只好用下破解方法了。网上有很多使用注册码的网文，但是注册码不稳定，随时可能被封。还是自行搭建一个注册服务器比较稳定。我使用了 ilanyu 博文 intellij idea license server 本地搭建教程 的方法，亲测十分有效。\n\n我的备用地址：百度云盘\n\n下载并解压文中的压缩包到本地，选择适合操作系统的版本运行。\n\n如果是在 linux 上运行，推荐创建一个脚本，代码如下：\n\n# 使用 nohup 创建守护进程，运行 intellijidealicenseserver_linux_amd64\n# 如果运行在其他 linux 发行版本，替换执行的脚本即可\nnohup sh intellijidealicenseserver_linux_amd64 2>&1\n\n\n这样做是因为：大部分人使用 linux 是使用仿真器连接虚拟机，如果断开连接，进程也会被 kill，每次启动这个注册服务器很麻烦不是吗？而启动了守护进程，则不会出现这种情况，只有你主动 kill 进程才能将其干掉。\n\nwindows 版本是 exe 程序，将其设为开机自动启动即可，别告诉我你不知道怎么设置开机自动启动。\n\n\n# 参考资料\n\n * intellij-idea-tutorial\n * 极客学院 - intellij idea 使用教程",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Eclipse 快速入门",frontmatter:{title:"Eclipse 快速入门",categories:["编程","Java","软件","IDE"],tags:["Java","IDE"],abbrlink:"bd5534bf",date:"2018-07-01T11:27:47.000Z",permalink:"/pages/a897a9/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/02.IDE/02.Eclipse.html",relativePath:"11.软件/02.IDE/02.Eclipse.md",key:"v-2040598b",path:"/pages/a897a9/",headers:[{level:2,title:"代码智能提示",slug:"代码智能提示",normalizedTitle:"代码智能提示",charIndex:19},{level:3,title:"Java 智能提示",slug:"java-智能提示",normalizedTitle:"java 智能提示",charIndex:30},{level:3,title:"JavaScript 智能提示",slug:"javascript-智能提示",normalizedTitle:"javascript 智能提示",charIndex:369},{level:3,title:"HTML 智能提示",slug:"html-智能提示",normalizedTitle:"html 智能提示",charIndex:474},{level:2,title:"插件安装",slug:"插件安装",normalizedTitle:"插件安装",charIndex:606},{level:2,title:"基本设置",slug:"基本设置",normalizedTitle:"基本设置",charIndex:1445},{level:2,title:"设置文本文件及 JSP 文件编码",slug:"设置文本文件及-jsp-文件编码",normalizedTitle:"设置文本文件及 jsp 文件编码",charIndex:1713},{level:2,title:"设置 JDK 本地 JavaDOC API 路径及源码路径",slug:"设置-jdk-本地-javadoc-api-路径及源码路径",normalizedTitle:"设置 jdk 本地 javadoc api 路径及源码路径",charIndex:1817},{level:2,title:"设置 Servlet 源码或其它 Jar 包源码",slug:"设置-servlet-源码或其它-jar-包源码",normalizedTitle:"设置 servlet 源码或其它 jar 包源码",charIndex:2162},{level:2,title:"反编译插件 JD-Eclipse",slug:"反编译插件-jd-eclipse",normalizedTitle:"反编译插件 jd-eclipse",charIndex:2632},{level:2,title:"Validate 优化",slug:"validate-优化",normalizedTitle:"validate 优化",charIndex:3006},{level:2,title:"常用快捷键",slug:"常用快捷键",normalizedTitle:"常用快捷键",charIndex:3336}],headersStr:"代码智能提示 Java 智能提示 JavaScript 智能提示 HTML 智能提示 插件安装 基本设置 设置文本文件及 JSP 文件编码 设置 JDK 本地 JavaDOC API 路径及源码路径 设置 Servlet 源码或其它 Jar 包源码 反编译插件 JD-Eclipse Validate 优化 常用快捷键",content:'# Eclipse 快速入门\n\n\n# 代码智能提示\n\n\n# Java 智能提示\n\nWindow -> Preferences -> Java -> Editor -> Content Assist -> Auto Activation\n\n\n\ndelay 是自动弹出提示框的延时时间，我们可以修改成 100 毫秒；triggers 这里默认是"."，只要加上"abcdefghijklmnopqrstuvwxyz"或者"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"，嘿嘿！这下就能做到和 VS 一样的输入每个字母都能提示啦：\n\n\n\n其它类型的文件比如 HTML、JavaScript、JSP 如果也能提供提示那不是更爽了？有了第二点设置的基础，其实这些设置都是一样的。\n\n\n# JavaScript 智能提示\n\nWindow -> Preferences -> JavaScript-> Editor -> Content Assist -> Auto-Activation\n\n\n\n\n# HTML 智能提示\n\nWindow -> Preferences -> Web -> HTML Files -> Editor -> Content Assist -> Auto-Activation\n\n\n\n保存后，我们再来输入看看，感觉真是不错呀：\n\n\n\n\n# 插件安装\n\n很多教科书上说到 Eclipse 的插件安装都是通过 Help -> Install New SoftWare 这种自动检索的方式，操作起来固然是方便，不过当我们不需要某种插件时不太容易找到要删除哪些内容，而且以后 Eclipse 版本升级的时候，通过这种方式安装过的插件都得再重新装一次。另外一种通过 Link 链接方式，就可以解决这些问题。\n\n我们以 Eclipse 的中文汉化包插件为例，先到官方提供的汉化包地址下载一个：http://www.eclipse.org/babel/downloads.php，注意选好自己的 Eclipse 版本：\n\n\n\n我的版本是 Kepler，然后进入下载页面，单击红框框中的链接，即可下载汉化包了：\n\n\n\n下载完解压缩后，会有个包含 features 和 plugin 目录的 eclipse 文件夹，把这个 eclipse 放在我们的 Eclipse 安装根目录，也就是和 eclipse.exe 同一级目录下。然后仍然在这一级目录下，新建一个 links 文件夹，并在该文件夹内，建一个 language.link 的文本文件。该文本文件的名字是可以任取的，后缀名是.link，而不是.txt 哟。好了，最后一步，编辑该文件，在里面写入刚才放入的语言包的地址，并用“\\”表示路径，一定要有 path= 这个前缀。\n\n\n\n保存文件后，重新打开 Eclipse，熟悉的中文界面终于看到了。虽然汉化不完全，不过也够用了不是么。如果仍然出现的是英文，说明汉化失败，重新检查下 language.link 文件中配置的信息是否和汉化包的目录一致。　　其它的插件安装方法也是如此，当不需要某个插件时，只需删除存放插件的目录和 links 目录下相应的 link 文件，或者改变下 link 文件里面的路径变成无效路径即可；对 Eclipse 做高版本升级时，也只需把老版存放插件的目录和 links 目录复制过去就行了。\n\n\n# 基本设置\n\n在 Preference 的搜索项中搜索 Text Editors。 可以参考我的设置： Show line numbers Show print margin Insert spaces for tabs\n\n设置代码的字体类型和大小：\n\nWindow -> Preferences -> General -> Appearance -> Content Assist -> Colors and Fornts，只需修改 Basic 里面的 Text Font 就可以了。\n\n推荐 Courier New。\n\n\n\n\n\n\n# 设置文本文件及 JSP 文件编码\n\nWindow -> Preferences -> General -> Workspace -> Text file encoding -> Other：\n\n\n\n\n\n\n# 设置 JDK 本地 JavaDOC API 路径及源码路径\n\n\n\n\n\n还都生成的是无意义的变量名，这样可能会对含有相同类型的变量参数的调用顺序造成干扰；\n\n这种问题，我们把 JDK 或者相应 Jar 包的源码导入进去就能避免了：\n\nWindow -> Preferences -> Java -> Installed JREs -> Edit：\n\n\n\n选中设置好的 JRE 目录，编辑，然后全选 JRE system libraries 下的所有 Jar 包，点击右边的 Source Attachment；\n\n\n\nExternal location 下，选中 JDK 安装目录下的 src.zip 文件，一路 OK 下来。\n\n\n\n设置完，我们再来看看，幸福来的好突然有木有！\n\n\n\n\n# 设置 Servlet 源码或其它 Jar 包源码\n\n\n\n上一步已经设置过了 JDK 的源码或 JavaDoc 路径，为啥现在又出来了呢？其实这个不难理解，因为我们使用到的类的源码并不在 JDK 的源码包中。\n\n仔细看，我们会发现这些 Jar 包其实都在 Tomcat 根目录下的 lib 文件夹中，但是翻遍了 Tomcat 目录也没有相应的 jar 或 zip 文件呀。既然本地没有，那就去官网上找找：\n\nhttp://tomcat.apache.org/download-70.cgi这里有Tomcat的安装包和源码包；\n\n\n\n可以自定义一个专门用于存放 JavaSource 和 JavaDoc 的文件夹，把下载文件放到该目录下，\n\n然后再切换到 Eclipse 下，选中没有代码提示的类或者函数， 按下 F3，点击 Change Attached Source：\n\n\n\n选择我们刚才下载好的 tomcat 源码文件，一路 OK。\n\n\n\n然后再回过头看看我们的代码提示，友好多了：\n\n\n\n其它 Jar 包源码的设置方式也一样。\n\n\n# 反编译插件 JD-Eclipse\n\n无论是开发还是调试，反编译必不可少，每次都用 jd-gui 打开去看，多麻烦，干脆配置下 JD 插件，自动关联.class：\n\n先从 http://jd.benow.ca/ 上下载离线安装包 jdeclipse_update_site.zip，解压缩后把 features、plugins 这 2 个文件夹复制到 新建文件夹 jdeclipse，然后把 jdeclipse 文件夹整个复制到 Eclipse 根目录的 dropins 文件夹下，重启 Eclipse 即可。这种方式是不是比建 link 文件更方便了？\n\n\n\n打开 Eclipse，Window -> Preferences -> General - > Editors ，把 .class 文件设置关联成 jd 插件的 editor\n\n\n\n\n# Validate 优化\n\n我们在 eclipse 里经常看到这个进程，validating... 逐个的检查每一个文件。那么如何关闭一些 validate 操作呢？\n\n\n\n打开 eclipse，点击【window】菜单，选择【preferences】选项。\n\n\n\n在左侧点击【validation】选项，在右侧可以看到 eclipse 进行的自动检查都有哪些内容。\n\n\n\n将 Manual（手动）保持不动，将 build 里面只留下 classpath dependency Validator，其他的全部去掉。\n\n\n\n最后点击【OK】按钮，保存设置。\n\n\n\n以后如果需要对文件进行校验检查的时候，在文件上点击右键，点击【Validate】进行检查。\n\n\n# 常用快捷键\n\n快捷键                    描述\nCtrl+1                 快速修复（最经典的快捷键,就不用多说了，可以解决很多问题，比如 import 类、try catch 包围等）\nCtrl+Shift+F           格式化当前代码\nCtrl+Shift+M           添加类的 import 导入\nCtrl+Shift+O           组织类的 import 导入（既有 Ctrl+Shift+M 的作用，又可以帮你去除没用的导入，很有用）\nCtrl+Y                 重做（与撤销 Ctrl+Z 相反）\nAlt+/                  内容辅助（帮你省了多少次键盘敲打，太常用了）\nCtrl+D                 删除当前行或者多行\nAlt+↓                  当前行和下面一行交互位置（特别实用,可以省去先剪切,再粘贴了）\nAlt+↑                  当前行和上面一行交互位置（同上）\nCtrl+Alt+↓             复制当前行到下一行（复制增加）\nCtrl+Alt+↑             复制当前行到上一行（复制增加）\nShift+Enter            在当前行的下一行插入空行（这时鼠标可以在当前行的任一位置,不一定是最后）\nCtrl+/                 注释当前行,再按则取消注释\nAlt+Shift+↑            选择封装元素\nAlt+Shift+←            选择上一个元素\nAlt+Shift+→            选择下一个元素\nShift+←                从光标处开始往左选择字符\nShift+→                从光标处开始往右选择字符\nCtrl+Shift+←           选中光标左边的单词\nCtrl+Shift+→           选中光标又边的单词\nCtrl+←                 光标移到左边单词的开头，相当于 vim 的 b\nCtrl+→                 光标移到右边单词的末尾，相当于 vim 的 e\nCtrl+K                 参照选中的 Word 快速定位到下一个（如果没有选中 word，则搜索上一次使用搜索的 word）\nCtrl+Shift+K           参照选中的 Word 快速定位到上一个\nCtrl+J                 正向增量查找（按下 Ctrl+J\n                       后,你所输入的每个字母编辑器都提供快速匹配定位到某个单词,如果没有,则在状态栏中显示没有找到了,查一个单词时,特别实用,要退出这个模式，按\n                       escape 建）\nCtrl+Shift+J           反向增量查找（和上条相同,只不过是从后往前查）\nCtrl+Shift+U           列出所有包含字符串的行\nCtrl+H                 打开搜索对话框\nCtrl+G                 工作区中的声明\nCtrl+Shift+G           工作区中的引用\nCtrl+Shift+T           搜索类（包括工程和关联的第三 jar 包）\nCtrl+Shift+R           搜索工程中的文件\nCtrl+E                 快速显示当前 Editer 的下拉列表（如果当前页面没有显示的用黑体表示）\nF4                     打开类型层次结构\nF3                     跳转到声明处\nAlt+←                  前一个编辑的页面\nAlt+→                  下一个编辑的页面（当然是针对上面那条来说了）\nCtrl+PageUp/PageDown   在编辑器中，切换已经打开的文件\nF5                     单步跳入\nF6                     单步跳过\nF7                     单步返回\nF8                     继续\nCtrl+Shift+D           显示变量的值\nCtrl+Shift+B           在当前行设置或者去掉断点\nCtrl+R                 运行至行(超好用，可以节省好多的断点)\nAlt+Shift+R            重命名方法名、属性或者变量名 （是我自己最爱用的一个了,尤其是变量和类的 Rename,比手工方法能节省很多劳动力）\nAlt+Shift+M            把一段函数内的代码抽取成方法 （这是重构里面最常用的方法之一了,尤其是对一大堆泥团代码有用）\nAlt+Shift+C            修改函数结构（比较实用,有 N 个函数调用了这个方法,修改一次搞定）\nAlt+Shift+L            抽取本地变量（ 可以直接把一些魔法数字和字符串抽取成一个变量,尤其是多处调用的时候）\nAlt+Shift+F            把 Class 中的 local 变量变为 field 变量 （比较实用的功能）\nAlt+Shift+I            合并变量（可能这样说有点不妥 Inline）\nAlt+Shift+V            移动函数和变量（不怎么常用）\nAlt+Shift+Z            重构的后悔药（Undo）\nAlt+Enter              显示当前选择资源的属性，windows 下的查看文件的属性就是这个快捷键，通常用来查看文件在 windows\n                       中的实际路径\nCtrl+↑                 文本编辑器 上滚行\nCtrl+↓                 文本编辑器 下滚行\nCtrl+M                 最大化当前的 Edit 或 View （再按则反之）\nCtrl+O                 快速显示 OutLine\nCtrl+T                 快速显示当前类的继承结构\nCtrl+W                 关闭当前 Editer\nCtrl+L                 文本编辑器 转至行\nF2                     显示工具提示描述',normalizedContent:'# eclipse 快速入门\n\n\n# 代码智能提示\n\n\n# java 智能提示\n\nwindow -> preferences -> java -> editor -> content assist -> auto activation\n\n\n\ndelay 是自动弹出提示框的延时时间，我们可以修改成 100 毫秒；triggers 这里默认是"."，只要加上"abcdefghijklmnopqrstuvwxyz"或者"abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz"，嘿嘿！这下就能做到和 vs 一样的输入每个字母都能提示啦：\n\n\n\n其它类型的文件比如 html、javascript、jsp 如果也能提供提示那不是更爽了？有了第二点设置的基础，其实这些设置都是一样的。\n\n\n# javascript 智能提示\n\nwindow -> preferences -> javascript-> editor -> content assist -> auto-activation\n\n\n\n\n# html 智能提示\n\nwindow -> preferences -> web -> html files -> editor -> content assist -> auto-activation\n\n\n\n保存后，我们再来输入看看，感觉真是不错呀：\n\n\n\n\n# 插件安装\n\n很多教科书上说到 eclipse 的插件安装都是通过 help -> install new software 这种自动检索的方式，操作起来固然是方便，不过当我们不需要某种插件时不太容易找到要删除哪些内容，而且以后 eclipse 版本升级的时候，通过这种方式安装过的插件都得再重新装一次。另外一种通过 link 链接方式，就可以解决这些问题。\n\n我们以 eclipse 的中文汉化包插件为例，先到官方提供的汉化包地址下载一个：http://www.eclipse.org/babel/downloads.php，注意选好自己的 eclipse 版本：\n\n\n\n我的版本是 kepler，然后进入下载页面，单击红框框中的链接，即可下载汉化包了：\n\n\n\n下载完解压缩后，会有个包含 features 和 plugin 目录的 eclipse 文件夹，把这个 eclipse 放在我们的 eclipse 安装根目录，也就是和 eclipse.exe 同一级目录下。然后仍然在这一级目录下，新建一个 links 文件夹，并在该文件夹内，建一个 language.link 的文本文件。该文本文件的名字是可以任取的，后缀名是.link，而不是.txt 哟。好了，最后一步，编辑该文件，在里面写入刚才放入的语言包的地址，并用“\\”表示路径，一定要有 path= 这个前缀。\n\n\n\n保存文件后，重新打开 eclipse，熟悉的中文界面终于看到了。虽然汉化不完全，不过也够用了不是么。如果仍然出现的是英文，说明汉化失败，重新检查下 language.link 文件中配置的信息是否和汉化包的目录一致。　　其它的插件安装方法也是如此，当不需要某个插件时，只需删除存放插件的目录和 links 目录下相应的 link 文件，或者改变下 link 文件里面的路径变成无效路径即可；对 eclipse 做高版本升级时，也只需把老版存放插件的目录和 links 目录复制过去就行了。\n\n\n# 基本设置\n\n在 preference 的搜索项中搜索 text editors。 可以参考我的设置： show line numbers show print margin insert spaces for tabs\n\n设置代码的字体类型和大小：\n\nwindow -> preferences -> general -> appearance -> content assist -> colors and fornts，只需修改 basic 里面的 text font 就可以了。\n\n推荐 courier new。\n\n\n\n\n\n\n# 设置文本文件及 jsp 文件编码\n\nwindow -> preferences -> general -> workspace -> text file encoding -> other：\n\n\n\n\n\n\n# 设置 jdk 本地 javadoc api 路径及源码路径\n\n\n\n\n\n还都生成的是无意义的变量名，这样可能会对含有相同类型的变量参数的调用顺序造成干扰；\n\n这种问题，我们把 jdk 或者相应 jar 包的源码导入进去就能避免了：\n\nwindow -> preferences -> java -> installed jres -> edit：\n\n\n\n选中设置好的 jre 目录，编辑，然后全选 jre system libraries 下的所有 jar 包，点击右边的 source attachment；\n\n\n\nexternal location 下，选中 jdk 安装目录下的 src.zip 文件，一路 ok 下来。\n\n\n\n设置完，我们再来看看，幸福来的好突然有木有！\n\n\n\n\n# 设置 servlet 源码或其它 jar 包源码\n\n\n\n上一步已经设置过了 jdk 的源码或 javadoc 路径，为啥现在又出来了呢？其实这个不难理解，因为我们使用到的类的源码并不在 jdk 的源码包中。\n\n仔细看，我们会发现这些 jar 包其实都在 tomcat 根目录下的 lib 文件夹中，但是翻遍了 tomcat 目录也没有相应的 jar 或 zip 文件呀。既然本地没有，那就去官网上找找：\n\nhttp://tomcat.apache.org/download-70.cgi这里有tomcat的安装包和源码包；\n\n\n\n可以自定义一个专门用于存放 javasource 和 javadoc 的文件夹，把下载文件放到该目录下，\n\n然后再切换到 eclipse 下，选中没有代码提示的类或者函数， 按下 f3，点击 change attached source：\n\n\n\n选择我们刚才下载好的 tomcat 源码文件，一路 ok。\n\n\n\n然后再回过头看看我们的代码提示，友好多了：\n\n\n\n其它 jar 包源码的设置方式也一样。\n\n\n# 反编译插件 jd-eclipse\n\n无论是开发还是调试，反编译必不可少，每次都用 jd-gui 打开去看，多麻烦，干脆配置下 jd 插件，自动关联.class：\n\n先从 http://jd.benow.ca/ 上下载离线安装包 jdeclipse_update_site.zip，解压缩后把 features、plugins 这 2 个文件夹复制到 新建文件夹 jdeclipse，然后把 jdeclipse 文件夹整个复制到 eclipse 根目录的 dropins 文件夹下，重启 eclipse 即可。这种方式是不是比建 link 文件更方便了？\n\n\n\n打开 eclipse，window -> preferences -> general - > editors ，把 .class 文件设置关联成 jd 插件的 editor\n\n\n\n\n# validate 优化\n\n我们在 eclipse 里经常看到这个进程，validating... 逐个的检查每一个文件。那么如何关闭一些 validate 操作呢？\n\n\n\n打开 eclipse，点击【window】菜单，选择【preferences】选项。\n\n\n\n在左侧点击【validation】选项，在右侧可以看到 eclipse 进行的自动检查都有哪些内容。\n\n\n\n将 manual（手动）保持不动，将 build 里面只留下 classpath dependency validator，其他的全部去掉。\n\n\n\n最后点击【ok】按钮，保存设置。\n\n\n\n以后如果需要对文件进行校验检查的时候，在文件上点击右键，点击【validate】进行检查。\n\n\n# 常用快捷键\n\n快捷键                    描述\nctrl+1                 快速修复（最经典的快捷键,就不用多说了，可以解决很多问题，比如 import 类、try catch 包围等）\nctrl+shift+f           格式化当前代码\nctrl+shift+m           添加类的 import 导入\nctrl+shift+o           组织类的 import 导入（既有 ctrl+shift+m 的作用，又可以帮你去除没用的导入，很有用）\nctrl+y                 重做（与撤销 ctrl+z 相反）\nalt+/                  内容辅助（帮你省了多少次键盘敲打，太常用了）\nctrl+d                 删除当前行或者多行\nalt+↓                  当前行和下面一行交互位置（特别实用,可以省去先剪切,再粘贴了）\nalt+↑                  当前行和上面一行交互位置（同上）\nctrl+alt+↓             复制当前行到下一行（复制增加）\nctrl+alt+↑             复制当前行到上一行（复制增加）\nshift+enter            在当前行的下一行插入空行（这时鼠标可以在当前行的任一位置,不一定是最后）\nctrl+/                 注释当前行,再按则取消注释\nalt+shift+↑            选择封装元素\nalt+shift+←            选择上一个元素\nalt+shift+→            选择下一个元素\nshift+←                从光标处开始往左选择字符\nshift+→                从光标处开始往右选择字符\nctrl+shift+←           选中光标左边的单词\nctrl+shift+→           选中光标又边的单词\nctrl+←                 光标移到左边单词的开头，相当于 vim 的 b\nctrl+→                 光标移到右边单词的末尾，相当于 vim 的 e\nctrl+k                 参照选中的 word 快速定位到下一个（如果没有选中 word，则搜索上一次使用搜索的 word）\nctrl+shift+k           参照选中的 word 快速定位到上一个\nctrl+j                 正向增量查找（按下 ctrl+j\n                       后,你所输入的每个字母编辑器都提供快速匹配定位到某个单词,如果没有,则在状态栏中显示没有找到了,查一个单词时,特别实用,要退出这个模式，按\n                       escape 建）\nctrl+shift+j           反向增量查找（和上条相同,只不过是从后往前查）\nctrl+shift+u           列出所有包含字符串的行\nctrl+h                 打开搜索对话框\nctrl+g                 工作区中的声明\nctrl+shift+g           工作区中的引用\nctrl+shift+t           搜索类（包括工程和关联的第三 jar 包）\nctrl+shift+r           搜索工程中的文件\nctrl+e                 快速显示当前 editer 的下拉列表（如果当前页面没有显示的用黑体表示）\nf4                     打开类型层次结构\nf3                     跳转到声明处\nalt+←                  前一个编辑的页面\nalt+→                  下一个编辑的页面（当然是针对上面那条来说了）\nctrl+pageup/pagedown   在编辑器中，切换已经打开的文件\nf5                     单步跳入\nf6                     单步跳过\nf7                     单步返回\nf8                     继续\nctrl+shift+d           显示变量的值\nctrl+shift+b           在当前行设置或者去掉断点\nctrl+r                 运行至行(超好用，可以节省好多的断点)\nalt+shift+r            重命名方法名、属性或者变量名 （是我自己最爱用的一个了,尤其是变量和类的 rename,比手工方法能节省很多劳动力）\nalt+shift+m            把一段函数内的代码抽取成方法 （这是重构里面最常用的方法之一了,尤其是对一大堆泥团代码有用）\nalt+shift+c            修改函数结构（比较实用,有 n 个函数调用了这个方法,修改一次搞定）\nalt+shift+l            抽取本地变量（ 可以直接把一些魔法数字和字符串抽取成一个变量,尤其是多处调用的时候）\nalt+shift+f            把 class 中的 local 变量变为 field 变量 （比较实用的功能）\nalt+shift+i            合并变量（可能这样说有点不妥 inline）\nalt+shift+v            移动函数和变量（不怎么常用）\nalt+shift+z            重构的后悔药（undo）\nalt+enter              显示当前选择资源的属性，windows 下的查看文件的属性就是这个快捷键，通常用来查看文件在 windows\n                       中的实际路径\nctrl+↑                 文本编辑器 上滚行\nctrl+↓                 文本编辑器 下滚行\nctrl+m                 最大化当前的 edit 或 view （再按则反之）\nctrl+o                 快速显示 outline\nctrl+t                 快速显示当前类的继承结构\nctrl+w                 关闭当前 editer\nctrl+l                 文本编辑器 转至行\nf2                     显示工具提示描述',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Vscode 快速入门",frontmatter:{title:"Vscode 快速入门",categories:["编程","Java","软件","IDE"],tags:["Java","IDE"],abbrlink:"849a3ae4",date:"2019-05-14T14:57:33.000Z",permalink:"/pages/a537c7/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/02.IDE/03.VsCode.html",relativePath:"11.软件/02.IDE/03.VsCode.md",key:"v-69d50af2",path:"/pages/a537c7/",headers:[{level:2,title:"快捷键",slug:"快捷键",normalizedTitle:"快捷键",charIndex:18},{level:3,title:"命令面板（Command Palette）",slug:"命令面板-command-palette",normalizedTitle:"命令面板（command palette）",charIndex:26},{level:3,title:"快速打开文件（Quick Open）",slug:"快速打开文件-quick-open",normalizedTitle:"快速打开文件（quick open）",charIndex:134},{level:3,title:"Status Bar",slug:"status-bar",normalizedTitle:"status bar",charIndex:195},{level:3,title:"改变语言模式",slug:"改变语言模式",normalizedTitle:"改变语言模式",charIndex:260},{level:3,title:"设置",slug:"设置",normalizedTitle:"设置",charIndex:313},{level:2,title:"插件",slug:"插件",normalizedTitle:"插件",charIndex:391},{level:2,title:"更多内容",slug:"更多内容",normalizedTitle:"更多内容",charIndex:561}],headersStr:"快捷键 命令面板（Command Palette） 快速打开文件（Quick Open） Status Bar 改变语言模式 设置 插件 更多内容",content:"# Vscode 快速入门\n\n\n# 快捷键\n\n\n# 命令面板（Command Palette）\n\n根据您当前的上下文访问所有可用命令。\n\n> Mac: cmd+shift+p or f1 Windows / Linux: ctrl+shift+p or f1\n\n\n# 快速打开文件（Quick Open）\n\n> Mac: cmd+p Windows / Linux: ctrl+p\n\n\n# Status Bar\n\n> Mac: shift+cmd+m Windows / Linux: ctrl+shift+m\n\n\n# 改变语言模式\n\n> Mac: cmd+k m Windows / Linux: ctrl+k m\n\n\n# 设置\n\n> Mac: cmd+, Windows / Linux: File > Preferences > Settings or ctrl+,\n\n\n# 插件\n\n * Chinese (Simplified) Language Pack for Visual Studio Code\n * Prettier - Code formatter\n * IntelliJ IDEA Keybindings\n * EditorConfig for VS Code\n * Git History\n\n\n# 更多内容\n\n * 官方\n   * https://github.com/Microsoft/vscode\n   * https://github.com/Microsoft/vscode-docs\n   * https://github.com/Microsoft/vscode-tips-and-tricks\n * 更多资源\n   * https://github.com/viatsko/awesome-vscode",normalizedContent:"# vscode 快速入门\n\n\n# 快捷键\n\n\n# 命令面板（command palette）\n\n根据您当前的上下文访问所有可用命令。\n\n> mac: cmd+shift+p or f1 windows / linux: ctrl+shift+p or f1\n\n\n# 快速打开文件（quick open）\n\n> mac: cmd+p windows / linux: ctrl+p\n\n\n# status bar\n\n> mac: shift+cmd+m windows / linux: ctrl+shift+m\n\n\n# 改变语言模式\n\n> mac: cmd+k m windows / linux: ctrl+k m\n\n\n# 设置\n\n> mac: cmd+, windows / linux: file > preferences > settings or ctrl+,\n\n\n# 插件\n\n * chinese (simplified) language pack for visual studio code\n * prettier - code formatter\n * intellij idea keybindings\n * editorconfig for vs code\n * git history\n\n\n# 更多内容\n\n * 官方\n   * https://github.com/microsoft/vscode\n   * https://github.com/microsoft/vscode-docs\n   * https://github.com/microsoft/vscode-tips-and-tricks\n * 更多资源\n   * https://github.com/viatsko/awesome-vscode",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java IDE",frontmatter:{title:"Java IDE",categories:["编程","Java","软件","IDE"],tags:["Java","IDE"],abbrlink:"c44dd053",date:"2022-02-18T08:53:11.000Z",hidden:!0,permalink:"/pages/2df5ea/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/02.IDE/",relativePath:"11.软件/02.IDE/README.md",key:"v-f12e4400",path:"/pages/2df5ea/",headersStr:null,content:"# Java IDE\n\n> 自从有了 IDE，写代码从此就告别了刀耕火种的蛮荒时代。\n> \n>  * Eclipse 是久负盛名的开源 Java IDE，我的学生时代一直使用它写 Java。\n>  * 曾经抗拒从转 Intellij Idea ，但后来发现真香，不得不说，确实是目前最优秀的 Java IDE。\n>  * 你可以在 vscode 中写各种语言，只要安装相应插件即可。如果你的项目中使用了很多种编程语言，又懒得在多个 IDE 之间切换，那么就用 vscode 来一网打尽吧。\n\n * Intellij IDEA 快速入门\n * Eclipse 快速入门\n * Vscode 快速入门",normalizedContent:"# java ide\n\n> 自从有了 ide，写代码从此就告别了刀耕火种的蛮荒时代。\n> \n>  * eclipse 是久负盛名的开源 java ide，我的学生时代一直使用它写 java。\n>  * 曾经抗拒从转 intellij idea ，但后来发现真香，不得不说，确实是目前最优秀的 java ide。\n>  * 你可以在 vscode 中写各种语言，只要安装相应插件即可。如果你的项目中使用了很多种编程语言，又懒得在多个 ide 之间切换，那么就用 vscode 来一网打尽吧。\n\n * intellij idea 快速入门\n * eclipse 快速入门\n * vscode 快速入门",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"监控工具对比",frontmatter:{title:"监控工具对比",categories:["编程","Java","软件","监控诊断"],tags:["Java","监控"],abbrlink:"7331d4e5",date:"2020-02-11T17:48:32.000Z",permalink:"/pages/c7c5ec/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/03.%E7%9B%91%E6%8E%A7%E8%AF%8A%E6%96%AD/01.%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E5%AF%B9%E6%AF%94.html",relativePath:"11.软件/03.监控诊断/01.监控工具对比.md",key:"v-5d502cb7",path:"/pages/c7c5ec/",headers:[{level:2,title:"监控工具发展史",slug:"监控工具发展史",normalizedTitle:"监控工具发展史",charIndex:13},{level:2,title:"监控工具比对",slug:"监控工具比对",normalizedTitle:"监控工具比对",charIndex:27},{level:3,title:"特性对比",slug:"特性对比",normalizedTitle:"特性对比",charIndex:38},{level:3,title:"生态对比",slug:"生态对比",normalizedTitle:"生态对比",charIndex:49},{level:2,title:"技术选型",slug:"技术选型",normalizedTitle:"技术选型",charIndex:60},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:153}],headersStr:"监控工具发展史 监控工具比对 特性对比 生态对比 技术选型 参考资料",content:"# 监控工具对比\n\n\n# 监控工具发展史\n\n\n\n\n# 监控工具比对\n\n\n# 特性对比\n\n\n\n\n# 生态对比\n\n\n\n\n# 技术选型\n\n * Zipkin 欠缺 APM 报表能力，不推荐。\n * 企业级，推荐 CAT\n * 关注和试点 SkyWalking。\n\n用好调用链监控，需要订制化、自研能力。\n\n\n# 参考资料\n\nCAT、Zipkin 和 SkyWalking 该如何选型？",normalizedContent:"# 监控工具对比\n\n\n# 监控工具发展史\n\n\n\n\n# 监控工具比对\n\n\n# 特性对比\n\n\n\n\n# 生态对比\n\n\n\n\n# 技术选型\n\n * zipkin 欠缺 apm 报表能力，不推荐。\n * 企业级，推荐 cat\n * 关注和试点 skywalking。\n\n用好调用链监控，需要订制化、自研能力。\n\n\n# 参考资料\n\ncat、zipkin 和 skywalking 该如何选型？",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"CAT 快速入门",frontmatter:{title:"CAT 快速入门",categories:["编程","Java","软件","监控诊断"],tags:["Java","监控","CAT"],abbrlink:"9e5e43a8",date:"2020-02-11T17:48:32.000Z",permalink:"/pages/83e684/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/03.%E7%9B%91%E6%8E%A7%E8%AF%8A%E6%96%AD/02.CAT.html",relativePath:"11.软件/03.监控诊断/02.CAT.md",key:"v-1a600385",path:"/pages/83e684/",headers:[{level:2,title:"CAT 简介",slug:"cat-简介",normalizedTitle:"cat 简介",charIndex:15},{level:3,title:"CAT 的优势",slug:"cat-的优势",normalizedTitle:"cat 的优势",charIndex:244},{level:3,title:"支持的消息类型",slug:"支持的消息类型",normalizedTitle:"支持的消息类型",charIndex:494},{level:2,title:"CAT 部署",slug:"cat-部署",normalizedTitle:"cat 部署",charIndex:895},{level:2,title:"CAT 报表",slug:"cat-报表",normalizedTitle:"cat 报表",charIndex:945},{level:2,title:"CAT 配置",slug:"cat-配置",normalizedTitle:"cat 配置",charIndex:1256},{level:2,title:"CAT 架构",slug:"cat-架构",normalizedTitle:"cat 架构",charIndex:1390},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:1886}],headersStr:"CAT 简介 CAT 的优势 支持的消息类型 CAT 部署 CAT 报表 CAT 配置 CAT 架构 参考资料",content:"# CAT 快速入门\n\n\n# CAT 简介\n\nCAT（Central Application Tracking），是基于 Java 开发的分布式实时监控系统。CAT 在基础存储、高性能通信、大规模在线访问、服务治理、实时监控、容器化及集群智能调度等领域提供业界领先的、统一的解决方案。CAT 目前在美团的产品定位是应用层的统一监控组件，基本接入了美团所有核心应用，在中间件（RPC、数据库、缓存、MQ 等）框架中得到广泛应用，为各业务线提供系统的性能指标、健康状况、实时告警等。\n\n\n# CAT 的优势\n\n * 实时处理：信息的价值会随时间锐减，尤其是事故处理过程中\n * 全量数据：最开始的设计目标就是全量采集，全量的好处有很多\n * 高可用：所有应用都倒下了，需要监控还站着，并告诉工程师发生了什么，做到故障还原和问题定位\n * 故障容忍：CAT 本身故障不应该影响业务正常运转，CAT 挂了，应用不该受影响，只是监控能力暂时减弱\n * 高吞吐：要想还原真相，需要全方位地监控和度量，必须要有超强的处理吞吐能力\n * 可扩展：支持分布式、跨 IDC 部署，横向扩展的监控系统\n\n\n# 支持的消息类型\n\nCAT 监控系统将每次 URL、Service 的请求内部执行情况都封装为一个完整的消息树、消息树可能包括 Transaction、Event、Heartbeat、Metric 等信息。\n\n * Transaction 适合记录跨越系统边界的程序访问行为,比如远程调用，数据库调用，也适合执行时间较长的业务逻辑监控，Transaction 用来记录一段代码的执行时间和次数\n * Event 用来记录一件事发生的次数，比如记录系统异常，它和 transaction 相比缺少了时间的统计，开销比 transaction 要小\n * Heartbeat 表示程序内定期产生的统计信息, 如 CPU 利用率, 内存利用率, 连接池状态, 系统负载等\n * Metric 用于记录业务指标、指标可能包含对一个指标记录次数、记录平均值、记录总和，业务指标最低统计粒度为 1 分钟\n\n\n\n\n# CAT 部署\n\nCat 部署可以参考 官方 Wiki - 服务端部署 ，非常详细，不赘述。\n\n\n# CAT 报表\n\n与其他监控工具（如 Zipkin、SkyWalking）相比，CAT 的报表功能最丰富。支持以下报表类型：\n\n * Transaction 报表 - 一段代码运行时间、次数，比如 URL、Cache、SQL 执行次数和响应时间\n * Event 报表 - 一行代码运行次数，比如出现一个异常\n * Problem 报表 - 根据 Transaction/Event 数据分析出来系统可能出现的异常，包括访问较慢的程序等\n * Heartbeat 报表 - JVM 内部一些状态信息，比如 Memory，Thread 等\n * Business 报表 - 业务监控报表，比如订单指标，支付等业务指标\n\n\n# CAT 配置\n\nCAT 提供了以下配置：\n\n * 项目配置 包括项目基本信息、机器分组配置\n * 告警配置 包括基本告警配置、告警规则、以及具体告警配置\n * 全局配置 包括服务端配置、消息采样配置、客户端路由\n * 业务指标 包括业务监控配置、业务标签配置\n\n\n# CAT 架构\n\nCAT 主要分为三个模块：\n\n * cat-client - 提供给业务以及中间层埋点的底层 SDK。\n * cat-consumer - 用于实时分析从客户端的提供的数据。\n * cat-home - 作为用户提供给用户的展示的控制端。\n\n在实际开发和部署中，cat-consumer 和 cat-home 是部署在一个 jvm 内部，每个 CAT 服务端都可以作为 consumer 也可以作为 home，这样既能减少整个 CAT 层级结构，也可以增加整个系统稳定性。\n\n\n\n上图是 CAT 目前多机房的整体结构图：\n\n * 路由中心是根据应用所在机房信息来决定客户端上报的 CAT 服务端地址\n * 每个机房内部都有的独立的原始信息存储集群 HDFS\n * cat-home 可以部署在一个机房也可以部署在多个机房，在做报表展示的时候，cat-home 会从 cat-consumer 中进行跨机房的调用，将所有的数据合并展示给用户\n * 实际过程中，cat-consumer、cat-home 以及路由中心都是部署在一起，每个服务端节点都可以充当任何一个角色\n\n\n# 参考资料\n\n * CAT Github",normalizedContent:"# cat 快速入门\n\n\n# cat 简介\n\ncat（central application tracking），是基于 java 开发的分布式实时监控系统。cat 在基础存储、高性能通信、大规模在线访问、服务治理、实时监控、容器化及集群智能调度等领域提供业界领先的、统一的解决方案。cat 目前在美团的产品定位是应用层的统一监控组件，基本接入了美团所有核心应用，在中间件（rpc、数据库、缓存、mq 等）框架中得到广泛应用，为各业务线提供系统的性能指标、健康状况、实时告警等。\n\n\n# cat 的优势\n\n * 实时处理：信息的价值会随时间锐减，尤其是事故处理过程中\n * 全量数据：最开始的设计目标就是全量采集，全量的好处有很多\n * 高可用：所有应用都倒下了，需要监控还站着，并告诉工程师发生了什么，做到故障还原和问题定位\n * 故障容忍：cat 本身故障不应该影响业务正常运转，cat 挂了，应用不该受影响，只是监控能力暂时减弱\n * 高吞吐：要想还原真相，需要全方位地监控和度量，必须要有超强的处理吞吐能力\n * 可扩展：支持分布式、跨 idc 部署，横向扩展的监控系统\n\n\n# 支持的消息类型\n\ncat 监控系统将每次 url、service 的请求内部执行情况都封装为一个完整的消息树、消息树可能包括 transaction、event、heartbeat、metric 等信息。\n\n * transaction 适合记录跨越系统边界的程序访问行为,比如远程调用，数据库调用，也适合执行时间较长的业务逻辑监控，transaction 用来记录一段代码的执行时间和次数\n * event 用来记录一件事发生的次数，比如记录系统异常，它和 transaction 相比缺少了时间的统计，开销比 transaction 要小\n * heartbeat 表示程序内定期产生的统计信息, 如 cpu 利用率, 内存利用率, 连接池状态, 系统负载等\n * metric 用于记录业务指标、指标可能包含对一个指标记录次数、记录平均值、记录总和，业务指标最低统计粒度为 1 分钟\n\n\n\n\n# cat 部署\n\ncat 部署可以参考 官方 wiki - 服务端部署 ，非常详细，不赘述。\n\n\n# cat 报表\n\n与其他监控工具（如 zipkin、skywalking）相比，cat 的报表功能最丰富。支持以下报表类型：\n\n * transaction 报表 - 一段代码运行时间、次数，比如 url、cache、sql 执行次数和响应时间\n * event 报表 - 一行代码运行次数，比如出现一个异常\n * problem 报表 - 根据 transaction/event 数据分析出来系统可能出现的异常，包括访问较慢的程序等\n * heartbeat 报表 - jvm 内部一些状态信息，比如 memory，thread 等\n * business 报表 - 业务监控报表，比如订单指标，支付等业务指标\n\n\n# cat 配置\n\ncat 提供了以下配置：\n\n * 项目配置 包括项目基本信息、机器分组配置\n * 告警配置 包括基本告警配置、告警规则、以及具体告警配置\n * 全局配置 包括服务端配置、消息采样配置、客户端路由\n * 业务指标 包括业务监控配置、业务标签配置\n\n\n# cat 架构\n\ncat 主要分为三个模块：\n\n * cat-client - 提供给业务以及中间层埋点的底层 sdk。\n * cat-consumer - 用于实时分析从客户端的提供的数据。\n * cat-home - 作为用户提供给用户的展示的控制端。\n\n在实际开发和部署中，cat-consumer 和 cat-home 是部署在一个 jvm 内部，每个 cat 服务端都可以作为 consumer 也可以作为 home，这样既能减少整个 cat 层级结构，也可以增加整个系统稳定性。\n\n\n\n上图是 cat 目前多机房的整体结构图：\n\n * 路由中心是根据应用所在机房信息来决定客户端上报的 cat 服务端地址\n * 每个机房内部都有的独立的原始信息存储集群 hdfs\n * cat-home 可以部署在一个机房也可以部署在多个机房，在做报表展示的时候，cat-home 会从 cat-consumer 中进行跨机房的调用，将所有的数据合并展示给用户\n * 实际过程中，cat-consumer、cat-home 以及路由中心都是部署在一起，每个服务端节点都可以充当任何一个角色\n\n\n# 参考资料\n\n * cat github",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Zipkin 快速入门",frontmatter:{title:"Zipkin 快速入门",categories:["编程","Java","软件","监控诊断"],tags:["Java","监控","Zipkin"],abbrlink:"bed182d4",date:"2020-03-23T22:56:45.000Z",permalink:"/pages/82c168/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/03.%E7%9B%91%E6%8E%A7%E8%AF%8A%E6%96%AD/03.Zipkin.html",relativePath:"11.软件/03.监控诊断/03.Zipkin.md",key:"v-1a493fea",path:"/pages/82c168/",headers:[{level:2,title:"一、Zipkin 简介",slug:"一、zipkin-简介",normalizedTitle:"一、zipkin 简介",charIndex:308},{level:3,title:"特性",slug:"特性",normalizedTitle:"特性",charIndex:324},{level:3,title:"多平台",slug:"多平台",normalizedTitle:"多平台",charIndex:516},{level:3,title:"数据",slug:"数据",normalizedTitle:"数据",charIndex:46},{level:2,title:"二、Zipkin 安装",slug:"二、zipkin-安装",normalizedTitle:"二、zipkin 安装",charIndex:809},{level:3,title:"Docker",slug:"docker",normalizedTitle:"docker",charIndex:825},{level:3,title:"Java",slug:"java",normalizedTitle:"java",charIndex:28},{level:3,title:"编译方式",slug:"编译方式",normalizedTitle:"编译方式",charIndex:1014},{level:2,title:"三、Zipkin 架构",slug:"三、zipkin-架构",normalizedTitle:"三、zipkin 架构",charIndex:1307},{level:3,title:"Zipkin Server",slug:"zipkin-server",normalizedTitle:"zipkin server",charIndex:1468},{level:3,title:"Zipkin Client",slug:"zipkin-client",normalizedTitle:"zipkin client",charIndex:2035},{level:2,title:"四、Zipkin 客户端",slug:"四、zipkin-客户端",normalizedTitle:"四、zipkin 客户端",charIndex:5139},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:5297}],headersStr:"一、Zipkin 简介 特性 多平台 数据 二、Zipkin 安装 Docker Java 编译方式 三、Zipkin 架构 Zipkin Server Zipkin Client 四、Zipkin 客户端 参考资料",content:'# Zipkin 快速入门\n\nZipkin 是一个基于 Java 开发的、开源的、分布式实时数据跟踪系统（Distributed Tracking System）。它采集有助于解决服务架构中延迟问题的实时数据。\n\nZipkin 主要功能是聚集来自各个异构系统的实时监控数据。分布式跟踪系统还有其他比较成熟的实现，例如：Naver 的 Pinpoint、Apache 的 HTrace、阿里的鹰眼 Tracing、京东的 Hydra、新浪的 Watchman，美团点评的 CAT，skywalking 等。\n\nZipkin 基于 Google Dapper 的论文设计而来，由 Twitter 公司开发贡献。\n\n\n# 一、Zipkin 简介\n\n\n# 特性\n\n如果日志文件中有跟踪 ID，则可以直接跳至该跟踪 ID。 否则，您可以基于属性进行查询，例如服务，操作名称，标签和持续时间。 将为您总结一些有趣的数据，例如在服务中花费的时间百分比以及操作是否失败。\n\nZipkin UI 还提供了一个依赖关系图，该关系图显示了每个应用程序中跟踪了多少个请求。这对于识别聚合行为（包括错误路径或对不赞成使用的服务的调用）很有帮助。\n\n\n\n\n# 多平台\n\nZipkin 官方支持 C#、Go、Java、JavaScript、Ruby、Scala、PHP 语言。\n\n除此以外，社区还贡献了多种其他语言的支持，详情可以参考官方文档：Tracers and Instrumentation\n\n\n# 数据\n\nZipkin 服务器捆绑了用于采集和存储数据的扩展。\n\n默认情况下，数据可以通过 Http，Kafka 、RabbitMQ 或 RPC 传输。\n\n并存储在内存中或 MySQL、Cassandra 或 Elasticsearch 中。\n\n数据以 json 形式存储，可以参考：Zipkin 官方的 Swagger API\n\n\n\n\n# 二、Zipkin 安装\n\n\n# Docker\n\nDocker 启动方式：\n\ndocker run -d -p 9411:9411 openzipkin/zipkin\n\n\n\n# Java\n\n> 注意：必须运行在 JDK8+ 环境\n\nJava 启动方式：\n\ncurl -sSL https://zipkin.io/quickstart.sh | bash -s\njava -jar zipkin.jar\n\n\n\n# 编译方式\n\n适用于需要订制化的场景。\n\n# get the latest source\ngit clone https://github.com/openzipkin/zipkin\ncd zipkin\n# Build the server and also make its dependencies\n./mvnw -DskipTests --also-make -pl zipkin-server clean install\n# Run the server\njava -jar ./zipkin-server/target/zipkin-server-*exec.jar\n\n\n\n# 三、Zipkin 架构\n\nZipKin 可以分为两部分，\n\n * 一部分是 Zipkin server，用来作为数据的采集存储、数据分析与展示；\n * 另一部分是 Zipkin client 是 Zipkin 基于不同的语言及框架封装的一些列客户端工具，这些工具完成了追踪数据的生成与上报功能。\n\n架构如下：\n\n\n\n\n# Zipkin Server\n\nZipkin Server 主要包括四个模块：\n\n * Collector - 负责采集客户端传输的数据。\n * Storage - 负责存储采集的数据。当前支持 Memory，MySQL，Cassandra，ElasticSearch 等，默认存储在内存中。\n * API（Query） - 负责查询 Storage 中存储的数据。提供简单的 JSON API 获取数据，主要提供给 web UI 使用。\n * UI - 提供简单的 web 界面。\n\nInstrumented Client 和 Instrumented Server，是指分布式架构中使用了 Trace 工具的两个应用，Client 会调用 Server 提供的服务，两者都会向 Zipkin 上报 Trace 相关信息。在 Client 和 Server 通过 Transport 上报 Trace 信息后，由 Zipkin 的 Collector 模块接收，并由 Storage 模块将数据存储在对应的存储介质中，然后 Zipkin 提供 API 供 UI 界面查询 Trace 跟踪信息。Non-Instrumented Server，指的是未使用 Trace 工具的 Server，显然它不会上报 Trace 信息。\n\n\n# Zipkin Client\n\n * Tracer - Tracer 存在于你的应用中，它负责采集关于已发生操作的实时元数据。它们通常会检测库，因此对于用户是透明的。例如，已检测的 Web 服务器记录它何时接收到请求，以及何时发送响应。收集的跟踪数据称为跨度（Span）。\n * Instrumentation - Instrumentation 保证了生产环境的安全性和很少的开销。因此，它们仅在内部传播 ID，以告知接收方正在进行追踪。完成的 Span 将通过外部通信告知 Zipkin，类似于应用程序异步报告指标的方式。例如，当跟踪某个操作并且需要发出 http 请求时，会添加一些 header 来传播 ID。header 不用于发送详细信息，例如操作名称。\n * Reporter - 能够将数据发送到 Zipkin 的检测应用程序中的组件，被称为 Reporter。Reporter 有多种传输方式，可以将跟踪数据发送到 Zipkin 采集器，后者将跟踪数据持久化保存到存储中。稍后，API 会查询存储以向 UI 提供渲染数据。\n\n以下是 Zipkin 的一个示例工作流：\n\n┌─────────────┐ ┌───────────────────────┐  ┌─────────────┐  ┌──────────────────┐\n│ User Code   │ │ Trace Instrumentation │  │ Http Client │  │ Zipkin Collector │\n└─────────────┘ └───────────────────────┘  └─────────────┘  └──────────────────┘\n       │                 │                         │                 │\n           ┌─────────┐\n       │ ──┤GET /foo ├─▶ │ ────┐                   │                 │\n           └─────────┘         │ record tags\n       │                 │ ◀───┘                   │                 │\n                           ────┐\n       │                 │     │ add trace headers │                 │\n                           ◀───┘\n       │                 │ ────┐                   │                 │\n                               │ record timestamp\n       │                 │ ◀───┘                   │                 │\n                             ┌─────────────────┐\n       │                 │ ──┤GET /foo         ├─▶ │                 │\n                             │X-B3-TraceId: aa │     ────┐\n       │                 │   │X-B3-SpanId: 6b  │   │     │           │\n                             └─────────────────┘         │ invoke\n       │                 │                         │     │ request   │\n                                                         │\n       │                 │                         │     │           │\n                                 ┌────────┐          ◀───┘\n       │                 │ ◀─────┤200 OK  ├─────── │                 │\n                           ────┐ └────────┘\n       │                 │     │ record duration   │                 │\n            ┌────────┐     ◀───┘\n       │ ◀──┤200 OK  ├── │                         │                 │\n            └────────┘       ┌────────────────────────────────┐\n       │                 │ ──┤ asynchronously report span     ├────▶ │\n                             │                                │\n                             │{                               │\n                             │  "traceId": "aa",              │\n                             │  "id": "6b",                   │\n                             │  "name": "get",                │\n                             │  "timestamp": 1483945573944000,│\n                             │  "duration": 386000,           │\n                             │  "annotations": [              │\n                             │--snip--                        │\n                             └────────────────────────────────┘\n\n\nInstrumented client 和 server 是分别使用了 ZipKin Client 的服务，Zipkin Client 会根据配置将追踪数据发送到 Zipkin Server 中进行数据存储、分析和展示。\n\n\n# 四、Zipkin 客户端\n\nBrave 是 Java 版的 zipkin 客户端。\n\n一般不会手动编写 Trace 相关的代码，Brave 提供可一些开箱即用的库，帮助我们追踪一些特定的请求。比如：dubbo、grpc、servlet、mysql、httpClient、kafka、springMVC 等。\n\n\n# 参考资料\n\n * Zipkin 官网\n * Zipkin Github\n * brave',normalizedContent:'# zipkin 快速入门\n\nzipkin 是一个基于 java 开发的、开源的、分布式实时数据跟踪系统（distributed tracking system）。它采集有助于解决服务架构中延迟问题的实时数据。\n\nzipkin 主要功能是聚集来自各个异构系统的实时监控数据。分布式跟踪系统还有其他比较成熟的实现，例如：naver 的 pinpoint、apache 的 htrace、阿里的鹰眼 tracing、京东的 hydra、新浪的 watchman，美团点评的 cat，skywalking 等。\n\nzipkin 基于 google dapper 的论文设计而来，由 twitter 公司开发贡献。\n\n\n# 一、zipkin 简介\n\n\n# 特性\n\n如果日志文件中有跟踪 id，则可以直接跳至该跟踪 id。 否则，您可以基于属性进行查询，例如服务，操作名称，标签和持续时间。 将为您总结一些有趣的数据，例如在服务中花费的时间百分比以及操作是否失败。\n\nzipkin ui 还提供了一个依赖关系图，该关系图显示了每个应用程序中跟踪了多少个请求。这对于识别聚合行为（包括错误路径或对不赞成使用的服务的调用）很有帮助。\n\n\n\n\n# 多平台\n\nzipkin 官方支持 c#、go、java、javascript、ruby、scala、php 语言。\n\n除此以外，社区还贡献了多种其他语言的支持，详情可以参考官方文档：tracers and instrumentation\n\n\n# 数据\n\nzipkin 服务器捆绑了用于采集和存储数据的扩展。\n\n默认情况下，数据可以通过 http，kafka 、rabbitmq 或 rpc 传输。\n\n并存储在内存中或 mysql、cassandra 或 elasticsearch 中。\n\n数据以 json 形式存储，可以参考：zipkin 官方的 swagger api\n\n\n\n\n# 二、zipkin 安装\n\n\n# docker\n\ndocker 启动方式：\n\ndocker run -d -p 9411:9411 openzipkin/zipkin\n\n\n\n# java\n\n> 注意：必须运行在 jdk8+ 环境\n\njava 启动方式：\n\ncurl -ssl https://zipkin.io/quickstart.sh | bash -s\njava -jar zipkin.jar\n\n\n\n# 编译方式\n\n适用于需要订制化的场景。\n\n# get the latest source\ngit clone https://github.com/openzipkin/zipkin\ncd zipkin\n# build the server and also make its dependencies\n./mvnw -dskiptests --also-make -pl zipkin-server clean install\n# run the server\njava -jar ./zipkin-server/target/zipkin-server-*exec.jar\n\n\n\n# 三、zipkin 架构\n\nzipkin 可以分为两部分，\n\n * 一部分是 zipkin server，用来作为数据的采集存储、数据分析与展示；\n * 另一部分是 zipkin client 是 zipkin 基于不同的语言及框架封装的一些列客户端工具，这些工具完成了追踪数据的生成与上报功能。\n\n架构如下：\n\n\n\n\n# zipkin server\n\nzipkin server 主要包括四个模块：\n\n * collector - 负责采集客户端传输的数据。\n * storage - 负责存储采集的数据。当前支持 memory，mysql，cassandra，elasticsearch 等，默认存储在内存中。\n * api（query） - 负责查询 storage 中存储的数据。提供简单的 json api 获取数据，主要提供给 web ui 使用。\n * ui - 提供简单的 web 界面。\n\ninstrumented client 和 instrumented server，是指分布式架构中使用了 trace 工具的两个应用，client 会调用 server 提供的服务，两者都会向 zipkin 上报 trace 相关信息。在 client 和 server 通过 transport 上报 trace 信息后，由 zipkin 的 collector 模块接收，并由 storage 模块将数据存储在对应的存储介质中，然后 zipkin 提供 api 供 ui 界面查询 trace 跟踪信息。non-instrumented server，指的是未使用 trace 工具的 server，显然它不会上报 trace 信息。\n\n\n# zipkin client\n\n * tracer - tracer 存在于你的应用中，它负责采集关于已发生操作的实时元数据。它们通常会检测库，因此对于用户是透明的。例如，已检测的 web 服务器记录它何时接收到请求，以及何时发送响应。收集的跟踪数据称为跨度（span）。\n * instrumentation - instrumentation 保证了生产环境的安全性和很少的开销。因此，它们仅在内部传播 id，以告知接收方正在进行追踪。完成的 span 将通过外部通信告知 zipkin，类似于应用程序异步报告指标的方式。例如，当跟踪某个操作并且需要发出 http 请求时，会添加一些 header 来传播 id。header 不用于发送详细信息，例如操作名称。\n * reporter - 能够将数据发送到 zipkin 的检测应用程序中的组件，被称为 reporter。reporter 有多种传输方式，可以将跟踪数据发送到 zipkin 采集器，后者将跟踪数据持久化保存到存储中。稍后，api 会查询存储以向 ui 提供渲染数据。\n\n以下是 zipkin 的一个示例工作流：\n\n┌─────────────┐ ┌───────────────────────┐  ┌─────────────┐  ┌──────────────────┐\n│ user code   │ │ trace instrumentation │  │ http client │  │ zipkin collector │\n└─────────────┘ └───────────────────────┘  └─────────────┘  └──────────────────┘\n       │                 │                         │                 │\n           ┌─────────┐\n       │ ──┤get /foo ├─▶ │ ────┐                   │                 │\n           └─────────┘         │ record tags\n       │                 │ ◀───┘                   │                 │\n                           ────┐\n       │                 │     │ add trace headers │                 │\n                           ◀───┘\n       │                 │ ────┐                   │                 │\n                               │ record timestamp\n       │                 │ ◀───┘                   │                 │\n                             ┌─────────────────┐\n       │                 │ ──┤get /foo         ├─▶ │                 │\n                             │x-b3-traceid: aa │     ────┐\n       │                 │   │x-b3-spanid: 6b  │   │     │           │\n                             └─────────────────┘         │ invoke\n       │                 │                         │     │ request   │\n                                                         │\n       │                 │                         │     │           │\n                                 ┌────────┐          ◀───┘\n       │                 │ ◀─────┤200 ok  ├─────── │                 │\n                           ────┐ └────────┘\n       │                 │     │ record duration   │                 │\n            ┌────────┐     ◀───┘\n       │ ◀──┤200 ok  ├── │                         │                 │\n            └────────┘       ┌────────────────────────────────┐\n       │                 │ ──┤ asynchronously report span     ├────▶ │\n                             │                                │\n                             │{                               │\n                             │  "traceid": "aa",              │\n                             │  "id": "6b",                   │\n                             │  "name": "get",                │\n                             │  "timestamp": 1483945573944000,│\n                             │  "duration": 386000,           │\n                             │  "annotations": [              │\n                             │--snip--                        │\n                             └────────────────────────────────┘\n\n\ninstrumented client 和 server 是分别使用了 zipkin client 的服务，zipkin client 会根据配置将追踪数据发送到 zipkin server 中进行数据存储、分析和展示。\n\n\n# 四、zipkin 客户端\n\nbrave 是 java 版的 zipkin 客户端。\n\n一般不会手动编写 trace 相关的代码，brave 提供可一些开箱即用的库，帮助我们追踪一些特定的请求。比如：dubbo、grpc、servlet、mysql、httpclient、kafka、springmvc 等。\n\n\n# 参考资料\n\n * zipkin 官网\n * zipkin github\n * brave',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"SkyWalking 快速入门",frontmatter:{title:"SkyWalking 快速入门",categories:["编程","Java","软件","监控诊断"],tags:["Java","监控","SkyWalking"],abbrlink:"a6f15946",date:"2020-02-07T23:04:47.000Z",permalink:"/pages/d82d3c/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/03.%E7%9B%91%E6%8E%A7%E8%AF%8A%E6%96%AD/04.Skywalking.html",relativePath:"11.软件/03.监控诊断/04.Skywalking.md",key:"v-19f95e8b",path:"/pages/d82d3c/",headers:[{level:2,title:"一、SkyWalking 简介",slug:"一、skywalking-简介",normalizedTitle:"一、skywalking 简介",charIndex:106},{level:3,title:"SkyWalking 特性",slug:"skywalking-特性",normalizedTitle:"skywalking 特性",charIndex:194},{level:3,title:"SkyWalking 核心概念",slug:"skywalking-核心概念",normalizedTitle:"skywalking 核心概念",charIndex:337},{level:2,title:"二、SkyWalking 架构",slug:"二、skywalking-架构",normalizedTitle:"二、skywalking 架构",charIndex:569},{level:2,title:"三、SkyWalking 安装",slug:"三、skywalking-安装",normalizedTitle:"三、skywalking 安装",charIndex:1028},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:1177}],headersStr:"一、SkyWalking 简介 SkyWalking 特性 SkyWalking 核心概念 二、SkyWalking 架构 三、SkyWalking 安装 参考资料",content:"# SkyWalking 快速入门\n\nSkyWalking 是一个基于 Java 开发的分布式系统的应用程序性能监视工具，专为微服务、云原生架构和基于容器（Docker、K8s、Mesos）架构而设计。\n\n\n# 一、SkyWalking 简介\n\nSkyWalking 是观察性分析平台和应用性能管理系统。\n\n提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案。\n\n\n\n\n# SkyWalking 特性\n\n * 多种监控手段，语言探针和 service mesh\n * 多语言自动探针，Java，.NET Core 和 Node.JS\n * 轻量高效，不需要大数据\n * 模块化，UI、存储、集群管理多种机制可选\n * 支持告警\n * 优秀的可视化方案\n\n\n# SkyWalking 核心概念\n\n * Service - 服务。代表一组为传入请求提供相同的行为的工作负载。 使用代理或 SDK 时，可以定义服务名称。\n * Service Instance - 服务实例。服务组中的每个工作负载都称为一个实例。就像 Kubernetes 中的 Pod 一样，它在 OS 中不必是单个进程。\n * Endpoint - 端点。它是特定服务中用于传入请求的路径，例如 HTTP URI 路径或 RPC 服务类+方法签名。\n\n\n# 二、SkyWalking 架构\n\n从逻辑上讲，SkyWalking 分为四个部分：探针（Probes），平台后端，存储和 UI。\n\n\n\n * 探针（Probes） - 探针是指集成到目标系统中的代理或 SDK 库。它们负责收集数据（包括跟踪数据和统计数据）并将其按照 SkyWalking 的要求重新格式化为。\n * 平台后端 - 平台后端是一个提供后端服务的集群。它用于聚合、分析和驱动从探针到 UI 的流程。它还为传入格式（如 Zipkin 的格式），存储实现程序和集群管理提供可插入功能。 您甚至可以使用 Observability Analysis Language 自定义聚合和分析。\n * 存储 - 您可以选择一个 SkyWalking 已实现的存储，如由 Sharding-Sphere 管理的 ElasticSearch，H2 或 MySQL 集群，也可以自行实现一个存储。\n * UI - 用户界面很酷，对于 SkyWalking 最终用户而言非常强大。它也可以自定义以匹配您的自定义后端。\n\n\n# 三、SkyWalking 安装\n\n进入 Apache SkyWalking 官方下载页面，选择安装版本，下载解压到本地。\n\n\n\n安装分为三个部分：\n\n * Backend setup document\n * UI setup document\n * CLI set up document\n\n\n# 参考资料\n\n * SkyWalking Github",normalizedContent:"# skywalking 快速入门\n\nskywalking 是一个基于 java 开发的分布式系统的应用程序性能监视工具，专为微服务、云原生架构和基于容器（docker、k8s、mesos）架构而设计。\n\n\n# 一、skywalking 简介\n\nskywalking 是观察性分析平台和应用性能管理系统。\n\n提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案。\n\n\n\n\n# skywalking 特性\n\n * 多种监控手段，语言探针和 service mesh\n * 多语言自动探针，java，.net core 和 node.js\n * 轻量高效，不需要大数据\n * 模块化，ui、存储、集群管理多种机制可选\n * 支持告警\n * 优秀的可视化方案\n\n\n# skywalking 核心概念\n\n * service - 服务。代表一组为传入请求提供相同的行为的工作负载。 使用代理或 sdk 时，可以定义服务名称。\n * service instance - 服务实例。服务组中的每个工作负载都称为一个实例。就像 kubernetes 中的 pod 一样，它在 os 中不必是单个进程。\n * endpoint - 端点。它是特定服务中用于传入请求的路径，例如 http uri 路径或 rpc 服务类+方法签名。\n\n\n# 二、skywalking 架构\n\n从逻辑上讲，skywalking 分为四个部分：探针（probes），平台后端，存储和 ui。\n\n\n\n * 探针（probes） - 探针是指集成到目标系统中的代理或 sdk 库。它们负责收集数据（包括跟踪数据和统计数据）并将其按照 skywalking 的要求重新格式化为。\n * 平台后端 - 平台后端是一个提供后端服务的集群。它用于聚合、分析和驱动从探针到 ui 的流程。它还为传入格式（如 zipkin 的格式），存储实现程序和集群管理提供可插入功能。 您甚至可以使用 observability analysis language 自定义聚合和分析。\n * 存储 - 您可以选择一个 skywalking 已实现的存储，如由 sharding-sphere 管理的 elasticsearch，h2 或 mysql 集群，也可以自行实现一个存储。\n * ui - 用户界面很酷，对于 skywalking 最终用户而言非常强大。它也可以自定义以匹配您的自定义后端。\n\n\n# 三、skywalking 安装\n\n进入 apache skywalking 官方下载页面，选择安装版本，下载解压到本地。\n\n\n\n安装分为三个部分：\n\n * backend setup document\n * ui setup document\n * cli set up document\n\n\n# 参考资料\n\n * skywalking github",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Arthas 快速入门",frontmatter:{title:"Arthas 快速入门",categories:["编程","Java","软件","监控诊断"],tags:["Java","诊断","Arthas"],abbrlink:"e60b19c0",date:"2020-02-07T23:04:47.000Z",permalink:"/pages/b6a542/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/03.%E7%9B%91%E6%8E%A7%E8%AF%8A%E6%96%AD/05.Arthas.html",relativePath:"11.软件/03.监控诊断/05.Arthas.md",key:"v-46ed506a",path:"/pages/b6a542/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:54},{level:2,title:"安装",slug:"安装",normalizedTitle:"安装",charIndex:376},{level:3,title:"使用arthas-boot（推荐）",slug:"使用arthas-boot-推荐",normalizedTitle:"使用arthas-boot（推荐）",charIndex:383},{level:3,title:"使用as.sh",slug:"使用as-sh",normalizedTitle:"使用as.sh",charIndex:756},{level:3,title:"全量安装",slug:"全量安装",normalizedTitle:"全量安装",charIndex:1097},{level:2,title:"基础使用",slug:"基础使用",normalizedTitle:"基础使用",charIndex:1236},{level:3,title:"启动 Demo",slug:"启动-demo",normalizedTitle:"启动 demo",charIndex:1245},{level:3,title:"启动 arthas",slug:"启动-arthas",normalizedTitle:"启动 arthas",charIndex:1410},{level:3,title:"查看 dashboard",slug:"查看-dashboard",normalizedTitle:"查看 dashboard",charIndex:2510},{level:3,title:"通过 thread 命令来获取到arthas-demo进程的 Main Class",slug:"通过-thread-命令来获取到arthas-demo进程的-main-class",normalizedTitle:"通过 thread 命令来获取到arthas-demo进程的 main class",charIndex:4594},{level:3,title:"通过 jad 来反编译 Main Class",slug:"通过-jad-来反编译-main-class",normalizedTitle:"通过 jad 来反编译 main class",charIndex:4751},{level:3,title:"watch",slug:"watch",normalizedTitle:"watch",charIndex:6952},{level:3,title:"退出 arthas",slug:"退出-arthas",normalizedTitle:"退出 arthas",charIndex:7824},{level:2,title:"进阶使用",slug:"进阶使用",normalizedTitle:"进阶使用",charIndex:7814},{level:3,title:"基础命令",slug:"基础命令",normalizedTitle:"基础命令",charIndex:7959},{level:3,title:"jvm 相关",slug:"jvm-相关",normalizedTitle:"jvm 相关",charIndex:8332},{level:3,title:"class/classloader 相关",slug:"class-classloader-相关",normalizedTitle:"class/classloader 相关",charIndex:8653},{level:3,title:"monitor/watch/trace 相关",slug:"monitor-watch-trace-相关",normalizedTitle:"monitor/watch/trace 相关",charIndex:8931},{level:3,title:"options",slug:"options",normalizedTitle:"options",charIndex:9236},{level:3,title:"管道",slug:"管道",normalizedTitle:"管道",charIndex:9279},{level:3,title:"后台异步任务",slug:"后台异步任务",normalizedTitle:"后台异步任务",charIndex:9428},{level:3,title:"Web Console",slug:"web-console",normalizedTitle:"web console",charIndex:9646},{level:3,title:"用户数据回报",slug:"用户数据回报",normalizedTitle:"用户数据回报",charIndex:9703},{level:3,title:"其他特性",slug:"其他特性",normalizedTitle:"其他特性",charIndex:9909},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:9967}],headersStr:"简介 安装 使用arthas-boot（推荐） 使用as.sh 全量安装 基础使用 启动 Demo 启动 arthas 查看 dashboard 通过 thread 命令来获取到arthas-demo进程的 Main Class 通过 jad 来反编译 Main Class watch 退出 arthas 进阶使用 基础命令 jvm 相关 class/classloader 相关 monitor/watch/trace 相关 options 管道 后台异步任务 Web Console 用户数据回报 其他特性 参考资料",content:"# Arthas 快速入门\n\n> Arthas 是 Alibaba 开源的 Java 诊断工具 。\n\n\n# 简介\n\nArthas可以解决的问题：\n\n 1. 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？\n 2. 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？\n 3. 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？\n 4. 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！\n 5. 是否有一个全局视角来查看系统的运行状况？\n 6. 有什么办法可以监控到 JVM 的实时运行状态？\n\nArthas支持 JDK 6+，支持 Linux/Mac/Windows，采用命令行交互模式，同时提供丰富的 Tab 自动补全功能，进一步方便进行问题的定位和诊断。\n\n\n# 安装\n\n\n# 使用arthas-boot（推荐）\n\n下载arthas-boot.jar，然后用java -jar的方式启动：\n\nwget https://alibaba.github.io/arthas/arthas-boot.jar\njava -jar arthas-boot.jar\n\n\n打印帮助信息：\n\njava -jar arthas-boot.jar -h\n\n\n * 如果下载速度比较慢，可以使用 aliyun 的镜像：\n   \n   java -jar arthas-boot.jar --repo-mirror aliyun --use-http\n   \n\n * 如果从 github 下载有问题，可以使用 gitee 镜像\n   \n   wget https://arthas.gitee.io/arthas-boot.jar\n   \n\n\n# 使用as.sh\n\nArthas 支持在 Linux/Unix/Mac 等平台上一键安装，请复制以下内容，并粘贴到命令行中，敲 回车 执行即可：\n\ncurl -L https://alibaba.github.io/arthas/install.sh | sh\n\n\n上述命令会下载启动脚本文件 as.sh 到当前目录，你可以放在任何地方或将其加入到 $PATH 中。\n\n直接在 shell 下面执行./as.sh，就会进入交互界面。\n\n也可以执行./as.sh -h来获取更多参数信息。\n\n * 如果从 github 下载有问题，可以使用 gitee 镜像\n   \n   curl -L https://arthas.gitee.io/install.sh | sh\n   \n\n\n# 全量安装\n\n最新版本，点击下载：下载地址\n\n解压后，在文件夹里有arthas-boot.jar，直接用java -jar的方式启动：\n\njava -jar arthas-boot.jar\n\n\n打印帮助信息：\n\njava -jar arthas-boot.jar -h\n\n\n\n# 基础使用\n\n\n# 启动 Demo\n\nwget https://alibaba.github.io/arthas/arthas-demo.jar\njava -jar arthas-demo.jar\n\n\narthas-demo是一个简单的程序，每隔一秒生成一个随机数，再执行质因式分解，并打印出分解结果。\n\narthas-demo源代码：查看\n\n\n# 启动 arthas\n\n在命令行下面执行（使用和目标进程一致的用户启动，否则可能 attach 失败）：\n\nwget https://alibaba.github.io/arthas/arthas-boot.jar\njava -jar arthas-boot.jar\n\n\n * 执行该程序的用户需要和目标进程具有相同的权限。比如以admin用户来执行：sudo su admin && java -jar arthas-boot.jar 或 sudo -u admin -EH java -jar arthas-boot.jar。\n * 如果 attach 不上目标进程，可以查看~/logs/arthas/ 目录下的日志。\n * 如果下载速度比较慢，可以使用 aliyun 的镜像：java -jar arthas-boot.jar --repo-mirror aliyun --use-http\n * java -jar arthas-boot.jar -h 打印更多参数信息。\n\n选择应用 java 进程：\n\n$ $ java -jar arthas-boot.jar\n* [1]: 35542\n  [2]: 71560 arthas-demo.jar\n\n\nDemo 进程是第 2 个，则输入 2，再输入回车/enter。Arthas 会 attach 到目标进程上，并输出日志：\n\n[INFO] Try to attach process 71560\n[INFO] Attach process 71560 success.\n[INFO] arthas-client connect 127.0.0.1 3658\n  ,---.  ,------. ,--------.,--.  ,--.  ,---.   ,---.\n /  O  \\ |  .--. ''--.  .--'|  '--'  | /  O  \\ '   .-'\n|  .-.  ||  '--'.'   |  |   |  .--.  ||  .-.  |`.  `-.\n|  | |  ||  |\\  \\    |  |   |  |  |  ||  | |  |.-'    |\n`--' `--'`--' '--'   `--'   `--'  `--'`--' `--'`-----'\n\nwiki: https://alibaba.github.io/arthas\nversion: 3.0.5.20181127201536\npid: 71560\ntime: 2018-11-28 19:16:24\n\n$\n\n\n\n# 查看 dashboard\n\n输入dashboard，按回车/enter，会展示当前进程的信息，按ctrl+c可以中断执行。\n\n$ dashboard\nID     NAME                   GROUP          PRIORI STATE  %CPU    TIME   INTERRU DAEMON\n17     pool-2-thread-1        system         5      WAITIN 67      0:0    false   false\n27     Timer-for-arthas-dashb system         10     RUNNAB 32      0:0    false   true\n11     AsyncAppender-Worker-a system         9      WAITIN 0       0:0    false   true\n9      Attach Listener        system         9      RUNNAB 0       0:0    false   true\n3      Finalizer              system         8      WAITIN 0       0:0    false   true\n2      Reference Handler      system         10     WAITIN 0       0:0    false   true\n4      Signal Dispatcher      system         9      RUNNAB 0       0:0    false   true\n26     as-command-execute-dae system         10     TIMED_ 0       0:0    false   true\n13     job-timeout            system         9      TIMED_ 0       0:0    false   true\n1      main                   main           5      TIMED_ 0       0:0    false   false\n14     nioEventLoopGroup-2-1  system         10     RUNNAB 0       0:0    false   false\n18     nioEventLoopGroup-2-2  system         10     RUNNAB 0       0:0    false   false\n23     nioEventLoopGroup-2-3  system         10     RUNNAB 0       0:0    false   false\n15     nioEventLoopGroup-3-1  system         10     RUNNAB 0       0:0    false   false\nMemory             used   total max    usage GC\nheap               32M    155M  1820M  1.77% gc.ps_scavenge.count  4\nps_eden_space      14M    65M   672M   2.21% gc.ps_scavenge.time(m 166\nps_survivor_space  4M     5M    5M           s)\nps_old_gen         12M    85M   1365M  0.91% gc.ps_marksweep.count 0\nnonheap            20M    23M   -1           gc.ps_marksweep.time( 0\ncode_cache         3M     5M    240M   1.32% ms)\nRuntime\nos.name                Mac OS X\nos.version             10.13.4\njava.version           1.8.0_162\njava.home              /Library/Java/JavaVir\n                       tualMachines/jdk1.8.0\n                       _162.jdk/Contents/Hom\n                       e/jre\n\n\n\n# 通过 thread 命令来获取到arthas-demo进程的 Main Class\n\nthread 1会打印线程 ID 1 的栈，通常是 main 函数的线程。\n\n$ thread 1 | grep 'main('\n    at demo.MathGame.main(MathGame.java:17)\n\n\n\n# 通过 jad 来反编译 Main Class\n\n$ jad demo.MathGame\n\nClassLoader:\n+-sun.misc.Launcher$AppClassLoader@3d4eac69\n  +-sun.misc.Launcher$ExtClassLoader@66350f69\n\nLocation:\n/tmp/arthas-demo.jar\n\n/*\n * Decompiled with CFR 0_132.\n */\npackage demo;\n\nimport java.io.PrintStream;\nimport java.util.ArrayList;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Random;\nimport java.util.concurrent.TimeUnit;\n\npublic class MathGame {\n    private static Random random = new Random();\n    private int illegalArgumentCount = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n        MathGame game = new MathGame();\n        do {\n            game.run();\n            TimeUnit.SECONDS.sleep(1L);\n        } while (true);\n    }\n\n    public void run() throws InterruptedException {\n        try {\n            int number = random.nextInt();\n            List<Integer> primeFactors = this.primeFactors(number);\n            MathGame.print(number, primeFactors);\n        }\n        catch (Exception e) {\n            System.out.println(String.format(\"illegalArgumentCount:%3d, \", this.illegalArgumentCount) + e.getMessage());\n        }\n    }\n\n    public static void print(int number, List<Integer> primeFactors) {\n        StringBuffer sb = new StringBuffer(\"\" + number + \"=\");\n        Iterator<Integer> iterator = primeFactors.iterator();\n        while (iterator.hasNext()) {\n            int factor = iterator.next();\n            sb.append(factor).append('*');\n        }\n        if (sb.charAt(sb.length() - 1) == '*') {\n            sb.deleteCharAt(sb.length() - 1);\n        }\n        System.out.println(sb);\n    }\n\n    public List<Integer> primeFactors(int number) {\n        if (number < 2) {\n            ++this.illegalArgumentCount;\n            throw new IllegalArgumentException(\"number is: \" + number + \", need >= 2\");\n        }\n        ArrayList<Integer> result = new ArrayList<Integer>();\n        int i = 2;\n        while (i <= number) {\n            if (number % i == 0) {\n                result.add(i);\n                number /= i;\n                i = 2;\n                continue;\n            }\n            ++i;\n        }\n        return result;\n    }\n}\n\nAffect(row-cnt:1) cost in 970 ms.\n\n\n\n# watch\n\n通过watch命令来查看demo.MathGame#primeFactors函数的返回值：\n\n$ watch demo.MathGame primeFactors returnObj\nPress Ctrl+C to abort.\nAffect(class-cnt:1 , method-cnt:1) cost in 107 ms.\nts=2018-11-28 19:22:30; [cost=1.715367ms] result=null\nts=2018-11-28 19:22:31; [cost=0.185203ms] result=null\nts=2018-11-28 19:22:32; [cost=19.012416ms] result=@ArrayList[\n    @Integer[5],\n    @Integer[47],\n    @Integer[2675531],\n]\nts=2018-11-28 19:22:33; [cost=0.311395ms] result=@ArrayList[\n    @Integer[2],\n    @Integer[5],\n    @Integer[317],\n    @Integer[503],\n    @Integer[887],\n]\nts=2018-11-28 19:22:34; [cost=10.136007ms] result=@ArrayList[\n    @Integer[2],\n    @Integer[2],\n    @Integer[3],\n    @Integer[3],\n    @Integer[31],\n    @Integer[717593],\n]\nts=2018-11-28 19:22:35; [cost=29.969732ms] result=@ArrayList[\n    @Integer[5],\n    @Integer[29],\n    @Integer[7651739],\n]\n\n\n更多的功能可以查看进阶使用。\n\n\n# 退出 arthas\n\n如果只是退出当前的连接，可以用quit或者exit命令。Attach 到目标进程上的 arthas 还会继续运行，端口会保持开放，下次连接时可以直接连接上。\n\n如果想完全退出 arthas，可以执行shutdown命令。\n\n\n# 进阶使用\n\n\n# 基础命令\n\n * help——查看命令帮助信息\n * cat——打印文件内容，和 linux 里的 cat 命令类似\n * pwd——返回当前的工作目录，和 linux 命令类似\n * cls——清空当前屏幕区域\n * session——查看当前会话的信息\n * reset——重置增强类，将被 Arthas 增强过的类全部还原，Arthas 服务端关闭时会重置所有增强过的类\n * version——输出当前目标 Java 进程所加载的 Arthas 版本号\n * history——打印命令历史\n * quit——退出当前 Arthas 客户端，其他 Arthas 客户端不受影响\n * shutdown——关闭 Arthas 服务端，所有 Arthas 客户端全部退出\n * keymap——Arthas 快捷键列表及自定义快捷键\n\n\n# jvm 相关\n\n * dashboard——当前系统的实时数据面板\n * thread——查看当前 JVM 的线程堆栈信息\n * jvm——查看当前 JVM 的信息\n * sysprop——查看和修改 JVM 的系统属性\n * sysenv——查看 JVM 的环境变量\n * vmoption——查看和修改 JVM 里诊断相关的 option\n * logger——查看和修改 logger\n * getstatic——查看类的静态属性\n * ognl——执行 ognl 表达式\n * mbean——查看 Mbean 的信息\n * heapdump——dump java heap, 类似 jmap 命令的 heap dump 功能\n\n\n# class/classloader 相关\n\n * sc——查看 JVM 已加载的类信息\n * sm——查看已加载类的方法信息\n * jad——反编译指定已加载类的源码\n * mc——内存编绎器，内存编绎.java文件为.class文件\n * redefine——加载外部的.class文件，redefine 到 JVM 里\n * dump——dump 已加载类的 byte code 到特定目录\n * classloader——查看 classloader 的继承树，urls，类加载信息，使用 classloader 去 getResource\n\n\n# monitor/watch/trace 相关\n\n> 请注意，这些命令，都通过字节码增强技术来实现的，会在指定类的方法中插入一些切面来实现数据统计和观测，因此在线上、预发使用时，请尽量明确需要观测的类、方法以及条件，诊断结束要执行 shutdown 或将增强过的类执行 reset 命令。\n\n * monitor——方法执行监控\n * watch——方法执行数据观测\n * trace——方法内部调用路径，并输出方法路径上的每个节点上耗时\n * stack——输出当前方法被调用的调用路径\n * tt——方法执行数据的时空隧道，记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测\n\n\n# options\n\n * options——查看或设置 Arthas 全局开关\n\n\n# 管道\n\nArthas 支持使用管道对上述命令的结果进行进一步的处理，如sm java.lang.String * | grep 'index'\n\n * grep——搜索满足条件的 \b 结果\n * plaintext——将 \b 命令的结果去除 ANSI 颜色\n * wc——按行统计输出结果\n\n\n# 后台异步任务\n\n当线上出现偶发的问题，比如需要 watch 某个条件，而这个条件一天可能才会出现一次时，异步后台任务就派上用场了，详情请参考这里\n\n * 使用 > 将结果重写向到日志文件，使用 & 指定命令是后台运行，session 断开不影响任务执行（生命周期默认为 1 天）\n * jobs——列出所有 job\n * kill——强制终止任务\n * fg——将暂停的任务拉到前台执行\n * bg——将暂停的任务放到后台执行\n\n\n# Web Console\n\n通过 websocket 连接 Arthas。\n\n * Web Console\n\n\n# 用户数据回报\n\n在3.1.4版本后，增加了用户数据回报功能，方便统一做安全或者历史数据统计。\n\n在启动时，指定stat-url，就会回报执行的每一行命令，比如： ./as.sh --stat-url 'http://192.168.10.11:8080/api/stat'\n\n在 tunnel server 里有一个示例的回报代码，用户可以自己在服务器上实现。\n\nStatController.java\n\n\n# 其他特性\n\n * 异步命令支持\n * 执行结果存日志\n * 批处理的支持\n * ognl 表达式的用法说明\n\n\n# 参考资料\n\n * Arthas Github\n * Arthas 用户文档\n * arthas 源码分析",normalizedContent:"# arthas 快速入门\n\n> arthas 是 alibaba 开源的 java 诊断工具 。\n\n\n# 简介\n\narthas可以解决的问题：\n\n 1. 这个类从哪个 jar 包加载的？为什么会报各种类相关的 exception？\n 2. 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？\n 3. 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？\n 4. 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！\n 5. 是否有一个全局视角来查看系统的运行状况？\n 6. 有什么办法可以监控到 jvm 的实时运行状态？\n\narthas支持 jdk 6+，支持 linux/mac/windows，采用命令行交互模式，同时提供丰富的 tab 自动补全功能，进一步方便进行问题的定位和诊断。\n\n\n# 安装\n\n\n# 使用arthas-boot（推荐）\n\n下载arthas-boot.jar，然后用java -jar的方式启动：\n\nwget https://alibaba.github.io/arthas/arthas-boot.jar\njava -jar arthas-boot.jar\n\n\n打印帮助信息：\n\njava -jar arthas-boot.jar -h\n\n\n * 如果下载速度比较慢，可以使用 aliyun 的镜像：\n   \n   java -jar arthas-boot.jar --repo-mirror aliyun --use-http\n   \n\n * 如果从 github 下载有问题，可以使用 gitee 镜像\n   \n   wget https://arthas.gitee.io/arthas-boot.jar\n   \n\n\n# 使用as.sh\n\narthas 支持在 linux/unix/mac 等平台上一键安装，请复制以下内容，并粘贴到命令行中，敲 回车 执行即可：\n\ncurl -l https://alibaba.github.io/arthas/install.sh | sh\n\n\n上述命令会下载启动脚本文件 as.sh 到当前目录，你可以放在任何地方或将其加入到 $path 中。\n\n直接在 shell 下面执行./as.sh，就会进入交互界面。\n\n也可以执行./as.sh -h来获取更多参数信息。\n\n * 如果从 github 下载有问题，可以使用 gitee 镜像\n   \n   curl -l https://arthas.gitee.io/install.sh | sh\n   \n\n\n# 全量安装\n\n最新版本，点击下载：下载地址\n\n解压后，在文件夹里有arthas-boot.jar，直接用java -jar的方式启动：\n\njava -jar arthas-boot.jar\n\n\n打印帮助信息：\n\njava -jar arthas-boot.jar -h\n\n\n\n# 基础使用\n\n\n# 启动 demo\n\nwget https://alibaba.github.io/arthas/arthas-demo.jar\njava -jar arthas-demo.jar\n\n\narthas-demo是一个简单的程序，每隔一秒生成一个随机数，再执行质因式分解，并打印出分解结果。\n\narthas-demo源代码：查看\n\n\n# 启动 arthas\n\n在命令行下面执行（使用和目标进程一致的用户启动，否则可能 attach 失败）：\n\nwget https://alibaba.github.io/arthas/arthas-boot.jar\njava -jar arthas-boot.jar\n\n\n * 执行该程序的用户需要和目标进程具有相同的权限。比如以admin用户来执行：sudo su admin && java -jar arthas-boot.jar 或 sudo -u admin -eh java -jar arthas-boot.jar。\n * 如果 attach 不上目标进程，可以查看~/logs/arthas/ 目录下的日志。\n * 如果下载速度比较慢，可以使用 aliyun 的镜像：java -jar arthas-boot.jar --repo-mirror aliyun --use-http\n * java -jar arthas-boot.jar -h 打印更多参数信息。\n\n选择应用 java 进程：\n\n$ $ java -jar arthas-boot.jar\n* [1]: 35542\n  [2]: 71560 arthas-demo.jar\n\n\ndemo 进程是第 2 个，则输入 2，再输入回车/enter。arthas 会 attach 到目标进程上，并输出日志：\n\n[info] try to attach process 71560\n[info] attach process 71560 success.\n[info] arthas-client connect 127.0.0.1 3658\n  ,---.  ,------. ,--------.,--.  ,--.  ,---.   ,---.\n /  o  \\ |  .--. ''--.  .--'|  '--'  | /  o  \\ '   .-'\n|  .-.  ||  '--'.'   |  |   |  .--.  ||  .-.  |`.  `-.\n|  | |  ||  |\\  \\    |  |   |  |  |  ||  | |  |.-'    |\n`--' `--'`--' '--'   `--'   `--'  `--'`--' `--'`-----'\n\nwiki: https://alibaba.github.io/arthas\nversion: 3.0.5.20181127201536\npid: 71560\ntime: 2018-11-28 19:16:24\n\n$\n\n\n\n# 查看 dashboard\n\n输入dashboard，按回车/enter，会展示当前进程的信息，按ctrl+c可以中断执行。\n\n$ dashboard\nid     name                   group          priori state  %cpu    time   interru daemon\n17     pool-2-thread-1        system         5      waitin 67      0:0    false   false\n27     timer-for-arthas-dashb system         10     runnab 32      0:0    false   true\n11     asyncappender-worker-a system         9      waitin 0       0:0    false   true\n9      attach listener        system         9      runnab 0       0:0    false   true\n3      finalizer              system         8      waitin 0       0:0    false   true\n2      reference handler      system         10     waitin 0       0:0    false   true\n4      signal dispatcher      system         9      runnab 0       0:0    false   true\n26     as-command-execute-dae system         10     timed_ 0       0:0    false   true\n13     job-timeout            system         9      timed_ 0       0:0    false   true\n1      main                   main           5      timed_ 0       0:0    false   false\n14     nioeventloopgroup-2-1  system         10     runnab 0       0:0    false   false\n18     nioeventloopgroup-2-2  system         10     runnab 0       0:0    false   false\n23     nioeventloopgroup-2-3  system         10     runnab 0       0:0    false   false\n15     nioeventloopgroup-3-1  system         10     runnab 0       0:0    false   false\nmemory             used   total max    usage gc\nheap               32m    155m  1820m  1.77% gc.ps_scavenge.count  4\nps_eden_space      14m    65m   672m   2.21% gc.ps_scavenge.time(m 166\nps_survivor_space  4m     5m    5m           s)\nps_old_gen         12m    85m   1365m  0.91% gc.ps_marksweep.count 0\nnonheap            20m    23m   -1           gc.ps_marksweep.time( 0\ncode_cache         3m     5m    240m   1.32% ms)\nruntime\nos.name                mac os x\nos.version             10.13.4\njava.version           1.8.0_162\njava.home              /library/java/javavir\n                       tualmachines/jdk1.8.0\n                       _162.jdk/contents/hom\n                       e/jre\n\n\n\n# 通过 thread 命令来获取到arthas-demo进程的 main class\n\nthread 1会打印线程 id 1 的栈，通常是 main 函数的线程。\n\n$ thread 1 | grep 'main('\n    at demo.mathgame.main(mathgame.java:17)\n\n\n\n# 通过 jad 来反编译 main class\n\n$ jad demo.mathgame\n\nclassloader:\n+-sun.misc.launcher$appclassloader@3d4eac69\n  +-sun.misc.launcher$extclassloader@66350f69\n\nlocation:\n/tmp/arthas-demo.jar\n\n/*\n * decompiled with cfr 0_132.\n */\npackage demo;\n\nimport java.io.printstream;\nimport java.util.arraylist;\nimport java.util.iterator;\nimport java.util.list;\nimport java.util.random;\nimport java.util.concurrent.timeunit;\n\npublic class mathgame {\n    private static random random = new random();\n    private int illegalargumentcount = 0;\n\n    public static void main(string[] args) throws interruptedexception {\n        mathgame game = new mathgame();\n        do {\n            game.run();\n            timeunit.seconds.sleep(1l);\n        } while (true);\n    }\n\n    public void run() throws interruptedexception {\n        try {\n            int number = random.nextint();\n            list<integer> primefactors = this.primefactors(number);\n            mathgame.print(number, primefactors);\n        }\n        catch (exception e) {\n            system.out.println(string.format(\"illegalargumentcount:%3d, \", this.illegalargumentcount) + e.getmessage());\n        }\n    }\n\n    public static void print(int number, list<integer> primefactors) {\n        stringbuffer sb = new stringbuffer(\"\" + number + \"=\");\n        iterator<integer> iterator = primefactors.iterator();\n        while (iterator.hasnext()) {\n            int factor = iterator.next();\n            sb.append(factor).append('*');\n        }\n        if (sb.charat(sb.length() - 1) == '*') {\n            sb.deletecharat(sb.length() - 1);\n        }\n        system.out.println(sb);\n    }\n\n    public list<integer> primefactors(int number) {\n        if (number < 2) {\n            ++this.illegalargumentcount;\n            throw new illegalargumentexception(\"number is: \" + number + \", need >= 2\");\n        }\n        arraylist<integer> result = new arraylist<integer>();\n        int i = 2;\n        while (i <= number) {\n            if (number % i == 0) {\n                result.add(i);\n                number /= i;\n                i = 2;\n                continue;\n            }\n            ++i;\n        }\n        return result;\n    }\n}\n\naffect(row-cnt:1) cost in 970 ms.\n\n\n\n# watch\n\n通过watch命令来查看demo.mathgame#primefactors函数的返回值：\n\n$ watch demo.mathgame primefactors returnobj\npress ctrl+c to abort.\naffect(class-cnt:1 , method-cnt:1) cost in 107 ms.\nts=2018-11-28 19:22:30; [cost=1.715367ms] result=null\nts=2018-11-28 19:22:31; [cost=0.185203ms] result=null\nts=2018-11-28 19:22:32; [cost=19.012416ms] result=@arraylist[\n    @integer[5],\n    @integer[47],\n    @integer[2675531],\n]\nts=2018-11-28 19:22:33; [cost=0.311395ms] result=@arraylist[\n    @integer[2],\n    @integer[5],\n    @integer[317],\n    @integer[503],\n    @integer[887],\n]\nts=2018-11-28 19:22:34; [cost=10.136007ms] result=@arraylist[\n    @integer[2],\n    @integer[2],\n    @integer[3],\n    @integer[3],\n    @integer[31],\n    @integer[717593],\n]\nts=2018-11-28 19:22:35; [cost=29.969732ms] result=@arraylist[\n    @integer[5],\n    @integer[29],\n    @integer[7651739],\n]\n\n\n更多的功能可以查看进阶使用。\n\n\n# 退出 arthas\n\n如果只是退出当前的连接，可以用quit或者exit命令。attach 到目标进程上的 arthas 还会继续运行，端口会保持开放，下次连接时可以直接连接上。\n\n如果想完全退出 arthas，可以执行shutdown命令。\n\n\n# 进阶使用\n\n\n# 基础命令\n\n * help——查看命令帮助信息\n * cat——打印文件内容，和 linux 里的 cat 命令类似\n * pwd——返回当前的工作目录，和 linux 命令类似\n * cls——清空当前屏幕区域\n * session——查看当前会话的信息\n * reset——重置增强类，将被 arthas 增强过的类全部还原，arthas 服务端关闭时会重置所有增强过的类\n * version——输出当前目标 java 进程所加载的 arthas 版本号\n * history——打印命令历史\n * quit——退出当前 arthas 客户端，其他 arthas 客户端不受影响\n * shutdown——关闭 arthas 服务端，所有 arthas 客户端全部退出\n * keymap——arthas 快捷键列表及自定义快捷键\n\n\n# jvm 相关\n\n * dashboard——当前系统的实时数据面板\n * thread——查看当前 jvm 的线程堆栈信息\n * jvm——查看当前 jvm 的信息\n * sysprop——查看和修改 jvm 的系统属性\n * sysenv——查看 jvm 的环境变量\n * vmoption——查看和修改 jvm 里诊断相关的 option\n * logger——查看和修改 logger\n * getstatic——查看类的静态属性\n * ognl——执行 ognl 表达式\n * mbean——查看 mbean 的信息\n * heapdump——dump java heap, 类似 jmap 命令的 heap dump 功能\n\n\n# class/classloader 相关\n\n * sc——查看 jvm 已加载的类信息\n * sm——查看已加载类的方法信息\n * jad——反编译指定已加载类的源码\n * mc——内存编绎器，内存编绎.java文件为.class文件\n * redefine——加载外部的.class文件，redefine 到 jvm 里\n * dump——dump 已加载类的 byte code 到特定目录\n * classloader——查看 classloader 的继承树，urls，类加载信息，使用 classloader 去 getresource\n\n\n# monitor/watch/trace 相关\n\n> 请注意，这些命令，都通过字节码增强技术来实现的，会在指定类的方法中插入一些切面来实现数据统计和观测，因此在线上、预发使用时，请尽量明确需要观测的类、方法以及条件，诊断结束要执行 shutdown 或将增强过的类执行 reset 命令。\n\n * monitor——方法执行监控\n * watch——方法执行数据观测\n * trace——方法内部调用路径，并输出方法路径上的每个节点上耗时\n * stack——输出当前方法被调用的调用路径\n * tt——方法执行数据的时空隧道，记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测\n\n\n# options\n\n * options——查看或设置 arthas 全局开关\n\n\n# 管道\n\narthas 支持使用管道对上述命令的结果进行进一步的处理，如sm java.lang.string * | grep 'index'\n\n * grep——搜索满足条件的 \b 结果\n * plaintext——将 \b 命令的结果去除 ansi 颜色\n * wc——按行统计输出结果\n\n\n# 后台异步任务\n\n当线上出现偶发的问题，比如需要 watch 某个条件，而这个条件一天可能才会出现一次时，异步后台任务就派上用场了，详情请参考这里\n\n * 使用 > 将结果重写向到日志文件，使用 & 指定命令是后台运行，session 断开不影响任务执行（生命周期默认为 1 天）\n * jobs——列出所有 job\n * kill——强制终止任务\n * fg——将暂停的任务拉到前台执行\n * bg——将暂停的任务放到后台执行\n\n\n# web console\n\n通过 websocket 连接 arthas。\n\n * web console\n\n\n# 用户数据回报\n\n在3.1.4版本后，增加了用户数据回报功能，方便统一做安全或者历史数据统计。\n\n在启动时，指定stat-url，就会回报执行的每一行命令，比如： ./as.sh --stat-url 'http://192.168.10.11:8080/api/stat'\n\n在 tunnel server 里有一个示例的回报代码，用户可以自己在服务器上实现。\n\nstatcontroller.java\n\n\n# 其他特性\n\n * 异步命令支持\n * 执行结果存日志\n * 批处理的支持\n * ognl 表达式的用法说明\n\n\n# 参考资料\n\n * arthas github\n * arthas 用户文档\n * arthas 源码分析",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 监控诊断",frontmatter:{title:"Java 监控诊断",categories:["编程","Java","软件","监控诊断"],tags:["Java","监控","诊断"],abbrlink:"7af21817",date:"2020-02-11T17:48:32.000Z",permalink:"/pages/2853ec/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/03.%E7%9B%91%E6%8E%A7%E8%AF%8A%E6%96%AD/",relativePath:"11.软件/03.监控诊断/README.md",key:"v-1f33db24",path:"/pages/2853ec/",headers:[{level:2,title:"内容",slug:"内容",normalizedTitle:"内容",charIndex:16},{level:2,title:"资料",slug:"资料",normalizedTitle:"资料",charIndex:75}],headersStr:"内容 资料",content:"# Java 监控诊断\n\n\n# 内容\n\n * 监控工具对比\n * CAT\n * Zipkin\n * SkyWalking\n * Arthas\n\n\n# 资料\n\n * CAT Github\n * Zipkin Github\n * SkyWalking Github\n * PinPoint Github\n * Arthas Github",normalizedContent:"# java 监控诊断\n\n\n# 内容\n\n * 监控工具对比\n * cat\n * zipkin\n * skywalking\n * arthas\n\n\n# 资料\n\n * cat github\n * zipkin github\n * skywalking github\n * pinpoint github\n * arthas github",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 软件",frontmatter:{title:"Java 软件",categories:["编程","Java","软件","IDE"],tags:["Java"],abbrlink:"bd90f980",date:"2022-02-18T08:53:11.000Z",hidden:!0,permalink:"/pages/dab057/"},regularPath:"/11.%E8%BD%AF%E4%BB%B6/",relativePath:"11.软件/README.md",key:"v-415dc8b8",path:"/pages/dab057/",headers:[{level:2,title:"📖 内容",slug:"📖-内容",normalizedTitle:"📖 内容",charIndex:71},{level:3,title:"构建",slug:"构建",normalizedTitle:"构建",charIndex:46},{level:3,title:"IDE",slug:"ide",normalizedTitle:"ide",charIndex:51},{level:3,title:"监控诊断",slug:"监控诊断",normalizedTitle:"监控诊断",charIndex:768},{level:2,title:"📚 资料",slug:"📚-资料",normalizedTitle:"📚 资料",charIndex:902},{level:2,title:"🚪 传送",slug:"🚪-传送",normalizedTitle:"🚪 传送",charIndex:989}],headersStr:"📖 内容 构建 IDE 监控诊断 📚 资料 🚪 传送",content:"# Java 软件\n\n> 本部分内容主要是 Java 开发领域使用的一些 Java 软件，如构建工具、IDE、服务器、日志中心等等。\n\n\n# 📖 内容\n\n\n# 构建\n\n> Java 项目需要通过 构建工具 来管理项目依赖，完成编译、打包、发布、生成 JavaDoc 等任务。\n> \n>  * 目前最主流的构建工具是 Maven，它的功能非常强大。\n>  * Gradle 号称是要替代 Maven 等构件工具，它的版本管理确实简洁，但是需要学习 Groovy，学习成本比 Maven 高。\n>  * Ant 功能比 Maven 和 Gradle 要弱，现代 Java 项目基本不用了，但也有一些传统的 Java 项目还在使用。\n\n * Maven 📚\n   * Maven 快速入门\n   * Maven 教程之 pom.xml 详解\n   * Maven 教程之 settings.xml 详解\n   * Maven 实战问题和最佳实践\n   * Maven 教程之发布 jar 到私服或中央仓库\n   * Maven 插件之代码检查\n * Ant 简易教程\n\n\n# IDE\n\n> 自从有了 IDE，写代码从此就告别了刀耕火种的蛮荒时代。\n> \n>  * Eclipse 是久负盛名的开源 Java IDE，我的学生时代一直使用它写 Java。\n>  * 曾经抗拒从转 Intellij Idea ，但后来发现真香，不得不说，确实是目前最优秀的 Java IDE。\n>  * 你可以在 vscode 中写各种语言，只要安装相应插件即可。如果你的项目中使用了很多种编程语言，又懒得在多个 IDE 之间切换，那么就用 vscode 来一网打尽吧。\n\n * Intellij Idea\n * Eclipse\n * vscode\n\n\n# 监控诊断\n\n> 监控/诊断 工具主要用于 Java 应用的运维。通过采集、分析、存储、可视化应用的有效数据，帮助开发者、使用者快速定位问题，找到性能瓶颈。\n\n * 监控工具对比\n * CAT\n * Zipkin\n * SkyWalking\n * Arthas\n\n\n# 📚 资料\n\n * 官网\n   * Maven Github\n   * Maven 官方文档\n   * Ant 官方手册\n * 书籍\n   * 《Maven 实战》\n\n\n# 🚪 传送\n\n◾ 🏠 JAVA-TUTORIAL 首页 ◾ 🎯 我的博客 ◾",normalizedContent:"# java 软件\n\n> 本部分内容主要是 java 开发领域使用的一些 java 软件，如构建工具、ide、服务器、日志中心等等。\n\n\n# 📖 内容\n\n\n# 构建\n\n> java 项目需要通过 构建工具 来管理项目依赖，完成编译、打包、发布、生成 javadoc 等任务。\n> \n>  * 目前最主流的构建工具是 maven，它的功能非常强大。\n>  * gradle 号称是要替代 maven 等构件工具，它的版本管理确实简洁，但是需要学习 groovy，学习成本比 maven 高。\n>  * ant 功能比 maven 和 gradle 要弱，现代 java 项目基本不用了，但也有一些传统的 java 项目还在使用。\n\n * maven 📚\n   * maven 快速入门\n   * maven 教程之 pom.xml 详解\n   * maven 教程之 settings.xml 详解\n   * maven 实战问题和最佳实践\n   * maven 教程之发布 jar 到私服或中央仓库\n   * maven 插件之代码检查\n * ant 简易教程\n\n\n# ide\n\n> 自从有了 ide，写代码从此就告别了刀耕火种的蛮荒时代。\n> \n>  * eclipse 是久负盛名的开源 java ide，我的学生时代一直使用它写 java。\n>  * 曾经抗拒从转 intellij idea ，但后来发现真香，不得不说，确实是目前最优秀的 java ide。\n>  * 你可以在 vscode 中写各种语言，只要安装相应插件即可。如果你的项目中使用了很多种编程语言，又懒得在多个 ide 之间切换，那么就用 vscode 来一网打尽吧。\n\n * intellij idea\n * eclipse\n * vscode\n\n\n# 监控诊断\n\n> 监控/诊断 工具主要用于 java 应用的运维。通过采集、分析、存储、可视化应用的有效数据，帮助开发者、使用者快速定位问题，找到性能瓶颈。\n\n * 监控工具对比\n * cat\n * zipkin\n * skywalking\n * arthas\n\n\n# 📚 资料\n\n * 官网\n   * maven github\n   * maven 官方文档\n   * ant 官方手册\n * 书籍\n   * 《maven 实战》\n\n\n# 🚪 传送\n\n◾ 🏠 java-tutorial 首页 ◾ 🎯 我的博客 ◾",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 和 JSON 序列化",frontmatter:{title:"Java 和 JSON 序列化",categories:["编程","Java","工具","IO"],tags:["Java","IO","序列化","JSON"],abbrlink:"37e168b9",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/a14952/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/01.IO/01.JSON%E5%BA%8F%E5%88%97%E5%8C%96.html",relativePath:"12.工具/01.IO/01.JSON序列化.md",key:"v-4f0d9490",path:"/pages/a14952/",headers:[{level:2,title:"JSON 简介",slug:"json-简介",normalizedTitle:"json 简介",charIndex:184},{level:3,title:"JSON 是什么",slug:"json-是什么",normalizedTitle:"json 是什么",charIndex:196},{level:3,title:"JSON 标准",slug:"json-标准",normalizedTitle:"json 标准",charIndex:426},{level:3,title:"JSON 优缺点",slug:"json-优缺点",normalizedTitle:"json 优缺点",charIndex:979},{level:3,title:"JSON 工具",slug:"json-工具",normalizedTitle:"json 工具",charIndex:1571},{level:3,title:"Java JSON 库",slug:"java-json-库",normalizedTitle:"java json 库",charIndex:1815},{level:3,title:"JSON 编码指南",slug:"json-编码指南",normalizedTitle:"json 编码指南",charIndex:2018},{level:2,title:"Fastjson 应用",slug:"fastjson-应用",normalizedTitle:"fastjson 应用",charIndex:2713},{level:3,title:"添加 maven 依赖",slug:"添加-maven-依赖",normalizedTitle:"添加 maven 依赖",charIndex:2729},{level:3,title:"Fastjson API",slug:"fastjson-api",normalizedTitle:"fastjson api",charIndex:2876},{level:4,title:"定义 Bean",slug:"定义-bean",normalizedTitle:"定义 bean",charIndex:2892},{level:4,title:"序列化",slug:"序列化",normalizedTitle:"序列化",charIndex:14},{level:4,title:"反序列化",slug:"反序列化",normalizedTitle:"反序列化",charIndex:3508},{level:3,title:"Fastjson 注解",slug:"fastjson-注解",normalizedTitle:"fastjson 注解",charIndex:3575},{level:4,title:"@JSONField",slug:"jsonfield",normalizedTitle:"@jsonfield",charIndex:3590},{level:4,title:"@JSONType",slug:"jsontype",normalizedTitle:"@jsontype",charIndex:4046},{level:2,title:"Jackson 应用",slug:"jackson-应用",normalizedTitle:"jackson 应用",charIndex:4338},{level:3,title:"添加 maven 依赖",slug:"添加-maven-依赖-2",normalizedTitle:"添加 maven 依赖",charIndex:2729},{level:3,title:"Jackson API",slug:"jackson-api",normalizedTitle:"jackson api",charIndex:4569},{level:4,title:"序列化",slug:"序列化-2",normalizedTitle:"序列化",charIndex:14},{level:4,title:"反序列化",slug:"反序列化-2",normalizedTitle:"反序列化",charIndex:3508},{level:4,title:"容器的序列化和反序列化",slug:"容器的序列化和反序列化",normalizedTitle:"容器的序列化和反序列化",charIndex:5132},{level:3,title:"Jackson 注解",slug:"jackson-注解",normalizedTitle:"jackson 注解",charIndex:5550},{level:4,title:"@JsonProperty",slug:"jsonproperty",normalizedTitle:"@jsonproperty",charIndex:5610},{level:4,title:"@JsonIgnoreProperties 和 @JsonIgnore",slug:"jsonignoreproperties-和-jsonignore",normalizedTitle:"@jsonignoreproperties 和 @jsonignore",charIndex:5968},{level:4,title:"@JsonCreator",slug:"jsoncreator",normalizedTitle:"@jsoncreator",charIndex:6556},{level:4,title:"@JsonPropertyOrder",slug:"jsonpropertyorder",normalizedTitle:"@jsonpropertyorder",charIndex:6858},{level:2,title:"Gson 应用",slug:"gson-应用",normalizedTitle:"gson 应用",charIndex:7008},{level:3,title:"添加 maven 依赖",slug:"添加-maven-依赖-3",normalizedTitle:"添加 maven 依赖",charIndex:2729},{level:3,title:"Gson API",slug:"gson-api",normalizedTitle:"gson api",charIndex:7198},{level:4,title:"序列化",slug:"序列化-3",normalizedTitle:"序列化",charIndex:14},{level:4,title:"反序列化",slug:"反序列化-3",normalizedTitle:"反序列化",charIndex:3508},{level:4,title:"GsonBuilder",slug:"gsonbuilder",normalizedTitle:"gsonbuilder",charIndex:7719},{level:3,title:"Gson 注解",slug:"gson-注解",normalizedTitle:"gson 注解",charIndex:7977},{level:4,title:"@Since",slug:"since",normalizedTitle:"@since",charIndex:7988},{level:4,title:"@SerializedName",slug:"serializedname",normalizedTitle:"@serializedname",charIndex:8605},{level:2,title:"示例源码",slug:"示例源码",normalizedTitle:"示例源码",charIndex:8904},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:8937}],headersStr:"JSON 简介 JSON 是什么 JSON 标准 JSON 优缺点 JSON 工具 Java JSON 库 JSON 编码指南 Fastjson 应用 添加 maven 依赖 Fastjson API 定义 Bean 序列化 反序列化 Fastjson 注解 @JSONField @JSONType Jackson 应用 添加 maven 依赖 Jackson API 序列化 反序列化 容器的序列化和反序列化 Jackson 注解 @JsonProperty @JsonIgnoreProperties 和 @JsonIgnore @JsonCreator @JsonPropertyOrder Gson 应用 添加 maven 依赖 Gson API 序列化 反序列化 GsonBuilder Gson 注解 @Since @SerializedName 示例源码 参考资料",content:'# Java 和 JSON 序列化\n\n> JSON（JavaScript Object Notation）是一种基于文本的数据交换格式。几乎所有的编程语言都有很好的库或第三方工具来提供基于 JSON 的 API 支持，因此你可以非常方便地使用任何自己喜欢的编程语言来处理 JSON 数据。\n> \n> 本文主要从 Java 语言的角度来讲解 JSON 的应用。\n\n\n# JSON 简介\n\n\n# JSON 是什么\n\nJSON 起源于 1999 年的 JS 语言规范 ECMA262 的一个子集（即 15.12 章节描述了格式与解析），后来 2003 年作为一个数据格式ECMA404（很囧的序号有不有？）发布。 2006 年，作为 rfc4627 发布，这时规范增加到 18 页，去掉没用的部分，十页不到。\n\nJSON 的应用很广泛，这里有超过 100 种语言下的 JSON 库：json.org。\n\n更多的可以参考这里，关于 json 的一切。\n\n\n# JSON 标准\n\n这估计是最简单标准规范之一：\n\n * 只有两种结构：对象内的键值对集合结构和数组，对象用 {} 表示、内部是 "key":"value"，数组用 [] 表示，不同值用逗号分开\n * 基本数值有 7 个： false / null / true / object / array / number / string\n * 再加上结构可以嵌套，进而可以用来表达复杂的数据\n * 一个简单实例：\n\n{\n  "Image": {\n    "Width": 800,\n    "Height": 600,\n    "Title": "View from 15th Floor",\n    "Thumbnail": {\n      "Url": "http://www.example.com/image/481989943",\n      "Height": 125,\n      "Width": "100"\n    },\n    "IDs": [116, 943, 234, 38793]\n  }\n}\n\n\n> 扩展阅读：\n> \n>  * http://www.json.org/json-zh.html - 图文并茂介绍 json 数据形式\n> \n>  * json 的 RFC 文档\n\n\n# JSON 优缺点\n\n优点：\n\n * 基于纯文本，所以对于人类阅读是很友好的。\n * 规范简单，所以容易处理，开箱即用，特别是 JS 类的 ECMA 脚本里是内建支持的，可以直接作为对象使用。\n * 平台无关性，因为类型和结构都是平台无关的，而且好处理，容易实现不同语言的处理类库，可以作为多个不同异构系统之间的数据传输格式协议，特别是在 HTTP/REST 下的数据格式。\n\n缺点：\n\n * 性能一般，文本表示的数据一般来说比二进制大得多，在数据传输上和解析处理上都要更影响性能。\n * 缺乏 schema，跟同是文本数据格式的 XML 比，在类型的严格性和丰富性上要差很多。XML 可以借由 XSD 或 DTD 来定义复杂的格式，并由此来验证 XML 文档是否符合格式要求，甚至进一步的，可以基于 XSD 来生成具体语言的操作代码，例如 apache xmlbeans。并且这些工具组合到一起，形成一套庞大的生态，例如基于 XML 可以实现 SOAP 和 WSDL，一系列的 ws-*规范。但是我们也可以看到 JSON 在缺乏规范的情况下，实际上有更大一些的灵活性，特别是近年来 REST 的快速发展，已经有一些 schema 相关的发展(例如理解 JSON Schema，使用 JSON Schema， 在线 schema 测试)，也有类似于 WSDL 的WADL出现。\n\n\n# JSON 工具\n\n * 使用 JSON 实现 RPC（类似 XML-RPC）：JSON-RPC\n\n * 使用 JSON 实现 path 查询操作（类似 XML-PATH）：JsonPATH\n\n * 在线查询工具：JsonPATH\n\n * 格式化工具：jsbeautifier\n\n * chrome 插件：5 个 Json View 插件\n\n * 在线 Mock: 在线 mock\n\n * 其他 Mock：SoapUI可以支持，SwaggerUI 也可以，RestMock也可以。\n\n\n# Java JSON 库\n\nJava 中比较流行的 JSON 库有：\n\n * Fastjson - 阿里巴巴开发的 JSON 库，性能十分优秀。\n * Jackson - 社区十分活跃且更新速度很快。Spring 框架默认 JSON 库。\n * Gson - 谷歌开发的 JSON 库，目前功能最全的 JSON 库 。\n\n从性能上来看，一般情况下：Fastjson > Jackson > Gson\n\n\n# JSON 编码指南\n\n> 遵循好的设计与编码风格，能提前解决 80%的问题，个人推荐 Google JSON 风格指南。\n> \n>  * 英文版Google JSON Style Guide：https://google.github.io/styleguide/jsoncstyleguide.xml\n>  * 中文版Google JSON 风格指南：https://github.com/darcyliu/google-styleguide/blob/master/JSONStyleGuide.md\n\n简单摘录如下：\n\n * 属性名和值都是用双引号，不要把注释写到对象里面，对象数据要简洁\n * 不要随意结构化分组对象，推荐是用扁平化方式，层次不要太复杂\n * 命名方式要有意义，比如单复数表示\n * 驼峰式命名，遵循 Bean 规范\n * 使用版本来控制变更冲突\n * 对于一些关键字，不要拿来做 key\n * 如果一个属性是可选的或者包含空值或 null 值，考虑从 JSON 中去掉该属性，除非它的存在有很强的语义原因\n * 序列化枚举类型时，使用 name 而不是 value\n * 日期要用标准格式处理\n * 设计好通用的分页参数\n * 设计好异常处理\n\nJSON API与 Google JSON 风格指南有很多可以相互参照之处。\n\nJSON API是数据交互规范，用以定义客户端如何获取与修改资源，以及服务器如何响应对应请求。\n\nJSON API 设计用来最小化请求的数量，以及客户端与服务器间传输的数据量。在高效实现的同时，无需牺牲可读性、灵活性和可发现性。\n\n\n# Fastjson 应用\n\n\n# 添加 maven 依赖\n\n<dependency>\n    <groupId>com.alibaba</groupId>\n    <artifactId>fastjson</artifactId>\n    <version>x.x.x</version>\n</dependency>\n\n\n\n# Fastjson API\n\n# 定义 Bean\n\nGroup.java\n\npublic class Group {\n\n    private Long       id;\n    private String     name;\n    private List<User> users = new ArrayList<User>();\n}\n\n\nUser.java\n\npublic class User {\n\n    private Long   id;\n    private String name;\n}\n\n\n初始化 Bean\n\nGroup group = new Group();\ngroup.setId(0L);\ngroup.setName("admin");\n\nUser guestUser = new User();\nguestUser.setId(2L);\nguestUser.setName("guest");\n\nUser rootUser = new User();\nrootUser.setId(3L);\nrootUser.setName("root");\n\ngroup.addUser(guestUser);\ngroup.addUser(rootUser);\n\n\n# 序列化\n\nString jsonString = JSON.toJSONString(group);\nSystem.out.println(jsonString);\n\n\n# 反序列化\n\nGroup bean = JSON.parseObject(jsonString, Group.class);\n\n\n\n# Fastjson 注解\n\n# @JSONField\n\n> 扩展阅读：更多 API 使用细节可以参考：JSONField 用法，这里介绍基本用法。\n\n可以配置在属性（setter、getter）和字段（必须是 public field）上。\n\n@JSONField(name="ID")\npublic int getId() {return id;}\n\n// 配置date序列化和反序列使用yyyyMMdd日期格式\n@JSONField(format="yyyyMMdd")\npublic Date date1;\n\n// 不序列化\n@JSONField(serialize=false)\npublic Date date2;\n\n// 不反序列化\n@JSONField(deserialize=false)\npublic Date date3;\n\n// 按ordinal排序\n@JSONField(ordinal = 2)\nprivate int f1;\n\n@JSONField(ordinal = 1)\nprivate int f2;\n\n\n# @JSONType\n\n * 自定义序列化：ObjectSerializer\n * 子类型处理：SeeAlso\n\nJSONType.alphabetic 属性: fastjson 缺省时会使用字母序序列化，如果你是希望按照 java fields/getters 的自然顺序序列化，可以配置 JSONType.alphabetic，使用方法如下：\n\n@JSONType(alphabetic = false)\npublic static class B {\n    public int f2;\n    public int f1;\n    public int f0;\n}\n\n\n\n# Jackson 应用\n\n> 扩展阅读：更多 API 使用细节可以参考 jackson-databind 官方说明\n\n\n# 添加 maven 依赖\n\n<dependency>\n    <groupId>com.fasterxml.jackson.core</groupId>\n    <artifactId>jackson-databind</artifactId>\n    <version>2.9.8</version>\n</dependency>\n\n\n\n# Jackson API\n\n# 序列化\n\nObjectMapper mapper = new ObjectMapper();\n\nmapper.writeValue(new File("result.json"), myResultObject);\n// or:\nbyte[] jsonBytes = mapper.writeValueAsBytes(myResultObject);\n// or:\nString jsonString = mapper.writeValueAsString(myResultObject);\n\n\n# 反序列化\n\nObjectMapper mapper = new ObjectMapper();\n\nMyValue value = mapper.readValue(new File("data.json"), MyValue.class);\n// or:\nvalue = mapper.readValue(new URL("http://some.com/api/entry.json"), MyValue.class);\n// or:\nvalue = mapper.readValue("{\\"name\\":\\"Bob\\", \\"age\\":13}", MyValue.class);\n\n\n# 容器的序列化和反序列化\n\nPerson p = new Person("Tom", 20);\nPerson p2 = new Person("Jack", 22);\nPerson p3 = new Person("Mary", 18);\n\nList<Person> persons = new LinkedList<>();\npersons.add(p);\npersons.add(p2);\npersons.add(p3);\n\nMap<String, List> map = new HashMap<>();\nmap.put("persons", persons);\n\nString json = null;\ntry {\n json = mapper.writeValueAsString(map);\n} catch (JsonProcessingException e) {\n e.printStackTrace();\n}\n\n\n\n# Jackson 注解\n\n> 扩展阅读：更多注解使用细节可以参考 jackson-annotations 官方说明\n\n# @JsonProperty\n\npublic class MyBean {\n   private String _name;\n\n   // without annotation, we\'d get "theName", but we want "name":\n   @JsonProperty("name")\n   public String getTheName() { return _name; }\n\n   // note: it is enough to add annotation on just getter OR setter;\n   // so we can omit it here\n   public void setTheName(String n) { _name = n; }\n}\n\n\n# @JsonIgnoreProperties 和 @JsonIgnore\n\n// means that if we see "foo" or "bar" in JSON, they will be quietly skipped\n// regardless of whether POJO has such properties\n@JsonIgnoreProperties({ "foo", "bar" })\npublic class MyBean {\n   // will not be written as JSON; nor assigned from JSON:\n   @JsonIgnore\n   public String internal;\n\n   // no annotation, public field is read/written normally\n   public String external;\n\n   @JsonIgnore\n   public void setCode(int c) { _code = c; }\n\n   // note: will also be ignored because setter has annotation!\n   public int getCode() { return _code; }\n}\n\n\n# @JsonCreator\n\npublic class CtorBean {\n  public final String name;\n  public final int age;\n\n  @JsonCreator // constructor can be public, private, whatever\n  private CtorBean(@JsonProperty("name") String name,\n    @JsonProperty("age") int age)\n  {\n      this.name = name;\n      this.age = age;\n  }\n}\n\n\n# @JsonPropertyOrder\n\nalphabetic 设为 true 表示，json 字段按自然顺序排列，默认为 false。\n\n@JsonPropertyOrder(alphabetic = true)\npublic class JacksonAnnotationBean {}\n\n\n\n# Gson 应用\n\n> 详细内容可以参考官方文档：Gson 用户指南\n\n\n# 添加 maven 依赖\n\n<dependency>\n    <groupId>com.google.code.gson</groupId>\n    <artifactId>gson</artifactId>\n    <version>2.8.6</version>\n</dependency>\n\n\n\n# Gson API\n\n# 序列化\n\nGson gson = new Gson();\ngson.toJson(1);            // ==> 1\ngson.toJson("abcd");       // ==> "abcd"\ngson.toJson(10L); // ==> 10\nint[] values = { 1 };\ngson.toJson(values);       // ==> [1]\n\n\n# 反序列化\n\nint i1 = gson.fromJson("1", int.class);\nInteger i2 = gson.fromJson("1", Integer.class);\nLong l1 = gson.fromJson("1", Long.class);\nBoolean b1 = gson.fromJson("false", Boolean.class);\nString str = gson.fromJson("\\"abc\\"", String.class);\nString[] anotherStr = gson.fromJson("[\\"abc\\"]", String[].class);\n\n\n# GsonBuilder\n\nGson 实例可以通过 GsonBuilder 来定制实例化，以控制其序列化、反序列化行为。\n\nGson gson = new GsonBuilder()\n  .setPrettyPrinting()\n  .setDateFormat("yyyy-MM-dd HH:mm:ss")\n  .excludeFieldsWithModifiers(Modifier.STATIC, Modifier.TRANSIENT, Modifier.VOLATILE)\n  .create();\n\n\n\n# Gson 注解\n\n# @Since\n\n@Since 用于控制对象的序列化版本。示例：\n\npublic class VersionedClass {\n  @Since(1.1) private final String newerField;\n  @Since(1.0) private final String newField;\n  private final String field;\n\n  public VersionedClass() {\n    this.newerField = "newer";\n    this.newField = "new";\n    this.field = "old";\n  }\n}\n\nVersionedClass versionedObject = new VersionedClass();\nGson gson = new GsonBuilder().setVersion(1.0).create();\nString jsonOutput = gson.toJson(versionedObject);\nSystem.out.println(jsonOutput);\nSystem.out.println();\n\ngson = new Gson();\njsonOutput = gson.toJson(versionedObject);\nSystem.out.println(jsonOutput);\n\n\n# @SerializedName\n\n@SerializedName 用于将类成员按照指定名称序列化、反序列化。示例：\n\nprivate class SomeObject {\n  @SerializedName("custom_naming") private final String someField;\n  private final String someOtherField;\n\n  public SomeObject(String a, String b) {\n    this.someField = a;\n    this.someOtherField = b;\n  }\n}\n\n\n\n# 示例源码\n\n> 示例源码：javalib-io-json\n\n\n# 参考资料\n\n * 官方\n   * Fastjson Github\n   * Gson Github\n   * jackson 官方文档\n   * jackson-databind\n * 文章\n   * http://www.json.org/json-zh.html\n   * json 的 RFC 文档\n   * JSON 最佳实践\n   * 【简明教程】JSON',normalizedContent:'# java 和 json 序列化\n\n> json（javascript object notation）是一种基于文本的数据交换格式。几乎所有的编程语言都有很好的库或第三方工具来提供基于 json 的 api 支持，因此你可以非常方便地使用任何自己喜欢的编程语言来处理 json 数据。\n> \n> 本文主要从 java 语言的角度来讲解 json 的应用。\n\n\n# json 简介\n\n\n# json 是什么\n\njson 起源于 1999 年的 js 语言规范 ecma262 的一个子集（即 15.12 章节描述了格式与解析），后来 2003 年作为一个数据格式ecma404（很囧的序号有不有？）发布。 2006 年，作为 rfc4627 发布，这时规范增加到 18 页，去掉没用的部分，十页不到。\n\njson 的应用很广泛，这里有超过 100 种语言下的 json 库：json.org。\n\n更多的可以参考这里，关于 json 的一切。\n\n\n# json 标准\n\n这估计是最简单标准规范之一：\n\n * 只有两种结构：对象内的键值对集合结构和数组，对象用 {} 表示、内部是 "key":"value"，数组用 [] 表示，不同值用逗号分开\n * 基本数值有 7 个： false / null / true / object / array / number / string\n * 再加上结构可以嵌套，进而可以用来表达复杂的数据\n * 一个简单实例：\n\n{\n  "image": {\n    "width": 800,\n    "height": 600,\n    "title": "view from 15th floor",\n    "thumbnail": {\n      "url": "http://www.example.com/image/481989943",\n      "height": 125,\n      "width": "100"\n    },\n    "ids": [116, 943, 234, 38793]\n  }\n}\n\n\n> 扩展阅读：\n> \n>  * http://www.json.org/json-zh.html - 图文并茂介绍 json 数据形式\n> \n>  * json 的 rfc 文档\n\n\n# json 优缺点\n\n优点：\n\n * 基于纯文本，所以对于人类阅读是很友好的。\n * 规范简单，所以容易处理，开箱即用，特别是 js 类的 ecma 脚本里是内建支持的，可以直接作为对象使用。\n * 平台无关性，因为类型和结构都是平台无关的，而且好处理，容易实现不同语言的处理类库，可以作为多个不同异构系统之间的数据传输格式协议，特别是在 http/rest 下的数据格式。\n\n缺点：\n\n * 性能一般，文本表示的数据一般来说比二进制大得多，在数据传输上和解析处理上都要更影响性能。\n * 缺乏 schema，跟同是文本数据格式的 xml 比，在类型的严格性和丰富性上要差很多。xml 可以借由 xsd 或 dtd 来定义复杂的格式，并由此来验证 xml 文档是否符合格式要求，甚至进一步的，可以基于 xsd 来生成具体语言的操作代码，例如 apache xmlbeans。并且这些工具组合到一起，形成一套庞大的生态，例如基于 xml 可以实现 soap 和 wsdl，一系列的 ws-*规范。但是我们也可以看到 json 在缺乏规范的情况下，实际上有更大一些的灵活性，特别是近年来 rest 的快速发展，已经有一些 schema 相关的发展(例如理解 json schema，使用 json schema， 在线 schema 测试)，也有类似于 wsdl 的wadl出现。\n\n\n# json 工具\n\n * 使用 json 实现 rpc（类似 xml-rpc）：json-rpc\n\n * 使用 json 实现 path 查询操作（类似 xml-path）：jsonpath\n\n * 在线查询工具：jsonpath\n\n * 格式化工具：jsbeautifier\n\n * chrome 插件：5 个 json view 插件\n\n * 在线 mock: 在线 mock\n\n * 其他 mock：soapui可以支持，swaggerui 也可以，restmock也可以。\n\n\n# java json 库\n\njava 中比较流行的 json 库有：\n\n * fastjson - 阿里巴巴开发的 json 库，性能十分优秀。\n * jackson - 社区十分活跃且更新速度很快。spring 框架默认 json 库。\n * gson - 谷歌开发的 json 库，目前功能最全的 json 库 。\n\n从性能上来看，一般情况下：fastjson > jackson > gson\n\n\n# json 编码指南\n\n> 遵循好的设计与编码风格，能提前解决 80%的问题，个人推荐 google json 风格指南。\n> \n>  * 英文版google json style guide：https://google.github.io/styleguide/jsoncstyleguide.xml\n>  * 中文版google json 风格指南：https://github.com/darcyliu/google-styleguide/blob/master/jsonstyleguide.md\n\n简单摘录如下：\n\n * 属性名和值都是用双引号，不要把注释写到对象里面，对象数据要简洁\n * 不要随意结构化分组对象，推荐是用扁平化方式，层次不要太复杂\n * 命名方式要有意义，比如单复数表示\n * 驼峰式命名，遵循 bean 规范\n * 使用版本来控制变更冲突\n * 对于一些关键字，不要拿来做 key\n * 如果一个属性是可选的或者包含空值或 null 值，考虑从 json 中去掉该属性，除非它的存在有很强的语义原因\n * 序列化枚举类型时，使用 name 而不是 value\n * 日期要用标准格式处理\n * 设计好通用的分页参数\n * 设计好异常处理\n\njson api与 google json 风格指南有很多可以相互参照之处。\n\njson api是数据交互规范，用以定义客户端如何获取与修改资源，以及服务器如何响应对应请求。\n\njson api 设计用来最小化请求的数量，以及客户端与服务器间传输的数据量。在高效实现的同时，无需牺牲可读性、灵活性和可发现性。\n\n\n# fastjson 应用\n\n\n# 添加 maven 依赖\n\n<dependency>\n    <groupid>com.alibaba</groupid>\n    <artifactid>fastjson</artifactid>\n    <version>x.x.x</version>\n</dependency>\n\n\n\n# fastjson api\n\n# 定义 bean\n\ngroup.java\n\npublic class group {\n\n    private long       id;\n    private string     name;\n    private list<user> users = new arraylist<user>();\n}\n\n\nuser.java\n\npublic class user {\n\n    private long   id;\n    private string name;\n}\n\n\n初始化 bean\n\ngroup group = new group();\ngroup.setid(0l);\ngroup.setname("admin");\n\nuser guestuser = new user();\nguestuser.setid(2l);\nguestuser.setname("guest");\n\nuser rootuser = new user();\nrootuser.setid(3l);\nrootuser.setname("root");\n\ngroup.adduser(guestuser);\ngroup.adduser(rootuser);\n\n\n# 序列化\n\nstring jsonstring = json.tojsonstring(group);\nsystem.out.println(jsonstring);\n\n\n# 反序列化\n\ngroup bean = json.parseobject(jsonstring, group.class);\n\n\n\n# fastjson 注解\n\n# @jsonfield\n\n> 扩展阅读：更多 api 使用细节可以参考：jsonfield 用法，这里介绍基本用法。\n\n可以配置在属性（setter、getter）和字段（必须是 public field）上。\n\n@jsonfield(name="id")\npublic int getid() {return id;}\n\n// 配置date序列化和反序列使用yyyymmdd日期格式\n@jsonfield(format="yyyymmdd")\npublic date date1;\n\n// 不序列化\n@jsonfield(serialize=false)\npublic date date2;\n\n// 不反序列化\n@jsonfield(deserialize=false)\npublic date date3;\n\n// 按ordinal排序\n@jsonfield(ordinal = 2)\nprivate int f1;\n\n@jsonfield(ordinal = 1)\nprivate int f2;\n\n\n# @jsontype\n\n * 自定义序列化：objectserializer\n * 子类型处理：seealso\n\njsontype.alphabetic 属性: fastjson 缺省时会使用字母序序列化，如果你是希望按照 java fields/getters 的自然顺序序列化，可以配置 jsontype.alphabetic，使用方法如下：\n\n@jsontype(alphabetic = false)\npublic static class b {\n    public int f2;\n    public int f1;\n    public int f0;\n}\n\n\n\n# jackson 应用\n\n> 扩展阅读：更多 api 使用细节可以参考 jackson-databind 官方说明\n\n\n# 添加 maven 依赖\n\n<dependency>\n    <groupid>com.fasterxml.jackson.core</groupid>\n    <artifactid>jackson-databind</artifactid>\n    <version>2.9.8</version>\n</dependency>\n\n\n\n# jackson api\n\n# 序列化\n\nobjectmapper mapper = new objectmapper();\n\nmapper.writevalue(new file("result.json"), myresultobject);\n// or:\nbyte[] jsonbytes = mapper.writevalueasbytes(myresultobject);\n// or:\nstring jsonstring = mapper.writevalueasstring(myresultobject);\n\n\n# 反序列化\n\nobjectmapper mapper = new objectmapper();\n\nmyvalue value = mapper.readvalue(new file("data.json"), myvalue.class);\n// or:\nvalue = mapper.readvalue(new url("http://some.com/api/entry.json"), myvalue.class);\n// or:\nvalue = mapper.readvalue("{\\"name\\":\\"bob\\", \\"age\\":13}", myvalue.class);\n\n\n# 容器的序列化和反序列化\n\nperson p = new person("tom", 20);\nperson p2 = new person("jack", 22);\nperson p3 = new person("mary", 18);\n\nlist<person> persons = new linkedlist<>();\npersons.add(p);\npersons.add(p2);\npersons.add(p3);\n\nmap<string, list> map = new hashmap<>();\nmap.put("persons", persons);\n\nstring json = null;\ntry {\n json = mapper.writevalueasstring(map);\n} catch (jsonprocessingexception e) {\n e.printstacktrace();\n}\n\n\n\n# jackson 注解\n\n> 扩展阅读：更多注解使用细节可以参考 jackson-annotations 官方说明\n\n# @jsonproperty\n\npublic class mybean {\n   private string _name;\n\n   // without annotation, we\'d get "thename", but we want "name":\n   @jsonproperty("name")\n   public string getthename() { return _name; }\n\n   // note: it is enough to add annotation on just getter or setter;\n   // so we can omit it here\n   public void setthename(string n) { _name = n; }\n}\n\n\n# @jsonignoreproperties 和 @jsonignore\n\n// means that if we see "foo" or "bar" in json, they will be quietly skipped\n// regardless of whether pojo has such properties\n@jsonignoreproperties({ "foo", "bar" })\npublic class mybean {\n   // will not be written as json; nor assigned from json:\n   @jsonignore\n   public string internal;\n\n   // no annotation, public field is read/written normally\n   public string external;\n\n   @jsonignore\n   public void setcode(int c) { _code = c; }\n\n   // note: will also be ignored because setter has annotation!\n   public int getcode() { return _code; }\n}\n\n\n# @jsoncreator\n\npublic class ctorbean {\n  public final string name;\n  public final int age;\n\n  @jsoncreator // constructor can be public, private, whatever\n  private ctorbean(@jsonproperty("name") string name,\n    @jsonproperty("age") int age)\n  {\n      this.name = name;\n      this.age = age;\n  }\n}\n\n\n# @jsonpropertyorder\n\nalphabetic 设为 true 表示，json 字段按自然顺序排列，默认为 false。\n\n@jsonpropertyorder(alphabetic = true)\npublic class jacksonannotationbean {}\n\n\n\n# gson 应用\n\n> 详细内容可以参考官方文档：gson 用户指南\n\n\n# 添加 maven 依赖\n\n<dependency>\n    <groupid>com.google.code.gson</groupid>\n    <artifactid>gson</artifactid>\n    <version>2.8.6</version>\n</dependency>\n\n\n\n# gson api\n\n# 序列化\n\ngson gson = new gson();\ngson.tojson(1);            // ==> 1\ngson.tojson("abcd");       // ==> "abcd"\ngson.tojson(10l); // ==> 10\nint[] values = { 1 };\ngson.tojson(values);       // ==> [1]\n\n\n# 反序列化\n\nint i1 = gson.fromjson("1", int.class);\ninteger i2 = gson.fromjson("1", integer.class);\nlong l1 = gson.fromjson("1", long.class);\nboolean b1 = gson.fromjson("false", boolean.class);\nstring str = gson.fromjson("\\"abc\\"", string.class);\nstring[] anotherstr = gson.fromjson("[\\"abc\\"]", string[].class);\n\n\n# gsonbuilder\n\ngson 实例可以通过 gsonbuilder 来定制实例化，以控制其序列化、反序列化行为。\n\ngson gson = new gsonbuilder()\n  .setprettyprinting()\n  .setdateformat("yyyy-mm-dd hh:mm:ss")\n  .excludefieldswithmodifiers(modifier.static, modifier.transient, modifier.volatile)\n  .create();\n\n\n\n# gson 注解\n\n# @since\n\n@since 用于控制对象的序列化版本。示例：\n\npublic class versionedclass {\n  @since(1.1) private final string newerfield;\n  @since(1.0) private final string newfield;\n  private final string field;\n\n  public versionedclass() {\n    this.newerfield = "newer";\n    this.newfield = "new";\n    this.field = "old";\n  }\n}\n\nversionedclass versionedobject = new versionedclass();\ngson gson = new gsonbuilder().setversion(1.0).create();\nstring jsonoutput = gson.tojson(versionedobject);\nsystem.out.println(jsonoutput);\nsystem.out.println();\n\ngson = new gson();\njsonoutput = gson.tojson(versionedobject);\nsystem.out.println(jsonoutput);\n\n\n# @serializedname\n\n@serializedname 用于将类成员按照指定名称序列化、反序列化。示例：\n\nprivate class someobject {\n  @serializedname("custom_naming") private final string somefield;\n  private final string someotherfield;\n\n  public someobject(string a, string b) {\n    this.somefield = a;\n    this.someotherfield = b;\n  }\n}\n\n\n\n# 示例源码\n\n> 示例源码：javalib-io-json\n\n\n# 参考资料\n\n * 官方\n   * fastjson github\n   * gson github\n   * jackson 官方文档\n   * jackson-databind\n * 文章\n   * http://www.json.org/json-zh.html\n   * json 的 rfc 文档\n   * json 最佳实践\n   * 【简明教程】json',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 二进制序列化",frontmatter:{title:"Java 二进制序列化",categories:["编程","Java","工具","IO"],tags:["Java","IO","序列化","二进制"],abbrlink:"7684267f",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/95f25b/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/01.IO/02.%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%BA%8F%E5%88%97%E5%8C%96.html",relativePath:"12.工具/01.IO/02.二进制序列化.md",key:"v-d23f2b76",path:"/pages/95f25b/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:18},{level:3,title:"为什么需要二进制序列化库",slug:"为什么需要二进制序列化库",normalizedTitle:"为什么需要二进制序列化库",charIndex:25},{level:3,title:"主流序列化库简介",slug:"主流序列化库简介",normalizedTitle:"主流序列化库简介",charIndex:379},{level:4,title:"Protobuf",slug:"protobuf",normalizedTitle:"protobuf",charIndex:391},{level:4,title:"Thrift",slug:"thrift",normalizedTitle:"thrift",charIndex:526},{level:4,title:"Hessian",slug:"hessian",normalizedTitle:"hessian",charIndex:761},{level:4,title:"Kryo",slug:"kryo",normalizedTitle:"kryo",charIndex:907},{level:4,title:"FST",slug:"fst",normalizedTitle:"fst",charIndex:1047},{level:4,title:"小结",slug:"小结",normalizedTitle:"小结",charIndex:1205},{level:2,title:"FST 应用",slug:"fst-应用",normalizedTitle:"fst 应用",charIndex:1583},{level:3,title:"引入依赖",slug:"引入依赖",normalizedTitle:"引入依赖",charIndex:1594},{level:3,title:"FST API",slug:"fst-api",normalizedTitle:"fst api",charIndex:1726},{level:2,title:"Kryo 应用",slug:"kryo-应用",normalizedTitle:"kryo 应用",charIndex:3615},{level:3,title:"引入依赖",slug:"引入依赖-2",normalizedTitle:"引入依赖",charIndex:1594},{level:3,title:"Kryo API",slug:"kryo-api",normalizedTitle:"kryo api",charIndex:3770},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:6866}],headersStr:"简介 为什么需要二进制序列化库 主流序列化库简介 Protobuf Thrift Hessian Kryo FST 小结 FST 应用 引入依赖 FST API Kryo 应用 引入依赖 Kryo API 参考资料",content:'# Java 二进制序列化\n\n\n# 简介\n\n\n# 为什么需要二进制序列化库\n\n原因很简单，就是 Java 默认的序列化机制（ObjectInputStream 和 ObjectOutputStream）具有很多缺点。\n\n> 不了解 Java 默认的序列化机制，可以参考：Java 序列化\n\nJava 自身的序列化方式具有以下缺点：\n\n * 无法跨语言使用。这点最为致命，对于很多需要跨语言通信的异构系统来说，不能跨语言序列化，即意味着完全无法通信（彼此数据不能识别，当然无法交互了）。\n * 序列化的性能不高。序列化后的数据体积较大，这大大影响存储和传输的效率。\n * 序列化一定需要实现 Serializable 接口。\n * 需要关注 serialVersionUID。\n\n引入二进制序列化库就是为了解决这些问题，这在 RPC 应用中尤为常见。\n\n\n# 主流序列化库简介\n\n# Protobuf\n\nProtobuf 是 Google 开发的结构序列化库。\n\n它具有以下特性：\n\n * 结构化数据存储格式（xml,json 等）\n * 高性能编解码技术\n * 语言和平台无关，扩展性好\n * 支持 Java, C++, Python 三种语言\n\n# Thrift\n\n> Thrift 是 apache 开源项目，是一个点对点的 RPC 实现。\n\n它具有以下特性：\n\n * 支持多种语言（目前支持 28 种语言，如：C++、go、Java、Php、Python、Ruby 等等）。\n * 使用了组建大型数据交换及存储工具，对于大型系统中的内部数据传输，相对于 Json 和 xml 在性能上和传输大小上都有明显的优势。\n * 支持三种比较典型的编码方式（通用二进制编码，压缩二进制编码，优化的可选字段压缩编解码）。\n\n# Hessian\n\n> Hessian 是一种二进制传输协议。\n> \n> RPC 框架 Dubbo 就支持 Thrift 和 Hession。\n\n它具有以下特性：\n\n * 支持多种语言。如：Java、Python、C++、C#、PHP、Ruby 等。\n * 相对其他二进制序列化库较慢。\n\n# Kryo\n\n> Kryo 是用于 Java 的快速高效的二进制对象图序列化框架。Kryo 还可以执行自动的深拷贝和浅拷贝。 这是从对象到对象的直接复制，而不是从对象到字节的复制。\n\n它具有以下特性：\n\n * 速度快，序列化体积小\n * 官方不支持 Java 以外的其他语言\n\n# FST\n\n> FST 是一个 Java 实现二进制序列化库。\n\n它具有以下特性：\n\n * 近乎于 100% 兼容 JDK 序列化，且比 JDK 原序列化方式快 10 倍\n * 2.17 开始与 Android 兼容\n * （可选）2.29 开始支持将任何可序列化的对象图编码/解码为 JSON（包括共享引用）\n\n# 小结\n\n了解了以上这些常见的二进制序列化库的特性。在技术选型时，我们就可以做到有的放矢。\n\n（1）选型参考依据\n\n对于二进制序列化库，我们的选型考量一般有以下几点：\n\n * 是否支持跨语言\n   * 根据业务实际需求来决定。一般来说，支持跨语言，为了兼容，使用复杂度上一般会更高一些。\n * 序列化、反序列化的性能\n * 类库是否轻量化，API 是否简单易懂\n\n（2）选型建议\n\n * 如果需要跨语言通信，那么可以考虑：Protobuf、Thrift、Hession。\n   \n   * thrift、protobuf - 适用于对性能敏感，对开发体验要求不高的内部系统。\n   * hessian - 适用于对开发体验敏感，性能有要求的内外部系统。\n\n * 如果不需要跨语言通信，可以考虑：Kryo 和 FST，性能不错，且 API 十分简单。\n\n\n# FST 应用\n\n\n# 引入依赖\n\n<dependency>\n <groupId>de.ruedigermoeller</groupId>\n <artifactId>fst</artifactId>\n <version>2.56</version>\n</dependency>\n\n\n\n# FST API\n\n示例：\n\nimport org.nustaq.serialization.FSTConfiguration;\n\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Base64;\n\npublic class FstDemo {\n\n private static FSTConfiguration DEFAULT_CONFIG = FSTConfiguration.createDefaultConfiguration();\n\n /**\n  * 将对象序列化为 byte 数组\n  *\n  * @param obj 任意对象\n  * @param <T> 对象的类型\n  * @return 序列化后的 byte 数组\n  */\n public static <T> byte[] writeToBytes(T obj) {\n  return DEFAULT_CONFIG.asByteArray(obj);\n }\n\n /**\n  * 将对象序列化为 byte 数组后，再使用 Base64 编码\n  *\n  * @param obj 任意对象\n  * @param <T> 对象的类型\n  * @return 序列化后的字符串\n  */\n public static <T> String writeToString(T obj) {\n  byte[] bytes = writeToBytes(obj);\n  return new String(Base64.getEncoder().encode(bytes), StandardCharsets.UTF_8);\n }\n\n /**\n  * 将 byte 数组反序列化为原对象\n  *\n  * @param bytes {@link #writeToBytes} 方法序列化后的 byte 数组\n  * @param clazz 原对象的类型\n  * @param <T>   原对象的类型\n  * @return 原对象\n  */\n public static <T> T readFromBytes(byte[] bytes, Class<T> clazz) throws IOException {\n  Object obj = DEFAULT_CONFIG.asObject(bytes);\n  if (clazz.isInstance(obj)) {\n   return (T) obj;\n  } else {\n   throw new IOException("derialize failed");\n  }\n }\n\n /**\n  * 将字符串反序列化为原对象，先使用 Base64 解码\n  *\n  * @param str   {@link #writeToString} 方法序列化后的字符串\n  * @param clazz 原对象的类型\n  * @param <T>   原对象的类型\n  * @return 原对象\n  */\n public static <T> T readFromString(String str, Class<T> clazz) throws IOException {\n  byte[] bytes = str.getBytes(StandardCharsets.UTF_8);\n  return readFromBytes(Base64.getDecoder().decode(bytes), clazz);\n }\n\n}\n\n\n测试：\n\nlong begin = System.currentTimeMillis();\nfor (int i = 0; i < BATCH_SIZE; i++) {\n    TestBean oldBean = BeanUtils.initJdk8Bean();\n    byte[] bytes = FstDemo.writeToBytes(oldBean);\n    TestBean newBean = FstDemo.readFromBytes(bytes, TestBean.class);\n}\nlong end = System.currentTimeMillis();\nSystem.out.printf("FST 序列化/反序列化耗时：%s", (end - begin));\n\n\n\n# Kryo 应用\n\n\n# 引入依赖\n\n<dependency>\n  <groupId>com.esotericsoftware</groupId>\n  <artifactId>kryo</artifactId>\n  <version>5.0.0-RC4</version>\n</dependency>\n\n\n\n# Kryo API\n\n示例：\n\nimport com.esotericsoftware.kryo.Kryo;\nimport com.esotericsoftware.kryo.io.Input;\nimport com.esotericsoftware.kryo.io.Output;\nimport com.esotericsoftware.kryo.util.DefaultInstantiatorStrategy;\nimport org.objenesis.strategy.StdInstantiatorStrategy;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Base64;\n\npublic class KryoDemo {\n\n // 每个线程的 Kryo 实例\n private static final ThreadLocal<Kryo> kryoLocal = ThreadLocal.withInitial(() -> {\n  Kryo kryo = new Kryo();\n\n  /**\n   * 不要轻易改变这里的配置！更改之后，序列化的格式就会发生变化，\n   * 上线的同时就必须清除 Redis 里的所有缓存，\n   * 否则那些缓存再回来反序列化的时候，就会报错\n   */\n  //支持对象循环引用（否则会栈溢出）\n  kryo.setReferences(true); //默认值就是 true，添加此行的目的是为了提醒维护者，不要改变这个配置\n\n  //不强制要求注册类（注册行为无法保证多个 JVM 内同一个类的注册编号相同；而且业务系统中大量的 Class 也难以一一注册）\n  kryo.setRegistrationRequired(false); //默认值就是 false，添加此行的目的是为了提醒维护者，不要改变这个配置\n\n  //Fix the NPE bug when deserializing Collections.\n  ((DefaultInstantiatorStrategy) kryo.getInstantiatorStrategy())\n   .setFallbackInstantiatorStrategy(new StdInstantiatorStrategy());\n\n  return kryo;\n });\n\n /**\n  * 获得当前线程的 Kryo 实例\n  *\n  * @return 当前线程的 Kryo 实例\n  */\n public static Kryo getInstance() {\n  return kryoLocal.get();\n }\n\n /**\n  * 将对象序列化为 byte 数组\n  *\n  * @param obj 任意对象\n  * @param <T> 对象的类型\n  * @return 序列化后的 byte 数组\n  */\n public static <T> byte[] writeToBytes(T obj) {\n  ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();\n  Output output = new Output(byteArrayOutputStream);\n\n  Kryo kryo = getInstance();\n  kryo.writeObject(output, obj);\n  output.flush();\n\n  return byteArrayOutputStream.toByteArray();\n }\n\n /**\n  * 将对象序列化为 byte 数组后，再使用 Base64 编码\n  *\n  * @param obj 任意对象\n  * @param <T> 对象的类型\n  * @return 序列化后的字符串\n  */\n public static <T> String writeToString(T obj) {\n  byte[] bytes = writeToBytes(obj);\n  return new String(Base64.getEncoder().encode(bytes), StandardCharsets.UTF_8);\n }\n\n /**\n  * 将 byte 数组反序列化为原对象\n  *\n  * @param bytes {@link #writeToBytes} 方法序列化后的 byte 数组\n  * @param clazz 原对象的类型\n  * @param <T>   原对象的类型\n  * @return 原对象\n  */\n @SuppressWarnings("unchecked")\n public static <T> T readFromBytes(byte[] bytes, Class<T> clazz) {\n  ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(bytes);\n  Input input = new Input(byteArrayInputStream);\n\n  Kryo kryo = getInstance();\n  return (T) kryo.readObject(input, clazz);\n }\n\n /**\n  * 将字符串反序列化为原对象，先使用 Base64 解码\n  *\n  * @param str   {@link #writeToString} 方法序列化后的字符串\n  * @param clazz 原对象的类型\n  * @param <T>   原对象的类型\n  * @return 原对象\n  */\n public static <T> T readFromString(String str, Class<T> clazz) {\n  byte[] bytes = str.getBytes(StandardCharsets.UTF_8);\n  return readFromBytes(Base64.getDecoder().decode(bytes), clazz);\n }\n\n}\n\n\n测试：\n\nlong begin = System.currentTimeMillis();\nfor (int i = 0; i < BATCH_SIZE; i++) {\n    TestBean oldBean = BeanUtils.initJdk8Bean();\n    byte[] bytes = KryoDemo.writeToBytes(oldBean);\n    TestBean newBean = KryoDemo.readFromBytes(bytes, TestBean.class);\n}\nlong end = System.currentTimeMillis();\nSystem.out.printf("Kryo 序列化/反序列化耗时：%s", (end - begin));\n\n\n\n# 参考资料\n\n * 官方\n   * Protobuf 官网\n   * Protobuf Github\n   * Thrift Github\n   * Kryo Github\n   * Hessian 官网\n   * FST Github\n * 文章\n   * java 序列化框架对比',normalizedContent:'# java 二进制序列化\n\n\n# 简介\n\n\n# 为什么需要二进制序列化库\n\n原因很简单，就是 java 默认的序列化机制（objectinputstream 和 objectoutputstream）具有很多缺点。\n\n> 不了解 java 默认的序列化机制，可以参考：java 序列化\n\njava 自身的序列化方式具有以下缺点：\n\n * 无法跨语言使用。这点最为致命，对于很多需要跨语言通信的异构系统来说，不能跨语言序列化，即意味着完全无法通信（彼此数据不能识别，当然无法交互了）。\n * 序列化的性能不高。序列化后的数据体积较大，这大大影响存储和传输的效率。\n * 序列化一定需要实现 serializable 接口。\n * 需要关注 serialversionuid。\n\n引入二进制序列化库就是为了解决这些问题，这在 rpc 应用中尤为常见。\n\n\n# 主流序列化库简介\n\n# protobuf\n\nprotobuf 是 google 开发的结构序列化库。\n\n它具有以下特性：\n\n * 结构化数据存储格式（xml,json 等）\n * 高性能编解码技术\n * 语言和平台无关，扩展性好\n * 支持 java, c++, python 三种语言\n\n# thrift\n\n> thrift 是 apache 开源项目，是一个点对点的 rpc 实现。\n\n它具有以下特性：\n\n * 支持多种语言（目前支持 28 种语言，如：c++、go、java、php、python、ruby 等等）。\n * 使用了组建大型数据交换及存储工具，对于大型系统中的内部数据传输，相对于 json 和 xml 在性能上和传输大小上都有明显的优势。\n * 支持三种比较典型的编码方式（通用二进制编码，压缩二进制编码，优化的可选字段压缩编解码）。\n\n# hessian\n\n> hessian 是一种二进制传输协议。\n> \n> rpc 框架 dubbo 就支持 thrift 和 hession。\n\n它具有以下特性：\n\n * 支持多种语言。如：java、python、c++、c#、php、ruby 等。\n * 相对其他二进制序列化库较慢。\n\n# kryo\n\n> kryo 是用于 java 的快速高效的二进制对象图序列化框架。kryo 还可以执行自动的深拷贝和浅拷贝。 这是从对象到对象的直接复制，而不是从对象到字节的复制。\n\n它具有以下特性：\n\n * 速度快，序列化体积小\n * 官方不支持 java 以外的其他语言\n\n# fst\n\n> fst 是一个 java 实现二进制序列化库。\n\n它具有以下特性：\n\n * 近乎于 100% 兼容 jdk 序列化，且比 jdk 原序列化方式快 10 倍\n * 2.17 开始与 android 兼容\n * （可选）2.29 开始支持将任何可序列化的对象图编码/解码为 json（包括共享引用）\n\n# 小结\n\n了解了以上这些常见的二进制序列化库的特性。在技术选型时，我们就可以做到有的放矢。\n\n（1）选型参考依据\n\n对于二进制序列化库，我们的选型考量一般有以下几点：\n\n * 是否支持跨语言\n   * 根据业务实际需求来决定。一般来说，支持跨语言，为了兼容，使用复杂度上一般会更高一些。\n * 序列化、反序列化的性能\n * 类库是否轻量化，api 是否简单易懂\n\n（2）选型建议\n\n * 如果需要跨语言通信，那么可以考虑：protobuf、thrift、hession。\n   \n   * thrift、protobuf - 适用于对性能敏感，对开发体验要求不高的内部系统。\n   * hessian - 适用于对开发体验敏感，性能有要求的内外部系统。\n\n * 如果不需要跨语言通信，可以考虑：kryo 和 fst，性能不错，且 api 十分简单。\n\n\n# fst 应用\n\n\n# 引入依赖\n\n<dependency>\n <groupid>de.ruedigermoeller</groupid>\n <artifactid>fst</artifactid>\n <version>2.56</version>\n</dependency>\n\n\n\n# fst api\n\n示例：\n\nimport org.nustaq.serialization.fstconfiguration;\n\nimport java.io.ioexception;\nimport java.nio.charset.standardcharsets;\nimport java.util.base64;\n\npublic class fstdemo {\n\n private static fstconfiguration default_config = fstconfiguration.createdefaultconfiguration();\n\n /**\n  * 将对象序列化为 byte 数组\n  *\n  * @param obj 任意对象\n  * @param <t> 对象的类型\n  * @return 序列化后的 byte 数组\n  */\n public static <t> byte[] writetobytes(t obj) {\n  return default_config.asbytearray(obj);\n }\n\n /**\n  * 将对象序列化为 byte 数组后，再使用 base64 编码\n  *\n  * @param obj 任意对象\n  * @param <t> 对象的类型\n  * @return 序列化后的字符串\n  */\n public static <t> string writetostring(t obj) {\n  byte[] bytes = writetobytes(obj);\n  return new string(base64.getencoder().encode(bytes), standardcharsets.utf_8);\n }\n\n /**\n  * 将 byte 数组反序列化为原对象\n  *\n  * @param bytes {@link #writetobytes} 方法序列化后的 byte 数组\n  * @param clazz 原对象的类型\n  * @param <t>   原对象的类型\n  * @return 原对象\n  */\n public static <t> t readfrombytes(byte[] bytes, class<t> clazz) throws ioexception {\n  object obj = default_config.asobject(bytes);\n  if (clazz.isinstance(obj)) {\n   return (t) obj;\n  } else {\n   throw new ioexception("derialize failed");\n  }\n }\n\n /**\n  * 将字符串反序列化为原对象，先使用 base64 解码\n  *\n  * @param str   {@link #writetostring} 方法序列化后的字符串\n  * @param clazz 原对象的类型\n  * @param <t>   原对象的类型\n  * @return 原对象\n  */\n public static <t> t readfromstring(string str, class<t> clazz) throws ioexception {\n  byte[] bytes = str.getbytes(standardcharsets.utf_8);\n  return readfrombytes(base64.getdecoder().decode(bytes), clazz);\n }\n\n}\n\n\n测试：\n\nlong begin = system.currenttimemillis();\nfor (int i = 0; i < batch_size; i++) {\n    testbean oldbean = beanutils.initjdk8bean();\n    byte[] bytes = fstdemo.writetobytes(oldbean);\n    testbean newbean = fstdemo.readfrombytes(bytes, testbean.class);\n}\nlong end = system.currenttimemillis();\nsystem.out.printf("fst 序列化/反序列化耗时：%s", (end - begin));\n\n\n\n# kryo 应用\n\n\n# 引入依赖\n\n<dependency>\n  <groupid>com.esotericsoftware</groupid>\n  <artifactid>kryo</artifactid>\n  <version>5.0.0-rc4</version>\n</dependency>\n\n\n\n# kryo api\n\n示例：\n\nimport com.esotericsoftware.kryo.kryo;\nimport com.esotericsoftware.kryo.io.input;\nimport com.esotericsoftware.kryo.io.output;\nimport com.esotericsoftware.kryo.util.defaultinstantiatorstrategy;\nimport org.objenesis.strategy.stdinstantiatorstrategy;\n\nimport java.io.bytearrayinputstream;\nimport java.io.bytearrayoutputstream;\nimport java.nio.charset.standardcharsets;\nimport java.util.base64;\n\npublic class kryodemo {\n\n // 每个线程的 kryo 实例\n private static final threadlocal<kryo> kryolocal = threadlocal.withinitial(() -> {\n  kryo kryo = new kryo();\n\n  /**\n   * 不要轻易改变这里的配置！更改之后，序列化的格式就会发生变化，\n   * 上线的同时就必须清除 redis 里的所有缓存，\n   * 否则那些缓存再回来反序列化的时候，就会报错\n   */\n  //支持对象循环引用（否则会栈溢出）\n  kryo.setreferences(true); //默认值就是 true，添加此行的目的是为了提醒维护者，不要改变这个配置\n\n  //不强制要求注册类（注册行为无法保证多个 jvm 内同一个类的注册编号相同；而且业务系统中大量的 class 也难以一一注册）\n  kryo.setregistrationrequired(false); //默认值就是 false，添加此行的目的是为了提醒维护者，不要改变这个配置\n\n  //fix the npe bug when deserializing collections.\n  ((defaultinstantiatorstrategy) kryo.getinstantiatorstrategy())\n   .setfallbackinstantiatorstrategy(new stdinstantiatorstrategy());\n\n  return kryo;\n });\n\n /**\n  * 获得当前线程的 kryo 实例\n  *\n  * @return 当前线程的 kryo 实例\n  */\n public static kryo getinstance() {\n  return kryolocal.get();\n }\n\n /**\n  * 将对象序列化为 byte 数组\n  *\n  * @param obj 任意对象\n  * @param <t> 对象的类型\n  * @return 序列化后的 byte 数组\n  */\n public static <t> byte[] writetobytes(t obj) {\n  bytearrayoutputstream bytearrayoutputstream = new bytearrayoutputstream();\n  output output = new output(bytearrayoutputstream);\n\n  kryo kryo = getinstance();\n  kryo.writeobject(output, obj);\n  output.flush();\n\n  return bytearrayoutputstream.tobytearray();\n }\n\n /**\n  * 将对象序列化为 byte 数组后，再使用 base64 编码\n  *\n  * @param obj 任意对象\n  * @param <t> 对象的类型\n  * @return 序列化后的字符串\n  */\n public static <t> string writetostring(t obj) {\n  byte[] bytes = writetobytes(obj);\n  return new string(base64.getencoder().encode(bytes), standardcharsets.utf_8);\n }\n\n /**\n  * 将 byte 数组反序列化为原对象\n  *\n  * @param bytes {@link #writetobytes} 方法序列化后的 byte 数组\n  * @param clazz 原对象的类型\n  * @param <t>   原对象的类型\n  * @return 原对象\n  */\n @suppresswarnings("unchecked")\n public static <t> t readfrombytes(byte[] bytes, class<t> clazz) {\n  bytearrayinputstream bytearrayinputstream = new bytearrayinputstream(bytes);\n  input input = new input(bytearrayinputstream);\n\n  kryo kryo = getinstance();\n  return (t) kryo.readobject(input, clazz);\n }\n\n /**\n  * 将字符串反序列化为原对象，先使用 base64 解码\n  *\n  * @param str   {@link #writetostring} 方法序列化后的字符串\n  * @param clazz 原对象的类型\n  * @param <t>   原对象的类型\n  * @return 原对象\n  */\n public static <t> t readfromstring(string str, class<t> clazz) {\n  byte[] bytes = str.getbytes(standardcharsets.utf_8);\n  return readfrombytes(base64.getdecoder().decode(bytes), clazz);\n }\n\n}\n\n\n测试：\n\nlong begin = system.currenttimemillis();\nfor (int i = 0; i < batch_size; i++) {\n    testbean oldbean = beanutils.initjdk8bean();\n    byte[] bytes = kryodemo.writetobytes(oldbean);\n    testbean newbean = kryodemo.readfrombytes(bytes, testbean.class);\n}\nlong end = system.currenttimemillis();\nsystem.out.printf("kryo 序列化/反序列化耗时：%s", (end - begin));\n\n\n\n# 参考资料\n\n * 官方\n   * protobuf 官网\n   * protobuf github\n   * thrift github\n   * kryo github\n   * hessian 官网\n   * fst github\n * 文章\n   * java 序列化框架对比',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 序列化工具",frontmatter:{title:"Java 序列化工具",categories:["编程","Java","工具","IO"],tags:["Java","IO","序列化"],abbrlink:"53c50fed",date:"2022-02-17T22:34:30.000Z",hidden:!0,permalink:"/pages/0358e9/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/01.IO/",relativePath:"12.工具/01.IO/README.md",key:"v-199c639b",path:"/pages/0358e9/",headers:[{level:2,title:"内容",slug:"内容",normalizedTitle:"内容",charIndex:278},{level:2,title:"资料",slug:"资料",normalizedTitle:"资料",charIndex:360}],headersStr:"内容 资料",content:"# Java 序列化工具\n\nJava 官方的序列化存在许多问题，因此，很多人更愿意使用优秀的第三方序列化工具来替代 Java 自身的序列化机制。 如果想详细了解 Java 自身序列化方式，可以参考：深入理解 Java 序列化\n\n序列化库技术选型：\n\n * thrift、protobuf - 适用于对性能敏感，对开发体验要求不高的内部系统。\n * hessian - 适用于对开发体验敏感，性能有要求的内外部系统。\n * jackson、gson、fastjson - 适用于对序列化后的数据要求有良好的可读性（转为 json 、xml 形式）。\n\n\n# 内容\n\n * JSON - Fastjson、Jackson、Gson\n * 二进制 - Protobuf、Thrift、Hessian、Kryo、FST\n\n\n# 资料\n\n * Thrift Github\n * Protobuf Github\n * Hessian 官网\n * Fastjson Github\n * Jackson Github\n * Gson Github",normalizedContent:"# java 序列化工具\n\njava 官方的序列化存在许多问题，因此，很多人更愿意使用优秀的第三方序列化工具来替代 java 自身的序列化机制。 如果想详细了解 java 自身序列化方式，可以参考：深入理解 java 序列化\n\n序列化库技术选型：\n\n * thrift、protobuf - 适用于对性能敏感，对开发体验要求不高的内部系统。\n * hessian - 适用于对开发体验敏感，性能有要求的内外部系统。\n * jackson、gson、fastjson - 适用于对序列化后的数据要求有良好的可读性（转为 json 、xml 形式）。\n\n\n# 内容\n\n * json - fastjson、jackson、gson\n * 二进制 - protobuf、thrift、hessian、kryo、fst\n\n\n# 资料\n\n * thrift github\n * protobuf github\n * hessian 官网\n * fastjson github\n * jackson github\n * gson github",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Lombok 快速入门",frontmatter:{title:"Lombok 快速入门",categories:["编程","Java","工具","JavaBean"],tags:["Java","JavaBean","Lombok"],abbrlink:"6f8c7136",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/0d31cd/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/02.JavaBean/01.Lombok.html",relativePath:"12.工具/02.JavaBean/01.Lombok.md",key:"v-2507e04a",path:"/pages/0d31cd/",headers:[{level:2,title:"Lombok 简介",slug:"lombok-简介",normalizedTitle:"lombok 简介",charIndex:18},{level:2,title:"Lombok 安装",slug:"lombok-安装",normalizedTitle:"lombok 安装",charIndex:222},{level:2,title:"Lombok 使用",slug:"lombok-使用",normalizedTitle:"lombok 使用",charIndex:789},{level:3,title:"@Getter and @Setter",slug:"getter-and-setter",normalizedTitle:"@getter and @setter",charIndex:829},{level:3,title:"@NonNull",slug:"nonnull",normalizedTitle:"@nonnull",charIndex:1264},{level:3,title:"@ToString",slug:"tostring",normalizedTitle:"@tostring",charIndex:1810},{level:3,title:"@EqualsAndHashCode",slug:"equalsandhashcode",normalizedTitle:"@equalsandhashcode",charIndex:2434},{level:3,title:"@Data",slug:"data",normalizedTitle:"@data",charIndex:4312},{level:3,title:"@Cleanup",slug:"cleanup",normalizedTitle:"@cleanup",charIndex:6361},{level:3,title:"@Synchronized",slug:"synchronized",normalizedTitle:"@synchronized",charIndex:7025},{level:3,title:"@SneakyThrows",slug:"sneakythrows",normalizedTitle:"@sneakythrows",charIndex:7492},{level:3,title:"示例源码",slug:"示例源码",normalizedTitle:"示例源码",charIndex:7824},{level:2,title:"Lombok 使用注意点",slug:"lombok-使用注意点",normalizedTitle:"lombok 使用注意点",charIndex:7854},{level:3,title:"谨慎使用 @Builder",slug:"谨慎使用-builder",normalizedTitle:"谨慎使用 @builder",charIndex:7871},{level:3,title:"@Data 注解和继承",slug:"data-注解和继承",normalizedTitle:"@data 注解和继承",charIndex:10399},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:12933}],headersStr:"Lombok 简介 Lombok 安装 Lombok 使用 @Getter and @Setter @NonNull @ToString @EqualsAndHashCode @Data @Cleanup @Synchronized @SneakyThrows 示例源码 Lombok 使用注意点 谨慎使用 @Builder @Data 注解和继承 参考资料",content:'# Lombok 快速入门\n\n\n# Lombok 简介\n\nLombok 是一种 Java 实用工具，可用来帮助开发人员消除 Java 的冗长，尤其是对于简单的 Java 对象（POJO）。它通过注释实现这一目的。通过在开发环境中实现 Lombok，开发人员可以节省构建诸如 hashCode() 和 equals() 、getter / setter 这样的方法以及以往用来分类各种 accessor 和 mutator 的大量时间。\n\n\n# Lombok 安装\n\n由于 Lombok 仅在编译阶段生成代码，所以使用 Lombok 注解的源代码，在 IDE 中会被高亮显示错误，针对这个问题可以通过安装 IDE 对应的插件来解决。具体的安装方式可以参考：Setting up Lombok with Eclipse and Intellij\n\n使 IntelliJ IDEA 支持 Lombok 方式如下：\n\n * Intellij 设置支持注解处理\n   * 点击 File > Settings > Build > Annotation Processors\n   * 勾选 Enable annotation processing\n * 安装插件\n   * 点击 Settings > Plugins > Browse repositories\n   * 查找 Lombok Plugin 并进行安装\n   * 重启 IntelliJ IDEA\n * 将 lombok 添加到 pom 文件\n\n<dependency>\n    <groupId>org.projectlombok</groupId>\n    <artifactId>lombok</artifactId>\n    <version>1.16.8</version>\n</dependency>\n\n\n\n# Lombok 使用\n\nLombok 提供注解 API 来修饰指定的类：\n\n\n# @Getter and @Setter\n\n@Getter and @Setter Lombok 代码：\n\n@Getter @Setter private boolean employed = true;\n@Setter(AccessLevel.PROTECTED) private String name;\n\n\n等价于 Java 源码：\n\nprivate boolean employed = true;\nprivate String name;\n\npublic boolean isEmployed() {\n    return employed;\n}\n\npublic void setEmployed(final boolean employed) {\n    this.employed = employed;\n}\n\nprotected void setName(final String name) {\n    this.name = name;\n}\n\n\n\n# @NonNull\n\n@NonNull Lombok 代码：\n\n@Getter @Setter @NonNull\nprivate List<Person> members;\n\n\n等价于 Java 源码：\n\n@NonNull\nprivate List<Person> members;\n\npublic Family(@NonNull final List<Person> members) {\n    if (members == null) throw new java.lang.NullPointerException("members");\n    this.members = members;\n}\n\n@NonNull\npublic List<Person> getMembers() {\n    return members;\n}\n\npublic void setMembers(@NonNull final List<Person> members) {\n    if (members == null) throw new java.lang.NullPointerException("members");\n    this.members = members;\n}\n\n\n\n# @ToString\n\n@ToString Lombok 代码：\n\n@ToString(callSuper=true,exclude="someExcludedField")\npublic class Foo extends Bar {\n    private boolean someBoolean = true;\n    private String someStringField;\n    private float someExcludedField;\n}\n\n\n等价于 Java 源码：\n\npublic class Foo extends Bar {\n    private boolean someBoolean = true;\n    private String someStringField;\n    private float someExcludedField;\n\n    @java.lang.Override\n    public java.lang.String toString() {\n        return "Foo(super=" + super.toString() +\n            ", someBoolean=" + someBoolean +\n            ", someStringField=" + someStringField + ")";\n    }\n}\n\n\n\n# @EqualsAndHashCode\n\n@EqualsAndHashCode Lombok 代码：\n\n@EqualsAndHashCode(callSuper=true,exclude={"address","city","state","zip"})\npublic class Person extends SentientBeing {\n    enum Gender { Male, Female }\n\n    @NonNull private String name;\n    @NonNull private Gender gender;\n\n    private String ssn;\n    private String address;\n    private String city;\n    private String state;\n    private String zip;\n}\n\n\n等价于 Java 源码：\n\npublic class Person extends SentientBeing {\n\n    enum Gender {\n        /*public static final*/ Male /* = new Gender() */,\n        /*public static final*/ Female /* = new Gender() */;\n    }\n    @NonNull\n    private String name;\n    @NonNull\n    private Gender gender;\n    private String ssn;\n    private String address;\n    private String city;\n    private String state;\n    private String zip;\n\n    @java.lang.Override\n    public boolean equals(final java.lang.Object o) {\n        if (o == this) return true;\n        if (o == null) return false;\n        if (o.getClass() != this.getClass()) return false;\n        if (!super.equals(o)) return false;\n        final Person other = (Person)o;\n        if (this.name == null ? other.name != null : !this.name.equals(other.name)) return false;\n        if (this.gender == null ? other.gender != null : !this.gender.equals(other.gender)) return false;\n        if (this.ssn == null ? other.ssn != null : !this.ssn.equals(other.ssn)) return false;\n        return true;\n    }\n\n    @java.lang.Override\n    public int hashCode() {\n        final int PRIME = 31;\n        int result = 1;\n        result = result * PRIME + super.hashCode();\n        result = result * PRIME + (this.name == null ? 0 : this.name.hashCode());\n        result = result * PRIME + (this.gender == null ? 0 : this.gender.hashCode());\n        result = result * PRIME + (this.ssn == null ? 0 : this.ssn.hashCode());\n        return result;\n    }\n}\n\n\n\n# @Data\n\n@Data Lombok 代码：\n\n@Data(staticConstructor="of")\npublic class Company {\n    private final Person founder;\n    private String name;\n    private List<Person> employees;\n}\n\n\n等价于 Java 源码：\n\npublic class Company {\n    private final Person founder;\n    private String name;\n    private List<Person> employees;\n\n    private Company(final Person founder) {\n        this.founder = founder;\n    }\n\n    public static Company of(final Person founder) {\n        return new Company(founder);\n    }\n\n    public Person getFounder() {\n        return founder;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(final String name) {\n        this.name = name;\n    }\n\n    public List<Person> getEmployees() {\n        return employees;\n    }\n\n    public void setEmployees(final List<Person> employees) {\n        this.employees = employees;\n    }\n\n    @java.lang.Override\n    public boolean equals(final java.lang.Object o) {\n        if (o == this) return true;\n        if (o == null) return false;\n        if (o.getClass() != this.getClass()) return false;\n        final Company other = (Company)o;\n        if (this.founder == null ? other.founder != null : !this.founder.equals(other.founder)) return false;\n        if (this.name == null ? other.name != null : !this.name.equals(other.name)) return false;\n        if (this.employees == null ? other.employees != null : !this.employees.equals(other.employees)) return false;\n        return true;\n    }\n\n    @java.lang.Override\n    public int hashCode() {\n        final int PRIME = 31;\n        int result = 1;\n        result = result * PRIME + (this.founder == null ? 0 : this.founder.hashCode());\n        result = result * PRIME + (this.name == null ? 0 : this.name.hashCode());\n        result = result * PRIME + (this.employees == null ? 0 : this.employees.hashCode());\n        return result;\n    }\n\n    @java.lang.Override\n    public java.lang.String toString() {\n        return "Company(founder=" + founder + ", name=" + name + ", employees=" + employees + ")";\n    }\n}\n\n\n\n# @Cleanup\n\n@Cleanup Lombok 代码：\n\npublic void testCleanUp() {\n    try {\n        @Cleanup ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        baos.write(new byte[] {\'Y\',\'e\',\'s\'});\n        System.out.println(baos.toString());\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n}\n\n\n等价于 Java 源码：\n\npublic void testCleanUp() {\n    try {\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        try {\n            baos.write(new byte[]{\'Y\', \'e\', \'s\'});\n            System.out.println(baos.toString());\n        } finally {\n            baos.close();\n        }\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n}\n\n\n\n# @Synchronized\n\n@Synchronized Lombok 代码：\n\nprivate DateFormat format = new SimpleDateFormat("MM-dd-YYYY");\n\n@Synchronized\npublic String synchronizedFormat(Date date) {\n    return format.format(date);\n}\n\n\n等价于 Java 源码：\n\nprivate final java.lang.Object $lock = new java.lang.Object[0];\nprivate DateFormat format = new SimpleDateFormat("MM-dd-YYYY");\n\npublic String synchronizedFormat(Date date) {\n    synchronized ($lock) {\n        return format.format(date);\n    }\n}\n\n\n\n# @SneakyThrows\n\n@SneakyThrows Lombok 代码：\n\n@SneakyThrows\npublic void testSneakyThrows() {\n    throw new IllegalAccessException();\n}\n\n\n等价于 Java 源码：\n\npublic void testSneakyThrows() {\n    try {\n        throw new IllegalAccessException();\n    } catch (java.lang.Throwable $ex) {\n        throw lombok.Lombok.sneakyThrow($ex);\n    }\n}\n\n\n\n# 示例源码\n\n> 示例源码：javalib-bean\n\n\n# Lombok 使用注意点\n\n\n# 谨慎使用 @Builder\n\n在类上标注了 @Data 和 @Builder 注解的时候，编译时，lombok 优化后的 Class 中会没有默认的构造方法。在反序列化的时候，没有默认构造方法就可能会报错。\n\n【示例】使用 @Builder 不当导致 json 反序列化失败\n\n@Data\n@Builder\npublic class BuilderDemo01 {\n\n    private String name;\n\n    public static void main(String[] args) throws JsonProcessingException {\n        BuilderDemo01 demo01 = BuilderDemo01.builder().name("demo01").build();\n        ObjectMapper mapper = new ObjectMapper();\n        String json = mapper.writeValueAsString(demo01);\n        BuilderDemo01 expectDemo01 = mapper.readValue(json, BuilderDemo01.class);\n        System.out.println(expectDemo01.toString());\n    }\n\n}\n\n\n运行时会抛出异常：\n\nException in thread "main" com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `io.github.dunwu.javatech.bean.lombok.BuilderDemo01` (although at least one Creator exists): cannot deserialize from Object value (no delegate- or property-based Creator)\n at [Source: (String)"{"name":"demo01"}"; line: 1, column: 2]\n\tat com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:63)\n\tat com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1432)\n\tat com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1062)\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1297)\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:326)\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:159)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4218)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3214)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3182)\n\tat io.github.dunwu.javatech.bean.lombok.BuilderDemo01.main(BuilderDemo01.java:22)\n\n\n【示例】使用 @Builder 正确方法\n\n@Data\n@Builder\n@NoArgsConstructor\n@AllArgsConstructor\npublic class BuilderDemo02 {\n\n    private String name;\n\n    public static void main(String[] args) throws JsonProcessingException {\n        BuilderDemo02 demo02 = BuilderDemo02.builder().name("demo01").build();\n        ObjectMapper mapper = new ObjectMapper();\n        String json = mapper.writeValueAsString(demo02);\n        BuilderDemo02 expectDemo02 = mapper.readValue(json, BuilderDemo02.class);\n        System.out.println(expectDemo02.toString());\n    }\n\n}\n\n\n\n# @Data 注解和继承\n\n使用 @Data 注解时，则有了 @EqualsAndHashCode 注解，那么就会在此类中存在 equals(Object other) 和 hashCode() 方法，且不会使用父类的属性，这就导致了可能的问题。比如，有多个类有相同的部分属性，把它们定义到父类中，恰好 id（数据库主键）也在父类中，那么就会存在部分对象在比较时，它们并不相等，这是因为：lombok 自动生成的 equals(Object other) 和 hashCode() 方法判定为相等，从而导致和预期不符。\n\n修复此问题的方法很简单：\n\n * 使用 @Data 时，加上 @EqualsAndHashCode(callSuper=true) 注解。\n * 使用 @Getter @Setter @ToString 代替 @Data 并且自定义 equals(Object other) 和 hashCode() 方法。\n\n【示例】测试 @Data 和 @EqualsAndHashCode\n\n@Data\n@ToString(exclude = "age")\n@EqualsAndHashCode(exclude = { "age", "sex" })\npublic class Person {\n\n    protected String name;\n\n    protected Integer age;\n\n    protected String sex;\n\n}\n\n@Data\n@EqualsAndHashCode(callSuper = true, exclude = { "address", "city", "state", "zip" })\npublic class EqualsAndHashCodeDemo extends Person {\n\n    @NonNull\n    private String name;\n\n    @NonNull\n    private Gender gender;\n\n    private String ssn;\n\n    private String address;\n\n    private String city;\n\n    private String state;\n\n    private String zip;\n\n    public EqualsAndHashCodeDemo(@NonNull String name, @NonNull Gender gender) {\n        this.name = name;\n        this.gender = gender;\n    }\n\n    public EqualsAndHashCodeDemo(@NonNull String name, @NonNull Gender gender,\n        String ssn, String address, String city, String state, String zip) {\n        this.name = name;\n        this.gender = gender;\n        this.ssn = ssn;\n        this.address = address;\n        this.city = city;\n        this.state = state;\n        this.zip = zip;\n    }\n\n    public enum Gender {\n        Male,\n        Female\n    }\n\n}\n\n@Test\n@DisplayName("测试 @EqualsAndHashCode")\npublic void testEqualsAndHashCodeDemo() {\n    EqualsAndHashCodeDemo demo1 =\n        new EqualsAndHashCodeDemo("name1", EqualsAndHashCodeDemo.Gender.Female, "ssn", "xxx", "xxx", "xxx", "xxx");\n    EqualsAndHashCodeDemo demo2 =\n        new EqualsAndHashCodeDemo("name1", EqualsAndHashCodeDemo.Gender.Female, "ssn", "ooo", "ooo", "ooo", "ooo");\n    Assertions.assertEquals(demo1, demo2);\n\n    Person person = new Person();\n    person.setName("张三");\n    person.setAge(20);\n    person.setSex("男");\n\n    Person person2 = new Person();\n    person2.setName("张三");\n    person2.setAge(18);\n    person2.setSex("男");\n\n    Person person3 = new Person();\n    person3.setName("李四");\n    person3.setAge(20);\n    person3.setSex("男");\n\n    Assertions.assertEquals(person2, person);\n    Assertions.assertNotEquals(person3, person);\n}\n\n\n上面的单元测试可以通过，但如果将 @EqualsAndHashCode(callSuper = true, exclude = { "address", "city", "state", "zip" }) 注掉就会报错。\n\n\n# 参考资料\n\n * Lombok 官网\n * Lombok Github\n * IntelliJ IDEA - Lombok Plugin',normalizedContent:'# lombok 快速入门\n\n\n# lombok 简介\n\nlombok 是一种 java 实用工具，可用来帮助开发人员消除 java 的冗长，尤其是对于简单的 java 对象（pojo）。它通过注释实现这一目的。通过在开发环境中实现 lombok，开发人员可以节省构建诸如 hashcode() 和 equals() 、getter / setter 这样的方法以及以往用来分类各种 accessor 和 mutator 的大量时间。\n\n\n# lombok 安装\n\n由于 lombok 仅在编译阶段生成代码，所以使用 lombok 注解的源代码，在 ide 中会被高亮显示错误，针对这个问题可以通过安装 ide 对应的插件来解决。具体的安装方式可以参考：setting up lombok with eclipse and intellij\n\n使 intellij idea 支持 lombok 方式如下：\n\n * intellij 设置支持注解处理\n   * 点击 file > settings > build > annotation processors\n   * 勾选 enable annotation processing\n * 安装插件\n   * 点击 settings > plugins > browse repositories\n   * 查找 lombok plugin 并进行安装\n   * 重启 intellij idea\n * 将 lombok 添加到 pom 文件\n\n<dependency>\n    <groupid>org.projectlombok</groupid>\n    <artifactid>lombok</artifactid>\n    <version>1.16.8</version>\n</dependency>\n\n\n\n# lombok 使用\n\nlombok 提供注解 api 来修饰指定的类：\n\n\n# @getter and @setter\n\n@getter and @setter lombok 代码：\n\n@getter @setter private boolean employed = true;\n@setter(accesslevel.protected) private string name;\n\n\n等价于 java 源码：\n\nprivate boolean employed = true;\nprivate string name;\n\npublic boolean isemployed() {\n    return employed;\n}\n\npublic void setemployed(final boolean employed) {\n    this.employed = employed;\n}\n\nprotected void setname(final string name) {\n    this.name = name;\n}\n\n\n\n# @nonnull\n\n@nonnull lombok 代码：\n\n@getter @setter @nonnull\nprivate list<person> members;\n\n\n等价于 java 源码：\n\n@nonnull\nprivate list<person> members;\n\npublic family(@nonnull final list<person> members) {\n    if (members == null) throw new java.lang.nullpointerexception("members");\n    this.members = members;\n}\n\n@nonnull\npublic list<person> getmembers() {\n    return members;\n}\n\npublic void setmembers(@nonnull final list<person> members) {\n    if (members == null) throw new java.lang.nullpointerexception("members");\n    this.members = members;\n}\n\n\n\n# @tostring\n\n@tostring lombok 代码：\n\n@tostring(callsuper=true,exclude="someexcludedfield")\npublic class foo extends bar {\n    private boolean someboolean = true;\n    private string somestringfield;\n    private float someexcludedfield;\n}\n\n\n等价于 java 源码：\n\npublic class foo extends bar {\n    private boolean someboolean = true;\n    private string somestringfield;\n    private float someexcludedfield;\n\n    @java.lang.override\n    public java.lang.string tostring() {\n        return "foo(super=" + super.tostring() +\n            ", someboolean=" + someboolean +\n            ", somestringfield=" + somestringfield + ")";\n    }\n}\n\n\n\n# @equalsandhashcode\n\n@equalsandhashcode lombok 代码：\n\n@equalsandhashcode(callsuper=true,exclude={"address","city","state","zip"})\npublic class person extends sentientbeing {\n    enum gender { male, female }\n\n    @nonnull private string name;\n    @nonnull private gender gender;\n\n    private string ssn;\n    private string address;\n    private string city;\n    private string state;\n    private string zip;\n}\n\n\n等价于 java 源码：\n\npublic class person extends sentientbeing {\n\n    enum gender {\n        /*public static final*/ male /* = new gender() */,\n        /*public static final*/ female /* = new gender() */;\n    }\n    @nonnull\n    private string name;\n    @nonnull\n    private gender gender;\n    private string ssn;\n    private string address;\n    private string city;\n    private string state;\n    private string zip;\n\n    @java.lang.override\n    public boolean equals(final java.lang.object o) {\n        if (o == this) return true;\n        if (o == null) return false;\n        if (o.getclass() != this.getclass()) return false;\n        if (!super.equals(o)) return false;\n        final person other = (person)o;\n        if (this.name == null ? other.name != null : !this.name.equals(other.name)) return false;\n        if (this.gender == null ? other.gender != null : !this.gender.equals(other.gender)) return false;\n        if (this.ssn == null ? other.ssn != null : !this.ssn.equals(other.ssn)) return false;\n        return true;\n    }\n\n    @java.lang.override\n    public int hashcode() {\n        final int prime = 31;\n        int result = 1;\n        result = result * prime + super.hashcode();\n        result = result * prime + (this.name == null ? 0 : this.name.hashcode());\n        result = result * prime + (this.gender == null ? 0 : this.gender.hashcode());\n        result = result * prime + (this.ssn == null ? 0 : this.ssn.hashcode());\n        return result;\n    }\n}\n\n\n\n# @data\n\n@data lombok 代码：\n\n@data(staticconstructor="of")\npublic class company {\n    private final person founder;\n    private string name;\n    private list<person> employees;\n}\n\n\n等价于 java 源码：\n\npublic class company {\n    private final person founder;\n    private string name;\n    private list<person> employees;\n\n    private company(final person founder) {\n        this.founder = founder;\n    }\n\n    public static company of(final person founder) {\n        return new company(founder);\n    }\n\n    public person getfounder() {\n        return founder;\n    }\n\n    public string getname() {\n        return name;\n    }\n\n    public void setname(final string name) {\n        this.name = name;\n    }\n\n    public list<person> getemployees() {\n        return employees;\n    }\n\n    public void setemployees(final list<person> employees) {\n        this.employees = employees;\n    }\n\n    @java.lang.override\n    public boolean equals(final java.lang.object o) {\n        if (o == this) return true;\n        if (o == null) return false;\n        if (o.getclass() != this.getclass()) return false;\n        final company other = (company)o;\n        if (this.founder == null ? other.founder != null : !this.founder.equals(other.founder)) return false;\n        if (this.name == null ? other.name != null : !this.name.equals(other.name)) return false;\n        if (this.employees == null ? other.employees != null : !this.employees.equals(other.employees)) return false;\n        return true;\n    }\n\n    @java.lang.override\n    public int hashcode() {\n        final int prime = 31;\n        int result = 1;\n        result = result * prime + (this.founder == null ? 0 : this.founder.hashcode());\n        result = result * prime + (this.name == null ? 0 : this.name.hashcode());\n        result = result * prime + (this.employees == null ? 0 : this.employees.hashcode());\n        return result;\n    }\n\n    @java.lang.override\n    public java.lang.string tostring() {\n        return "company(founder=" + founder + ", name=" + name + ", employees=" + employees + ")";\n    }\n}\n\n\n\n# @cleanup\n\n@cleanup lombok 代码：\n\npublic void testcleanup() {\n    try {\n        @cleanup bytearrayoutputstream baos = new bytearrayoutputstream();\n        baos.write(new byte[] {\'y\',\'e\',\'s\'});\n        system.out.println(baos.tostring());\n    } catch (ioexception e) {\n        e.printstacktrace();\n    }\n}\n\n\n等价于 java 源码：\n\npublic void testcleanup() {\n    try {\n        bytearrayoutputstream baos = new bytearrayoutputstream();\n        try {\n            baos.write(new byte[]{\'y\', \'e\', \'s\'});\n            system.out.println(baos.tostring());\n        } finally {\n            baos.close();\n        }\n    } catch (ioexception e) {\n        e.printstacktrace();\n    }\n}\n\n\n\n# @synchronized\n\n@synchronized lombok 代码：\n\nprivate dateformat format = new simpledateformat("mm-dd-yyyy");\n\n@synchronized\npublic string synchronizedformat(date date) {\n    return format.format(date);\n}\n\n\n等价于 java 源码：\n\nprivate final java.lang.object $lock = new java.lang.object[0];\nprivate dateformat format = new simpledateformat("mm-dd-yyyy");\n\npublic string synchronizedformat(date date) {\n    synchronized ($lock) {\n        return format.format(date);\n    }\n}\n\n\n\n# @sneakythrows\n\n@sneakythrows lombok 代码：\n\n@sneakythrows\npublic void testsneakythrows() {\n    throw new illegalaccessexception();\n}\n\n\n等价于 java 源码：\n\npublic void testsneakythrows() {\n    try {\n        throw new illegalaccessexception();\n    } catch (java.lang.throwable $ex) {\n        throw lombok.lombok.sneakythrow($ex);\n    }\n}\n\n\n\n# 示例源码\n\n> 示例源码：javalib-bean\n\n\n# lombok 使用注意点\n\n\n# 谨慎使用 @builder\n\n在类上标注了 @data 和 @builder 注解的时候，编译时，lombok 优化后的 class 中会没有默认的构造方法。在反序列化的时候，没有默认构造方法就可能会报错。\n\n【示例】使用 @builder 不当导致 json 反序列化失败\n\n@data\n@builder\npublic class builderdemo01 {\n\n    private string name;\n\n    public static void main(string[] args) throws jsonprocessingexception {\n        builderdemo01 demo01 = builderdemo01.builder().name("demo01").build();\n        objectmapper mapper = new objectmapper();\n        string json = mapper.writevalueasstring(demo01);\n        builderdemo01 expectdemo01 = mapper.readvalue(json, builderdemo01.class);\n        system.out.println(expectdemo01.tostring());\n    }\n\n}\n\n\n运行时会抛出异常：\n\nexception in thread "main" com.fasterxml.jackson.databind.exc.mismatchedinputexception: cannot construct instance of `io.github.dunwu.javatech.bean.lombok.builderdemo01` (although at least one creator exists): cannot deserialize from object value (no delegate- or property-based creator)\n at [source: (string)"{"name":"demo01"}"; line: 1, column: 2]\n\tat com.fasterxml.jackson.databind.exc.mismatchedinputexception.from(mismatchedinputexception.java:63)\n\tat com.fasterxml.jackson.databind.deserializationcontext.reportinputmismatch(deserializationcontext.java:1432)\n\tat com.fasterxml.jackson.databind.deserializationcontext.handlemissinginstantiator(deserializationcontext.java:1062)\n\tat com.fasterxml.jackson.databind.deser.beandeserializerbase.deserializefromobjectusingnondefault(beandeserializerbase.java:1297)\n\tat com.fasterxml.jackson.databind.deser.beandeserializer.deserializefromobject(beandeserializer.java:326)\n\tat com.fasterxml.jackson.databind.deser.beandeserializer.deserialize(beandeserializer.java:159)\n\tat com.fasterxml.jackson.databind.objectmapper._readmapandclose(objectmapper.java:4218)\n\tat com.fasterxml.jackson.databind.objectmapper.readvalue(objectmapper.java:3214)\n\tat com.fasterxml.jackson.databind.objectmapper.readvalue(objectmapper.java:3182)\n\tat io.github.dunwu.javatech.bean.lombok.builderdemo01.main(builderdemo01.java:22)\n\n\n【示例】使用 @builder 正确方法\n\n@data\n@builder\n@noargsconstructor\n@allargsconstructor\npublic class builderdemo02 {\n\n    private string name;\n\n    public static void main(string[] args) throws jsonprocessingexception {\n        builderdemo02 demo02 = builderdemo02.builder().name("demo01").build();\n        objectmapper mapper = new objectmapper();\n        string json = mapper.writevalueasstring(demo02);\n        builderdemo02 expectdemo02 = mapper.readvalue(json, builderdemo02.class);\n        system.out.println(expectdemo02.tostring());\n    }\n\n}\n\n\n\n# @data 注解和继承\n\n使用 @data 注解时，则有了 @equalsandhashcode 注解，那么就会在此类中存在 equals(object other) 和 hashcode() 方法，且不会使用父类的属性，这就导致了可能的问题。比如，有多个类有相同的部分属性，把它们定义到父类中，恰好 id（数据库主键）也在父类中，那么就会存在部分对象在比较时，它们并不相等，这是因为：lombok 自动生成的 equals(object other) 和 hashcode() 方法判定为相等，从而导致和预期不符。\n\n修复此问题的方法很简单：\n\n * 使用 @data 时，加上 @equalsandhashcode(callsuper=true) 注解。\n * 使用 @getter @setter @tostring 代替 @data 并且自定义 equals(object other) 和 hashcode() 方法。\n\n【示例】测试 @data 和 @equalsandhashcode\n\n@data\n@tostring(exclude = "age")\n@equalsandhashcode(exclude = { "age", "sex" })\npublic class person {\n\n    protected string name;\n\n    protected integer age;\n\n    protected string sex;\n\n}\n\n@data\n@equalsandhashcode(callsuper = true, exclude = { "address", "city", "state", "zip" })\npublic class equalsandhashcodedemo extends person {\n\n    @nonnull\n    private string name;\n\n    @nonnull\n    private gender gender;\n\n    private string ssn;\n\n    private string address;\n\n    private string city;\n\n    private string state;\n\n    private string zip;\n\n    public equalsandhashcodedemo(@nonnull string name, @nonnull gender gender) {\n        this.name = name;\n        this.gender = gender;\n    }\n\n    public equalsandhashcodedemo(@nonnull string name, @nonnull gender gender,\n        string ssn, string address, string city, string state, string zip) {\n        this.name = name;\n        this.gender = gender;\n        this.ssn = ssn;\n        this.address = address;\n        this.city = city;\n        this.state = state;\n        this.zip = zip;\n    }\n\n    public enum gender {\n        male,\n        female\n    }\n\n}\n\n@test\n@displayname("测试 @equalsandhashcode")\npublic void testequalsandhashcodedemo() {\n    equalsandhashcodedemo demo1 =\n        new equalsandhashcodedemo("name1", equalsandhashcodedemo.gender.female, "ssn", "xxx", "xxx", "xxx", "xxx");\n    equalsandhashcodedemo demo2 =\n        new equalsandhashcodedemo("name1", equalsandhashcodedemo.gender.female, "ssn", "ooo", "ooo", "ooo", "ooo");\n    assertions.assertequals(demo1, demo2);\n\n    person person = new person();\n    person.setname("张三");\n    person.setage(20);\n    person.setsex("男");\n\n    person person2 = new person();\n    person2.setname("张三");\n    person2.setage(18);\n    person2.setsex("男");\n\n    person person3 = new person();\n    person3.setname("李四");\n    person3.setage(20);\n    person3.setsex("男");\n\n    assertions.assertequals(person2, person);\n    assertions.assertnotequals(person3, person);\n}\n\n\n上面的单元测试可以通过，但如果将 @equalsandhashcode(callsuper = true, exclude = { "address", "city", "state", "zip" }) 注掉就会报错。\n\n\n# 参考资料\n\n * lombok 官网\n * lombok github\n * intellij idea - lombok plugin',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Dozer 快速入门",frontmatter:{title:"Dozer 快速入门",categories:["编程","Java","工具","JavaBean"],tags:["Java","JavaBean","Dozer"],abbrlink:"3632a3b1",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/596174/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/02.JavaBean/02.Dozer.html",relativePath:"12.工具/02.JavaBean/02.Dozer.md",key:"v-696c277c",path:"/pages/596174/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:127},{level:2,title:"安装",slug:"安装",normalizedTitle:"安装",charIndex:259},{level:3,title:"引入 jar 包",slug:"引入-jar-包",normalizedTitle:"引入 jar 包",charIndex:266},{level:3,title:"Eclipse 插件",slug:"eclipse-插件",normalizedTitle:"eclipse 插件",charIndex:580},{level:2,title:"使用",slug:"使用",normalizedTitle:"使用",charIndex:292},{level:3,title:"准备",slug:"准备",normalizedTitle:"准备",charIndex:761},{level:3,title:"Dozer 的配置",slug:"dozer-的配置",normalizedTitle:"dozer 的配置",charIndex:1126},{level:4,title:"为什么要有映射配置?",slug:"为什么要有映射配置",normalizedTitle:"为什么要有映射配置?",charIndex:1139},{level:4,title:"映射配置文件",slug:"映射配置文件",normalizedTitle:"映射配置文件",charIndex:1501},{level:3,title:"与 Spring 整合",slug:"与-spring-整合",normalizedTitle:"与 spring 整合",charIndex:2226},{level:4,title:"配置 DozerBeanMapperFactoryBean",slug:"配置-dozerbeanmapperfactorybean",normalizedTitle:"配置 dozerbeanmapperfactorybean",charIndex:2241},{level:4,title:"自动装配",slug:"自动装配",normalizedTitle:"自动装配",charIndex:3075},{level:2,title:"Dozer 支持的数据类型转换",slug:"dozer-支持的数据类型转换",normalizedTitle:"dozer 支持的数据类型转换",charIndex:3686},{level:2,title:"Dozer 的映射配置",slug:"dozer-的映射配置",normalizedTitle:"dozer 的映射配置",charIndex:5053},{level:3,title:"用注解来配置映射",slug:"用注解来配置映射",normalizedTitle:"用注解来配置映射",charIndex:5184},{level:3,title:"用 API 来配置映射",slug:"用-api-来配置映射",normalizedTitle:"用 api 来配置映射",charIndex:6247},{level:3,title:"用 XML 来配置映射",slug:"用-xml-来配置映射",normalizedTitle:"用 xml 来配置映射",charIndex:6297},{level:4,title:"属性名不同时的映射(Basic Property Mapping)",slug:"属性名不同时的映射-basic-property-mapping",normalizedTitle:"属性名不同时的映射(basic property mapping)",charIndex:6382},{level:4,title:"字符串和日期映射(String to Date Mapping)",slug:"字符串和日期映射-string-to-date-mapping",normalizedTitle:"字符串和日期映射(string to date mapping)",charIndex:6507},{level:4,title:"集合和数组映射(Collection and Array Mapping)",slug:"集合和数组映射-collection-and-array-mapping",normalizedTitle:"集合和数组映射(collection and array mapping)",charIndex:7304},{level:4,title:"深度映射(Deep Mapping)",slug:"深度映射-deep-mapping",normalizedTitle:"深度映射(deep mapping)",charIndex:8457},{level:4,title:"排除属性(Excluding Fields)",slug:"排除属性-excluding-fields",normalizedTitle:"排除属性(excluding fields)",charIndex:8945},{level:4,title:"单向映射(One-Way Mapping)",slug:"单向映射-one-way-mapping",normalizedTitle:"单向映射(one-way mapping)",charIndex:9175},{level:4,title:"全局配置(Global Configuration)",slug:"全局配置-global-configuration",normalizedTitle:"全局配置(global configuration)",charIndex:9772},{level:4,title:"定制转换(Custom Converters)",slug:"定制转换-custom-converters",normalizedTitle:"定制转换(custom converters)",charIndex:10716},{level:4,title:"映射的继承(Inheritance Mapping)",slug:"映射的继承-inheritance-mapping",normalizedTitle:"映射的继承(inheritance mapping)",charIndex:13131},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:9054}],headersStr:"简介 安装 引入 jar 包 Eclipse 插件 使用 准备 Dozer 的配置 为什么要有映射配置? 映射配置文件 与 Spring 整合 配置 DozerBeanMapperFactoryBean 自动装配 Dozer 支持的数据类型转换 Dozer 的映射配置 用注解来配置映射 用 API 来配置映射 用 XML 来配置映射 属性名不同时的映射(Basic Property Mapping) 字符串和日期映射(String to Date Mapping) 集合和数组映射(Collection and Array Mapping) 深度映射(Deep Mapping) 排除属性(Excluding Fields) 单向映射(One-Way Mapping) 全局配置(Global Configuration) 定制转换(Custom Converters) 映射的继承(Inheritance Mapping) 参考",content:'# Dozer 快速入门\n\n这篇文章是本人在阅读 Dozer 官方文档（5.5.1 版本，官网已经一年多没更新了）的过程中，整理下来我认为比较基础的应用场景。\n\n本文中提到的例子应该能覆盖 JavaBean 映射的大部分场景，希望对你有所帮助。\n\n\n# 简介\n\nDozer 是什么?\n\nDozer 是一个 JavaBean 映射工具库。\n\n它支持简单的属性映射，复杂类型映射，双向映射，隐式显式的映射，以及递归映射。\n\n它支持三种映射方式：注解、API、XML。\n\n它是开源的，遵从Apache 2.0 协议\n\n\n# 安装\n\n\n# 引入 jar 包\n\nmaven 方式\n\n如果你的项目使用 maven，添加以下依赖到你的 pom.xml 即可：\n\n<dependency>\n    <groupId>net.sf.dozer</groupId>\n    <artifactId>dozer</artifactId>\n    <version>5.4.0</version>\n</dependency>\n\n\n非 maven 方式\n\n如果你的项目不使用 maven，那就只能发扬不怕苦不怕累的精神了。\n\n使用 Dozer 需要引入 Dozer 的 jar 包以及其依赖的第三方 jar 包。\n\n * Dozer\n * Dozer 依赖的第三方 jar 包\n\n\n# Eclipse 插件\n\nDozer 有插件可以在 Eclipse 中使用(不知道是否好用，反正我没用过)\n\n插件地址: http://dozer.sourceforge.net/eclipse-plugin\n\n\n# 使用\n\n将 Dozer 引入到工程中后，我们就可以来小试一番了。\n\n实践出真知，先以一个最简单的例子来展示 Dozer 映射的处理过程。\n\n\n# 准备\n\n我们先准备两个要互相映射的类\n\nNotSameAttributeA.java\n\npublic class NotSameAttributeA {\n    private long id;\n    private String name;\n    private Date date;\n\n    // 省略getter/setter\n}\n\n\nNotSameAttributeB.java\n\npublic class NotSameAttributeB {\n    private long id;\n    private String value;\n    private Date date;\n\n    // 省略getter/setter\n}\n\n\n这两个类存在属性名不完全相同的情况：name 和 value。\n\n\n# Dozer 的配置\n\n# 为什么要有映射配置?\n\n如果要映射的两个对象有完全相同的属性名，那么一切都很简单。\n\n只需要直接使用 Dozer 的 API 即可：\n\nMapper mapper = new DozerBeanMapper();\nDestinationObject destObject =\n    mapper.map(sourceObject, DestinationObject.class);\n\n\n但实际映射时，往往存在属性名不同的情况。\n\n所以，你需要一些配置来告诉 Dozer 应该转换什么，怎么转换。\n\n注：官网着重建议：在现实应用中，最好不要每次映射对象时都创建一个Mapper实例来工作，这样会产生不必要的开销。如果你不使用 IoC 容器（如：spring）来管理你的项目，那么，最好将Mapper定义为单例模式。\n\n# 映射配置文件\n\n在src/test/resources目录下添加dozer/dozer-mapping.xml文件。 <mapping>标签中允许你定义<class-a>和<class-b>，对应着相互映射的类。 <field>标签里定义要映射的特殊属性。需要注意<a>和<class-a>对应，<b>和<class-b>对应，聪明的你，猜也猜出来了吧。\n\n<?xml version="1.0" encoding="UTF-8"?>\n<mappings xmlns="http://dozer.sourceforge.net" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n          xsi:schemaLocation="http://dozer.sourceforge.net\n          http://dozer.sourceforge.net/schema/beanmapping.xsd">\n  <mapping date-format="yyyy-MM-dd">\n    <class-a>org.zp.notes.spring.common.dozer.vo.NotSameAttributeA</class-a>\n    <class-b>org.zp.notes.spring.common.dozer.vo.NotSameAttributeB</class-b>\n    <field>\n      <a>name</a>\n      <b>value</b>\n    </field>\n  </mapping>\n</mappings>\n\n\n\n# 与 Spring 整合\n\n# 配置 DozerBeanMapperFactoryBean\n\n在src/test/resources目录下添加spring/spring-dozer.xml文件。\n\nDozer 与 Spring 的整合很便利，你只需要声明一个DozerBeanMapperFactoryBean， 将所有的 dozer 映射配置文件作为属性注入到mappingFiles， DozerBeanMapperFactoryBean会加载这些规则。\n\nspring-dozer.xml 文件范例\n\n<?xml version="1.0" encoding="UTF-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n       xsi:schemaLocation="http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans-2.0.xsd"\n       default-autowire="byName" default-lazy-init="false">\n\n  <bean id="mapper" class="org.dozer.spring.DozerBeanMapperFactoryBean">\n    <property name="mappingFiles">\n      <list>\n        <value>classpath*:dozer/dozer-mapping.xml</value>\n      </list>\n    </property>\n  </bean>\n</beans>\n\n\n# 自动装配\n\n至此，万事具备，你只需要自动装配mapper。\n\nRunWith(SpringJUnit4ClassRunner.class)\n@ContextConfiguration(locations = {"classpath:spring/spring-dozer.xml"})\n@TransactionConfiguration(defaultRollback = false)\npublic class DozerTest extends TestCase {\n    @Autowired\n    Mapper mapper;\n\n    @Test\n    public void testNotSameAttributeMapping() {\n        NotSameAttributeA src = new NotSameAttributeA();\n        src.setId(007);\n        src.setName("邦德");\n        src.setDate(new Date());\n\n        NotSameAttributeB desc = mapper.map(src, NotSameAttributeB.class);\n        Assert.assertNotNull(desc);\n    }\n}\n\n\n运行一下单元测试，绿灯通过。\n\n\n# Dozer 支持的数据类型转换\n\nDozer 可以自动做数据类型转换。当前，Dozer 支持以下数据类型转换（都是双向的）\n\n * Primitive to Primitive Wrapper\n   \n   原型(int、long 等)和原型包装类(Integer、Long)\n\n * Primitive to Custom Wrapper\n   \n   原型和定制的包装\n\n * Primitive Wrapper to Primitive Wrapper\n   \n   原型包装类和包装类\n\n * Primitive to Primitive\n   \n   原型和原型\n\n * Complex Type to Complex Type\n   \n   复杂类型和复杂类型\n\n * String to Primitive\n   \n   字符串和原型\n\n * String to Primitive Wrapper\n   \n   字符串和原型包装类\n\n * String to Complex Type if the Complex Type contains a String constructor\n   \n   字符串和有字符串构造器的复杂类型（类）\n\n * String to Map\n   \n   字符串和 Map\n\n * Collection to Collection\n   \n   集合和集合\n\n * Collection to Array\n   \n   集合和数组\n\n * Map to Complex Type\n   \n   Map 和复杂类型\n\n * Map to Custom Map Type\n   \n   Map 和定制 Map 类型\n\n * Enum to Enum\n   \n   枚举和枚举\n\n * Each of these can be mapped to one another: java.util.Date, java.sql.Date, java.sql.Time, java.sql.Timestamp, java.util.Calendar, java.util.GregorianCalendar\n   \n   这些时间相关的常见类可以互换：java.util.Date, java.sql.Date, java.sql.Time, java.sql.Timestamp, java.util.Calendar, java.util.GregorianCalendar\n\n * String to any of the supported Date/Calendar Objects.\n   \n   字符串和支持 Date/Calendar 的对象\n\n * Objects containing a toString() method that produces a long representing time in (ms) to any supported Date/Calendar object.\n   \n   如果一个对象的 toString()方法返回的是一个代表 long 型的时间数值（单位：ms），就可以和任何支持 Date/Calendar 的对象转换。\n\n\n# Dozer 的映射配置\n\n在前面的简单例子中，我们体验了一把 Dozer 的映射流程。但是两个类进行映射，有很多复杂的情况，相应的，你也需要一些更复杂的配置。\n\nDozer 有三种映射配置方式：\n\n * 注解方式\n * API 方式\n * XML 方式\n\n\n# 用注解来配置映射\n\nDozer 5.3.2版本开始支持注解方式配置映射（只有一个注解：@Mapping）。可以应对一些简单的映射处理，复杂的就玩不转了。\n\n看一下@Mapping的声明就可以知道，这个注解只能用于元素和方法。\n\n@Retention(RetentionPolicy.RUNTIME)\n@Target({ElementType.FIELD, ElementType.METHOD})\npublic @interface Mapping {\n  String value() default "";\n}\n\n\n让我们来试试吧：\n\nTargetBean.java\n\npublic class SourceBean {\n\n    private Long id;\n\n    private String name;\n\n    @Mapping("binaryData")\n    private String data;\n\n    @Mapping("pk")\n    public Long getId() {\n        return this.id;\n    }\n\n    //其余getter/setter方法略\n}\n\n\nTargetBean.java\n\npublic class TargetBean {\n\n    private String pk;\n\n    private String name;\n\n    private String binaryData;\n\n    //getter/setter方法略\n}\n\n\n定义了两个相互映射的 Java 类，只需要在源类中用@Mapping标记和目标类中对应的属性就可以了。\n\n@Test\npublic void testAnnotationMapping() {\n SourceBean src = new SourceBean();\n src.setId(7L);\n src.setName("邦德");\n src.setData("00000111");\n\n TargetBean desc = mapper.map(src, TargetBean.class);\n Assert.assertNotNull(desc);\n}\n\n\n测试一下，绿灯通过。\n\n官方文档说，虽然当前版本（文档的版本对应 Dozer 5.5.1）仅支持@Mapping，但是在未来的发布版本会提供其他的注解功能，那就敬请期待吧（再次吐槽一下：一年多没更新了）。\n\n\n# 用 API 来配置映射\n\n个人觉得这种方式比较麻烦，不推荐，也不想多做介绍，就是这么任性。\n\n\n# 用 XML 来配置映射\n\n需要强调的是：如果两个类的所有属性都能很好的互转，可以你中有我，我中有你，不分彼此，那么就不要画蛇添足的在 xml 中去声明映射规则了。\n\n# 属性名不同时的映射(Basic Property Mapping)\n\nDozer 会自动映射属性名相同的属性，所以不必添加在 xml 文件中。\n\n<field>\n  <a>one</a>\n  <b>onePrime</b>\n</field>\n\n\n# 字符串和日期映射(String to Date Mapping)\n\n字符串在和日期进行映射时，允许用户指定日期的格式。\n\n格式的设置分为三个作用域级别：\n\n属性级别\n\n对当前属性有效（这个属性必须是日期字符串）\n\n<field>\n  <a date-format="MM/dd/yyyy HH:mm:ss:SS">dateString</a>\n  <b>dateObject</b>\n</field>\n\n\n类级别\n\n对这个类中的所有日期相关的属性有效\n\n<mapping date-format="MM-dd-yyyy HH:mm:ss">\n  <class-a>org.dozer.vo.TestObject</class-a>\n  <class-b>org.dozer.vo.TestObjectPrime</class-b>\n  <field>\n    <a>dateString</a>\n    <b>dateObject</b>\n  </field>\n</mapping>\n\n\n全局级别\n\n对整个文件中的所有日期相关的属性有效。\n\n<mappings>\n  <configuration>\n    <date-format>MM/dd/yyyy HH:mm</date-format>\n  </configuration>\n\n  <mapping wildcard="true">\n    <class-a>org.dozer.vo.TestObject</class-a>\n    <class-b>org.dozer.vo.TestObjectPrime</class-b>\n    <field>\n      <a>dateString</a>\n      <b>dateObject</b>\n    </field>\n  </mapping>\n</mappings>\n\n\n# 集合和数组映射(Collection and Array Mapping)\n\nDozer 可以自动处理以下类型的双向转换。\n\n * List to List\n * List to Array\n * Array to Array\n * Set to Set\n * Set to Array\n * Set to List\n\n使用 hint\n\n如果使用泛型或数组，没有必要使用 hint。\n\n如果不使用泛型或数组。在处理集合或数组之间的转换时，你需要用hint指定目标列表的数据类型。\n\n若你不指定hint，Dozer 将认为目标集合和源集合的类型是一致的。\n\n使用 Hints 的范例：\n\n<field>\n  <a>hintList</a>\n  <b>hintList</b>\n  <b-hint>org.dozer.vo.TheFirstSubClassPrime</b-hint>\n</field>\n\n\n累计映射和非累计映射（Cumulative vs. Non-Cumulative List Mapping）\n\n如果你要转换的目标类已经初始化，你可以选择让 Dozer 添加或更新对象到你的集合中。\n\n而这取决于relationship-type配置，默认是累计。\n\n它的设置有作用域级别：\n\n * 全局级\n\n<mappings>\n  <configuration>\n     <relationship-type>non-cumulative</relationship-type>\n  </configuration>\n</mappings>\n\n\n * 类级别\n\n<mappings>\n  <mapping relationship-type="non-cumulative">\n    \x3c!-- 省略 --\x3e\n  </mapping>\n</mappings>\n\n\n * 属性级别\n\n<field relationship-type="cumulative">\n  <a>hintList</a>\n  <b>hintList</b>\n  <a-hint>org.dozer.vo.TheFirstSubClass</a-hint>\n  <b-hint>org.dozer.vo.TheFirstSubClassPrime</b-hint>\n</field>\n\n\n移动孤儿(Removing Orphans)\n\n这里的孤儿是指目标集合中存在，但是源集合中不存在的元素。\n\n你可以使用remove-orphans开关来选择是否移除这样的元素。\n\n<field remove-orphans="true">\n  <a>srcList</a>\n  <b>destList</b>\n</field>\n\n\n# 深度映射(Deep Mapping)\n\n所谓深度映射，是指允许你指定属性的属性（比如一个类的属性本身也是一个类）。举例来说\n\nSource.java\n\npublic class Source {\n private long id;\n    private String info;\n}\n\n\nDest.java\n\npublic class Dest {\n private long id;\n    private Info info;\n}\n\n\npublic class Info {\n private String content;\n}\n\n\n映射规则\n\n<mapping>\n  <class-a>org.zp.notes.spring.common.dozer.vo.Source</class-a>\n  <class-b>org.zp.notes.spring.common.dozer.vo.Dest</class-b>\n  <field>\n    <a>info</a>\n    <b>info.content</b>\n  </field>\n</mapping>\n\n\n# 排除属性(Excluding Fields)\n\n就像任何团体都有捣乱分子，类之间转换时也有想要排除的因子。\n\n如何在做类型转换时，自动排除一些属性，Dozer 提供了几种方法，这里只介绍一种比较通用的方法。\n\n更多详情参考官网。\n\nfield-exclude 可以排除不需要映射的属性。\n\n<field-exclude>\n  <a>fieldToExclude</a>\n  <b>fieldToExclude</b>\n</field-exclude>\n\n\n# 单向映射(One-Way Mapping)\n\n注：本文的映射方式，无特殊说明，都是双向映射的。\n\n有的场景可能希望转换过程不可逆，即单向转换。\n\n单向转换可以通过使用one-way来开启\n\n类级别\n\n<mapping type="one-way">\n  <class-a>org.dozer.vo.TestObjectFoo</class-a>\n  <class-b>org.dozer.vo.TestObjectFooPrime</class-b>\n    <field>\n      <a>oneFoo</a>\n      <b>oneFooPrime</b>\n    </field>\n</mapping>\n\n\n属性级别\n\n<mapping>\n  <class-a>org.dozer.vo.TestObjectFoo2</class-a>\n  <class-b>org.dozer.vo.TestObjectFooPrime2</class-b>\n  <field type="one-way">\n    <a>oneFoo2</a>\n    <b>oneFooPrime2</b>\n  </field>\n\n  <field type="one-way">\n    <a>oneFoo3.prime</a>\n    <b>oneFooPrime3</b>\n  </field>\n\n\n# 全局配置(Global Configuration)\n\n全局配置用来设置全局的配置信息。此外，任何定制转换都是在这里定义的。\n\n全局配置都是可选的。\n\n * <date-format>表示日期格式\n * <stop-on-errors>错误处理开关\n * <wildcard>通配符\n * <trim-strings>裁剪字符串开关\n\n<configuration >\n\n  <date-format>MM/dd/yyyy HH:mm</date-format>\n  <stop-on-errors>true</stop-on-errors>\n  <wildcard>true</wildcard>\n  <trim-strings>false</trim-strings>\n\n  <custom-converters> \x3c!-- these are always bi-directional --\x3e\n    <converter type="org.dozer.converters.TestCustomConverter" >\n      <class-a>org.dozer.vo.TestCustomConverterObject</class-a>\n      <class-b>another.type.to.Associate</class-b>\n    </converter>\n\n  </custom-converters>\n</configuration>\n\n\n全局配置的作用是帮助你少配置一些参数，如果个别类的映射规则需要变更，你可以 mapping 中覆盖它。\n\n覆盖的范例如下\n\n<mapping date-format="MM-dd-yyyy HH:mm:ss">\n  \x3c!-- 省略 --\x3e\n</mapping>\n\n<mapping wildcard="false">\n  \x3c!-- 省略 --\x3e\n</mapping>\n\n<mapping stop-on-errors="false">\n  \x3c!-- 省略 --\x3e\n</mapping>\n\n<mapping trim-strings="true">\n  \x3c!-- 省略 --\x3e\n</mapping>\n\n\n# 定制转换(Custom Converters)\n\n如果 Dozer 默认的转换规则不能满足实际需要，你可以选择定制转换。\n\n定制转换通过配置 XML 来告诉 Dozer 如何去转换两个指定的类。当 Dozer 转换这两个指定类的时候，会调用你的映射规则去替换标准映射规则。\n\n为了让 Dozer 识别，你必须实现org.dozer.CustomConverter接口。否则，Dozer 会抛异常。\n\n具体做法：\n\n(1) 创建一个类实现org.dozer.CustomConverter接口。\n\npublic class TestCustomConverter implements CustomConverter {\n\n  public Object convert(Object destination, Object source,\n      Class destClass, Class sourceClass) {\n    if (source == null) {\n      return null;\n    }\n    CustomDoubleObject dest = null;\n    if (source instanceof Double) {\n      // check to see if the object already exists\n      if (destination == null) {\n        dest = new CustomDoubleObject();\n      } else {\n        dest = (CustomDoubleObject) destination;\n      }\n      dest.setTheDouble(((Double) source).doubleValue());\n      return dest;\n    } else if (source instanceof CustomDoubleObject) {\n      double sourceObj =\n        ((CustomDoubleObject) source).getTheDouble();\n      return new Double(sourceObj);\n    } else {\n      throw new MappingException("Converter TestCustomConverter "\n          + "used incorrectly. Arguments passed in were:"\n          + destination + " and " + source);\n    }\n  }\n\n\n(2) 在 xml 中引用定制的映射规则\n\n引用定制的映射规则也是分级的，你可以酌情使用。\n\n * 全局级\n\n<?xml version="1.0" encoding="UTF-8"?>\n<mappings xmlns="http://dozer.sourceforge.net"\n          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n          xsi:schemaLocation="http://dozer.sourceforge.net\n          http://dozer.sourceforge.net/schema/beanmapping.xsd">\n  <configuration>\n    \x3c!-- 总是双向转换的 --\x3e\n    <custom-converters>\n      <converter type="org.dozer.converters.TestCustomConverter" >\n        <class-a>org.dozer.vo.CustomDoubleObject</class-a>\n        <class-b>java.lang.Double</class-b>\n      </converter>\n\n      \x3c!-- You are responsible for mapping everything between\n           ClassA and ClassB --\x3e\n      <converter\n        type="org.dozer.converters.TestCustomHashMapConverter" >\n        <class-a>org.dozer.vo.TestCustomConverterHashMapObject</class-a>\n        <class-b>org.dozer.vo.TestCustomConverterHashMapPrimeObject</class-b>\n      </converter>\n    </custom-converters>\n  </configuration>\n</mappings>\n\n\n * 属性级\n\n<mapping>\n  <class-a>org.dozer.vo.SimpleObj</class-a>\n  <class-b>org.dozer.vo.SimpleObjPrime2</class-b>\n  <field custom-converter=\n    "org.dozer.converters.TestCustomConverter">\n    <a>field1</a>\n    <b>field1Prime</b>\n  </field>\n</mapping>\n\n\n# 映射的继承(Inheritance Mapping)\n\nDozer 支持映射规则的继承机制。\n\n属性如果有着相同的名字则不需要在 xml 中配置，除非使用了hint\n\n我们来看一个例子\n\n<mapping>\n  <class-a>org.dozer.vo.SuperClass</class-a>\n  <class-b>org.dozer.vo.SuperClassPrime</class-b>\n\n  <field>\n    <a>superAttribute</a>\n    <b>superAttr</b>\n  </field>\n</mapping>\n\n<mapping>\n  <class-a>org.dozer.vo.SubClass</class-a>\n  <class-b>org.dozer.vo.SubClassPrime</class-b>\n\n  <field>\n    <a>attribute</a>\n    <b>attributePrime</b>\n  </field>\n</mapping>\n\n<mapping>\n  <class-a>org.dozer.vo.SubClass2</class-a>\n  <class-b>org.dozer.vo.SubClassPrime2</class-b>\n\n  <field>\n    <a>attribute2</a>\n    <b>attributePrime2</b>\n  </field>\n</mapping>\n\n\n在上面的例子中 SubClass、SubClass2 是 SuperClass 的子类；\n\nSubClassPrime 和 SubClassPrime2 是 SuperClassPrime 的子类。\n\nsuperAttribute 和 superAttr 的映射规则会被子类所继承，所以不必再重复的在子类中去声明。\n\n\n# 参考\n\nDozer 官方文档 | Dozer 源码地址',normalizedContent:'# dozer 快速入门\n\n这篇文章是本人在阅读 dozer 官方文档（5.5.1 版本，官网已经一年多没更新了）的过程中，整理下来我认为比较基础的应用场景。\n\n本文中提到的例子应该能覆盖 javabean 映射的大部分场景，希望对你有所帮助。\n\n\n# 简介\n\ndozer 是什么?\n\ndozer 是一个 javabean 映射工具库。\n\n它支持简单的属性映射，复杂类型映射，双向映射，隐式显式的映射，以及递归映射。\n\n它支持三种映射方式：注解、api、xml。\n\n它是开源的，遵从apache 2.0 协议\n\n\n# 安装\n\n\n# 引入 jar 包\n\nmaven 方式\n\n如果你的项目使用 maven，添加以下依赖到你的 pom.xml 即可：\n\n<dependency>\n    <groupid>net.sf.dozer</groupid>\n    <artifactid>dozer</artifactid>\n    <version>5.4.0</version>\n</dependency>\n\n\n非 maven 方式\n\n如果你的项目不使用 maven，那就只能发扬不怕苦不怕累的精神了。\n\n使用 dozer 需要引入 dozer 的 jar 包以及其依赖的第三方 jar 包。\n\n * dozer\n * dozer 依赖的第三方 jar 包\n\n\n# eclipse 插件\n\ndozer 有插件可以在 eclipse 中使用(不知道是否好用，反正我没用过)\n\n插件地址: http://dozer.sourceforge.net/eclipse-plugin\n\n\n# 使用\n\n将 dozer 引入到工程中后，我们就可以来小试一番了。\n\n实践出真知，先以一个最简单的例子来展示 dozer 映射的处理过程。\n\n\n# 准备\n\n我们先准备两个要互相映射的类\n\nnotsameattributea.java\n\npublic class notsameattributea {\n    private long id;\n    private string name;\n    private date date;\n\n    // 省略getter/setter\n}\n\n\nnotsameattributeb.java\n\npublic class notsameattributeb {\n    private long id;\n    private string value;\n    private date date;\n\n    // 省略getter/setter\n}\n\n\n这两个类存在属性名不完全相同的情况：name 和 value。\n\n\n# dozer 的配置\n\n# 为什么要有映射配置?\n\n如果要映射的两个对象有完全相同的属性名，那么一切都很简单。\n\n只需要直接使用 dozer 的 api 即可：\n\nmapper mapper = new dozerbeanmapper();\ndestinationobject destobject =\n    mapper.map(sourceobject, destinationobject.class);\n\n\n但实际映射时，往往存在属性名不同的情况。\n\n所以，你需要一些配置来告诉 dozer 应该转换什么，怎么转换。\n\n注：官网着重建议：在现实应用中，最好不要每次映射对象时都创建一个mapper实例来工作，这样会产生不必要的开销。如果你不使用 ioc 容器（如：spring）来管理你的项目，那么，最好将mapper定义为单例模式。\n\n# 映射配置文件\n\n在src/test/resources目录下添加dozer/dozer-mapping.xml文件。 <mapping>标签中允许你定义<class-a>和<class-b>，对应着相互映射的类。 <field>标签里定义要映射的特殊属性。需要注意<a>和<class-a>对应，<b>和<class-b>对应，聪明的你，猜也猜出来了吧。\n\n<?xml version="1.0" encoding="utf-8"?>\n<mappings xmlns="http://dozer.sourceforge.net" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n          xsi:schemalocation="http://dozer.sourceforge.net\n          http://dozer.sourceforge.net/schema/beanmapping.xsd">\n  <mapping date-format="yyyy-mm-dd">\n    <class-a>org.zp.notes.spring.common.dozer.vo.notsameattributea</class-a>\n    <class-b>org.zp.notes.spring.common.dozer.vo.notsameattributeb</class-b>\n    <field>\n      <a>name</a>\n      <b>value</b>\n    </field>\n  </mapping>\n</mappings>\n\n\n\n# 与 spring 整合\n\n# 配置 dozerbeanmapperfactorybean\n\n在src/test/resources目录下添加spring/spring-dozer.xml文件。\n\ndozer 与 spring 的整合很便利，你只需要声明一个dozerbeanmapperfactorybean， 将所有的 dozer 映射配置文件作为属性注入到mappingfiles， dozerbeanmapperfactorybean会加载这些规则。\n\nspring-dozer.xml 文件范例\n\n<?xml version="1.0" encoding="utf-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n       xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n       xsi:schemalocation="http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans-2.0.xsd"\n       default-autowire="byname" default-lazy-init="false">\n\n  <bean id="mapper" class="org.dozer.spring.dozerbeanmapperfactorybean">\n    <property name="mappingfiles">\n      <list>\n        <value>classpath*:dozer/dozer-mapping.xml</value>\n      </list>\n    </property>\n  </bean>\n</beans>\n\n\n# 自动装配\n\n至此，万事具备，你只需要自动装配mapper。\n\nrunwith(springjunit4classrunner.class)\n@contextconfiguration(locations = {"classpath:spring/spring-dozer.xml"})\n@transactionconfiguration(defaultrollback = false)\npublic class dozertest extends testcase {\n    @autowired\n    mapper mapper;\n\n    @test\n    public void testnotsameattributemapping() {\n        notsameattributea src = new notsameattributea();\n        src.setid(007);\n        src.setname("邦德");\n        src.setdate(new date());\n\n        notsameattributeb desc = mapper.map(src, notsameattributeb.class);\n        assert.assertnotnull(desc);\n    }\n}\n\n\n运行一下单元测试，绿灯通过。\n\n\n# dozer 支持的数据类型转换\n\ndozer 可以自动做数据类型转换。当前，dozer 支持以下数据类型转换（都是双向的）\n\n * primitive to primitive wrapper\n   \n   原型(int、long 等)和原型包装类(integer、long)\n\n * primitive to custom wrapper\n   \n   原型和定制的包装\n\n * primitive wrapper to primitive wrapper\n   \n   原型包装类和包装类\n\n * primitive to primitive\n   \n   原型和原型\n\n * complex type to complex type\n   \n   复杂类型和复杂类型\n\n * string to primitive\n   \n   字符串和原型\n\n * string to primitive wrapper\n   \n   字符串和原型包装类\n\n * string to complex type if the complex type contains a string constructor\n   \n   字符串和有字符串构造器的复杂类型（类）\n\n * string to map\n   \n   字符串和 map\n\n * collection to collection\n   \n   集合和集合\n\n * collection to array\n   \n   集合和数组\n\n * map to complex type\n   \n   map 和复杂类型\n\n * map to custom map type\n   \n   map 和定制 map 类型\n\n * enum to enum\n   \n   枚举和枚举\n\n * each of these can be mapped to one another: java.util.date, java.sql.date, java.sql.time, java.sql.timestamp, java.util.calendar, java.util.gregoriancalendar\n   \n   这些时间相关的常见类可以互换：java.util.date, java.sql.date, java.sql.time, java.sql.timestamp, java.util.calendar, java.util.gregoriancalendar\n\n * string to any of the supported date/calendar objects.\n   \n   字符串和支持 date/calendar 的对象\n\n * objects containing a tostring() method that produces a long representing time in (ms) to any supported date/calendar object.\n   \n   如果一个对象的 tostring()方法返回的是一个代表 long 型的时间数值（单位：ms），就可以和任何支持 date/calendar 的对象转换。\n\n\n# dozer 的映射配置\n\n在前面的简单例子中，我们体验了一把 dozer 的映射流程。但是两个类进行映射，有很多复杂的情况，相应的，你也需要一些更复杂的配置。\n\ndozer 有三种映射配置方式：\n\n * 注解方式\n * api 方式\n * xml 方式\n\n\n# 用注解来配置映射\n\ndozer 5.3.2版本开始支持注解方式配置映射（只有一个注解：@mapping）。可以应对一些简单的映射处理，复杂的就玩不转了。\n\n看一下@mapping的声明就可以知道，这个注解只能用于元素和方法。\n\n@retention(retentionpolicy.runtime)\n@target({elementtype.field, elementtype.method})\npublic @interface mapping {\n  string value() default "";\n}\n\n\n让我们来试试吧：\n\ntargetbean.java\n\npublic class sourcebean {\n\n    private long id;\n\n    private string name;\n\n    @mapping("binarydata")\n    private string data;\n\n    @mapping("pk")\n    public long getid() {\n        return this.id;\n    }\n\n    //其余getter/setter方法略\n}\n\n\ntargetbean.java\n\npublic class targetbean {\n\n    private string pk;\n\n    private string name;\n\n    private string binarydata;\n\n    //getter/setter方法略\n}\n\n\n定义了两个相互映射的 java 类，只需要在源类中用@mapping标记和目标类中对应的属性就可以了。\n\n@test\npublic void testannotationmapping() {\n sourcebean src = new sourcebean();\n src.setid(7l);\n src.setname("邦德");\n src.setdata("00000111");\n\n targetbean desc = mapper.map(src, targetbean.class);\n assert.assertnotnull(desc);\n}\n\n\n测试一下，绿灯通过。\n\n官方文档说，虽然当前版本（文档的版本对应 dozer 5.5.1）仅支持@mapping，但是在未来的发布版本会提供其他的注解功能，那就敬请期待吧（再次吐槽一下：一年多没更新了）。\n\n\n# 用 api 来配置映射\n\n个人觉得这种方式比较麻烦，不推荐，也不想多做介绍，就是这么任性。\n\n\n# 用 xml 来配置映射\n\n需要强调的是：如果两个类的所有属性都能很好的互转，可以你中有我，我中有你，不分彼此，那么就不要画蛇添足的在 xml 中去声明映射规则了。\n\n# 属性名不同时的映射(basic property mapping)\n\ndozer 会自动映射属性名相同的属性，所以不必添加在 xml 文件中。\n\n<field>\n  <a>one</a>\n  <b>oneprime</b>\n</field>\n\n\n# 字符串和日期映射(string to date mapping)\n\n字符串在和日期进行映射时，允许用户指定日期的格式。\n\n格式的设置分为三个作用域级别：\n\n属性级别\n\n对当前属性有效（这个属性必须是日期字符串）\n\n<field>\n  <a date-format="mm/dd/yyyy hh:mm:ss:ss">datestring</a>\n  <b>dateobject</b>\n</field>\n\n\n类级别\n\n对这个类中的所有日期相关的属性有效\n\n<mapping date-format="mm-dd-yyyy hh:mm:ss">\n  <class-a>org.dozer.vo.testobject</class-a>\n  <class-b>org.dozer.vo.testobjectprime</class-b>\n  <field>\n    <a>datestring</a>\n    <b>dateobject</b>\n  </field>\n</mapping>\n\n\n全局级别\n\n对整个文件中的所有日期相关的属性有效。\n\n<mappings>\n  <configuration>\n    <date-format>mm/dd/yyyy hh:mm</date-format>\n  </configuration>\n\n  <mapping wildcard="true">\n    <class-a>org.dozer.vo.testobject</class-a>\n    <class-b>org.dozer.vo.testobjectprime</class-b>\n    <field>\n      <a>datestring</a>\n      <b>dateobject</b>\n    </field>\n  </mapping>\n</mappings>\n\n\n# 集合和数组映射(collection and array mapping)\n\ndozer 可以自动处理以下类型的双向转换。\n\n * list to list\n * list to array\n * array to array\n * set to set\n * set to array\n * set to list\n\n使用 hint\n\n如果使用泛型或数组，没有必要使用 hint。\n\n如果不使用泛型或数组。在处理集合或数组之间的转换时，你需要用hint指定目标列表的数据类型。\n\n若你不指定hint，dozer 将认为目标集合和源集合的类型是一致的。\n\n使用 hints 的范例：\n\n<field>\n  <a>hintlist</a>\n  <b>hintlist</b>\n  <b-hint>org.dozer.vo.thefirstsubclassprime</b-hint>\n</field>\n\n\n累计映射和非累计映射（cumulative vs. non-cumulative list mapping）\n\n如果你要转换的目标类已经初始化，你可以选择让 dozer 添加或更新对象到你的集合中。\n\n而这取决于relationship-type配置，默认是累计。\n\n它的设置有作用域级别：\n\n * 全局级\n\n<mappings>\n  <configuration>\n     <relationship-type>non-cumulative</relationship-type>\n  </configuration>\n</mappings>\n\n\n * 类级别\n\n<mappings>\n  <mapping relationship-type="non-cumulative">\n    \x3c!-- 省略 --\x3e\n  </mapping>\n</mappings>\n\n\n * 属性级别\n\n<field relationship-type="cumulative">\n  <a>hintlist</a>\n  <b>hintlist</b>\n  <a-hint>org.dozer.vo.thefirstsubclass</a-hint>\n  <b-hint>org.dozer.vo.thefirstsubclassprime</b-hint>\n</field>\n\n\n移动孤儿(removing orphans)\n\n这里的孤儿是指目标集合中存在，但是源集合中不存在的元素。\n\n你可以使用remove-orphans开关来选择是否移除这样的元素。\n\n<field remove-orphans="true">\n  <a>srclist</a>\n  <b>destlist</b>\n</field>\n\n\n# 深度映射(deep mapping)\n\n所谓深度映射，是指允许你指定属性的属性（比如一个类的属性本身也是一个类）。举例来说\n\nsource.java\n\npublic class source {\n private long id;\n    private string info;\n}\n\n\ndest.java\n\npublic class dest {\n private long id;\n    private info info;\n}\n\n\npublic class info {\n private string content;\n}\n\n\n映射规则\n\n<mapping>\n  <class-a>org.zp.notes.spring.common.dozer.vo.source</class-a>\n  <class-b>org.zp.notes.spring.common.dozer.vo.dest</class-b>\n  <field>\n    <a>info</a>\n    <b>info.content</b>\n  </field>\n</mapping>\n\n\n# 排除属性(excluding fields)\n\n就像任何团体都有捣乱分子，类之间转换时也有想要排除的因子。\n\n如何在做类型转换时，自动排除一些属性，dozer 提供了几种方法，这里只介绍一种比较通用的方法。\n\n更多详情参考官网。\n\nfield-exclude 可以排除不需要映射的属性。\n\n<field-exclude>\n  <a>fieldtoexclude</a>\n  <b>fieldtoexclude</b>\n</field-exclude>\n\n\n# 单向映射(one-way mapping)\n\n注：本文的映射方式，无特殊说明，都是双向映射的。\n\n有的场景可能希望转换过程不可逆，即单向转换。\n\n单向转换可以通过使用one-way来开启\n\n类级别\n\n<mapping type="one-way">\n  <class-a>org.dozer.vo.testobjectfoo</class-a>\n  <class-b>org.dozer.vo.testobjectfooprime</class-b>\n    <field>\n      <a>onefoo</a>\n      <b>onefooprime</b>\n    </field>\n</mapping>\n\n\n属性级别\n\n<mapping>\n  <class-a>org.dozer.vo.testobjectfoo2</class-a>\n  <class-b>org.dozer.vo.testobjectfooprime2</class-b>\n  <field type="one-way">\n    <a>onefoo2</a>\n    <b>onefooprime2</b>\n  </field>\n\n  <field type="one-way">\n    <a>onefoo3.prime</a>\n    <b>onefooprime3</b>\n  </field>\n\n\n# 全局配置(global configuration)\n\n全局配置用来设置全局的配置信息。此外，任何定制转换都是在这里定义的。\n\n全局配置都是可选的。\n\n * <date-format>表示日期格式\n * <stop-on-errors>错误处理开关\n * <wildcard>通配符\n * <trim-strings>裁剪字符串开关\n\n<configuration >\n\n  <date-format>mm/dd/yyyy hh:mm</date-format>\n  <stop-on-errors>true</stop-on-errors>\n  <wildcard>true</wildcard>\n  <trim-strings>false</trim-strings>\n\n  <custom-converters> \x3c!-- these are always bi-directional --\x3e\n    <converter type="org.dozer.converters.testcustomconverter" >\n      <class-a>org.dozer.vo.testcustomconverterobject</class-a>\n      <class-b>another.type.to.associate</class-b>\n    </converter>\n\n  </custom-converters>\n</configuration>\n\n\n全局配置的作用是帮助你少配置一些参数，如果个别类的映射规则需要变更，你可以 mapping 中覆盖它。\n\n覆盖的范例如下\n\n<mapping date-format="mm-dd-yyyy hh:mm:ss">\n  \x3c!-- 省略 --\x3e\n</mapping>\n\n<mapping wildcard="false">\n  \x3c!-- 省略 --\x3e\n</mapping>\n\n<mapping stop-on-errors="false">\n  \x3c!-- 省略 --\x3e\n</mapping>\n\n<mapping trim-strings="true">\n  \x3c!-- 省略 --\x3e\n</mapping>\n\n\n# 定制转换(custom converters)\n\n如果 dozer 默认的转换规则不能满足实际需要，你可以选择定制转换。\n\n定制转换通过配置 xml 来告诉 dozer 如何去转换两个指定的类。当 dozer 转换这两个指定类的时候，会调用你的映射规则去替换标准映射规则。\n\n为了让 dozer 识别，你必须实现org.dozer.customconverter接口。否则，dozer 会抛异常。\n\n具体做法：\n\n(1) 创建一个类实现org.dozer.customconverter接口。\n\npublic class testcustomconverter implements customconverter {\n\n  public object convert(object destination, object source,\n      class destclass, class sourceclass) {\n    if (source == null) {\n      return null;\n    }\n    customdoubleobject dest = null;\n    if (source instanceof double) {\n      // check to see if the object already exists\n      if (destination == null) {\n        dest = new customdoubleobject();\n      } else {\n        dest = (customdoubleobject) destination;\n      }\n      dest.setthedouble(((double) source).doublevalue());\n      return dest;\n    } else if (source instanceof customdoubleobject) {\n      double sourceobj =\n        ((customdoubleobject) source).getthedouble();\n      return new double(sourceobj);\n    } else {\n      throw new mappingexception("converter testcustomconverter "\n          + "used incorrectly. arguments passed in were:"\n          + destination + " and " + source);\n    }\n  }\n\n\n(2) 在 xml 中引用定制的映射规则\n\n引用定制的映射规则也是分级的，你可以酌情使用。\n\n * 全局级\n\n<?xml version="1.0" encoding="utf-8"?>\n<mappings xmlns="http://dozer.sourceforge.net"\n          xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n          xsi:schemalocation="http://dozer.sourceforge.net\n          http://dozer.sourceforge.net/schema/beanmapping.xsd">\n  <configuration>\n    \x3c!-- 总是双向转换的 --\x3e\n    <custom-converters>\n      <converter type="org.dozer.converters.testcustomconverter" >\n        <class-a>org.dozer.vo.customdoubleobject</class-a>\n        <class-b>java.lang.double</class-b>\n      </converter>\n\n      \x3c!-- you are responsible for mapping everything between\n           classa and classb --\x3e\n      <converter\n        type="org.dozer.converters.testcustomhashmapconverter" >\n        <class-a>org.dozer.vo.testcustomconverterhashmapobject</class-a>\n        <class-b>org.dozer.vo.testcustomconverterhashmapprimeobject</class-b>\n      </converter>\n    </custom-converters>\n  </configuration>\n</mappings>\n\n\n * 属性级\n\n<mapping>\n  <class-a>org.dozer.vo.simpleobj</class-a>\n  <class-b>org.dozer.vo.simpleobjprime2</class-b>\n  <field custom-converter=\n    "org.dozer.converters.testcustomconverter">\n    <a>field1</a>\n    <b>field1prime</b>\n  </field>\n</mapping>\n\n\n# 映射的继承(inheritance mapping)\n\ndozer 支持映射规则的继承机制。\n\n属性如果有着相同的名字则不需要在 xml 中配置，除非使用了hint\n\n我们来看一个例子\n\n<mapping>\n  <class-a>org.dozer.vo.superclass</class-a>\n  <class-b>org.dozer.vo.superclassprime</class-b>\n\n  <field>\n    <a>superattribute</a>\n    <b>superattr</b>\n  </field>\n</mapping>\n\n<mapping>\n  <class-a>org.dozer.vo.subclass</class-a>\n  <class-b>org.dozer.vo.subclassprime</class-b>\n\n  <field>\n    <a>attribute</a>\n    <b>attributeprime</b>\n  </field>\n</mapping>\n\n<mapping>\n  <class-a>org.dozer.vo.subclass2</class-a>\n  <class-b>org.dozer.vo.subclassprime2</class-b>\n\n  <field>\n    <a>attribute2</a>\n    <b>attributeprime2</b>\n  </field>\n</mapping>\n\n\n在上面的例子中 subclass、subclass2 是 superclass 的子类；\n\nsubclassprime 和 subclassprime2 是 superclassprime 的子类。\n\nsuperattribute 和 superattr 的映射规则会被子类所继承，所以不必再重复的在子类中去声明。\n\n\n# 参考\n\ndozer 官方文档 | dozer 源码地址',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Freemark 快速入门",frontmatter:{title:"Freemark 快速入门",categories:["编程","Java","工具","模板引擎"],tags:["Java","模板引擎","Freemark"],abbrlink:"468afcee",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/34ec25/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/03.%E6%A8%A1%E6%9D%BF%E5%BC%95%E6%93%8E/01.Freemark.html",relativePath:"12.工具/03.模板引擎/01.Freemark.md",key:"v-783c66c8",path:"/pages/34ec25/",headers:[{level:2,title:"Freemark 简介",slug:"freemark-简介",normalizedTitle:"freemark 简介",charIndex:145},{level:2,title:"总体结构",slug:"总体结构",normalizedTitle:"总体结构",charIndex:456},{level:3,title:"指令",slug:"指令",normalizedTitle:"指令",charIndex:823},{level:3,title:"表达式",slug:"表达式",normalizedTitle:"表达式",charIndex:1073},{level:3,title:"变量",slug:"变量",normalizedTitle:"变量",charIndex:1357},{level:2,title:"数据类型",slug:"数据类型",normalizedTitle:"数据类型",charIndex:2450},{level:3,title:"标量",slug:"标量",normalizedTitle:"标量",charIndex:2477},{level:3,title:"容器",slug:"容器",normalizedTitle:"容器",charIndex:2688},{level:3,title:"子程序",slug:"子程序",normalizedTitle:"子程序",charIndex:2715},{level:3,title:"其它",slug:"其它",normalizedTitle:"其它",charIndex:2744},{level:2,title:"转义符",slug:"转义符",normalizedTitle:"转义符",charIndex:2758},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:3075}],headersStr:"Freemark 简介 总体结构 指令 表达式 变量 数据类型 标量 容器 子程序 其它 转义符 参考资料",content:'# Freemark 快速入门\n\n> FreeMarker 是一款模板引擎： 即一种基于模板和要改变的数据， 并用来生成输出文本(HTML 网页，电子邮件，配置文件，源代码等)的通用工具。 它不是面向最终用户的，而是一个 Java 类库，是一款程序员可以嵌入他们所开发产品的组件。\n\n\n# Freemark 简介\n\nFreemark 模板编写为 FreeMarker Template Language (FTL)。它是简单的，专用的语言， 不是 像 PHP 那样成熟的编程语言。在模板中，你可以专注于如何展现数据， 而在模板之外可以专注于要展示什么数据。\n\n\n\n这种方式通常被称为 MVC (模型 视图 控制器) 模式，对于动态网页来说，是一种特别流行的模式。 它帮助从开发人员(Java 程序员)中分离出网页设计师(HTML 设计师)。设计师无需面对模板中的复杂逻辑， 在没有程序员来修改或重新编译代码时，也可以修改页面的样式。\n\nFreemark 模板一句话概括就是：模板 + 数据模型 = 输出\n\n\n# 总体结构\n\n * 文本：文本会照着原样来输出。\n * 插值：这部分的输出会被计算的值来替换。插值由 ${ and } 所分隔(或者 #{ and }，这种风格已经不建议再使用了；点击查看更多)。\n * FTL 标签：FTL 标签和 HTML 标签很相似，但是它们却是给 FreeMarker 的指示， 而且不会打印在输出内容中。\n * 注释：注释和 HTML 的注释也很相似，但它们是由 <#-- 和 --\x3e来分隔的。注释会被 FreeMarker 直接忽略， 更不会在输出内容中显示。\n\n\n\n> 🔔 注意：\n> \n>  * FTL 是区分大小写的。\n>  * 插值 仅仅可以在 文本 中使用。\n>  * FTL 标签 不可以在其他 FTL 标签 和 插值 中使用。\n>  * 注释 可以放在 FTL 标签 和 插值 中。\n\n\n# 指令\n\nFTL 指令有两种类型： 预定义指令 和 用户自定义指令。 对于用户自定义的指令使用 @ 来代替 #。\n\n> 🔔 注意：\n> \n>  * FreeMarker 仅仅关心 FTL 标签的嵌套而不关心 HTML 标签的嵌套。 它只会把 HTML 看做是文本，不会来解释 HTML。\n>  * 如果你尝试使用一个不存在的指令(比如，输错了指令的名称)， FreeMarker 就会拒绝执行模板，同时抛出错误信息。\n>  * FreeMarker 会忽略 FTL 标签中多余的 空白标记。\n\n\n# 表达式\n\n以下为快速浏览清单，如果需要了解更多细节，请参考这里。\n\n * 直接指定值\n   * 字符串： "Foo" 或者 \'Foo\' 或者 "It\'s \\"quoted\\"" 或者 \'It\\\'s "quoted"\' 或者 r"C:\\raw\\string"\n   * 数字： 123.45\n   * 布尔值： true， false\n   * 序列： ["foo", "bar", 123.45]； 值域： 0..9, 0..<10 (或 0..!10), 0..\n   * 哈希表： {"name":"green mouse", "price":150}\n * 检索变量\n   * 顶层变量： user\n   * 从哈希表中检索数据： user.name， user["name"]\n   * 从序列中检索数据： products[5]\n   * 特殊变量： .main\n * 字符串操作\n   * 插值(或连接)： "Hello ${user}!" (或 "Hello " + user + "!")\n   * 获取一个字符： name[0]\n   * 字符串切分： 包含结尾： name[0..4]，不包含结尾： name[0..<5]，基于长度(宽容处理)： name[0..*5]，去除开头：name[5..]\n * 序列操作\n   * 连接： users + ["guest"]\n   * 序列切分：包含结尾： products[20..29]， 不包含结尾： products[20..<30]，基于长度(宽容处理)：products[20..*10]，去除开头： products[20..]\n * 哈希表操作\n   * 连接： passwords + { "joe": "secret42" }\n * 算术运算： (x * 1.5 + 10) / 2 - y % 100\n * 比较运算： x == y， x != y， x < y， x > y， x >= y， x <= y， x lt y， x lte y， x gt y， x gte y， 等等。。。。。。\n * 逻辑操作： !registered && (firstVisit || fromEurope)\n * 内建函数： name?upper_case, path?ensure_starts_with(\'/\')\n * 方法调用： repeat("What", 3)\n * 处理不存在的值\n   * 默认值： name!"unknown" 或者 (user.name)!"unknown" 或者 name! 或者 (user.name)!\n   * 检测不存在的值： name?? 或者 (user.name)??\n * 赋值操作： =, +=, -=, *=, /=, %=, ++, --\n\n\n# 变量\n\n注意：变量 仅仅 在 文本区 (比如 <h1>Hello ${name}!</h1>) 和 字符串 中起作用。\n\n正确示例：\n\n<#include "/footer/${company}.html">\n<#if big>...</#if>\n\n\n错误示例：\n\n<#if ${big}>...</#if>\n<#if "${big}">...</#if>\n\n\n\n# 数据类型\n\nFreemark 支持的类型有：\n\n\n# 标量\n\n字符串\n\n${"Hello ${user}"}\n${"I can escape with \\\\ ${user}"}\n${r"Now I can read dollar signs $"}\n\n\n输出：\n\nHello deister\nI can escape with \\ deister\nNow I can read dollar signs $\n\n\n数字\n\n布尔值\n\n日期/时间 (日期，时间或日期时间)\n\n\n# 容器\n\n * 哈希表\n * 序列\n * 集合\n\n\n# 子程序\n\n * 方法和函数\n * 用户自定义指令\n\n\n# 其它\n\n * 结点\n\n\n# 转义符\n\nFTL 支持的所有转义字符：\n\n转义序列     含义\n\\"       引号 (u0022)\n\\\'       单引号(又称为撇号) (u0027)\n\\{       起始花括号：{\n\\\\       反斜杠 (u005C)\n\\n       换行符 (u000A)\n\\r       回车 (u000D)\n\\t       水平制表符(又称为 tab) (u0009)\n\\b       退格 (u0008)\n\\f       换页 (u000C)\n\\l       小于号：<\n\\g       大于号：>\n\\a       &符：&\n\\xCode   字符的 16 进制 Unicode 码 (UCS 码)\n\n\n# 参考资料\n\n * Freemark Github\n * Freemark 中文教程\n * 在线 Freemark 工具',normalizedContent:'# freemark 快速入门\n\n> freemarker 是一款模板引擎： 即一种基于模板和要改变的数据， 并用来生成输出文本(html 网页，电子邮件，配置文件，源代码等)的通用工具。 它不是面向最终用户的，而是一个 java 类库，是一款程序员可以嵌入他们所开发产品的组件。\n\n\n# freemark 简介\n\nfreemark 模板编写为 freemarker template language (ftl)。它是简单的，专用的语言， 不是 像 php 那样成熟的编程语言。在模板中，你可以专注于如何展现数据， 而在模板之外可以专注于要展示什么数据。\n\n\n\n这种方式通常被称为 mvc (模型 视图 控制器) 模式，对于动态网页来说，是一种特别流行的模式。 它帮助从开发人员(java 程序员)中分离出网页设计师(html 设计师)。设计师无需面对模板中的复杂逻辑， 在没有程序员来修改或重新编译代码时，也可以修改页面的样式。\n\nfreemark 模板一句话概括就是：模板 + 数据模型 = 输出\n\n\n# 总体结构\n\n * 文本：文本会照着原样来输出。\n * 插值：这部分的输出会被计算的值来替换。插值由 ${ and } 所分隔(或者 #{ and }，这种风格已经不建议再使用了；点击查看更多)。\n * ftl 标签：ftl 标签和 html 标签很相似，但是它们却是给 freemarker 的指示， 而且不会打印在输出内容中。\n * 注释：注释和 html 的注释也很相似，但它们是由 <#-- 和 --\x3e来分隔的。注释会被 freemarker 直接忽略， 更不会在输出内容中显示。\n\n\n\n> 🔔 注意：\n> \n>  * ftl 是区分大小写的。\n>  * 插值 仅仅可以在 文本 中使用。\n>  * ftl 标签 不可以在其他 ftl 标签 和 插值 中使用。\n>  * 注释 可以放在 ftl 标签 和 插值 中。\n\n\n# 指令\n\nftl 指令有两种类型： 预定义指令 和 用户自定义指令。 对于用户自定义的指令使用 @ 来代替 #。\n\n> 🔔 注意：\n> \n>  * freemarker 仅仅关心 ftl 标签的嵌套而不关心 html 标签的嵌套。 它只会把 html 看做是文本，不会来解释 html。\n>  * 如果你尝试使用一个不存在的指令(比如，输错了指令的名称)， freemarker 就会拒绝执行模板，同时抛出错误信息。\n>  * freemarker 会忽略 ftl 标签中多余的 空白标记。\n\n\n# 表达式\n\n以下为快速浏览清单，如果需要了解更多细节，请参考这里。\n\n * 直接指定值\n   * 字符串： "foo" 或者 \'foo\' 或者 "it\'s \\"quoted\\"" 或者 \'it\\\'s "quoted"\' 或者 r"c:\\raw\\string"\n   * 数字： 123.45\n   * 布尔值： true， false\n   * 序列： ["foo", "bar", 123.45]； 值域： 0..9, 0..<10 (或 0..!10), 0..\n   * 哈希表： {"name":"green mouse", "price":150}\n * 检索变量\n   * 顶层变量： user\n   * 从哈希表中检索数据： user.name， user["name"]\n   * 从序列中检索数据： products[5]\n   * 特殊变量： .main\n * 字符串操作\n   * 插值(或连接)： "hello ${user}!" (或 "hello " + user + "!")\n   * 获取一个字符： name[0]\n   * 字符串切分： 包含结尾： name[0..4]，不包含结尾： name[0..<5]，基于长度(宽容处理)： name[0..*5]，去除开头：name[5..]\n * 序列操作\n   * 连接： users + ["guest"]\n   * 序列切分：包含结尾： products[20..29]， 不包含结尾： products[20..<30]，基于长度(宽容处理)：products[20..*10]，去除开头： products[20..]\n * 哈希表操作\n   * 连接： passwords + { "joe": "secret42" }\n * 算术运算： (x * 1.5 + 10) / 2 - y % 100\n * 比较运算： x == y， x != y， x < y， x > y， x >= y， x <= y， x lt y， x lte y， x gt y， x gte y， 等等。。。。。。\n * 逻辑操作： !registered && (firstvisit || fromeurope)\n * 内建函数： name?upper_case, path?ensure_starts_with(\'/\')\n * 方法调用： repeat("what", 3)\n * 处理不存在的值\n   * 默认值： name!"unknown" 或者 (user.name)!"unknown" 或者 name! 或者 (user.name)!\n   * 检测不存在的值： name?? 或者 (user.name)??\n * 赋值操作： =, +=, -=, *=, /=, %=, ++, --\n\n\n# 变量\n\n注意：变量 仅仅 在 文本区 (比如 <h1>hello ${name}!</h1>) 和 字符串 中起作用。\n\n正确示例：\n\n<#include "/footer/${company}.html">\n<#if big>...</#if>\n\n\n错误示例：\n\n<#if ${big}>...</#if>\n<#if "${big}">...</#if>\n\n\n\n# 数据类型\n\nfreemark 支持的类型有：\n\n\n# 标量\n\n字符串\n\n${"hello ${user}"}\n${"i can escape with \\\\ ${user}"}\n${r"now i can read dollar signs $"}\n\n\n输出：\n\nhello deister\ni can escape with \\ deister\nnow i can read dollar signs $\n\n\n数字\n\n布尔值\n\n日期/时间 (日期，时间或日期时间)\n\n\n# 容器\n\n * 哈希表\n * 序列\n * 集合\n\n\n# 子程序\n\n * 方法和函数\n * 用户自定义指令\n\n\n# 其它\n\n * 结点\n\n\n# 转义符\n\nftl 支持的所有转义字符：\n\n转义序列     含义\n\\"       引号 (u0022)\n\\\'       单引号(又称为撇号) (u0027)\n\\{       起始花括号：{\n\\\\       反斜杠 (u005c)\n\\n       换行符 (u000a)\n\\r       回车 (u000d)\n\\t       水平制表符(又称为 tab) (u0009)\n\\b       退格 (u0008)\n\\f       换页 (u000c)\n\\l       小于号：<\n\\g       大于号：>\n\\a       &符：&\n\\xcode   字符的 16 进制 unicode 码 (ucs 码)\n\n\n# 参考资料\n\n * freemark github\n * freemark 中文教程\n * 在线 freemark 工具',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Thymeleaf 快速入门",frontmatter:{title:"Thymeleaf 快速入门",categories:["编程","Java","工具","模板引擎"],tags:["Java","模板引擎","Thymeleaf"],abbrlink:"33db93c3",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/2263fb/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/03.%E6%A8%A1%E6%9D%BF%E5%BC%95%E6%93%8E/02.Thymeleaf.html",relativePath:"12.工具/03.模板引擎/02.Thymeleaf.md",key:"v-eb512f24",path:"/pages/2263fb/",headers:[{level:2,title:"标准方言",slug:"标准方言",normalizedTitle:"标准方言",charIndex:21},{level:3,title:"表达式",slug:"表达式",normalizedTitle:"表达式",charIndex:130},{level:4,title:"变量表达式",slug:"变量表达式",normalizedTitle:"变量表达式",charIndex:144},{level:4,title:"选择表达式",slug:"选择表达式",normalizedTitle:"选择表达式",charIndex:161},{level:4,title:"消息(i18n)表达式",slug:"消息-i18n-表达式",normalizedTitle:"消息(i18n)表达式",charIndex:1027},{level:4,title:"链接(URL)表达式",slug:"链接-url-表达式",normalizedTitle:"链接(url)表达式",charIndex:1485},{level:4,title:"片段表达式",slug:"片段表达式",normalizedTitle:"片段表达式",charIndex:227},{level:4,title:"表达式预处理",slug:"表达式预处理",normalizedTitle:"表达式预处理",charIndex:2876},{level:3,title:"文字和操作",slug:"文字和操作",normalizedTitle:"文字和操作",charIndex:3067},{level:3,title:"基本属性",slug:"基本属性",normalizedTitle:"基本属性",charIndex:3614},{level:3,title:"标准 URL",slug:"标准-url",normalizedTitle:"标准 url",charIndex:4096},{level:4,title:"绝对网址",slug:"绝对网址",normalizedTitle:"绝对网址",charIndex:4246},{level:4,title:"上下文相关 URL",slug:"上下文相关-url",normalizedTitle:"上下文相关 url",charIndex:4511},{level:4,title:"与服务器相关 URL",slug:"与服务器相关-url",normalizedTitle:"与服务器相关 url",charIndex:4834},{level:4,title:"协议相关 URL",slug:"协议相关-url",normalizedTitle:"协议相关 url",charIndex:5097},{level:4,title:"添加参数",slug:"添加参数",normalizedTitle:"添加参数",charIndex:5361},{level:4,title:"网址片段标识符",slug:"网址片段标识符",normalizedTitle:"网址片段标识符",charIndex:5852},{level:4,title:"URL 重写",slug:"url-重写",normalizedTitle:"url 重写",charIndex:1532},{level:4,title:"URL 其它属性",slug:"url-其它属性",normalizedTitle:"url 其它属性",charIndex:6360},{level:4,title:"在 URL 中使用表达式",slug:"在-url-中使用表达式",normalizedTitle:"在 url 中使用表达式",charIndex:6656},{level:2,title:"扩展",slug:"扩展",normalizedTitle:"扩展",charIndex:7655},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:7668}],headersStr:"标准方言 表达式 变量表达式 选择表达式 消息(i18n)表达式 链接(URL)表达式 片段表达式 表达式预处理 文字和操作 基本属性 标准 URL 绝对网址 上下文相关 URL 与服务器相关 URL 协议相关 URL 添加参数 网址片段标识符 URL 重写 URL 其它属性 在 URL 中使用表达式 扩展 参考资料",content:'# Thymeleaf 快速入门\n\n\n# 标准方言\n\n标准方言是指 Thymeleaf 定义了一组功能，这些功能应该足以满足大多数情况。可以识别这些标准方言在模板中的使用，因为它将包含以th前缀开头的属性，如<span th:text="...">。\n\n\n# 表达式\n\n${...} : 变量表达式。\n\n*{...} : 选择表达式。\n\n#{...} : 消息 (i18n) 表达式。\n\n@{...} : 链接 (URL) 表达式。\n\n~{...} : 片段表达式。\n\n# 变量表达式\n\n变量表达式是 OGNL 表达式 - 如果将 Thymeleaf 与 Spring - 集成在上下文变量上(也称为 Spring 术语中的模型属性)，则为 Spring EL。 它们看起来像这样:\n\n${session.user.name}\n\n\n它们作为属性值或作为它们的一部分，取决于属性:\n\n<span th:text="${book.author.name}"></span>\n\n\n上面的表达式与下面是相同的(在 OGNL 和 SpringEL 中):\n\n((Book)context.getVariable("book")).getAuthor().getName()\n\n\n但是不仅在涉及输出的场景中找到变量表达式，而且还可以使用更复杂的处理方式，如:条件，迭代…等等。\n\n<li th:each="book : ${books}"></li>\n\n\n这里${books}从上下文中选择名为books的变量，并在th:each中使用循环将其评估为迭代器。\n\n# 选择表达式\n\n选择表达式就像变量表达式一样，它们不是整个上下文变量映射上执行，而是在先前选择的对象。 它们看起来像这样:\n\n*{customer.name}\n\n\n它们所作用的对象由th:object属性指定:\n\n<div th:object="${book}">\n  ...\n  <span th:text="*{title}">...</span>\n  ...\n</div>\n\n\n所以这相当于:\n\n{\n  // th:object="${book}"\n  final Book selection = (Book) context.getVariable("book");\n  // th:text="*{title}"\n  output(selection.getTitle());\n}\n\n\n# 消息(i18n)表达式\n\n消息表达式(通常称为文本外部化，国际化或 i18n)允许从外部源(如:.properties)文件中检索特定于语言环境的消息，通过键来引用这引用消息。\n\n在 Spring 应用程序中，它将自动与 Spring 的 MessageSource 机制集成。如下 -\n\n#{main.title}\n#{message.entrycreated(${entryId})}\n\n\n以下是在模板中使用它们的方式:\n\n<table>\n  ...\n  <th th:text="#{header.address.city}">...</th>\n  <th th:text="#{header.address.country}">...</th>\n  ...\n</table>\n\n\n请注意，如果希望消息键由上下文变量的值确定，或者希望将变量指定为参数，则可以在消息表达式中使用变量表达式:\n\n#{${config.adminWelcomeKey}(${session.user.name})} Jsp\n\n\n# 链接(URL)表达式\n\n链接表达式在构建 URL 并向其添加有用的上下文和会话信息(通常称为 URL 重写的过程)。 因此，对于部署在 Web 服务器的/myapp上下文中的 Web 应用程序，可以使用以下表达式:\n\n<a th:href="@{/order/list}">...</a>\n\n\n可以转换成如下的东西:\n\n<a href="/myapp/order/list">...</a>\n\n\n甚至，如果需要保持会话，并且 cookie 未启用(或者服务器还不知道)，那么生成的格式为:\n\n<a href="/myapp/order/list;jsessionid=s2ds3fa31abd241e2a01932">...</a> HTML\n\n\n网址也可以带参数，如下所示:\n\n<a th:href="@{/order/details(id=${orderId},type=${orderType})}">...</a>\n\n\n这将产生类似以下的结果 -\n\n\x3c!-- 注意＆符号会在标签属性中进行HTML转义... --\x3e\n<a href="/myapp/order/details?id=23&type=online">...</a>\n\n\n链接表达式可以是相对的，在这种情况下，应用程序上下文将不会被加到 URL 的前面:\n\n<a th:href="@{../documents/report}">...</a>\n\n\n也是服务器相对的(同样，没有应用程序上下文的前缀):\n\n<a th:href="@{~/contents/main}">...</a>\n\n\n和协议相关(就像绝对 URL 一样，但浏览器将使用与正在显示的页面相同的 HTTP 或 HTTPS 协议):\n\n<a th:href="@{//static.mycompany.com/res/initial}">...</a>\n\n\n当然，链接表达式也可以是绝对的:\n\n<a th:href="@{http://www.mycompany.com/main}">...</a>\n\n\n但是绝对(或协议相对)URL ，在 Thymeleaf 链接表达式中应该添加什么值？ 很简单:由响应过滤器定义 URL 重写:在基于 Servlet 的 Web 应用程序中，对于每个输出的 URL(上下文相对，相对，绝对…)，在显示 URL 之前，Thymeleaf 总是调用HttpServletResponse.encodeUrl(...)机制。 这意味着一个过滤器可以通过包装 HttpServletResponse 对象来为应用程序执行自定义的 URL 重写。\n\n# 片段表达式\n\n片段表达式是一种简单的方法用来表示标记的片段并将其移动到模板中。 由于这些表达式，片段可以被复制，传递给其他模板的参数等等。\n\n最常见的是使用th:insert或th:replace来插入片段:\n\n<div th:insert="~{commons :: main}">...</div>\n\n\n但是它们可以在任何地方使用，就像任何其他变量一样:\n\n<div th:with="frag=~{footer :: #main/text()}">\n  <p th:insert="${frag}"></p>\n</div>\n\n\n片段表达式可以有参数。\n\n# 表达式预处理\n\n关于表达式的最后一件事是知道表达式预处理，在__之间指定，如下所示:\n\n#{selection.__${sel.code}__}\n\n\n上面代码中，第一个被执行的变量表达式是:${sel.code}，并且将使用它的结果作为表达式的一部分(假设${sel.code}的结果为:ALL)，在此处执行国际化的情况下(这将查找与关键selection.ALL消息)。\n\n\n# 文字和操作\n\n有很多类型的文字和操作可用，它们分别如下:\n\n * 文字\n   * 文本文字，例如:\'one text\', \'Another one!\',…\n   * 数字文字，例如:0,10, 314, 31.01, 112.83,…\n   * 布尔文字，例如:true,false\n   * Null 文字，例如:Null\n   * 文字标记，例如:one, sometext, main,…\n * 文本操作:\n   * 字符串连接:+\n   * 文字替换:|The name is ${name}|\n * 算术运算:\n   * 二进制操作:+, -, *, /, %\n   * 减号(一元运算符):-\n * 布尔运算:\n   * 二进制运算符，and,or\n   * 布尔否定(一元运算符):!,not\n * 比较和相等:\n   * 比较运算符:>,<,>=,<=(gt,lt,ge,le)\n   * 相等运算符:==, != (eq, ne)\n * 条件操作符:\n   * If-then:(if) ? (then)\n   * If-then-else:(if) ? (then) : (else)\n   * Default: (value) ?: (defaultvalue)\n\n\n# 基本属性\n\n下面来看看标准方言中的几个最基本的属性。 从th:文本开始，它代替了标签的主体:\n\n<p th:text="#{msg.welcome}">Welcome everyone!</p>\n\n\n现在，th:each重复它所在元素的次数，由它的表达式返回的数组或列表所指定的次数，为迭代元素创建一个内部变量，其语法与 Java 的 foreach 表达式相同:\n\n<li th:each="book : ${books}" th:text="${book.title}">\n  En las Orillas del Sar\n</li>\n\n\n最后，Thymeleaf 为特定的 XHTML 和 HTML5 属性提供了许多th属性，这些属性只评估它们的表达式，并将这些属性的值设置为结果。\n\n<form th:action="@{/createOrder}">\n  <input type="button" th:value="#{form.submit}" />\n  <a th:href="@{/admin/users}"></a>\n</form>\n\n\n\n# 标准 URL\n\nThymeleaf 标准方言(称为 Standard 和 SpringStandard)提供了一种在 Web 应用程序中轻松创建 URL 的方法，以便它们包含任何所需的 URL 工件。 这是通过连接表达方式来完成的，这是一种类似于 Thymeleaf 标准的表现:@{...}\n\n# 绝对网址\n\n绝对 URL 用于创建到其他服务器的链接。它们需要指定一个协议名称(http://或https://)开头。\n\n<a th:href="@{https://www.yiibai.com/thymeleaf/}"></a>\n\n\n上面链接不会被修改，除非在服务器上配置了 URL 重写过滤器，并在HttpServletResponse.encodeUrl(...)方法中执行修改。最后生成的 HTML 代码如下:\n\n<a href="https://www.yiibai.com/thymeleaf/"></a>\n\n\n# 上下文相关 URL\n\n最常用的 URL 类型是上下文相关的。 这些 URL 是一旦安装在服务器上，就会与 Web 应用程序根相关联 URL。 例如，如果将一个名称为myapp.war的文件部署到一个 Tomcat 服务器中，那么应用程序一般是通过 URL:http://localhost:8080/myapp来访问，myapp就是上下文名称。\n\n与上下文相关的 URL 以/字符开头:\n\n<a th:href="@{/order/list}"></a>\n\n\n如果应用程序访问 URL 为:http://localhost:8080/myapp，则此 URL 将输出:\n\n<a href="/myapp/order/list"></a>\n\n\n# 与服务器相关 URL\n\n服务器相关的 URL 与上下文相关的 URL 非常相似，只是它们不假定 URL 要链接到应用程序上下文中的资源，因此允许链接到同一服务器中的不同上下文:\n\n<a th:href="@{~/billing-app/showDetails.html}"></a>\n\n\n当前应用程序的上下文将被忽略，因此尽管应用程序部署在http:// localhost:8080 / myapp，但该 URL 将输出:\n\n<a href="/billing-app/showDetails.html"></a>\n\n\n# 协议相关 URL\n\n与协议相关的 URL 实际上是绝对的 URL，它将保持用于显示当前页面的协议(HTTP，HTTPS)。 它们通常用于包括样式，脚本等外部资源:\n\n<script th:src="@{//scriptserver.example.net/myscript.js}">\n  ...\n<\/script>\n\n\n它将呈现与上面一致的 URL(URL 重写除外)，如:\n\n<script src="//scriptserver.example.net/myscript.js">\n  ...\n<\/script>\n\n\n# 添加参数\n\n如何向使用@{...}表达式创建的 URL 添加参数？ 这也很简单:\n\n<a th:href="@{/order/details(id=3)}"></a>\n\n\n上面示例代码，最终将输出为:\n\n<a href="/order/details?id=3"></a>\n\n\n也可以添加几个参数，用逗号分隔它们:\n\n<a th:href="@{/order/details(id=3,action=\'show_all\')}"></a>\n\n\n上面代码将输出结果为:\n\n\x3c!-- 注意＆符号在标签属性中进行HTML转义... --\x3e\n<a href="/order/details?id=3&action=show_all"></a>\n\n\n还可以使用正常参数的路径变量的形式包含参数，但在 URL 的路径中指定一个占位符:\n\n<a th:href="@{/order/{id}/details(id=3,action=\'show_all\')}"></a>\n\n\n上面输出结果为:\n\n<a href="/order/3/details?action=show_all"></a>\n\n\n# 网址片段标识符\n\n片段标识符可以包含在 URL 中，包含参数和不包含参数。 它们将始终包含在网址的基础上，参考以下代码:\n\n<a th:href="@{/home#all_info(action=\'show\')}"></a>\n\n\n执行输出结果如下 -\n\n<a href="/home?action=show#all_info">\n\n\n# URL 重写\n\nThymeleaf 允许在应用程序中配置 URL 重写过滤器，它通过调用 Thymeleaf 模板生成的每个 URL 的 Servlet API 的javax.servlet.http.HttpServletResponse类中的response.encodeURL()方法来实现。\n\n下面在 Java Web 应用程序中支持 URL 重写操作的标准方式，并允许 URL:\n\n * 自动检测用户是否启用了 Cookie，如果未启用或者如果它是第一个请求并且 cookie 配置仍未知。则将;jsessionid=...片段添加到 URL。\n * 在需要时自动将代理配置应用于 URL。\n * 使用不同的 CDN 设置，以便链接到分布在多个服务器中的内容。\n\n# URL 其它属性\n\n不要以为在@{...}表达式中只有th:href属性来表示 URL 。 事实上，它们可以像变量表达式(${...})或消息外部化/国际化(＃{...})一样用于任何地方。\n\n例如，表单提交时，可使用以下写法 -\n\n<form th:action="@{/order/processOrder}"></form>\n\n\n或作为其他表达的一部分。 如下作为外部化/国际化字符串的参数:\n\n<p\n  th:text="#{orders.explanation(\'3\', @{/order/details(id=3,action=\'show_all\')})}"\n></p>\n\n\n# 在 URL 中使用表达式\n\n下面来看看，如下所示的 URL 表达式:\n\n<a th:href="@{/order/details(id=3,action=\'show_all\')}"></a>\n\n\n但3和\'show_all\'都不能是文字值，因为只有在运行时才能知道它们的值，怎么办？\n\n<a\n  th:href="@{/order/details(id=${order.id},action=(${user.admin} ? \'show_all\' : \'show_public\'))}"\n></a>\n\n\n下面看看另一个 URL 表达式，如下所示:\n\n<a th:href="@{/order/details(id=${order.id})}"></a>\n\n\n它其实是下面 URL 的一个快捷方式:\n\n<a th:href="@{\'/order/details\'(id=${order.id})}"></a>\n\n\n这意味着 URL 基本身可以被指定为一个表达式，例如一个变量表达式:\n\n<a th:href="@{${detailsURL}(id=${order.id})}"></a>\n\n\n或外部化/国际化的文本:\n\n<a th:href="@{#{orders.details.localized_url}(id=${order.id})}"></a>\n\n\n甚至可以使用复杂的表达式，包括条件表达式，例如:\n\n<a\n  th:href="@{(${user.admin}? \'/admin/home\' : ${user.homeUrl})(id=${order.id})}"\n></a>\n\n\n如果要更清洁，那么可以使用th:with :\n\n<a\n  th:with="baseUrl=(${user.admin}? \'/admin/home\' : ${user.homeUrl})"\n  th:href="@{${baseUrl}(id=${order.id})}"\n></a>\n\n\n又或者 -\n\n<div th:with="baseUrl=(${user.admin}? \'/admin/home\' : ${user.homeUrl})">\n  ...\n  <a th:href="@{${baseUrl}(id=${order.id})}">...</a>\n  ...\n</div>\n\n\n\n# 扩展\n\nTODO\n\n\n# 参考资料\n\n * Thymeleaf 官网\n * Thymeleaf Github\n * Thymeleaf 教程',normalizedContent:'# thymeleaf 快速入门\n\n\n# 标准方言\n\n标准方言是指 thymeleaf 定义了一组功能，这些功能应该足以满足大多数情况。可以识别这些标准方言在模板中的使用，因为它将包含以th前缀开头的属性，如<span th:text="...">。\n\n\n# 表达式\n\n${...} : 变量表达式。\n\n*{...} : 选择表达式。\n\n#{...} : 消息 (i18n) 表达式。\n\n@{...} : 链接 (url) 表达式。\n\n~{...} : 片段表达式。\n\n# 变量表达式\n\n变量表达式是 ognl 表达式 - 如果将 thymeleaf 与 spring - 集成在上下文变量上(也称为 spring 术语中的模型属性)，则为 spring el。 它们看起来像这样:\n\n${session.user.name}\n\n\n它们作为属性值或作为它们的一部分，取决于属性:\n\n<span th:text="${book.author.name}"></span>\n\n\n上面的表达式与下面是相同的(在 ognl 和 springel 中):\n\n((book)context.getvariable("book")).getauthor().getname()\n\n\n但是不仅在涉及输出的场景中找到变量表达式，而且还可以使用更复杂的处理方式，如:条件，迭代…等等。\n\n<li th:each="book : ${books}"></li>\n\n\n这里${books}从上下文中选择名为books的变量，并在th:each中使用循环将其评估为迭代器。\n\n# 选择表达式\n\n选择表达式就像变量表达式一样，它们不是整个上下文变量映射上执行，而是在先前选择的对象。 它们看起来像这样:\n\n*{customer.name}\n\n\n它们所作用的对象由th:object属性指定:\n\n<div th:object="${book}">\n  ...\n  <span th:text="*{title}">...</span>\n  ...\n</div>\n\n\n所以这相当于:\n\n{\n  // th:object="${book}"\n  final book selection = (book) context.getvariable("book");\n  // th:text="*{title}"\n  output(selection.gettitle());\n}\n\n\n# 消息(i18n)表达式\n\n消息表达式(通常称为文本外部化，国际化或 i18n)允许从外部源(如:.properties)文件中检索特定于语言环境的消息，通过键来引用这引用消息。\n\n在 spring 应用程序中，它将自动与 spring 的 messagesource 机制集成。如下 -\n\n#{main.title}\n#{message.entrycreated(${entryid})}\n\n\n以下是在模板中使用它们的方式:\n\n<table>\n  ...\n  <th th:text="#{header.address.city}">...</th>\n  <th th:text="#{header.address.country}">...</th>\n  ...\n</table>\n\n\n请注意，如果希望消息键由上下文变量的值确定，或者希望将变量指定为参数，则可以在消息表达式中使用变量表达式:\n\n#{${config.adminwelcomekey}(${session.user.name})} jsp\n\n\n# 链接(url)表达式\n\n链接表达式在构建 url 并向其添加有用的上下文和会话信息(通常称为 url 重写的过程)。 因此，对于部署在 web 服务器的/myapp上下文中的 web 应用程序，可以使用以下表达式:\n\n<a th:href="@{/order/list}">...</a>\n\n\n可以转换成如下的东西:\n\n<a href="/myapp/order/list">...</a>\n\n\n甚至，如果需要保持会话，并且 cookie 未启用(或者服务器还不知道)，那么生成的格式为:\n\n<a href="/myapp/order/list;jsessionid=s2ds3fa31abd241e2a01932">...</a> html\n\n\n网址也可以带参数，如下所示:\n\n<a th:href="@{/order/details(id=${orderid},type=${ordertype})}">...</a>\n\n\n这将产生类似以下的结果 -\n\n\x3c!-- 注意＆符号会在标签属性中进行html转义... --\x3e\n<a href="/myapp/order/details?id=23&type=online">...</a>\n\n\n链接表达式可以是相对的，在这种情况下，应用程序上下文将不会被加到 url 的前面:\n\n<a th:href="@{../documents/report}">...</a>\n\n\n也是服务器相对的(同样，没有应用程序上下文的前缀):\n\n<a th:href="@{~/contents/main}">...</a>\n\n\n和协议相关(就像绝对 url 一样，但浏览器将使用与正在显示的页面相同的 http 或 https 协议):\n\n<a th:href="@{//static.mycompany.com/res/initial}">...</a>\n\n\n当然，链接表达式也可以是绝对的:\n\n<a th:href="@{http://www.mycompany.com/main}">...</a>\n\n\n但是绝对(或协议相对)url ，在 thymeleaf 链接表达式中应该添加什么值？ 很简单:由响应过滤器定义 url 重写:在基于 servlet 的 web 应用程序中，对于每个输出的 url(上下文相对，相对，绝对…)，在显示 url 之前，thymeleaf 总是调用httpservletresponse.encodeurl(...)机制。 这意味着一个过滤器可以通过包装 httpservletresponse 对象来为应用程序执行自定义的 url 重写。\n\n# 片段表达式\n\n片段表达式是一种简单的方法用来表示标记的片段并将其移动到模板中。 由于这些表达式，片段可以被复制，传递给其他模板的参数等等。\n\n最常见的是使用th:insert或th:replace来插入片段:\n\n<div th:insert="~{commons :: main}">...</div>\n\n\n但是它们可以在任何地方使用，就像任何其他变量一样:\n\n<div th:with="frag=~{footer :: #main/text()}">\n  <p th:insert="${frag}"></p>\n</div>\n\n\n片段表达式可以有参数。\n\n# 表达式预处理\n\n关于表达式的最后一件事是知道表达式预处理，在__之间指定，如下所示:\n\n#{selection.__${sel.code}__}\n\n\n上面代码中，第一个被执行的变量表达式是:${sel.code}，并且将使用它的结果作为表达式的一部分(假设${sel.code}的结果为:all)，在此处执行国际化的情况下(这将查找与关键selection.all消息)。\n\n\n# 文字和操作\n\n有很多类型的文字和操作可用，它们分别如下:\n\n * 文字\n   * 文本文字，例如:\'one text\', \'another one!\',…\n   * 数字文字，例如:0,10, 314, 31.01, 112.83,…\n   * 布尔文字，例如:true,false\n   * null 文字，例如:null\n   * 文字标记，例如:one, sometext, main,…\n * 文本操作:\n   * 字符串连接:+\n   * 文字替换:|the name is ${name}|\n * 算术运算:\n   * 二进制操作:+, -, *, /, %\n   * 减号(一元运算符):-\n * 布尔运算:\n   * 二进制运算符，and,or\n   * 布尔否定(一元运算符):!,not\n * 比较和相等:\n   * 比较运算符:>,<,>=,<=(gt,lt,ge,le)\n   * 相等运算符:==, != (eq, ne)\n * 条件操作符:\n   * if-then:(if) ? (then)\n   * if-then-else:(if) ? (then) : (else)\n   * default: (value) ?: (defaultvalue)\n\n\n# 基本属性\n\n下面来看看标准方言中的几个最基本的属性。 从th:文本开始，它代替了标签的主体:\n\n<p th:text="#{msg.welcome}">welcome everyone!</p>\n\n\n现在，th:each重复它所在元素的次数，由它的表达式返回的数组或列表所指定的次数，为迭代元素创建一个内部变量，其语法与 java 的 foreach 表达式相同:\n\n<li th:each="book : ${books}" th:text="${book.title}">\n  en las orillas del sar\n</li>\n\n\n最后，thymeleaf 为特定的 xhtml 和 html5 属性提供了许多th属性，这些属性只评估它们的表达式，并将这些属性的值设置为结果。\n\n<form th:action="@{/createorder}">\n  <input type="button" th:value="#{form.submit}" />\n  <a th:href="@{/admin/users}"></a>\n</form>\n\n\n\n# 标准 url\n\nthymeleaf 标准方言(称为 standard 和 springstandard)提供了一种在 web 应用程序中轻松创建 url 的方法，以便它们包含任何所需的 url 工件。 这是通过连接表达方式来完成的，这是一种类似于 thymeleaf 标准的表现:@{...}\n\n# 绝对网址\n\n绝对 url 用于创建到其他服务器的链接。它们需要指定一个协议名称(http://或https://)开头。\n\n<a th:href="@{https://www.yiibai.com/thymeleaf/}"></a>\n\n\n上面链接不会被修改，除非在服务器上配置了 url 重写过滤器，并在httpservletresponse.encodeurl(...)方法中执行修改。最后生成的 html 代码如下:\n\n<a href="https://www.yiibai.com/thymeleaf/"></a>\n\n\n# 上下文相关 url\n\n最常用的 url 类型是上下文相关的。 这些 url 是一旦安装在服务器上，就会与 web 应用程序根相关联 url。 例如，如果将一个名称为myapp.war的文件部署到一个 tomcat 服务器中，那么应用程序一般是通过 url:http://localhost:8080/myapp来访问，myapp就是上下文名称。\n\n与上下文相关的 url 以/字符开头:\n\n<a th:href="@{/order/list}"></a>\n\n\n如果应用程序访问 url 为:http://localhost:8080/myapp，则此 url 将输出:\n\n<a href="/myapp/order/list"></a>\n\n\n# 与服务器相关 url\n\n服务器相关的 url 与上下文相关的 url 非常相似，只是它们不假定 url 要链接到应用程序上下文中的资源，因此允许链接到同一服务器中的不同上下文:\n\n<a th:href="@{~/billing-app/showdetails.html}"></a>\n\n\n当前应用程序的上下文将被忽略，因此尽管应用程序部署在http:// localhost:8080 / myapp，但该 url 将输出:\n\n<a href="/billing-app/showdetails.html"></a>\n\n\n# 协议相关 url\n\n与协议相关的 url 实际上是绝对的 url，它将保持用于显示当前页面的协议(http，https)。 它们通常用于包括样式，脚本等外部资源:\n\n<script th:src="@{//scriptserver.example.net/myscript.js}">\n  ...\n<\/script>\n\n\n它将呈现与上面一致的 url(url 重写除外)，如:\n\n<script src="//scriptserver.example.net/myscript.js">\n  ...\n<\/script>\n\n\n# 添加参数\n\n如何向使用@{...}表达式创建的 url 添加参数？ 这也很简单:\n\n<a th:href="@{/order/details(id=3)}"></a>\n\n\n上面示例代码，最终将输出为:\n\n<a href="/order/details?id=3"></a>\n\n\n也可以添加几个参数，用逗号分隔它们:\n\n<a th:href="@{/order/details(id=3,action=\'show_all\')}"></a>\n\n\n上面代码将输出结果为:\n\n\x3c!-- 注意＆符号在标签属性中进行html转义... --\x3e\n<a href="/order/details?id=3&action=show_all"></a>\n\n\n还可以使用正常参数的路径变量的形式包含参数，但在 url 的路径中指定一个占位符:\n\n<a th:href="@{/order/{id}/details(id=3,action=\'show_all\')}"></a>\n\n\n上面输出结果为:\n\n<a href="/order/3/details?action=show_all"></a>\n\n\n# 网址片段标识符\n\n片段标识符可以包含在 url 中，包含参数和不包含参数。 它们将始终包含在网址的基础上，参考以下代码:\n\n<a th:href="@{/home#all_info(action=\'show\')}"></a>\n\n\n执行输出结果如下 -\n\n<a href="/home?action=show#all_info">\n\n\n# url 重写\n\nthymeleaf 允许在应用程序中配置 url 重写过滤器，它通过调用 thymeleaf 模板生成的每个 url 的 servlet api 的javax.servlet.http.httpservletresponse类中的response.encodeurl()方法来实现。\n\n下面在 java web 应用程序中支持 url 重写操作的标准方式，并允许 url:\n\n * 自动检测用户是否启用了 cookie，如果未启用或者如果它是第一个请求并且 cookie 配置仍未知。则将;jsessionid=...片段添加到 url。\n * 在需要时自动将代理配置应用于 url。\n * 使用不同的 cdn 设置，以便链接到分布在多个服务器中的内容。\n\n# url 其它属性\n\n不要以为在@{...}表达式中只有th:href属性来表示 url 。 事实上，它们可以像变量表达式(${...})或消息外部化/国际化(＃{...})一样用于任何地方。\n\n例如，表单提交时，可使用以下写法 -\n\n<form th:action="@{/order/processorder}"></form>\n\n\n或作为其他表达的一部分。 如下作为外部化/国际化字符串的参数:\n\n<p\n  th:text="#{orders.explanation(\'3\', @{/order/details(id=3,action=\'show_all\')})}"\n></p>\n\n\n# 在 url 中使用表达式\n\n下面来看看，如下所示的 url 表达式:\n\n<a th:href="@{/order/details(id=3,action=\'show_all\')}"></a>\n\n\n但3和\'show_all\'都不能是文字值，因为只有在运行时才能知道它们的值，怎么办？\n\n<a\n  th:href="@{/order/details(id=${order.id},action=(${user.admin} ? \'show_all\' : \'show_public\'))}"\n></a>\n\n\n下面看看另一个 url 表达式，如下所示:\n\n<a th:href="@{/order/details(id=${order.id})}"></a>\n\n\n它其实是下面 url 的一个快捷方式:\n\n<a th:href="@{\'/order/details\'(id=${order.id})}"></a>\n\n\n这意味着 url 基本身可以被指定为一个表达式，例如一个变量表达式:\n\n<a th:href="@{${detailsurl}(id=${order.id})}"></a>\n\n\n或外部化/国际化的文本:\n\n<a th:href="@{#{orders.details.localized_url}(id=${order.id})}"></a>\n\n\n甚至可以使用复杂的表达式，包括条件表达式，例如:\n\n<a\n  th:href="@{(${user.admin}? \'/admin/home\' : ${user.homeurl})(id=${order.id})}"\n></a>\n\n\n如果要更清洁，那么可以使用th:with :\n\n<a\n  th:with="baseurl=(${user.admin}? \'/admin/home\' : ${user.homeurl})"\n  th:href="@{${baseurl}(id=${order.id})}"\n></a>\n\n\n又或者 -\n\n<div th:with="baseurl=(${user.admin}? \'/admin/home\' : ${user.homeurl})">\n  ...\n  <a th:href="@{${baseurl}(id=${order.id})}">...</a>\n  ...\n</div>\n\n\n\n# 扩展\n\ntodo\n\n\n# 参考资料\n\n * thymeleaf 官网\n * thymeleaf github\n * thymeleaf 教程',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Velocity 快速入门",frontmatter:{title:"Velocity 快速入门",categories:["编程","Java","工具","模板引擎"],tags:["Java","模板引擎","Velocity"],abbrlink:"bed8d6a9",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/7ecb81/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/03.%E6%A8%A1%E6%9D%BF%E5%BC%95%E6%93%8E/03.Velocity.html",relativePath:"12.工具/03.模板引擎/03.Velocity.md",key:"v-a63f00f0",path:"/pages/7ecb81/",headers:[{level:2,title:"注释",slug:"注释",normalizedTitle:"注释",charIndex:247},{level:2,title:"引用",slug:"引用",normalizedTitle:"引用",charIndex:64},{level:3,title:"变量",slug:"变量",normalizedTitle:"变量",charIndex:667},{level:3,title:"属性",slug:"属性",normalizedTitle:"属性",charIndex:670},{level:3,title:"方法",slug:"方法",normalizedTitle:"方法",charIndex:78},{level:2,title:"赋值",slug:"赋值",normalizedTitle:"赋值",charIndex:947},{level:2,title:"字符串",slug:"字符串",normalizedTitle:"字符串",charIndex:1802},{level:2,title:"条件",slug:"条件",normalizedTitle:"条件",charIndex:1952},{level:2,title:"逻辑",slug:"逻辑",normalizedTitle:"逻辑",charIndex:2192},{level:2,title:"循环",slug:"循环",normalizedTitle:"循环",charIndex:2401},{level:2,title:"包含",slug:"包含",normalizedTitle:"包含",charIndex:2507},{level:2,title:"解析",slug:"解析",normalizedTitle:"解析",charIndex:1832},{level:2,title:"停止",slug:"停止",normalizedTitle:"停止",charIndex:2818},{level:2,title:"宏",slug:"宏",normalizedTitle:"宏",charIndex:2873},{level:2,title:"转义",slug:"转义",normalizedTitle:"转义",charIndex:3566},{level:2,title:"语义要点",slug:"语义要点",normalizedTitle:"语义要点",charIndex:3712},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:4105}],headersStr:"注释 引用 变量 属性 方法 赋值 字符串 条件 逻辑 循环 包含 解析 停止 宏 转义 语义要点 参考资料",content:'# Velocity 快速入门\n\nVelocity （简称 VTL）是一个基于 Java 的模版引擎。它允许 web 页面设计者引用 JAVA 代码预定义的方法。Web 设计者可以根据 MVC 模式和 JAVA 程序员并行工作，这意味着 Web 设计者可以单独专注于设计良好的站点，而程序员则可单独专注于编写底层代码。Velocity 将 Java 代码从 web 页面中分离出来，使站点在长时间运行后仍然具有很好的可维护性，并提供了一个除 JSP 和 PHP 之外的可行的被选方案。\n\n\n# 注释\n\n单行注释以##开始，并在本行结束。\n\n## This is a single line comment.\n\n\n多行注释，以 # 开始并以 # 结束可以处理这种情况。\n\n#*\n Thus begins a multi-line comment. Online visitors won\'t\n see this text because the Velocity Templating Engine will\n ignore it.\n*#\n\n\n注释块 ，可以用来存储诸如文档作者、版本信息等。\n\n#**\nThis is a VTL comment block and\nmay be used to store such information\nas the document author and versioning\ninformation:\n@author\n@version 5\n*#\n\n\n\n# 引用\n\nVTL 中有三种类型的引用：变量，属性和方法。\n\n\n# 变量\n\n变量（Variables）的简略标记是有一个前导 $ 字符后跟一个 VTL 标识符（Identifier.）组成。一个 VTL 标识符必须以一个字母开始(a .. z 或 A .. Z)。\n\n剩下的字符将由以下类型的字符组成：\n\n * 字母 (a .. z, A .. Z)\n * 数字 (0 .. 9)\n * 连字符("-")\n * 下划线 ("_")\n\n示例：有效变量\n\n## 有效变量变量名\n$foo\n$mudSlinger\n$mud-slinger\n$mud_slinger\n$mudSlinger1\n\n## 给变量赋值\n#set( $foo = "bar" )\n\n\n\n# 属性\n\nVTL 引用的第二种元素是属性，而属性具有独特的格式。属性的简略标记识前导符 $ 后跟一个 VTL 标识符，在后跟一个点号(".")最后又是一个 VTL 标识符。\n\n示例：有效属性\n\n$customer.Address\n$purchase.Total\n\n\n\n# 方法\n\n方法在 JAVA 代码中定义，并作一些有用的事情，比如运行一个计算器或者作出一个决定。方法是实际上也是引用，由前导符 $ 后跟一个 VTL 标识符，后跟一个 VTL 方法体（Method Body）。 VTL 方法体由一个 VTL 标识符后跟一个左括号，再跟可选的参数列表，最后是右括号。\n\n示例：有效方法\n\n$customer.getAddress()\n$purchase.getTotal()\n$page.setTitle( "My Home Page" )\n$person.setAttributes( ["Strange", "Weird", "Excited"] )\n\n\n\n# 赋值\n\n#set 指令用来为引用设置相应的值。值可以被值派给变量引用或者是属性引用，而且赋值要在括号里括起来。\n\n#set( $monkey = $bill ) ## variable reference\n#set( $monkey.Friend = "monica" ) ## string literal\n#set( $monkey.Blame = $whitehouse.Leak ) ## property reference\n#set( $monkey.Plan = $spindoctor.weave($web) ) ## method reference\n#set( $monkey.Number = 123 ) ##number literal\n#set( $monkey.Say = ["Not", $my, "fault"] ) ## ArrayList\n\n\n\n# 字符串\n\n使用 #set 指令时，括在双引号中的字面字符串将解析和重新解释 。 然而，当字面字符串括在单引号中时，不被解析：\n\n示例：\n\n#set( $foo = "bar" )\n$foo\n#set( $blargh = \'$foo\' )\n$blargh\n\n\n输出：\n\nBar\n $foo\n\n\n\n# 条件\n\nVTL 使用 #If、#elseif、#else 指令做条件语句控制。\n\n示例：\n\n#if( $foo < 10 )\n    <strong>Go North</strong>\n#elseif( $foo == 10 )\n    <strong>Go East</strong>\n#elseif( $bar == 6 )\n    <strong>Go South</strong>\n#else\n    <strong>Go West</strong>\n#end\n\n\n\n# 逻辑\n\nVTL 支持与（&&）、或（||）、非（!）逻辑判断。\n\n示例：\n\n#if( $foo && $bar )\n   <strong> This AND that</strong>\n#end\n\n#if( $foo || $bar )\n    <strong>This or That</strong>\n#end\n\n#if( !$foo )\n <strong>NOT that</strong>\n#end\n\n\n\n# 循环\n\nVTL 通过 #foreach 支持循环\n\n<ul>\n#foreach( $product in $allProducts )\n    <li>$product</li>\n#end\n</ul>\n\n\n\n# 包含\n\nVTL 通过 #include 来导入其他文件。\n\n示例：\n\n#include( "one.txt" )\n\n#include( "one.gif","two.txt","three.htm" )\n\n#include( "greetings.txt", $seasonalstock )\n\n\n\n# 解析\n\nVTL 通过 #parse 导入其他 vm 文件。\n\n$count\n#set( $count = $count - 1 )\n#if( $count > 0 )\n    #parse( "parsefoo.vm" )\n#else\n    All done with parsefoo.vm!\n#end\n\n\n\n# 停止\n\nVTL 使用 #stop 停止模板引擎的执行，并返回。这通常用作调试。\n\n#stop ##\n\n\n\n# 宏\n\nVTL 使用 #macro 和 #end 配合来定义宏，以此实现自定义指令。\n\n示例一：\n\n## 定义宏\n#macro( d )\n<tr><td></td></tr>\n#end\n\n## 使用宏\n#d()\n\n\n示例二：\n\n## 定义宏\n#macro( tablerows $color $somelist )\n  #foreach( $something in $somelist )\n    <tr><td bgcolor=$color>$something</td></tr>\n  #end\n#end\n\n## 使用宏\n#set( $greatlakes = ["Superior","Michigan","Huron","Erie","Ontario"] )\n#set( $color = "blue" )\n<table>\n    #tablerows( $color $greatlakes )\n</table>\n\n\n输出：\n\n<table>\n  <tr>\n    <td bgcolor="blue">Superior</td>\n  </tr>\n  <tr>\n    <td bgcolor="blue">Michigan</td>\n  </tr>\n  <tr>\n    <td bgcolor="blue">Huron</td>\n  </tr>\n  <tr>\n    <td bgcolor="blue">Erie</td>\n  </tr>\n  <tr>\n    <td bgcolor="blue">Ontario</td>\n  </tr>\n</table>\n\n\n\n# 转义\n\nVTL 使用 \\ 符号来进行字符转义。\n\n示例一\n\n## The following line defines $email in this template:\n#set( $email = "foo" )\n$email\n\\$email\n\n\n输出：\n\nfoo\n$email\n\n\n\n# 语义要点\n\nVelocity 有一些语义要点，容易产生歧义，这里归纳一下。\n\n（1）Velocity 的行为并不受空格的影响。\n\n示例：以下三种写法效果一致\n\n## 写法一\nSend me #set($foo = ["$10 and ","a cake"])#foreach($a in $foo)$a #end please.\n\n## 写法二\nSend me\n#set( $foo = ["$10 and ","a cake"] )\n#foreach( $a in $foo )\n$a\n#end\nplease.\n\n## 写法三\nSend me\n#set($foo       = ["$10 and ","a cake"])\n                 #foreach           ($a in $foo )$a\n         #end please.\n\n\n\n# 参考资料\n\n * Velocity Github\n * Velocity 官网\n * Velocity 中文文档\n * velocity-spring-boot-project',normalizedContent:'# velocity 快速入门\n\nvelocity （简称 vtl）是一个基于 java 的模版引擎。它允许 web 页面设计者引用 java 代码预定义的方法。web 设计者可以根据 mvc 模式和 java 程序员并行工作，这意味着 web 设计者可以单独专注于设计良好的站点，而程序员则可单独专注于编写底层代码。velocity 将 java 代码从 web 页面中分离出来，使站点在长时间运行后仍然具有很好的可维护性，并提供了一个除 jsp 和 php 之外的可行的被选方案。\n\n\n# 注释\n\n单行注释以##开始，并在本行结束。\n\n## this is a single line comment.\n\n\n多行注释，以 # 开始并以 # 结束可以处理这种情况。\n\n#*\n thus begins a multi-line comment. online visitors won\'t\n see this text because the velocity templating engine will\n ignore it.\n*#\n\n\n注释块 ，可以用来存储诸如文档作者、版本信息等。\n\n#**\nthis is a vtl comment block and\nmay be used to store such information\nas the document author and versioning\ninformation:\n@author\n@version 5\n*#\n\n\n\n# 引用\n\nvtl 中有三种类型的引用：变量，属性和方法。\n\n\n# 变量\n\n变量（variables）的简略标记是有一个前导 $ 字符后跟一个 vtl 标识符（identifier.）组成。一个 vtl 标识符必须以一个字母开始(a .. z 或 a .. z)。\n\n剩下的字符将由以下类型的字符组成：\n\n * 字母 (a .. z, a .. z)\n * 数字 (0 .. 9)\n * 连字符("-")\n * 下划线 ("_")\n\n示例：有效变量\n\n## 有效变量变量名\n$foo\n$mudslinger\n$mud-slinger\n$mud_slinger\n$mudslinger1\n\n## 给变量赋值\n#set( $foo = "bar" )\n\n\n\n# 属性\n\nvtl 引用的第二种元素是属性，而属性具有独特的格式。属性的简略标记识前导符 $ 后跟一个 vtl 标识符，在后跟一个点号(".")最后又是一个 vtl 标识符。\n\n示例：有效属性\n\n$customer.address\n$purchase.total\n\n\n\n# 方法\n\n方法在 java 代码中定义，并作一些有用的事情，比如运行一个计算器或者作出一个决定。方法是实际上也是引用，由前导符 $ 后跟一个 vtl 标识符，后跟一个 vtl 方法体（method body）。 vtl 方法体由一个 vtl 标识符后跟一个左括号，再跟可选的参数列表，最后是右括号。\n\n示例：有效方法\n\n$customer.getaddress()\n$purchase.gettotal()\n$page.settitle( "my home page" )\n$person.setattributes( ["strange", "weird", "excited"] )\n\n\n\n# 赋值\n\n#set 指令用来为引用设置相应的值。值可以被值派给变量引用或者是属性引用，而且赋值要在括号里括起来。\n\n#set( $monkey = $bill ) ## variable reference\n#set( $monkey.friend = "monica" ) ## string literal\n#set( $monkey.blame = $whitehouse.leak ) ## property reference\n#set( $monkey.plan = $spindoctor.weave($web) ) ## method reference\n#set( $monkey.number = 123 ) ##number literal\n#set( $monkey.say = ["not", $my, "fault"] ) ## arraylist\n\n\n\n# 字符串\n\n使用 #set 指令时，括在双引号中的字面字符串将解析和重新解释 。 然而，当字面字符串括在单引号中时，不被解析：\n\n示例：\n\n#set( $foo = "bar" )\n$foo\n#set( $blargh = \'$foo\' )\n$blargh\n\n\n输出：\n\nbar\n $foo\n\n\n\n# 条件\n\nvtl 使用 #if、#elseif、#else 指令做条件语句控制。\n\n示例：\n\n#if( $foo < 10 )\n    <strong>go north</strong>\n#elseif( $foo == 10 )\n    <strong>go east</strong>\n#elseif( $bar == 6 )\n    <strong>go south</strong>\n#else\n    <strong>go west</strong>\n#end\n\n\n\n# 逻辑\n\nvtl 支持与（&&）、或（||）、非（!）逻辑判断。\n\n示例：\n\n#if( $foo && $bar )\n   <strong> this and that</strong>\n#end\n\n#if( $foo || $bar )\n    <strong>this or that</strong>\n#end\n\n#if( !$foo )\n <strong>not that</strong>\n#end\n\n\n\n# 循环\n\nvtl 通过 #foreach 支持循环\n\n<ul>\n#foreach( $product in $allproducts )\n    <li>$product</li>\n#end\n</ul>\n\n\n\n# 包含\n\nvtl 通过 #include 来导入其他文件。\n\n示例：\n\n#include( "one.txt" )\n\n#include( "one.gif","two.txt","three.htm" )\n\n#include( "greetings.txt", $seasonalstock )\n\n\n\n# 解析\n\nvtl 通过 #parse 导入其他 vm 文件。\n\n$count\n#set( $count = $count - 1 )\n#if( $count > 0 )\n    #parse( "parsefoo.vm" )\n#else\n    all done with parsefoo.vm!\n#end\n\n\n\n# 停止\n\nvtl 使用 #stop 停止模板引擎的执行，并返回。这通常用作调试。\n\n#stop ##\n\n\n\n# 宏\n\nvtl 使用 #macro 和 #end 配合来定义宏，以此实现自定义指令。\n\n示例一：\n\n## 定义宏\n#macro( d )\n<tr><td></td></tr>\n#end\n\n## 使用宏\n#d()\n\n\n示例二：\n\n## 定义宏\n#macro( tablerows $color $somelist )\n  #foreach( $something in $somelist )\n    <tr><td bgcolor=$color>$something</td></tr>\n  #end\n#end\n\n## 使用宏\n#set( $greatlakes = ["superior","michigan","huron","erie","ontario"] )\n#set( $color = "blue" )\n<table>\n    #tablerows( $color $greatlakes )\n</table>\n\n\n输出：\n\n<table>\n  <tr>\n    <td bgcolor="blue">superior</td>\n  </tr>\n  <tr>\n    <td bgcolor="blue">michigan</td>\n  </tr>\n  <tr>\n    <td bgcolor="blue">huron</td>\n  </tr>\n  <tr>\n    <td bgcolor="blue">erie</td>\n  </tr>\n  <tr>\n    <td bgcolor="blue">ontario</td>\n  </tr>\n</table>\n\n\n\n# 转义\n\nvtl 使用 \\ 符号来进行字符转义。\n\n示例一\n\n## the following line defines $email in this template:\n#set( $email = "foo" )\n$email\n\\$email\n\n\n输出：\n\nfoo\n$email\n\n\n\n# 语义要点\n\nvelocity 有一些语义要点，容易产生歧义，这里归纳一下。\n\n（1）velocity 的行为并不受空格的影响。\n\n示例：以下三种写法效果一致\n\n## 写法一\nsend me #set($foo = ["$10 and ","a cake"])#foreach($a in $foo)$a #end please.\n\n## 写法二\nsend me\n#set( $foo = ["$10 and ","a cake"] )\n#foreach( $a in $foo )\n$a\n#end\nplease.\n\n## 写法三\nsend me\n#set($foo       = ["$10 and ","a cake"])\n                 #foreach           ($a in $foo )$a\n         #end please.\n\n\n\n# 参考资料\n\n * velocity github\n * velocity 官网\n * velocity 中文文档\n * velocity-spring-boot-project',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 模板引擎",frontmatter:{title:"Java 模板引擎",categories:["编程","Java","工具","模板引擎"],tags:["Java","模板引擎"],abbrlink:"d29d234e",date:"2022-02-17T22:34:30.000Z",hidden:!0,permalink:"/pages/9a5880/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/03.%E6%A8%A1%E6%9D%BF%E5%BC%95%E6%93%8E/",relativePath:"12.工具/03.模板引擎/README.md",key:"v-438f9dca",path:"/pages/9a5880/",headers:[{level:2,title:"内容",slug:"内容",normalizedTitle:"内容",charIndex:60},{level:2,title:"资源",slug:"资源",normalizedTitle:"资源",charIndex:342}],headersStr:"内容 资源",content:"# Java 模板引擎\n\n模板引擎不属于特定技术领域，它是跨领域跨平台的概念。 模板引擎的作用就是分离业务数据和最终呈现内容，它可以生成特定格式的文档（模板） 。\n\n模板引擎简单来说，就是：模板 + 数据模型 = 输出\n\n较早，也比较经典的模板引擎是 JavaEE 的标准技术 JSP。\n\n但 JSP 存在以下缺点，导致逐渐被淘汰：\n\n * 性能差\n   * JSP 本质上是 Servlet，第一次请求 JSP 页面，必须要在 web 服务器中编译成 servlet，所以第一次响应较慢。\n   * 每次请求 JSP 都是访问 servlet 再用输出流输出的 html 页面。\n   * JSP 中的内容很多，页面响应会很慢，因为是同步加载。\n * 无法前后端分离\n   * 动态资源和静态资源全部耦合在一起，无法做到前后端分离。一旦服务器出现状况，前后台一起玩完。\n   * 而且 Java 工程师既当爹又当妈，又要维护 Java 代码，又要维护 JSP 代码，痛苦。\n   * 前端工程师如果不理解 JSP 语法，面对各种 JSP 标签、表达式、指令，会一脸懵逼，痛苦。\n * 不是所有服务器都支持 - JSP 必须要在支持 JSP 技术的 web 服务器里运行（如 Tomcat）。但有些服务器则不支持 JSP ，如 Nginx。\n\n在 Java 领域，目前最常见的模板引擎就是：\n\n * Freemark\n * Thymeleaf\n * Velocity\n\n\n# 内容\n\n * Freemark\n * Thymeleaf\n * Velocity\n\n\n# 资源\n\n * Freemark\n   * Freemark Github\n   * Freemark 中文教程\n   * 在线 Freemark 工具\n * Velocity\n   * Velocity Github\n   * Velocity 官网\n   * Velocity 中文文档\n   * velocity-spring-boot-project",normalizedContent:"# java 模板引擎\n\n模板引擎不属于特定技术领域，它是跨领域跨平台的概念。 模板引擎的作用就是分离业务数据和最终呈现内容，它可以生成特定格式的文档（模板） 。\n\n模板引擎简单来说，就是：模板 + 数据模型 = 输出\n\n较早，也比较经典的模板引擎是 javaee 的标准技术 jsp。\n\n但 jsp 存在以下缺点，导致逐渐被淘汰：\n\n * 性能差\n   * jsp 本质上是 servlet，第一次请求 jsp 页面，必须要在 web 服务器中编译成 servlet，所以第一次响应较慢。\n   * 每次请求 jsp 都是访问 servlet 再用输出流输出的 html 页面。\n   * jsp 中的内容很多，页面响应会很慢，因为是同步加载。\n * 无法前后端分离\n   * 动态资源和静态资源全部耦合在一起，无法做到前后端分离。一旦服务器出现状况，前后台一起玩完。\n   * 而且 java 工程师既当爹又当妈，又要维护 java 代码，又要维护 jsp 代码，痛苦。\n   * 前端工程师如果不理解 jsp 语法，面对各种 jsp 标签、表达式、指令，会一脸懵逼，痛苦。\n * 不是所有服务器都支持 - jsp 必须要在支持 jsp 技术的 web 服务器里运行（如 tomcat）。但有些服务器则不支持 jsp ，如 nginx。\n\n在 java 领域，目前最常见的模板引擎就是：\n\n * freemark\n * thymeleaf\n * velocity\n\n\n# 内容\n\n * freemark\n * thymeleaf\n * velocity\n\n\n# 资源\n\n * freemark\n   * freemark github\n   * freemark 中文教程\n   * 在线 freemark 工具\n * velocity\n   * velocity github\n   * velocity 官网\n   * velocity 中文文档\n   * velocity-spring-boot-project",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"JUnit5 快速入门",frontmatter:{title:"JUnit5 快速入门",categories:["编程","Java","工具","测试"],tags:["Java","测试","JUnit"],abbrlink:"e85f4bbe",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/06533c/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/04.%E6%B5%8B%E8%AF%95/01.Junit.html",relativePath:"12.工具/04.测试/01.Junit.md",key:"v-c5441038",path:"/pages/06533c/",headers:[{level:2,title:"安装",slug:"安装",normalizedTitle:"安装",charIndex:37},{level:2,title:"JUnit 注解",slug:"junit-注解",normalizedTitle:"junit 注解",charIndex:764},{level:2,title:"编写单元测试",slug:"编写单元测试",normalizedTitle:"编写单元测试",charIndex:4766},{level:3,title:"基本的单元测试类和方法",slug:"基本的单元测试类和方法",normalizedTitle:"基本的单元测试类和方法",charIndex:4777},{level:3,title:"定制测试类和方法的显示名称",slug:"定制测试类和方法的显示名称",normalizedTitle:"定制测试类和方法的显示名称",charIndex:5731},{level:3,title:"断言（Assertions）",slug:"断言-assertions",normalizedTitle:"断言（assertions）",charIndex:6216},{level:3,title:"假想（Assumptions）",slug:"假想-assumptions",normalizedTitle:"假想（assumptions）",charIndex:9987},{level:3,title:"禁用",slug:"禁用",normalizedTitle:"禁用",charIndex:10949},{level:3,title:"测试条件",slug:"测试条件",normalizedTitle:"测试条件",charIndex:11359},{level:4,title:"操作系统条件",slug:"操作系统条件",normalizedTitle:"操作系统条件",charIndex:11367},{level:4,title:"Java 运行时版本条件",slug:"java-运行时版本条件",normalizedTitle:"java 运行时版本条件",charIndex:11731},{level:4,title:"系统属性条件",slug:"系统属性条件",normalizedTitle:"系统属性条件",charIndex:11950},{level:3,title:"嵌套测试",slug:"嵌套测试",normalizedTitle:"嵌套测试",charIndex:12188},{level:3,title:"重复测试",slug:"重复测试",normalizedTitle:"重复测试",charIndex:14499},{level:3,title:"参数化测试",slug:"参数化测试",normalizedTitle:"参数化测试",charIndex:16211},{level:2,title:"引用和引申",slug:"引用和引申",normalizedTitle:"引用和引申",charIndex:16398}],headersStr:"安装 JUnit 注解 编写单元测试 基本的单元测试类和方法 定制测试类和方法的显示名称 断言（Assertions） 假想（Assumptions） 禁用 测试条件 操作系统条件 Java 运行时版本条件 系统属性条件 嵌套测试 重复测试 参数化测试 引用和引申",content:'# JUnit5 快速入门\n\n> version: junit5\n\n\n# 安装\n\n在 pom 中添加依赖\n\n<properties>\n  <junit.jupiter.version>5.3.2</junit.jupiter.version>\n</properties>\n\n<dependencies>\n  <dependency>\n    <groupId>org.junit.jupiter</groupId>\n    <artifactId>junit-jupiter-api</artifactId>\n    <version>${junit.jupiter.version}</version>\n    <scope>test</scope>\n  </dependency>\n  <dependency>\n    <groupId>org.junit.jupiter</groupId>\n    <artifactId>junit-jupiter-params</artifactId>\n    <version>${junit.jupiter.version}</version>\n    <scope>test</scope>\n  </dependency>\n  <dependency>\n    <groupId>org.junit.jupiter</groupId>\n    <artifactId>junit-jupiter-engine</artifactId>\n    <version>${junit.jupiter.version}</version>\n    <scope>test</scope>\n  </dependency>\n</dependencies>\n\n\n组件间依赖关系：\n\n\n\n\n# JUnit 注解\n\nANNOTATION           DESCRIPTION\n@Test                Denotes that a method is a test method. Unlike JUnit 4’s\n                     @Test annotation, this annotation does not declare any\n                     attributes, since test extensions in JUnit Jupiter operate\n                     based on their own dedicated annotations. Such methods are\n                     inherited unless they are overridden.\n@ParameterizedTest   Denotes that a method is a parameterized test. Such methods\n                     are inherited unless they are overridden.\n@RepeatedTest        Denotes that a method is a test template for a repeated\n                     test. Such methods are inherited unless they are overridden.\n@TestFactory         Denotes that a method is a test factory for dynamic tests.\n                     Such methods are inherited unless they are overridden.\n@TestInstance        Used to configure the test instance lifecycle for the\n                     annotated test class. Such annotations are inherited.\n@TestTemplate        Denotes that a method is a template for test cases designed\n                     to be invoked multiple times depending on the number of\n                     invocation contexts returned by the registered providers.\n                     Such methods are inherited unless they are overridden.\n@DisplayName         Declares a custom display name for the test class or test\n                     method. Such annotations are not inherited.\n@BeforeEach          Denotes that the annotated method should be executed before\n                     each @Test, @RepeatedTest, @ParameterizedTest, or\n                     @TestFactory method in the current class; analogous to JUnit\n                     4’s @Before. Such methods are inherited unless they are\n                     overridden.\n@AfterEach           Denotes that the annotated method should be executed after\n                     each @Test, @RepeatedTest, @ParameterizedTest, or\n                     @TestFactory method in the current class; analogous to JUnit\n                     4’s @After. Such methods are inherited unless they are\n                     overridden.\n@BeforeAll           Denotes that the annotated method should be executed before\n                     all @Test, @RepeatedTest, @ParameterizedTest, and\n                     @TestFactory methods in the current class; analogous to\n                     JUnit 4’s @BeforeClass. Such methods are inherited (unless\n                     they are hidden or overridden) and must be static (unless\n                     the "per-class" test instance lifecycle is used).\n@AfterAll            Denotes that the annotated method should be executed after\n                     all @Test, @RepeatedTest, @ParameterizedTest, and\n                     @TestFactory methods in the current class; analogous to\n                     JUnit 4’s @AfterClass. Such methods are inherited (unless\n                     they are hidden or overridden) and must be static (unless\n                     the "per-class" test instance lifecycle is used).\n@Nested              Denotes that the annotated class is a nested, non-static\n                     test class. @BeforeAll and @AfterAllmethods cannot be used\n                     directly in a @Nested test class unless the "per-class" test\n                     instance lifecycle is used. Such annotations are not\n                     inherited.\n@Tag                 Used to declare tags for filtering tests, either at the\n                     class or method level; analogous to test groups in TestNG or\n                     Categories in JUnit 4. Such annotations are inherited at the\n                     class level but not at the method level.\n@Disabled            Used to disable a test class or test method; analogous to\n                     JUnit 4’s @Ignore. Such annotations are not inherited.\n@ExtendWith          Used to register custom extensions. Such annotations are\n                     inherited.\n\n\n# 编写单元测试\n\n\n# 基本的单元测试类和方法\n\nimport org.junit.jupiter.api.*;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nclass Junit5StandardTests {\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(Junit5StandardTests.class);\n\n    @BeforeAll\n    static void beforeAll() {\n        LOGGER.info("call beforeAll()");\n    }\n\n    @BeforeEach\n    void beforeEach() {\n        LOGGER.info("call beforeEach()");\n    }\n\n    @Test\n    void succeedingTest() {\n        LOGGER.info("call succeedingTest()");\n    }\n\n    @Test\n    void failingTest() {\n        LOGGER.info("call failingTest()");\n        // fail("a failing test");\n    }\n\n    @Test\n    @Disabled("for demonstration purposes")\n    void skippedTest() {\n        LOGGER.info("call skippedTest()");\n        // not executed\n    }\n\n    @AfterEach\n    void afterEach() {\n        LOGGER.info("call afterEach()");\n    }\n\n    @AfterAll\n    static void afterAll() {\n        LOGGER.info("call afterAll()");\n    }\n}\n\n\n\n# 定制测试类和方法的显示名称\n\n支持普通字符、特殊符号、emoji\n\nimport org.junit.jupiter.api.DisplayName;\nimport org.junit.jupiter.api.Test;\n\n@DisplayName("A special test case")\nclass JunitDisplayNameDemo {\n\n    @Test\n    @DisplayName("Custom test name containing spaces")\n    void testWithDisplayNameContainingSpaces() { }\n\n    @Test\n    @DisplayName("╯°□°）╯")\n    void testWithDisplayNameContainingSpecialCharacters() { }\n\n    @Test\n    @DisplayName("😱")\n    void testWithDisplayNameContainingEmoji() { }\n}\n\n\n\n# 断言（Assertions）\n\nimport org.junit.jupiter.api.BeforeAll;\nimport org.junit.jupiter.api.Test;\n\nimport static java.time.Duration.ofMillis;\nimport static java.time.Duration.ofMinutes;\nimport static org.junit.jupiter.api.Assertions.*;\n\nclass AssertionsDemo {\n\n    private static Person person;\n\n    @BeforeAll\n    public static void beforeAll() {\n        person = new Person("John", "Doe");\n    }\n\n    @Test\n    void standardAssertions() {\n        assertEquals(2, 2);\n        assertEquals(4, 4, "The optional assertion message is now the last parameter.");\n        assertTrue(\'a\' < \'b\', () -> "Assertion messages can be lazily evaluated -- "\n            + "to avoid constructing complex messages unnecessarily.");\n    }\n\n    @Test\n    void groupedAssertions() {\n        // In a grouped assertion all assertions are executed, and any\n        // failures will be reported together.\n        assertAll("person", () -> assertEquals("John", person.getFirstName()),\n            () -> assertEquals("Doe", person.getLastName()));\n    }\n\n    @Test\n    void dependentAssertions() {\n        // Within a code block, if an assertion fails the\n        // subsequent code in the same block will be skipped.\n        assertAll("properties", () -> {\n            String firstName = person.getFirstName();\n            assertNotNull(firstName);\n\n            // Executed only if the previous assertion is valid.\n            assertAll("first name", () -> assertTrue(firstName.startsWith("J")),\n                () -> assertTrue(firstName.endsWith("n")));\n        }, () -> {\n            // Grouped assertion, so processed independently\n            // of results of first name assertions.\n            String lastName = person.getLastName();\n            assertNotNull(lastName);\n\n            // Executed only if the previous assertion is valid.\n            assertAll("last name", () -> assertTrue(lastName.startsWith("D")),\n                () -> assertTrue(lastName.endsWith("e")));\n        });\n    }\n\n    @Test\n    void exceptionTesting() {\n        Throwable exception = assertThrows(IllegalArgumentException.class, () -> {\n            throw new IllegalArgumentException("a message");\n        });\n        assertEquals("a message", exception.getMessage());\n    }\n\n    @Test\n    void timeoutNotExceeded() {\n        // The following assertion succeeds.\n        assertTimeout(ofMinutes(2), () -> {\n            // Perform task that takes less than 2 minutes.\n        });\n    }\n\n    @Test\n    void timeoutNotExceededWithResult() {\n        // The following assertion succeeds, and returns the supplied object.\n        String actualResult = assertTimeout(ofMinutes(2), () -> {\n            return "a result";\n        });\n        assertEquals("a result", actualResult);\n    }\n\n    @Test\n    void timeoutNotExceededWithMethod() {\n        // The following assertion invokes a method reference and returns an object.\n        String actualGreeting = assertTimeout(ofMinutes(2), AssertionsDemo::greeting);\n        assertEquals("Hello, World!", actualGreeting);\n    }\n\n    @Test\n    void timeoutExceeded() {\n        // The following assertion fails with an error message similar to:\n        // execution exceeded timeout of 10 ms by 91 ms\n        assertTimeout(ofMillis(10), () -> {\n            // Simulate task that takes more than 10 ms.\n            Thread.sleep(100);\n        });\n    }\n\n    @Test\n    void timeoutExceededWithPreemptiveTermination() {\n        // The following assertion fails with an error message similar to:\n        // execution timed out after 10 ms\n        assertTimeoutPreemptively(ofMillis(10), () -> {\n            // Simulate task that takes more than 10 ms.\n            Thread.sleep(100);\n        });\n    }\n\n    private static String greeting() {\n        return "Hello, World!";\n    }\n\n}\n\n\n\n# 假想（Assumptions）\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assumptions.assumeTrue;\nimport static org.junit.jupiter.api.Assumptions.assumingThat;\n\nimport org.junit.jupiter.api.Test;\n\nclass AssumptionsDemo {\n\n    @Test\n    void testOnlyOnCiServer() {\n        assumeTrue("CI".equals(System.getenv("ENV")));\n        // remainder of test\n    }\n\n    @Test\n    void testOnlyOnDeveloperWorkstation() {\n        assumeTrue("DEV".equals(System.getenv("ENV")),\n            () -> "Aborting test: not on developer workstation");\n        // remainder of test\n    }\n\n    @Test\n    void testInAllEnvironments() {\n        assumingThat("CI".equals(System.getenv("ENV")),\n            () -> {\n                // perform these assertions only on the CI server\n                assertEquals(2, 2);\n            });\n\n        // perform these assertions in all environments\n        assertEquals("a string", "a string");\n    }\n\n}\n\n\n\n# 禁用\n\n禁用单元测试类示例：\n\nimport org.junit.jupiter.api.Disabled;\nimport org.junit.jupiter.api.Test;\n\n@Disabled\nclass DisabledClassDemo {\n    @Test\n    void testWillBeSkipped() {\n    }\n}\n\n\n禁用单元测试方法示例：\n\nimport org.junit.jupiter.api.Disabled;\nimport org.junit.jupiter.api.Test;\n\nclass DisabledTestsDemo {\n\n    @Disabled\n    @Test\n    void testWillBeSkipped() {\n    }\n\n    @Test\n    void testWillBeExecuted() {\n    }\n}\n\n\n\n# 测试条件\n\n# 操作系统条件\n\n@Test\n@EnabledOnOs(MAC)\nvoid onlyOnMacOs() {\n    // ...\n}\n\n@TestOnMac\nvoid testOnMac() {\n    // ...\n}\n\n@Test\n@EnabledOnOs({ LINUX, MAC })\nvoid onLinuxOrMac() {\n    // ...\n}\n\n@Test\n@DisabledOnOs(WINDOWS)\nvoid notOnWindows() {\n    // ...\n}\n\n@Target(ElementType.METHOD)\n@Retention(RetentionPolicy.RUNTIME)\n@Test\n@EnabledOnOs(MAC)\n@interface TestOnMac {\n}\n\n\n# Java 运行时版本条件\n\n@Test\n@EnabledOnJre(JAVA_8)\nvoid onlyOnJava8() {\n    // ...\n}\n\n@Test\n@EnabledOnJre({ JAVA_9, JAVA_10 })\nvoid onJava9Or10() {\n    // ...\n}\n\n@Test\n@DisabledOnJre(JAVA_9)\nvoid notOnJava9() {\n    // ...\n}\n\n\n# 系统属性条件\n\n@Test\n@EnabledIfSystemProperty(named = "os.arch", matches = ".*64.*")\nvoid onlyOn64BitArchitectures() {\n    // ...\n}\n\n@Test\n@DisabledIfSystemProperty(named = "ci-server", matches = "true")\nvoid notOnCiServer() {\n    // ...\n}\n\n\n\n# 嵌套测试\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\nimport static org.junit.jupiter.api.Assertions.assertTrue;\n\nimport java.util.EmptyStackException;\nimport java.util.Stack;\n\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.DisplayName;\nimport org.junit.jupiter.api.Nested;\nimport org.junit.jupiter.api.Test;\n\n@DisplayName("A stack")\nclass TestingAStackDemo {\n\n    Stack<Object> stack;\n\n    @Test\n    @DisplayName("is instantiated with new Stack()")\n    void isInstantiatedWithNew() {\n        new Stack<>();\n    }\n\n    @Nested\n    @DisplayName("when new")\n    class WhenNew {\n\n        @BeforeEach\n        void createNewStack() {\n            stack = new Stack<>();\n        }\n\n        @Test\n        @DisplayName("is empty")\n        void isEmpty() {\n            assertTrue(stack.isEmpty());\n        }\n\n        @Test\n        @DisplayName("throws EmptyStackException when popped")\n        void throwsExceptionWhenPopped() {\n            assertThrows(EmptyStackException.class, () -> stack.pop());\n        }\n\n        @Test\n        @DisplayName("throws EmptyStackException when peeked")\n        void throwsExceptionWhenPeeked() {\n            assertThrows(EmptyStackException.class, () -> stack.peek());\n        }\n\n        @Nested\n        @DisplayName("after pushing an element")\n        class AfterPushing {\n\n            String anElement = "an element";\n\n            @BeforeEach\n            void pushAnElement() {\n                stack.push(anElement);\n            }\n\n            @Test\n            @DisplayName("it is no longer empty")\n            void isNotEmpty() {\n                assertFalse(stack.isEmpty());\n            }\n\n            @Test\n            @DisplayName("returns the element when popped and is empty")\n            void returnElementWhenPopped() {\n                assertEquals(anElement, stack.pop());\n                assertTrue(stack.isEmpty());\n            }\n\n            @Test\n            @DisplayName("returns the element when peeked but remains not empty")\n            void returnElementWhenPeeked() {\n                assertEquals(anElement, stack.peek());\n                assertFalse(stack.isEmpty());\n            }\n        }\n    }\n}\n\n\n\n# 重复测试\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\nimport java.util.logging.Logger;\n\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.DisplayName;\nimport org.junit.jupiter.api.RepeatedTest;\nimport org.junit.jupiter.api.RepetitionInfo;\nimport org.junit.jupiter.api.TestInfo;\n\nclass RepeatedTestsDemo {\n\n    private Logger logger = // ...\n\n    @BeforeEach\n    void beforeEach(TestInfo testInfo, RepetitionInfo repetitionInfo) {\n        int currentRepetition = repetitionInfo.getCurrentRepetition();\n        int totalRepetitions = repetitionInfo.getTotalRepetitions();\n        String methodName = testInfo.getTestMethod().get().getName();\n        logger.info(String.format("About to execute repetition %d of %d for %s", //\n            currentRepetition, totalRepetitions, methodName));\n    }\n\n    @RepeatedTest(10)\n    void repeatedTest() {\n        // ...\n    }\n\n    @RepeatedTest(5)\n    void repeatedTestWithRepetitionInfo(RepetitionInfo repetitionInfo) {\n        assertEquals(5, repetitionInfo.getTotalRepetitions());\n    }\n\n    @RepeatedTest(value = 1, name = "{displayName} {currentRepetition}/{totalRepetitions}")\n    @DisplayName("Repeat!")\n    void customDisplayName(TestInfo testInfo) {\n        assertEquals(testInfo.getDisplayName(), "Repeat! 1/1");\n    }\n\n    @RepeatedTest(value = 1, name = RepeatedTest.LONG_DISPLAY_NAME)\n    @DisplayName("Details...")\n    void customDisplayNameWithLongPattern(TestInfo testInfo) {\n        assertEquals(testInfo.getDisplayName(), "Details... :: repetition 1 of 1");\n    }\n\n    @RepeatedTest(value = 5, name = "Wiederholung {currentRepetition} von {totalRepetitions}")\n    void repeatedTestInGerman() {\n        // ...\n    }\n\n}\n\n\n\n# 参数化测试\n\n@ParameterizedTest\n@ValueSource(strings = { "racecar", "radar", "able was I ere I saw elba" })\nvoid palindromes(String candidate) {\n    assertTrue(isPalindrome(candidate));\n}\n\n\n\n# 引用和引申\n\n * Github\n * 官方用户手册\n * Javadoc\n * 版本声明\n * 官方示例',normalizedContent:'# junit5 快速入门\n\n> version: junit5\n\n\n# 安装\n\n在 pom 中添加依赖\n\n<properties>\n  <junit.jupiter.version>5.3.2</junit.jupiter.version>\n</properties>\n\n<dependencies>\n  <dependency>\n    <groupid>org.junit.jupiter</groupid>\n    <artifactid>junit-jupiter-api</artifactid>\n    <version>${junit.jupiter.version}</version>\n    <scope>test</scope>\n  </dependency>\n  <dependency>\n    <groupid>org.junit.jupiter</groupid>\n    <artifactid>junit-jupiter-params</artifactid>\n    <version>${junit.jupiter.version}</version>\n    <scope>test</scope>\n  </dependency>\n  <dependency>\n    <groupid>org.junit.jupiter</groupid>\n    <artifactid>junit-jupiter-engine</artifactid>\n    <version>${junit.jupiter.version}</version>\n    <scope>test</scope>\n  </dependency>\n</dependencies>\n\n\n组件间依赖关系：\n\n\n\n\n# junit 注解\n\nannotation           description\n@test                denotes that a method is a test method. unlike junit 4’s\n                     @test annotation, this annotation does not declare any\n                     attributes, since test extensions in junit jupiter operate\n                     based on their own dedicated annotations. such methods are\n                     inherited unless they are overridden.\n@parameterizedtest   denotes that a method is a parameterized test. such methods\n                     are inherited unless they are overridden.\n@repeatedtest        denotes that a method is a test template for a repeated\n                     test. such methods are inherited unless they are overridden.\n@testfactory         denotes that a method is a test factory for dynamic tests.\n                     such methods are inherited unless they are overridden.\n@testinstance        used to configure the test instance lifecycle for the\n                     annotated test class. such annotations are inherited.\n@testtemplate        denotes that a method is a template for test cases designed\n                     to be invoked multiple times depending on the number of\n                     invocation contexts returned by the registered providers.\n                     such methods are inherited unless they are overridden.\n@displayname         declares a custom display name for the test class or test\n                     method. such annotations are not inherited.\n@beforeeach          denotes that the annotated method should be executed before\n                     each @test, @repeatedtest, @parameterizedtest, or\n                     @testfactory method in the current class; analogous to junit\n                     4’s @before. such methods are inherited unless they are\n                     overridden.\n@aftereach           denotes that the annotated method should be executed after\n                     each @test, @repeatedtest, @parameterizedtest, or\n                     @testfactory method in the current class; analogous to junit\n                     4’s @after. such methods are inherited unless they are\n                     overridden.\n@beforeall           denotes that the annotated method should be executed before\n                     all @test, @repeatedtest, @parameterizedtest, and\n                     @testfactory methods in the current class; analogous to\n                     junit 4’s @beforeclass. such methods are inherited (unless\n                     they are hidden or overridden) and must be static (unless\n                     the "per-class" test instance lifecycle is used).\n@afterall            denotes that the annotated method should be executed after\n                     all @test, @repeatedtest, @parameterizedtest, and\n                     @testfactory methods in the current class; analogous to\n                     junit 4’s @afterclass. such methods are inherited (unless\n                     they are hidden or overridden) and must be static (unless\n                     the "per-class" test instance lifecycle is used).\n@nested              denotes that the annotated class is a nested, non-static\n                     test class. @beforeall and @afterallmethods cannot be used\n                     directly in a @nested test class unless the "per-class" test\n                     instance lifecycle is used. such annotations are not\n                     inherited.\n@tag                 used to declare tags for filtering tests, either at the\n                     class or method level; analogous to test groups in testng or\n                     categories in junit 4. such annotations are inherited at the\n                     class level but not at the method level.\n@disabled            used to disable a test class or test method; analogous to\n                     junit 4’s @ignore. such annotations are not inherited.\n@extendwith          used to register custom extensions. such annotations are\n                     inherited.\n\n\n# 编写单元测试\n\n\n# 基本的单元测试类和方法\n\nimport org.junit.jupiter.api.*;\nimport org.slf4j.logger;\nimport org.slf4j.loggerfactory;\n\nclass junit5standardtests {\n\n    private static final logger logger = loggerfactory.getlogger(junit5standardtests.class);\n\n    @beforeall\n    static void beforeall() {\n        logger.info("call beforeall()");\n    }\n\n    @beforeeach\n    void beforeeach() {\n        logger.info("call beforeeach()");\n    }\n\n    @test\n    void succeedingtest() {\n        logger.info("call succeedingtest()");\n    }\n\n    @test\n    void failingtest() {\n        logger.info("call failingtest()");\n        // fail("a failing test");\n    }\n\n    @test\n    @disabled("for demonstration purposes")\n    void skippedtest() {\n        logger.info("call skippedtest()");\n        // not executed\n    }\n\n    @aftereach\n    void aftereach() {\n        logger.info("call aftereach()");\n    }\n\n    @afterall\n    static void afterall() {\n        logger.info("call afterall()");\n    }\n}\n\n\n\n# 定制测试类和方法的显示名称\n\n支持普通字符、特殊符号、emoji\n\nimport org.junit.jupiter.api.displayname;\nimport org.junit.jupiter.api.test;\n\n@displayname("a special test case")\nclass junitdisplaynamedemo {\n\n    @test\n    @displayname("custom test name containing spaces")\n    void testwithdisplaynamecontainingspaces() { }\n\n    @test\n    @displayname("╯°□°）╯")\n    void testwithdisplaynamecontainingspecialcharacters() { }\n\n    @test\n    @displayname("😱")\n    void testwithdisplaynamecontainingemoji() { }\n}\n\n\n\n# 断言（assertions）\n\nimport org.junit.jupiter.api.beforeall;\nimport org.junit.jupiter.api.test;\n\nimport static java.time.duration.ofmillis;\nimport static java.time.duration.ofminutes;\nimport static org.junit.jupiter.api.assertions.*;\n\nclass assertionsdemo {\n\n    private static person person;\n\n    @beforeall\n    public static void beforeall() {\n        person = new person("john", "doe");\n    }\n\n    @test\n    void standardassertions() {\n        assertequals(2, 2);\n        assertequals(4, 4, "the optional assertion message is now the last parameter.");\n        asserttrue(\'a\' < \'b\', () -> "assertion messages can be lazily evaluated -- "\n            + "to avoid constructing complex messages unnecessarily.");\n    }\n\n    @test\n    void groupedassertions() {\n        // in a grouped assertion all assertions are executed, and any\n        // failures will be reported together.\n        assertall("person", () -> assertequals("john", person.getfirstname()),\n            () -> assertequals("doe", person.getlastname()));\n    }\n\n    @test\n    void dependentassertions() {\n        // within a code block, if an assertion fails the\n        // subsequent code in the same block will be skipped.\n        assertall("properties", () -> {\n            string firstname = person.getfirstname();\n            assertnotnull(firstname);\n\n            // executed only if the previous assertion is valid.\n            assertall("first name", () -> asserttrue(firstname.startswith("j")),\n                () -> asserttrue(firstname.endswith("n")));\n        }, () -> {\n            // grouped assertion, so processed independently\n            // of results of first name assertions.\n            string lastname = person.getlastname();\n            assertnotnull(lastname);\n\n            // executed only if the previous assertion is valid.\n            assertall("last name", () -> asserttrue(lastname.startswith("d")),\n                () -> asserttrue(lastname.endswith("e")));\n        });\n    }\n\n    @test\n    void exceptiontesting() {\n        throwable exception = assertthrows(illegalargumentexception.class, () -> {\n            throw new illegalargumentexception("a message");\n        });\n        assertequals("a message", exception.getmessage());\n    }\n\n    @test\n    void timeoutnotexceeded() {\n        // the following assertion succeeds.\n        asserttimeout(ofminutes(2), () -> {\n            // perform task that takes less than 2 minutes.\n        });\n    }\n\n    @test\n    void timeoutnotexceededwithresult() {\n        // the following assertion succeeds, and returns the supplied object.\n        string actualresult = asserttimeout(ofminutes(2), () -> {\n            return "a result";\n        });\n        assertequals("a result", actualresult);\n    }\n\n    @test\n    void timeoutnotexceededwithmethod() {\n        // the following assertion invokes a method reference and returns an object.\n        string actualgreeting = asserttimeout(ofminutes(2), assertionsdemo::greeting);\n        assertequals("hello, world!", actualgreeting);\n    }\n\n    @test\n    void timeoutexceeded() {\n        // the following assertion fails with an error message similar to:\n        // execution exceeded timeout of 10 ms by 91 ms\n        asserttimeout(ofmillis(10), () -> {\n            // simulate task that takes more than 10 ms.\n            thread.sleep(100);\n        });\n    }\n\n    @test\n    void timeoutexceededwithpreemptivetermination() {\n        // the following assertion fails with an error message similar to:\n        // execution timed out after 10 ms\n        asserttimeoutpreemptively(ofmillis(10), () -> {\n            // simulate task that takes more than 10 ms.\n            thread.sleep(100);\n        });\n    }\n\n    private static string greeting() {\n        return "hello, world!";\n    }\n\n}\n\n\n\n# 假想（assumptions）\n\nimport static org.junit.jupiter.api.assertions.assertequals;\nimport static org.junit.jupiter.api.assumptions.assumetrue;\nimport static org.junit.jupiter.api.assumptions.assumingthat;\n\nimport org.junit.jupiter.api.test;\n\nclass assumptionsdemo {\n\n    @test\n    void testonlyonciserver() {\n        assumetrue("ci".equals(system.getenv("env")));\n        // remainder of test\n    }\n\n    @test\n    void testonlyondeveloperworkstation() {\n        assumetrue("dev".equals(system.getenv("env")),\n            () -> "aborting test: not on developer workstation");\n        // remainder of test\n    }\n\n    @test\n    void testinallenvironments() {\n        assumingthat("ci".equals(system.getenv("env")),\n            () -> {\n                // perform these assertions only on the ci server\n                assertequals(2, 2);\n            });\n\n        // perform these assertions in all environments\n        assertequals("a string", "a string");\n    }\n\n}\n\n\n\n# 禁用\n\n禁用单元测试类示例：\n\nimport org.junit.jupiter.api.disabled;\nimport org.junit.jupiter.api.test;\n\n@disabled\nclass disabledclassdemo {\n    @test\n    void testwillbeskipped() {\n    }\n}\n\n\n禁用单元测试方法示例：\n\nimport org.junit.jupiter.api.disabled;\nimport org.junit.jupiter.api.test;\n\nclass disabledtestsdemo {\n\n    @disabled\n    @test\n    void testwillbeskipped() {\n    }\n\n    @test\n    void testwillbeexecuted() {\n    }\n}\n\n\n\n# 测试条件\n\n# 操作系统条件\n\n@test\n@enabledonos(mac)\nvoid onlyonmacos() {\n    // ...\n}\n\n@testonmac\nvoid testonmac() {\n    // ...\n}\n\n@test\n@enabledonos({ linux, mac })\nvoid onlinuxormac() {\n    // ...\n}\n\n@test\n@disabledonos(windows)\nvoid notonwindows() {\n    // ...\n}\n\n@target(elementtype.method)\n@retention(retentionpolicy.runtime)\n@test\n@enabledonos(mac)\n@interface testonmac {\n}\n\n\n# java 运行时版本条件\n\n@test\n@enabledonjre(java_8)\nvoid onlyonjava8() {\n    // ...\n}\n\n@test\n@enabledonjre({ java_9, java_10 })\nvoid onjava9or10() {\n    // ...\n}\n\n@test\n@disabledonjre(java_9)\nvoid notonjava9() {\n    // ...\n}\n\n\n# 系统属性条件\n\n@test\n@enabledifsystemproperty(named = "os.arch", matches = ".*64.*")\nvoid onlyon64bitarchitectures() {\n    // ...\n}\n\n@test\n@disabledifsystemproperty(named = "ci-server", matches = "true")\nvoid notonciserver() {\n    // ...\n}\n\n\n\n# 嵌套测试\n\nimport static org.junit.jupiter.api.assertions.assertequals;\nimport static org.junit.jupiter.api.assertions.assertfalse;\nimport static org.junit.jupiter.api.assertions.assertthrows;\nimport static org.junit.jupiter.api.assertions.asserttrue;\n\nimport java.util.emptystackexception;\nimport java.util.stack;\n\nimport org.junit.jupiter.api.beforeeach;\nimport org.junit.jupiter.api.displayname;\nimport org.junit.jupiter.api.nested;\nimport org.junit.jupiter.api.test;\n\n@displayname("a stack")\nclass testingastackdemo {\n\n    stack<object> stack;\n\n    @test\n    @displayname("is instantiated with new stack()")\n    void isinstantiatedwithnew() {\n        new stack<>();\n    }\n\n    @nested\n    @displayname("when new")\n    class whennew {\n\n        @beforeeach\n        void createnewstack() {\n            stack = new stack<>();\n        }\n\n        @test\n        @displayname("is empty")\n        void isempty() {\n            asserttrue(stack.isempty());\n        }\n\n        @test\n        @displayname("throws emptystackexception when popped")\n        void throwsexceptionwhenpopped() {\n            assertthrows(emptystackexception.class, () -> stack.pop());\n        }\n\n        @test\n        @displayname("throws emptystackexception when peeked")\n        void throwsexceptionwhenpeeked() {\n            assertthrows(emptystackexception.class, () -> stack.peek());\n        }\n\n        @nested\n        @displayname("after pushing an element")\n        class afterpushing {\n\n            string anelement = "an element";\n\n            @beforeeach\n            void pushanelement() {\n                stack.push(anelement);\n            }\n\n            @test\n            @displayname("it is no longer empty")\n            void isnotempty() {\n                assertfalse(stack.isempty());\n            }\n\n            @test\n            @displayname("returns the element when popped and is empty")\n            void returnelementwhenpopped() {\n                assertequals(anelement, stack.pop());\n                asserttrue(stack.isempty());\n            }\n\n            @test\n            @displayname("returns the element when peeked but remains not empty")\n            void returnelementwhenpeeked() {\n                assertequals(anelement, stack.peek());\n                assertfalse(stack.isempty());\n            }\n        }\n    }\n}\n\n\n\n# 重复测试\n\nimport static org.junit.jupiter.api.assertions.assertequals;\n\nimport java.util.logging.logger;\n\nimport org.junit.jupiter.api.beforeeach;\nimport org.junit.jupiter.api.displayname;\nimport org.junit.jupiter.api.repeatedtest;\nimport org.junit.jupiter.api.repetitioninfo;\nimport org.junit.jupiter.api.testinfo;\n\nclass repeatedtestsdemo {\n\n    private logger logger = // ...\n\n    @beforeeach\n    void beforeeach(testinfo testinfo, repetitioninfo repetitioninfo) {\n        int currentrepetition = repetitioninfo.getcurrentrepetition();\n        int totalrepetitions = repetitioninfo.gettotalrepetitions();\n        string methodname = testinfo.gettestmethod().get().getname();\n        logger.info(string.format("about to execute repetition %d of %d for %s", //\n            currentrepetition, totalrepetitions, methodname));\n    }\n\n    @repeatedtest(10)\n    void repeatedtest() {\n        // ...\n    }\n\n    @repeatedtest(5)\n    void repeatedtestwithrepetitioninfo(repetitioninfo repetitioninfo) {\n        assertequals(5, repetitioninfo.gettotalrepetitions());\n    }\n\n    @repeatedtest(value = 1, name = "{displayname} {currentrepetition}/{totalrepetitions}")\n    @displayname("repeat!")\n    void customdisplayname(testinfo testinfo) {\n        assertequals(testinfo.getdisplayname(), "repeat! 1/1");\n    }\n\n    @repeatedtest(value = 1, name = repeatedtest.long_display_name)\n    @displayname("details...")\n    void customdisplaynamewithlongpattern(testinfo testinfo) {\n        assertequals(testinfo.getdisplayname(), "details... :: repetition 1 of 1");\n    }\n\n    @repeatedtest(value = 5, name = "wiederholung {currentrepetition} von {totalrepetitions}")\n    void repeatedtestingerman() {\n        // ...\n    }\n\n}\n\n\n\n# 参数化测试\n\n@parameterizedtest\n@valuesource(strings = { "racecar", "radar", "able was i ere i saw elba" })\nvoid palindromes(string candidate) {\n    asserttrue(ispalindrome(candidate));\n}\n\n\n\n# 引用和引申\n\n * github\n * 官方用户手册\n * javadoc\n * 版本声明\n * 官方示例',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Mockito 快速入门",frontmatter:{title:"Mockito 快速入门",categories:["编程","Java","工具","测试"],tags:["Java","测试","Mockito"],abbrlink:"6d4202df",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/ab18ad/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/04.%E6%B5%8B%E8%AF%95/02.Mockito.html",relativePath:"12.工具/04.测试/02.Mockito.md",key:"v-f8abeb6c",path:"/pages/ab18ad/",headers:[{level:2,title:"预备知识",slug:"预备知识",normalizedTitle:"预备知识",charIndex:52},{level:2,title:"使用 mock 对象来进行测试",slug:"使用-mock-对象来进行测试",normalizedTitle:"使用 mock 对象来进行测试",charIndex:120},{level:3,title:"单元测试的目标和挑战",slug:"单元测试的目标和挑战",normalizedTitle:"单元测试的目标和挑战",charIndex:140},{level:3,title:"测试类的分类",slug:"测试类的分类",normalizedTitle:"测试类的分类",charIndex:259},{level:3,title:"Mock 对象的产生",slug:"mock-对象的产生",normalizedTitle:"mock 对象的产生",charIndex:727},{level:3,title:"使用 Mockito 生成 Mock 对象",slug:"使用-mockito-生成-mock-对象",normalizedTitle:"使用 mockito 生成 mock 对象",charIndex:1021},{level:2,title:"为自己的项目添加 Mockito 依赖",slug:"为自己的项目添加-mockito-依赖",normalizedTitle:"为自己的项目添加 mockito 依赖",charIndex:1219},{level:3,title:"在 Gradle 添加 Mockito 依赖",slug:"在-gradle-添加-mockito-依赖",normalizedTitle:"在 gradle 添加 mockito 依赖",charIndex:1243},{level:3,title:"在 Maven 添加 Mockito 依赖",slug:"在-maven-添加-mockito-依赖",normalizedTitle:"在 maven 添加 mockito 依赖",charIndex:1427},{level:3,title:"在 Eclipse IDE 使用 Mockito",slug:"在-eclipse-ide-使用-mockito",normalizedTitle:"在 eclipse ide 使用 mockito",charIndex:1550},{level:3,title:"以 OSGi 或者 Eclipse 插件形式添加 Mockito 依赖",slug:"以-osgi-或者-eclipse-插件形式添加-mockito-依赖",normalizedTitle:"以 osgi 或者 eclipse 插件形式添加 mockito 依赖",charIndex:1653},{level:2,title:"使用 Mockito API",slug:"使用-mockito-api",normalizedTitle:"使用 mockito api",charIndex:1843},{level:3,title:"静态引用",slug:"静态引用",normalizedTitle:"静态引用",charIndex:1862},{level:3,title:"使用 Mockito 创建和配置 mock 对象",slug:"使用-mockito-创建和配置-mock-对象",normalizedTitle:"使用 mockito 创建和配置 mock 对象",charIndex:1951},{level:3,title:"配置 mock",slug:"配置-mock",normalizedTitle:"配置 mock",charIndex:1097},{level:3,title:"验证 mock 对象方法是否被调用",slug:"验证-mock-对象方法是否被调用",normalizedTitle:"验证 mock 对象方法是否被调用",charIndex:5121},{level:3,title:"使用 Spy 封装 java 对象",slug:"使用-spy-封装-java-对象",normalizedTitle:"使用 spy 封装 java 对象",charIndex:6082},{level:3,title:"使用 @InjectMocks 在 Mockito 中进行依赖注入",slug:"使用-injectmocks-在-mockito-中进行依赖注入",normalizedTitle:"使用 @injectmocks 在 mockito 中进行依赖注入",charIndex:6507},{level:3,title:"捕捉参数",slug:"捕捉参数",normalizedTitle:"捕捉参数",charIndex:7645},{level:3,title:"Mockito 的限制",slug:"mockito-的限制",normalizedTitle:"mockito 的限制",charIndex:8707},{level:2,title:"在 Android 中使用 Mockito",slug:"在-android-中使用-mockito",normalizedTitle:"在 android 中使用 mockito",charIndex:8817},{level:2,title:"实例：使用 Mockito 写一个 Instrumented Unit Test",slug:"实例-使用-mockito-写一个-instrumented-unit-test",normalizedTitle:"实例：使用 mockito 写一个 instrumented unit test",charIndex:9369},{level:3,title:"创建一个测试的 Android 应用",slug:"创建一个测试的-android-应用",normalizedTitle:"创建一个测试的 android 应用",charIndex:9414},{level:3,title:"在 app/build.gradle 文件中添加 Mockito 依赖",slug:"在-app-build-gradle-文件中添加-mockito-依赖",normalizedTitle:"在 app/build.gradle 文件中添加 mockito 依赖",charIndex:9789},{level:3,title:"创建测试",slug:"创建测试",normalizedTitle:"创建测试",charIndex:10344},{level:2,title:"实例：使用 Mockito 创建一个 mock 对象",slug:"实例-使用-mockito-创建一个-mock-对象",normalizedTitle:"实例：使用 mockito 创建一个 mock 对象",charIndex:11236},{level:3,title:"目标",slug:"目标",normalizedTitle:"目标",charIndex:145},{level:3,title:"创建一个 Twitter API 的例子",slug:"创建一个-twitter-api-的例子",normalizedTitle:"创建一个 twitter api 的例子",charIndex:11307},{level:3,title:"模拟 ITweet 的实例",slug:"模拟-itweet-的实例",normalizedTitle:"模拟 itweet 的实例",charIndex:11657},{level:3,title:"验证方法调用",slug:"验证方法调用",normalizedTitle:"验证方法调用",charIndex:12078},{level:3,title:"验证",slug:"验证",normalizedTitle:"验证",charIndex:619},{level:2,title:"模拟静态方法",slug:"模拟静态方法",normalizedTitle:"模拟静态方法",charIndex:12456},{level:3,title:"使用 Powermock 来模拟静态方法",slug:"使用-powermock-来模拟静态方法",normalizedTitle:"使用 powermock 来模拟静态方法",charIndex:12467},{level:3,title:"用封装的方法代替 Powermock",slug:"用封装的方法代替-powermock",normalizedTitle:"用封装的方法代替 powermock",charIndex:13368},{level:2,title:"引用和引申",slug:"引用和引申",normalizedTitle:"引用和引申",charIndex:13527}],headersStr:"预备知识 使用 mock 对象来进行测试 单元测试的目标和挑战 测试类的分类 Mock 对象的产生 使用 Mockito 生成 Mock 对象 为自己的项目添加 Mockito 依赖 在 Gradle 添加 Mockito 依赖 在 Maven 添加 Mockito 依赖 在 Eclipse IDE 使用 Mockito 以 OSGi 或者 Eclipse 插件形式添加 Mockito 依赖 使用 Mockito API 静态引用 使用 Mockito 创建和配置 mock 对象 配置 mock 验证 mock 对象方法是否被调用 使用 Spy 封装 java 对象 使用 @InjectMocks 在 Mockito 中进行依赖注入 捕捉参数 Mockito 的限制 在 Android 中使用 Mockito 实例：使用 Mockito 写一个 Instrumented Unit Test 创建一个测试的 Android 应用 在 app/build.gradle 文件中添加 Mockito 依赖 创建测试 实例：使用 Mockito 创建一个 mock 对象 目标 创建一个 Twitter API 的例子 模拟 ITweet 的实例 验证方法调用 验证 模拟静态方法 使用 Powermock 来模拟静态方法 用封装的方法代替 Powermock 引用和引申",content:'# Mockito 快速入门\n\n> Mockito 是一个针对 Java 的 mock 框架。\n\n\n# 预备知识\n\n如果需要往下学习，你需要先理解 Junit 框架中的单元测试。\n\n如果你不熟悉 JUnit，请看 Junit 教程\n\n\n# 使用 mock 对象来进行测试\n\n\n# 单元测试的目标和挑战\n\n单元测试的思路是在不涉及依赖关系的情况下测试代码（隔离性），所以测试代码与其他类或者系统的关系应该尽量被消除。一个可行的消除方法是替换掉依赖类（测试替换），也就是说我们可以使用替身来替换掉真正的依赖对象。\n\n\n# 测试类的分类\n\n * dummy object 做为参数传递给方法但是绝对不会被使用。譬如说，这种测试类内部的方法不会被调用，或者是用来填充某个方法的参数。\n * Fake 是真正接口或抽象类的实现体，但给对象内部实现很简单。譬如说，它存在内存中而不是真正的数据库中。（译者注：Fake 实现了真正的逻辑，但它的存在只是为了测试，而不适合于用在产品中。）\n * stub 类是依赖类的部分方法实现，而这些方法在你测试类和接口的时候会被用到，也就是说 stub 类在测试中会被实例化。stub 类会回应任何外部测试的调用。stub 类有时候还会记录调用的一些信息。\n * mock object 是指类或者接口的模拟实现，你可以自定义这个对象中某个方法的输出结果。\n\n测试替代技术能够在测试中模拟测试类以外对象。因此你可以验证测试类是否响应正常。譬如说，你可以验证在 Mock 对象的某一个方法是否被调用。这可以确保隔离了外部依赖的干扰只测试测试类。\n\n我们选择 Mock 对象的原因是因为 Mock 对象只需要少量代码的配置。\n\n\n# Mock 对象的产生\n\n你可以手动创建一个 Mock 对象或者使用 Mock 框架来模拟这些类，Mock 框架允许你在运行时创建 Mock 对象并且定义它的行为。\n\n一个典型的例子是把 Mock 对象模拟成数据的提供者。在正式的生产环境中它会被实现用来连接数据源。但是我们在测试的时候 Mock 对象将会模拟成数据提供者来确保我们的测试环境始终是相同的。\n\nMock 对象可以被提供来进行测试。因此，我们测试的类应该避免任何外部数据的强依赖。\n\n通过 Mock 对象或者 Mock 框架，我们可以测试代码中期望的行为。譬如说，验证只有某个存在 Mock 对象的方法是否被调用了。\n\n\n# 使用 Mockito 生成 Mock 对象\n\nMockito 是一个流行 mock 框架，可以和 JUnit 结合起来使用。Mockito 允许你创建和配置 mock 对象。使用 Mockito 可以明显的简化对外部依赖的测试类的开发。\n\n一般使用 Mockito 需要执行下面三步\n\n 1. 模拟并替换测试代码中外部依赖\n 2. 执行测试代码\n 3. 验证测试代码是否被正确的执行 0\n\n\n# 为自己的项目添加 Mockito 依赖\n\n\n# 在 Gradle 添加 Mockito 依赖\n\n如果你的项目使用 Gradle 构建，将下面代码加入 Gradle 的构建文件中为自己项目添加 Mockito 依赖\n\nrepositories { jcenter() }\ndependencies { testCompile "org.mockito:mockito-core:2.0.57-beta" }\n\n\n\n# 在 Maven 添加 Mockito 依赖\n\n需要在 Maven 声明依赖，您可以在 http://search.maven.org 网站中搜索 g:"org.mockito", a:"mockito-core" 来得到具体的声明方式。\n\n\n# 在 Eclipse IDE 使用 Mockito\n\nEclipse IDE 支持 Gradle 和 Maven 两种构建工具，所以在 Eclipse IDE 添加依赖取决你使用的是哪一个构建工具。\n\n\n# 以 OSGi 或者 Eclipse 插件形式添加 Mockito 依赖\n\n在 Eclipse RCP 应用依赖通常可以在 p2 update 上得到。Orbit 是一个很好的第三方仓库，我们可以在里面寻找能在 Eclipse 上使用的应用和插件。\n\nOrbit 仓库地址：http://download.eclipse.org/tools/orbit/downloads\n\n\n# 使用 Mockito API\n\n\n# 静态引用\n\n如果在代码中静态引用了org.mockito.Mockito.*;，那你你就可以直接调用静态方法和静态变量而不用创建对象，譬如直接调用 mock() 方法。\n\n\n# 使用 Mockito 创建和配置 mock 对象\n\n除了上面所说的使用 mock() 静态方法外，Mockito 还支持通过 @Mock 注解的方式来创建 mock 对象。\n\n如果你使用注解，那么必须要实例化 mock 对象。Mockito 在遇到使用注解的字段的时候，会调用MockitoAnnotations.initMocks(this) 来初始化该 mock 对象。另外也可以通过使用@RunWith(MockitoJUnitRunner.class)来达到相同的效果。\n\n通过下面的例子我们可以了解到使用@Mock 的方法和MockitoRule规则。\n\nimport static org.mockito.Mockito.*;\n\npublic class MockitoTest  {\n\n        @Mock\n        MyDatabase databaseMock; (1)\n\n        @Rule public MockitoRule mockitoRule = MockitoJUnit.rule(); (2)\n\n        @Test\n        public void testQuery()  {\n                ClassToTest t  = new ClassToTest(databaseMock); (3)\n                boolean check = t.query("* from t"); (4)\n                assertTrue(check); (5)\n                verify(databaseMock).query("* from t"); (6)\n        }\n}\n\n\n 1. 告诉 Mockito 模拟 databaseMock 实例\n 2. Mockito 通过 @mock 注解创建 mock 对象\n 3. 使用已经创建的 mock 初始化这个类\n 4. 在测试环境下，执行测试类中的代码\n 5. 使用断言确保调用的方法返回值为 true\n 6. 验证 query 方法是否被 MyDatabase 的 mock 对象调用\n\n\n# 配置 mock\n\n当我们需要配置某个方法的返回值的时候，Mockito 提供了链式的 API 供我们方便的调用\n\nwhen(….).thenReturn(….)可以被用来定义当条件满足时函数的返回值，如果你需要定义多个返回值，可以多次定义。当你多次调用函数的时候，Mockito 会根据你定义的先后顺序来返回返回值。Mocks 还可以根据传入参数的不同来定义不同的返回值。譬如说你的函数可以将anyString 或者 anyInt作为输入参数，然后定义其特定的放回值。\n\nimport static org.mockito.Mockito.*;\nimport static org.junit.Assert.*;\n\n@Test\npublic void test1()  {\n        //  创建 mock\n        MyClass test = Mockito.mock(MyClass.class);\n\n        // 自定义 getUniqueId() 的返回值\n        when(test.getUniqueId()).thenReturn(43);\n\n        // 在测试中使用mock对象\n        assertEquals(test.getUniqueId(), 43);\n}\n\n// 返回多个值\n@Test\npublic void testMoreThanOneReturnValue()  {\n        Iterator i= mock(Iterator.class);\n        when(i.next()).thenReturn("Mockito").thenReturn("rocks");\n        String result=i.next()+" "+i.next();\n        // 断言\n        assertEquals("Mockito rocks", result);\n}\n\n// 如何根据输入来返回值\n@Test\npublic void testReturnValueDependentOnMethodParameter()  {\n        Comparable c= mock(Comparable.class);\n        when(c.compareTo("Mockito")).thenReturn(1);\n        when(c.compareTo("Eclipse")).thenReturn(2);\n        // 断言\n        assertEquals(1,c.compareTo("Mockito"));\n}\n\n// 如何让返回值不依赖于输入\n@Test\npublic void testReturnValueInDependentOnMethodParameter()  {\n        Comparable c= mock(Comparable.class);\n        when(c.compareTo(anyInt())).thenReturn(-1);\n        // 断言\n        assertEquals(-1 ,c.compareTo(9));\n}\n\n// 根据参数类型来返回值\n@Test\npublic void testReturnValueInDependentOnMethodParameter()  {\n        Comparable c= mock(Comparable.class);\n        when(c.compareTo(isA(Todo.class))).thenReturn(0);\n        // 断言\n        Todo todo = new Todo(5);\n        assertEquals(todo ,c.compareTo(new Todo(1)));\n}\n\n\n对于无返回值的函数，我们可以使用doReturn(…).when(…).methodCall来获得类似的效果。例如我们想在调用某些无返回值函数的时候抛出异常，那么可以使用doThrow 方法。如下面代码片段所示\n\nimport static org.mockito.Mockito.*;\nimport static org.junit.Assert.*;\n\n// 下面测试用例描述了如何使用doThrow()方法\n\n@Test(expected=IOException.class)\npublic void testForIOException() {\n        // 创建并配置 mock 对象\n        OutputStream mockStream = mock(OutputStream.class);\n        doThrow(new IOException()).when(mockStream).close();\n\n        // 使用 mock\n        OutputStreamWriter streamWriter= new OutputStreamWriter(mockStream);\n        streamWriter.close();\n}\n\n\n\n# 验证 mock 对象方法是否被调用\n\nMockito 会跟踪 mock 对象里面所有的方法和变量。所以我们可以用来验证函数在传入特定参数的时候是否被调用。这种方式的测试称行为测试，行为测试并不会检查函数的返回值，而是检查在传入正确参数时候函数是否被调用。\n\nimport static org.mockito.Mockito.*;\n\n@Test\npublic void testVerify()  {\n        // 创建并配置 mock 对象\n        MyClass test = Mockito.mock(MyClass.class);\n        when(test.getUniqueId()).thenReturn(43);\n\n        // 调用mock对象里面的方法并传入参数为12\n        test.testing(12);\n        test.getUniqueId();\n        test.getUniqueId();\n\n        // 查看在传入参数为12的时候方法是否被调用\n        verify(test).testing(Matchers.eq(12));\n\n        // 方法是否被调用两次\n        verify(test, times(2)).getUniqueId();\n\n        // 其他用来验证函数是否被调用的方法\n        verify(mock, never()).someMethod("never called");\n        verify(mock, atLeastOnce()).someMethod("called at least once");\n        verify(mock, atLeast(2)).someMethod("called at least twice");\n        verify(mock, times(5)).someMethod("called five times");\n        verify(mock, atMost(3)).someMethod("called at most 3 times");\n}\n\n\n\n# 使用 Spy 封装 java 对象\n\n@Spy 或者spy()方法可以被用来封装 java 对象。被封装后，除非特殊声明（打桩 stub），否则都会真正的调用对象里面的每一个方法\n\nimport static org.mockito.Mockito.*;\n\n// Lets mock a LinkedList\nList list = new LinkedList();\nList spy = spy(list);\n\n// 可用 doReturn() 来打桩\ndoReturn("foo").when(spy).get(0);\n\n// 下面代码不生效\n// 真正的方法会被调用\n// 将会抛出 IndexOutOfBoundsException 的异常，因为 List 为空\nwhen(spy.get(0)).thenReturn("foo");\n\n\n方法verifyNoMoreInteractions()允许你检查没有其他的方法被调用了。\n\n\n# 使用 @InjectMocks 在 Mockito 中进行依赖注入\n\n我们也可以使用@InjectMocks 注解来创建对象，它会根据类型来注入对象里面的成员方法和变量。假定我们有 ArticleManager 类\n\npublic class ArticleManager {\n    private User user;\n    private ArticleDatabase database;\n\n    ArticleManager(User user) {\n     this.user = user;\n    }\n\n    void setDatabase(ArticleDatabase database) { }\n}\n\n\n这个类会被 Mockito 构造，而类的成员方法和变量都会被 mock 对象所代替，正如下面的代码片段所示：\n\n@RunWith(MockitoJUnitRunner.class)\npublic class ArticleManagerTest  {\n\n       @Mock ArticleCalculator calculator;\n       @Mock ArticleDatabase database;\n       @Most User user;\n\n       @Spy private UserProvider userProvider = new ConsumerUserProvider();\n\n       @InjectMocks private ArticleManager manager; (1)\n\n       @Test public void shouldDoSomething() {\n               // 假定 ArticleManager 有一个叫 initialize() 的方法被调用了\n               // 使用 ArticleListener 来调用 addListener 方法\n               manager.initialize();\n\n               // 验证 addListener 方法被调用\n               verify(database).addListener(any(ArticleListener.class));\n       }\n}\n\n\n 1. 创建 ArticleManager 实例并注入 Mock 对象\n\n更多的详情可以查看 http://docs.mockito.googlecode.com/hg/1.9.5/org/mockito/InjectMocks.html\n\n\n# 捕捉参数\n\nArgumentCaptor类允许我们在 verification 期间访问方法的参数。得到方法的参数后我们可以使用它进行测试。\n\nimport static org.hamcrest.Matchers.hasItem;\nimport static org.junit.Assert.assertThat;\nimport static org.mockito.Mockito.mock;\nimport static org.mockito.Mockito.verify;\n\nimport java.util.Arrays;\nimport java.util.List;\n\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.mockito.ArgumentCaptor;\nimport org.mockito.Captor;\nimport org.mockito.junit.MockitoJUnit;\nimport org.mockito.junit.MockitoRule;\n\npublic class MockitoTests {\n    @Rule\n    public MockitoRule rule = MockitoJUnit.rule();\n\n    @Captor\n    private ArgumentCaptor<List<String>> captor;\n\n    @Test\n    public final void shouldContainCertainListItem() {\n        List<String> asList = Arrays.asList("someElement_test", "someElement");\n        final List<String> mockedList = mock(List.class);\n        mockedList.addAll(asList);\n\n        verify(mockedList).addAll(captor.capture());\n        final List<String> capturedArgument = captor.getValue();\n        assertThat(capturedArgument, hasItem("someElement"));\n    }\n}\n\n\n\n# Mockito 的限制\n\nMockito 当然也有一定的限制。而下面三种数据类型则不能够被测试\n\n * final classes\n * anonymous classes\n * primitive types\n\n\n# 在 Android 中使用 Mockito\n\n在 Android 中的 Gradle 构建文件中加入 Mockito 依赖后就可以直接使用 Mockito 了。若想使用 Android Instrumented tests 的话，还需要添加 dexmaker 和 dexmaker-mockito 依赖到 Gradle 的构建文件中。（需要 Mockito 1.9.5 版本以上）\n\ndependencies {\n    testCompile \'junit:junit:4.12\'\n    // Mockito unit test 的依赖\n    testCompile \'org.mockito:mockito-core:1.+\'\n    // Mockito Android instrumentation tests 的依赖\n    androidTestCompile \'org.mockito:mockito-core:1.+\'\n    androidTestCompile "com.google.dexmaker:dexmaker:1.2"\n    androidTestCompile "com.google.dexmaker:dexmaker-mockito:1.2"\n}\n\n\n\n# 实例：使用 Mockito 写一个 Instrumented Unit Test\n\n\n# 创建一个测试的 Android 应用\n\n创建一个包名为com.vogella.android.testing.mockito.contextmock的 Android 应用，添加一个静态方法 ，方法里面创建一个包含参数的 Intent，如下代码所示：\n\npublic static Intent createQuery(Context context, String query, String value) {\n    // 简单起见，重用MainActivity\n    Intent i = new Intent(context, MainActivity.class);\n    i.putExtra("QUERY", query);\n    i.putExtra("VALUE", value);\n    return i;\n}\n\n\n\n# 在 app/build.gradle 文件中添加 Mockito 依赖\n\ndependencies {\n    // Mockito 和 JUnit 的依赖\n    // instrumentation unit tests on the JVM\n    androidTestCompile \'junit:junit:4.12\'\n    androidTestCompile \'org.mockito:mockito-core:2.0.57-beta\'\n    androidTestCompile \'com.android.support.test:runner:0.3\'\n    androidTestCompile "com.google.dexmaker:dexmaker:1.2"\n    androidTestCompile "com.google.dexmaker:dexmaker-mockito:1.2"\n\n    // Mockito 和 JUnit 的依赖\n    // tests on the JVM\n    testCompile \'junit:junit:4.12\'\n    testCompile \'org.mockito:mockito-core:1.+\'\n\n}\n\n\n\n# 创建测试\n\n使用 Mockito 创建一个单元测试来验证在传递正确 extra data 的情况下，intent 是否被触发。\n\n因此我们需要使用 Mockito 来 mock 一个Context对象，如下代码所示：\n\npackage com.vogella.android.testing.mockitocontextmock;\n\nimport android.content.Context;\nimport android.content.Intent;\nimport android.os.Bundle;\n\nimport org.junit.Test;\nimport org.junit.runner.RunWith;\nimport org.mockito.Mockito;\n\nimport static org.junit.Assert.assertEquals;\nimport static org.junit.Assert.assertNotNull;\n\npublic class TextIntentCreation {\n\n    @Test\n    public void testIntentShouldBeCreated() {\n        Context context = Mockito.mock(Context.class);\n        Intent intent = MainActivity.createQuery(context, "query", "value");\n        assertNotNull(intent);\n        Bundle extras = intent.getExtras();\n        assertNotNull(extras);\n        assertEquals("query", extras.getString("QUERY"));\n        assertEquals("value", extras.getString("VALUE"));\n    }\n}\n\n\n\n# 实例：使用 Mockito 创建一个 mock 对象\n\n\n# 目标\n\n创建一个 Api，它可以被 Mockito 来模拟并做一些工作\n\n\n# 创建一个 Twitter API 的例子\n\n实现 TwitterClient类，它内部使用到了 ITweet 的实现。但是ITweet实例很难得到，譬如说他需要启动一个很复杂的服务来得到。\n\npublic interface ITweet {\n\n        String getMessage();\n}\n\n\npublic class TwitterClient {\n\n        public void sendTweet(ITweet tweet) {\n                String message = tweet.getMessage();\n\n                // send the message to Twitter\n        }\n}\n\n\n\n# 模拟 ITweet 的实例\n\n为了能够不启动复杂的服务来得到 ITweet，我们可以使用 Mockito 来模拟得到该实例。\n\n@Test\npublic void testSendingTweet() {\n        TwitterClient twitterClient = new TwitterClient();\n\n        ITweet iTweet = mock(ITweet.class);\n\n        when(iTweet.getMessage()).thenReturn("Using mockito is great");\n\n        twitterClient.sendTweet(iTweet);\n}\n\n\n现在 TwitterClient 可以使用 ITweet 接口的实现，当调用 getMessage() 方法的时候将会打印 "Using Mockito is great" 信息。\n\n\n# 验证方法调用\n\n确保 getMessage() 方法至少调用一次。\n\n@Test\npublic void testSendingTweet() {\n        TwitterClient twitterClient = new TwitterClient();\n\n        ITweet iTweet = mock(ITweet.class);\n\n        when(iTweet.getMessage()).thenReturn("Using mockito is great");\n\n        twitterClient.sendTweet(iTweet);\n\n        verify(iTweet, atLeastOnce()).getMessage();\n}\n\n\n\n# 验证\n\n运行测试，查看代码是否测试通过。\n\n\n# 模拟静态方法\n\n\n# 使用 Powermock 来模拟静态方法\n\n因为 Mockito 不能够 mock 静态方法，因此我们可以使用 Powermock。\n\nimport java.net.InetAddress;\nimport java.net.UnknownHostException;\n\npublic final class NetworkReader {\n    public static String getLocalHostname() {\n        String hostname = "";\n        try {\n            InetAddress addr = InetAddress.getLocalHost();\n            // Get hostname\n            hostname = addr.getHostName();\n        } catch ( UnknownHostException e ) {\n        }\n        return hostname;\n    }\n}\n\n\n我们模拟了 NetworkReader 的依赖，如下代码所示：\n\nimport org.junit.runner.RunWith;\nimport org.powermock.core.classloader.annotations.PrepareForTest;\n\n@RunWith( PowerMockRunner.class )\n@PrepareForTest( NetworkReader.class )\npublic class MyTest {\n\n// 测试代码\n\n @Test\npublic void testSomething() {\n    mockStatic( NetworkUtil.class );\n    when( NetworkReader.getLocalHostname() ).andReturn( "localhost" );\n\n    // 与 NetworkReader 协作的测试\n}\n\n\n\n# 用封装的方法代替 Powermock\n\n有时候我们可以在静态方法周围包含非静态的方法来达到和 Powermock 同样的效果。\n\nclass FooWraper {\n      void someMethod() {\n           Foo.someStaticMethod()\n       }\n}\n\n\n\n# 引用和引申\n\n * 官网\n * Github\n * 使用强大的 Mockito 测试框架来测试你的代码',normalizedContent:'# mockito 快速入门\n\n> mockito 是一个针对 java 的 mock 框架。\n\n\n# 预备知识\n\n如果需要往下学习，你需要先理解 junit 框架中的单元测试。\n\n如果你不熟悉 junit，请看 junit 教程\n\n\n# 使用 mock 对象来进行测试\n\n\n# 单元测试的目标和挑战\n\n单元测试的思路是在不涉及依赖关系的情况下测试代码（隔离性），所以测试代码与其他类或者系统的关系应该尽量被消除。一个可行的消除方法是替换掉依赖类（测试替换），也就是说我们可以使用替身来替换掉真正的依赖对象。\n\n\n# 测试类的分类\n\n * dummy object 做为参数传递给方法但是绝对不会被使用。譬如说，这种测试类内部的方法不会被调用，或者是用来填充某个方法的参数。\n * fake 是真正接口或抽象类的实现体，但给对象内部实现很简单。譬如说，它存在内存中而不是真正的数据库中。（译者注：fake 实现了真正的逻辑，但它的存在只是为了测试，而不适合于用在产品中。）\n * stub 类是依赖类的部分方法实现，而这些方法在你测试类和接口的时候会被用到，也就是说 stub 类在测试中会被实例化。stub 类会回应任何外部测试的调用。stub 类有时候还会记录调用的一些信息。\n * mock object 是指类或者接口的模拟实现，你可以自定义这个对象中某个方法的输出结果。\n\n测试替代技术能够在测试中模拟测试类以外对象。因此你可以验证测试类是否响应正常。譬如说，你可以验证在 mock 对象的某一个方法是否被调用。这可以确保隔离了外部依赖的干扰只测试测试类。\n\n我们选择 mock 对象的原因是因为 mock 对象只需要少量代码的配置。\n\n\n# mock 对象的产生\n\n你可以手动创建一个 mock 对象或者使用 mock 框架来模拟这些类，mock 框架允许你在运行时创建 mock 对象并且定义它的行为。\n\n一个典型的例子是把 mock 对象模拟成数据的提供者。在正式的生产环境中它会被实现用来连接数据源。但是我们在测试的时候 mock 对象将会模拟成数据提供者来确保我们的测试环境始终是相同的。\n\nmock 对象可以被提供来进行测试。因此，我们测试的类应该避免任何外部数据的强依赖。\n\n通过 mock 对象或者 mock 框架，我们可以测试代码中期望的行为。譬如说，验证只有某个存在 mock 对象的方法是否被调用了。\n\n\n# 使用 mockito 生成 mock 对象\n\nmockito 是一个流行 mock 框架，可以和 junit 结合起来使用。mockito 允许你创建和配置 mock 对象。使用 mockito 可以明显的简化对外部依赖的测试类的开发。\n\n一般使用 mockito 需要执行下面三步\n\n 1. 模拟并替换测试代码中外部依赖\n 2. 执行测试代码\n 3. 验证测试代码是否被正确的执行 0\n\n\n# 为自己的项目添加 mockito 依赖\n\n\n# 在 gradle 添加 mockito 依赖\n\n如果你的项目使用 gradle 构建，将下面代码加入 gradle 的构建文件中为自己项目添加 mockito 依赖\n\nrepositories { jcenter() }\ndependencies { testcompile "org.mockito:mockito-core:2.0.57-beta" }\n\n\n\n# 在 maven 添加 mockito 依赖\n\n需要在 maven 声明依赖，您可以在 http://search.maven.org 网站中搜索 g:"org.mockito", a:"mockito-core" 来得到具体的声明方式。\n\n\n# 在 eclipse ide 使用 mockito\n\neclipse ide 支持 gradle 和 maven 两种构建工具，所以在 eclipse ide 添加依赖取决你使用的是哪一个构建工具。\n\n\n# 以 osgi 或者 eclipse 插件形式添加 mockito 依赖\n\n在 eclipse rcp 应用依赖通常可以在 p2 update 上得到。orbit 是一个很好的第三方仓库，我们可以在里面寻找能在 eclipse 上使用的应用和插件。\n\norbit 仓库地址：http://download.eclipse.org/tools/orbit/downloads\n\n\n# 使用 mockito api\n\n\n# 静态引用\n\n如果在代码中静态引用了org.mockito.mockito.*;，那你你就可以直接调用静态方法和静态变量而不用创建对象，譬如直接调用 mock() 方法。\n\n\n# 使用 mockito 创建和配置 mock 对象\n\n除了上面所说的使用 mock() 静态方法外，mockito 还支持通过 @mock 注解的方式来创建 mock 对象。\n\n如果你使用注解，那么必须要实例化 mock 对象。mockito 在遇到使用注解的字段的时候，会调用mockitoannotations.initmocks(this) 来初始化该 mock 对象。另外也可以通过使用@runwith(mockitojunitrunner.class)来达到相同的效果。\n\n通过下面的例子我们可以了解到使用@mock 的方法和mockitorule规则。\n\nimport static org.mockito.mockito.*;\n\npublic class mockitotest  {\n\n        @mock\n        mydatabase databasemock; (1)\n\n        @rule public mockitorule mockitorule = mockitojunit.rule(); (2)\n\n        @test\n        public void testquery()  {\n                classtotest t  = new classtotest(databasemock); (3)\n                boolean check = t.query("* from t"); (4)\n                asserttrue(check); (5)\n                verify(databasemock).query("* from t"); (6)\n        }\n}\n\n\n 1. 告诉 mockito 模拟 databasemock 实例\n 2. mockito 通过 @mock 注解创建 mock 对象\n 3. 使用已经创建的 mock 初始化这个类\n 4. 在测试环境下，执行测试类中的代码\n 5. 使用断言确保调用的方法返回值为 true\n 6. 验证 query 方法是否被 mydatabase 的 mock 对象调用\n\n\n# 配置 mock\n\n当我们需要配置某个方法的返回值的时候，mockito 提供了链式的 api 供我们方便的调用\n\nwhen(….).thenreturn(….)可以被用来定义当条件满足时函数的返回值，如果你需要定义多个返回值，可以多次定义。当你多次调用函数的时候，mockito 会根据你定义的先后顺序来返回返回值。mocks 还可以根据传入参数的不同来定义不同的返回值。譬如说你的函数可以将anystring 或者 anyint作为输入参数，然后定义其特定的放回值。\n\nimport static org.mockito.mockito.*;\nimport static org.junit.assert.*;\n\n@test\npublic void test1()  {\n        //  创建 mock\n        myclass test = mockito.mock(myclass.class);\n\n        // 自定义 getuniqueid() 的返回值\n        when(test.getuniqueid()).thenreturn(43);\n\n        // 在测试中使用mock对象\n        assertequals(test.getuniqueid(), 43);\n}\n\n// 返回多个值\n@test\npublic void testmorethanonereturnvalue()  {\n        iterator i= mock(iterator.class);\n        when(i.next()).thenreturn("mockito").thenreturn("rocks");\n        string result=i.next()+" "+i.next();\n        // 断言\n        assertequals("mockito rocks", result);\n}\n\n// 如何根据输入来返回值\n@test\npublic void testreturnvaluedependentonmethodparameter()  {\n        comparable c= mock(comparable.class);\n        when(c.compareto("mockito")).thenreturn(1);\n        when(c.compareto("eclipse")).thenreturn(2);\n        // 断言\n        assertequals(1,c.compareto("mockito"));\n}\n\n// 如何让返回值不依赖于输入\n@test\npublic void testreturnvalueindependentonmethodparameter()  {\n        comparable c= mock(comparable.class);\n        when(c.compareto(anyint())).thenreturn(-1);\n        // 断言\n        assertequals(-1 ,c.compareto(9));\n}\n\n// 根据参数类型来返回值\n@test\npublic void testreturnvalueindependentonmethodparameter()  {\n        comparable c= mock(comparable.class);\n        when(c.compareto(isa(todo.class))).thenreturn(0);\n        // 断言\n        todo todo = new todo(5);\n        assertequals(todo ,c.compareto(new todo(1)));\n}\n\n\n对于无返回值的函数，我们可以使用doreturn(…).when(…).methodcall来获得类似的效果。例如我们想在调用某些无返回值函数的时候抛出异常，那么可以使用dothrow 方法。如下面代码片段所示\n\nimport static org.mockito.mockito.*;\nimport static org.junit.assert.*;\n\n// 下面测试用例描述了如何使用dothrow()方法\n\n@test(expected=ioexception.class)\npublic void testforioexception() {\n        // 创建并配置 mock 对象\n        outputstream mockstream = mock(outputstream.class);\n        dothrow(new ioexception()).when(mockstream).close();\n\n        // 使用 mock\n        outputstreamwriter streamwriter= new outputstreamwriter(mockstream);\n        streamwriter.close();\n}\n\n\n\n# 验证 mock 对象方法是否被调用\n\nmockito 会跟踪 mock 对象里面所有的方法和变量。所以我们可以用来验证函数在传入特定参数的时候是否被调用。这种方式的测试称行为测试，行为测试并不会检查函数的返回值，而是检查在传入正确参数时候函数是否被调用。\n\nimport static org.mockito.mockito.*;\n\n@test\npublic void testverify()  {\n        // 创建并配置 mock 对象\n        myclass test = mockito.mock(myclass.class);\n        when(test.getuniqueid()).thenreturn(43);\n\n        // 调用mock对象里面的方法并传入参数为12\n        test.testing(12);\n        test.getuniqueid();\n        test.getuniqueid();\n\n        // 查看在传入参数为12的时候方法是否被调用\n        verify(test).testing(matchers.eq(12));\n\n        // 方法是否被调用两次\n        verify(test, times(2)).getuniqueid();\n\n        // 其他用来验证函数是否被调用的方法\n        verify(mock, never()).somemethod("never called");\n        verify(mock, atleastonce()).somemethod("called at least once");\n        verify(mock, atleast(2)).somemethod("called at least twice");\n        verify(mock, times(5)).somemethod("called five times");\n        verify(mock, atmost(3)).somemethod("called at most 3 times");\n}\n\n\n\n# 使用 spy 封装 java 对象\n\n@spy 或者spy()方法可以被用来封装 java 对象。被封装后，除非特殊声明（打桩 stub），否则都会真正的调用对象里面的每一个方法\n\nimport static org.mockito.mockito.*;\n\n// lets mock a linkedlist\nlist list = new linkedlist();\nlist spy = spy(list);\n\n// 可用 doreturn() 来打桩\ndoreturn("foo").when(spy).get(0);\n\n// 下面代码不生效\n// 真正的方法会被调用\n// 将会抛出 indexoutofboundsexception 的异常，因为 list 为空\nwhen(spy.get(0)).thenreturn("foo");\n\n\n方法verifynomoreinteractions()允许你检查没有其他的方法被调用了。\n\n\n# 使用 @injectmocks 在 mockito 中进行依赖注入\n\n我们也可以使用@injectmocks 注解来创建对象，它会根据类型来注入对象里面的成员方法和变量。假定我们有 articlemanager 类\n\npublic class articlemanager {\n    private user user;\n    private articledatabase database;\n\n    articlemanager(user user) {\n     this.user = user;\n    }\n\n    void setdatabase(articledatabase database) { }\n}\n\n\n这个类会被 mockito 构造，而类的成员方法和变量都会被 mock 对象所代替，正如下面的代码片段所示：\n\n@runwith(mockitojunitrunner.class)\npublic class articlemanagertest  {\n\n       @mock articlecalculator calculator;\n       @mock articledatabase database;\n       @most user user;\n\n       @spy private userprovider userprovider = new consumeruserprovider();\n\n       @injectmocks private articlemanager manager; (1)\n\n       @test public void shoulddosomething() {\n               // 假定 articlemanager 有一个叫 initialize() 的方法被调用了\n               // 使用 articlelistener 来调用 addlistener 方法\n               manager.initialize();\n\n               // 验证 addlistener 方法被调用\n               verify(database).addlistener(any(articlelistener.class));\n       }\n}\n\n\n 1. 创建 articlemanager 实例并注入 mock 对象\n\n更多的详情可以查看 http://docs.mockito.googlecode.com/hg/1.9.5/org/mockito/injectmocks.html\n\n\n# 捕捉参数\n\nargumentcaptor类允许我们在 verification 期间访问方法的参数。得到方法的参数后我们可以使用它进行测试。\n\nimport static org.hamcrest.matchers.hasitem;\nimport static org.junit.assert.assertthat;\nimport static org.mockito.mockito.mock;\nimport static org.mockito.mockito.verify;\n\nimport java.util.arrays;\nimport java.util.list;\n\nimport org.junit.rule;\nimport org.junit.test;\nimport org.mockito.argumentcaptor;\nimport org.mockito.captor;\nimport org.mockito.junit.mockitojunit;\nimport org.mockito.junit.mockitorule;\n\npublic class mockitotests {\n    @rule\n    public mockitorule rule = mockitojunit.rule();\n\n    @captor\n    private argumentcaptor<list<string>> captor;\n\n    @test\n    public final void shouldcontaincertainlistitem() {\n        list<string> aslist = arrays.aslist("someelement_test", "someelement");\n        final list<string> mockedlist = mock(list.class);\n        mockedlist.addall(aslist);\n\n        verify(mockedlist).addall(captor.capture());\n        final list<string> capturedargument = captor.getvalue();\n        assertthat(capturedargument, hasitem("someelement"));\n    }\n}\n\n\n\n# mockito 的限制\n\nmockito 当然也有一定的限制。而下面三种数据类型则不能够被测试\n\n * final classes\n * anonymous classes\n * primitive types\n\n\n# 在 android 中使用 mockito\n\n在 android 中的 gradle 构建文件中加入 mockito 依赖后就可以直接使用 mockito 了。若想使用 android instrumented tests 的话，还需要添加 dexmaker 和 dexmaker-mockito 依赖到 gradle 的构建文件中。（需要 mockito 1.9.5 版本以上）\n\ndependencies {\n    testcompile \'junit:junit:4.12\'\n    // mockito unit test 的依赖\n    testcompile \'org.mockito:mockito-core:1.+\'\n    // mockito android instrumentation tests 的依赖\n    androidtestcompile \'org.mockito:mockito-core:1.+\'\n    androidtestcompile "com.google.dexmaker:dexmaker:1.2"\n    androidtestcompile "com.google.dexmaker:dexmaker-mockito:1.2"\n}\n\n\n\n# 实例：使用 mockito 写一个 instrumented unit test\n\n\n# 创建一个测试的 android 应用\n\n创建一个包名为com.vogella.android.testing.mockito.contextmock的 android 应用，添加一个静态方法 ，方法里面创建一个包含参数的 intent，如下代码所示：\n\npublic static intent createquery(context context, string query, string value) {\n    // 简单起见，重用mainactivity\n    intent i = new intent(context, mainactivity.class);\n    i.putextra("query", query);\n    i.putextra("value", value);\n    return i;\n}\n\n\n\n# 在 app/build.gradle 文件中添加 mockito 依赖\n\ndependencies {\n    // mockito 和 junit 的依赖\n    // instrumentation unit tests on the jvm\n    androidtestcompile \'junit:junit:4.12\'\n    androidtestcompile \'org.mockito:mockito-core:2.0.57-beta\'\n    androidtestcompile \'com.android.support.test:runner:0.3\'\n    androidtestcompile "com.google.dexmaker:dexmaker:1.2"\n    androidtestcompile "com.google.dexmaker:dexmaker-mockito:1.2"\n\n    // mockito 和 junit 的依赖\n    // tests on the jvm\n    testcompile \'junit:junit:4.12\'\n    testcompile \'org.mockito:mockito-core:1.+\'\n\n}\n\n\n\n# 创建测试\n\n使用 mockito 创建一个单元测试来验证在传递正确 extra data 的情况下，intent 是否被触发。\n\n因此我们需要使用 mockito 来 mock 一个context对象，如下代码所示：\n\npackage com.vogella.android.testing.mockitocontextmock;\n\nimport android.content.context;\nimport android.content.intent;\nimport android.os.bundle;\n\nimport org.junit.test;\nimport org.junit.runner.runwith;\nimport org.mockito.mockito;\n\nimport static org.junit.assert.assertequals;\nimport static org.junit.assert.assertnotnull;\n\npublic class textintentcreation {\n\n    @test\n    public void testintentshouldbecreated() {\n        context context = mockito.mock(context.class);\n        intent intent = mainactivity.createquery(context, "query", "value");\n        assertnotnull(intent);\n        bundle extras = intent.getextras();\n        assertnotnull(extras);\n        assertequals("query", extras.getstring("query"));\n        assertequals("value", extras.getstring("value"));\n    }\n}\n\n\n\n# 实例：使用 mockito 创建一个 mock 对象\n\n\n# 目标\n\n创建一个 api，它可以被 mockito 来模拟并做一些工作\n\n\n# 创建一个 twitter api 的例子\n\n实现 twitterclient类，它内部使用到了 itweet 的实现。但是itweet实例很难得到，譬如说他需要启动一个很复杂的服务来得到。\n\npublic interface itweet {\n\n        string getmessage();\n}\n\n\npublic class twitterclient {\n\n        public void sendtweet(itweet tweet) {\n                string message = tweet.getmessage();\n\n                // send the message to twitter\n        }\n}\n\n\n\n# 模拟 itweet 的实例\n\n为了能够不启动复杂的服务来得到 itweet，我们可以使用 mockito 来模拟得到该实例。\n\n@test\npublic void testsendingtweet() {\n        twitterclient twitterclient = new twitterclient();\n\n        itweet itweet = mock(itweet.class);\n\n        when(itweet.getmessage()).thenreturn("using mockito is great");\n\n        twitterclient.sendtweet(itweet);\n}\n\n\n现在 twitterclient 可以使用 itweet 接口的实现，当调用 getmessage() 方法的时候将会打印 "using mockito is great" 信息。\n\n\n# 验证方法调用\n\n确保 getmessage() 方法至少调用一次。\n\n@test\npublic void testsendingtweet() {\n        twitterclient twitterclient = new twitterclient();\n\n        itweet itweet = mock(itweet.class);\n\n        when(itweet.getmessage()).thenreturn("using mockito is great");\n\n        twitterclient.sendtweet(itweet);\n\n        verify(itweet, atleastonce()).getmessage();\n}\n\n\n\n# 验证\n\n运行测试，查看代码是否测试通过。\n\n\n# 模拟静态方法\n\n\n# 使用 powermock 来模拟静态方法\n\n因为 mockito 不能够 mock 静态方法，因此我们可以使用 powermock。\n\nimport java.net.inetaddress;\nimport java.net.unknownhostexception;\n\npublic final class networkreader {\n    public static string getlocalhostname() {\n        string hostname = "";\n        try {\n            inetaddress addr = inetaddress.getlocalhost();\n            // get hostname\n            hostname = addr.gethostname();\n        } catch ( unknownhostexception e ) {\n        }\n        return hostname;\n    }\n}\n\n\n我们模拟了 networkreader 的依赖，如下代码所示：\n\nimport org.junit.runner.runwith;\nimport org.powermock.core.classloader.annotations.preparefortest;\n\n@runwith( powermockrunner.class )\n@preparefortest( networkreader.class )\npublic class mytest {\n\n// 测试代码\n\n @test\npublic void testsomething() {\n    mockstatic( networkutil.class );\n    when( networkreader.getlocalhostname() ).andreturn( "localhost" );\n\n    // 与 networkreader 协作的测试\n}\n\n\n\n# 用封装的方法代替 powermock\n\n有时候我们可以在静态方法周围包含非静态的方法来达到和 powermock 同样的效果。\n\nclass foowraper {\n      void somemethod() {\n           foo.somestaticmethod()\n       }\n}\n\n\n\n# 引用和引申\n\n * 官网\n * github\n * 使用强大的 mockito 测试框架来测试你的代码',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"JMeter 快速入门",frontmatter:{title:"JMeter 快速入门",categories:["编程","Java","工具","测试"],tags:["Java","测试","JMeter"],abbrlink:"808e762c",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/d99171/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/04.%E6%B5%8B%E8%AF%95/03.Jmeter.html",relativePath:"12.工具/04.测试/03.Jmeter.md",key:"v-955934dc",path:"/pages/d99171/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:79},{level:3,title:"特性",slug:"特性",normalizedTitle:"特性",charIndex:119},{level:3,title:"工作流",slug:"工作流",normalizedTitle:"工作流",charIndex:361},{level:3,title:"主要元素",slug:"主要元素",normalizedTitle:"主要元素",charIndex:436},{level:2,title:"安装",slug:"安装",normalizedTitle:"安装",charIndex:1331},{level:3,title:"环境要求",slug:"环境要求",normalizedTitle:"环境要求",charIndex:1338},{level:3,title:"下载",slug:"下载",normalizedTitle:"下载",charIndex:1444},{level:3,title:"启动",slug:"启动",normalizedTitle:"启动",charIndex:1541},{level:2,title:"使用",slug:"使用",normalizedTitle:"使用",charIndex:93},{level:3,title:"创建测试计划",slug:"创建测试计划",normalizedTitle:"创建测试计划",charIndex:1626},{level:4,title:"创建线程组",slug:"创建线程组",normalizedTitle:"创建线程组",charIndex:1713},{level:4,title:"配置原件",slug:"配置原件",normalizedTitle:"配置原件",charIndex:1777},{level:4,title:"构造 HTTP 请求",slug:"构造-http-请求",normalizedTitle:"构造 http 请求",charIndex:1853},{level:4,title:"添加 HTTP 请求头",slug:"添加-http-请求头",normalizedTitle:"添加 http 请求头",charIndex:1985},{level:4,title:"添加断言",slug:"添加断言",normalizedTitle:"添加断言",charIndex:2108},{level:4,title:"添加察看结果树",slug:"添加察看结果树",normalizedTitle:"添加察看结果树",charIndex:2191},{level:4,title:"添加汇总报告",slug:"添加汇总报告",normalizedTitle:"添加汇总报告",charIndex:2259},{level:4,title:"保存测试计划",slug:"保存测试计划",normalizedTitle:"保存测试计划",charIndex:1664},{level:3,title:"执行测试计划",slug:"执行测试计划",normalizedTitle:"执行测试计划",charIndex:2333},{level:2,title:"问题",slug:"问题",normalizedTitle:"问题",charIndex:2607},{level:3,title:"如何读取本地 txt/csv 文件作为请求参数",slug:"如何读取本地-txt-csv-文件作为请求参数",normalizedTitle:"如何读取本地 txt/csv 文件作为请求参数",charIndex:2614},{level:3,title:"如何有序发送数据",slug:"如何有序发送数据",normalizedTitle:"如何有序发送数据",charIndex:2890},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:2931}],headersStr:"简介 特性 工作流 主要元素 安装 环境要求 下载 启动 使用 创建测试计划 创建线程组 配置原件 构造 HTTP 请求 添加 HTTP 请求头 添加断言 添加察看结果树 添加汇总报告 保存测试计划 执行测试计划 问题 如何读取本地 txt/csv 文件作为请求参数 如何有序发送数据 参考资料",content:'# JMeter 快速入门\n\n> Jmeter 是一款基于 Java 开发的功能和性能测试软件。\n> \n> 🎁 本文编辑时的最新版本为：5.1.1\n\n\n# 简介\n\nJmeter 是一款使用 Java 开发的功能和性能测试软件。\n\n\n# 特性\n\nJmeter 能够加载和性能测试许多不同的应用程序/服务器/协议类型：\n\n * 网络 - HTTP，HTTPS(Java，NodeJS，PHP，ASP.NET 等)\n * SOAP / REST Web 服务\n * FTP 文件\n * 通过 JDBC 的数据库\n * LDAP\n * 通过 JMS 的面向消息的中间件(MOM)\n * 邮件-SMTP(S)，POP3(S)和 IMAP(S)\n * 本机命令或 Shell 脚本\n * TCP 协议\n * Java 对象\n\n\n# 工作流\n\nJmeter 的工作原理是仿真用户向服务器发送请求，并收集服务器应答信息并计算统计信息。\n\nJmeter 的工作流如下图所示：\n\n\n\n\n# 主要元素\n\nJmeter 的主要元素如下：\n\n * 测试计划(Test Plan) - 可以将测试计划视为 JMeter 的测试脚本 。测试计划由测试元素组成，例如线程组，逻辑控制器，样本生成控制器，监听器，定时器，断言和配置元素。\n * 线程组(Thread Group) - 线程组的作用是：模拟大量用户负载的运行场景。\n   * 设置线程数\n   * 设置加速期\n   * 设置执行测试的次数\n * 控制器(Controllers) - 可以分为两大类：\n   * 采样器（Sampler） - 采样器的作用是模拟用户对目标服务器发送请求。 采样器是必须将组件添加到测试计划中的，因为它只能让 JMeter 知道需要将哪种类型的请求发送到服务器。 请求可以是 HTTP，HTTP(s)，FTP，TCP，SMTP，SOAP 等。\n   * 逻辑控制器 - 逻辑控制器的作用是：控制多个请求发送的循环次数及顺序等。\n * 监听器(Listeners) - 监听器的作用是：收集测试结果信息。如查看结果树、汇总报告等。\n * 计时器(Timers) - 计时器的作用是：控制多个请求发送的时间频次。\n * 配置元素(Configuration Elements) - 配置元素的工作与采样器的工作类似。但是，它不发送请求，而是提供预备的数据等，如 CSV、函数助手。\n * 预处理器元素(Pre-Processor Elements) - 预处理器元素在采样器发出请求之前执行，如果预处理器附加到采样器元素，那么它将在该采样器元素运行之前执行。预处理器元素用于在运行之前准备环境及参数。\n * 后处理器元素(Post-Processor Elements) - 后处理器元素是在发送采样器请求之后执行的元素，常用于处理响应数据。\n\n\n\n> 📌 提示：\n> \n> Jmeter 元素的数量关系大致如下：\n> \n>  1. 脚本中最多只能有一个测试计划。\n>  2. 测试计划中至少要有一个线程组。\n>  3. 线程组中至少要有一个取样器。\n>  4. 线程组中至少要有一个监听器。\n\n\n# 安装\n\n\n# 环境要求\n\n * 必要的。Jmeter 基于 JDK8 开发，所以必须运行在 JDK8 环境。\n   \n   * JDK8\n\n * 可选的。有些 jar 包不是 Jmeter 提供的，如果需要相应的功能，需要自行下载并置于 lib 目录。\n   \n   * JDBC\n   * JMS\n   * Bouncy Castle\n\n\n# 下载\n\n进入 Jmeter 官网下载地址 选择需要版本进行下载。\n\n\n# 启动\n\n解压 Jmeter 压缩包，进入 bin 目录\n\nUnix 类系统运行 jmeter ；Windows 系统运行 jmeter.bat\n\n\n\n\n# 使用\n\n\n# 创建测试计划\n\n> 🔔 注意：\n> \n>  * 在运行整个测试计划之前，应保存测试计划。\n> \n>  * JMeter 的测试计划以 .jmx 扩展文件的形式保存。\n\n# 创建线程组\n\n * 在“测试计划”上右键 【添加】=>【线程（用户）】=>【线程组】。\n\n * 设置线程数和循环次数\n\n\n\n# 配置原件\n\n * 在新建的线程组上右键 【添加】=>【配置元件】=>【HTTP 请求默认值】。\n\n * 填写协议、服务器名称或 IP、端口号\n\n\n\n# 构造 HTTP 请求\n\n * 在“线程组”上右键 【添加-】=>【取样器】=>【HTTP 请求】。\n\n * 填写协议、服务器名称或 IP、端口号（如果配置了 HTTP 请求默认值可以忽略）\n\n * 填写方法、路径\n\n * 填写参数、消息体数据、文件上传\n\n\n\n# 添加 HTTP 请求头\n\n * 在“线程组”上右键 【添加】=>【配置元件】=>【HTTP 信息头管理器】\n * 由于我的测试例中传输的数据为 json 形式，所以设置键值对 Content-Type：application/json\n\n\n\n# 添加断言\n\n * 在“线程组”上右键 【添加】=>【断言】=>【 响应断言 】\n * 在我的案例中，以 HTTP 应答状态码为 200 来判断请求是否成功\n\n\n\n# 添加察看结果树\n\n * 在“线程组”上右键 【添加】=>【监听器】=>【察看结果树】\n * 直接点击运行，就可以查看测试结果\n\n\n\n# 添加汇总报告\n\n * 在“线程组”上右键 【添加】=>【监听器】=>【汇总报告】\n * 直接点击运行，就可以查看测试结果\n\n\n\n# 保存测试计划\n\n执行测试计划前，GUI 会提示先保存配置为 jmx 文件。\n\n\n# 执行测试计划\n\n官方建议不要直接使用 GUI 来执行测试计划，这种模式指适用于创建测试计划和 debug。\n\n执行测试计划应该使用命令行模式，语法形式如下：\n\njmeter -n -t [jmx file] -l [results file] -e -o [Path to web report folder]\n\n\n执行测试计划后，在 -e -o 参数后指定的 web 报告目录下，可以找到测试报告内容。在浏览器中打开 index.html 文件，可以看到如下报告：\n\n\n\n\n# 问题\n\n\n# 如何读取本地 txt/csv 文件作为请求参数\n\n参考：Jmeter 读取本地 txt/csv 文件作为请求参数，实现接口自动化\n\n（1）依次点击【添加】=>【配置元件】=>【CSV 数据文件设置】\n\n配置如下所示：\n\n\n\n重要配置说明（其他配置根据实际情况填）：\n\n * 文件名：输入需要导入的数据文件位置。\n * 文件编码：设为 UTF-8，避免乱码。\n * 变量名称：使用 , 分隔输入变量列表。如截图中设置了两个变量 a 和 b\n\n（2）在 HTTP 请求的消息体数据中配置参数\n\n[{"a":"${a}","b":"${b}"}]\n\n\n\n# 如何有序发送数据\n\n依次点击【添加】=>【逻辑控制器】=>【事务控制器】\n\n\n# 参考资料\n\n * Jmeter 官网\n * Jmeter Github\n * Jmeter 性能测试入门\n * 易百教程 - Jmeter 教程\n * Jmeter 读取本地 txt/csv 文件作为请求参数，实现接口自动化',normalizedContent:'# jmeter 快速入门\n\n> jmeter 是一款基于 java 开发的功能和性能测试软件。\n> \n> 🎁 本文编辑时的最新版本为：5.1.1\n\n\n# 简介\n\njmeter 是一款使用 java 开发的功能和性能测试软件。\n\n\n# 特性\n\njmeter 能够加载和性能测试许多不同的应用程序/服务器/协议类型：\n\n * 网络 - http，https(java，nodejs，php，asp.net 等)\n * soap / rest web 服务\n * ftp 文件\n * 通过 jdbc 的数据库\n * ldap\n * 通过 jms 的面向消息的中间件(mom)\n * 邮件-smtp(s)，pop3(s)和 imap(s)\n * 本机命令或 shell 脚本\n * tcp 协议\n * java 对象\n\n\n# 工作流\n\njmeter 的工作原理是仿真用户向服务器发送请求，并收集服务器应答信息并计算统计信息。\n\njmeter 的工作流如下图所示：\n\n\n\n\n# 主要元素\n\njmeter 的主要元素如下：\n\n * 测试计划(test plan) - 可以将测试计划视为 jmeter 的测试脚本 。测试计划由测试元素组成，例如线程组，逻辑控制器，样本生成控制器，监听器，定时器，断言和配置元素。\n * 线程组(thread group) - 线程组的作用是：模拟大量用户负载的运行场景。\n   * 设置线程数\n   * 设置加速期\n   * 设置执行测试的次数\n * 控制器(controllers) - 可以分为两大类：\n   * 采样器（sampler） - 采样器的作用是模拟用户对目标服务器发送请求。 采样器是必须将组件添加到测试计划中的，因为它只能让 jmeter 知道需要将哪种类型的请求发送到服务器。 请求可以是 http，http(s)，ftp，tcp，smtp，soap 等。\n   * 逻辑控制器 - 逻辑控制器的作用是：控制多个请求发送的循环次数及顺序等。\n * 监听器(listeners) - 监听器的作用是：收集测试结果信息。如查看结果树、汇总报告等。\n * 计时器(timers) - 计时器的作用是：控制多个请求发送的时间频次。\n * 配置元素(configuration elements) - 配置元素的工作与采样器的工作类似。但是，它不发送请求，而是提供预备的数据等，如 csv、函数助手。\n * 预处理器元素(pre-processor elements) - 预处理器元素在采样器发出请求之前执行，如果预处理器附加到采样器元素，那么它将在该采样器元素运行之前执行。预处理器元素用于在运行之前准备环境及参数。\n * 后处理器元素(post-processor elements) - 后处理器元素是在发送采样器请求之后执行的元素，常用于处理响应数据。\n\n\n\n> 📌 提示：\n> \n> jmeter 元素的数量关系大致如下：\n> \n>  1. 脚本中最多只能有一个测试计划。\n>  2. 测试计划中至少要有一个线程组。\n>  3. 线程组中至少要有一个取样器。\n>  4. 线程组中至少要有一个监听器。\n\n\n# 安装\n\n\n# 环境要求\n\n * 必要的。jmeter 基于 jdk8 开发，所以必须运行在 jdk8 环境。\n   \n   * jdk8\n\n * 可选的。有些 jar 包不是 jmeter 提供的，如果需要相应的功能，需要自行下载并置于 lib 目录。\n   \n   * jdbc\n   * jms\n   * bouncy castle\n\n\n# 下载\n\n进入 jmeter 官网下载地址 选择需要版本进行下载。\n\n\n# 启动\n\n解压 jmeter 压缩包，进入 bin 目录\n\nunix 类系统运行 jmeter ；windows 系统运行 jmeter.bat\n\n\n\n\n# 使用\n\n\n# 创建测试计划\n\n> 🔔 注意：\n> \n>  * 在运行整个测试计划之前，应保存测试计划。\n> \n>  * jmeter 的测试计划以 .jmx 扩展文件的形式保存。\n\n# 创建线程组\n\n * 在“测试计划”上右键 【添加】=>【线程（用户）】=>【线程组】。\n\n * 设置线程数和循环次数\n\n\n\n# 配置原件\n\n * 在新建的线程组上右键 【添加】=>【配置元件】=>【http 请求默认值】。\n\n * 填写协议、服务器名称或 ip、端口号\n\n\n\n# 构造 http 请求\n\n * 在“线程组”上右键 【添加-】=>【取样器】=>【http 请求】。\n\n * 填写协议、服务器名称或 ip、端口号（如果配置了 http 请求默认值可以忽略）\n\n * 填写方法、路径\n\n * 填写参数、消息体数据、文件上传\n\n\n\n# 添加 http 请求头\n\n * 在“线程组”上右键 【添加】=>【配置元件】=>【http 信息头管理器】\n * 由于我的测试例中传输的数据为 json 形式，所以设置键值对 content-type：application/json\n\n\n\n# 添加断言\n\n * 在“线程组”上右键 【添加】=>【断言】=>【 响应断言 】\n * 在我的案例中，以 http 应答状态码为 200 来判断请求是否成功\n\n\n\n# 添加察看结果树\n\n * 在“线程组”上右键 【添加】=>【监听器】=>【察看结果树】\n * 直接点击运行，就可以查看测试结果\n\n\n\n# 添加汇总报告\n\n * 在“线程组”上右键 【添加】=>【监听器】=>【汇总报告】\n * 直接点击运行，就可以查看测试结果\n\n\n\n# 保存测试计划\n\n执行测试计划前，gui 会提示先保存配置为 jmx 文件。\n\n\n# 执行测试计划\n\n官方建议不要直接使用 gui 来执行测试计划，这种模式指适用于创建测试计划和 debug。\n\n执行测试计划应该使用命令行模式，语法形式如下：\n\njmeter -n -t [jmx file] -l [results file] -e -o [path to web report folder]\n\n\n执行测试计划后，在 -e -o 参数后指定的 web 报告目录下，可以找到测试报告内容。在浏览器中打开 index.html 文件，可以看到如下报告：\n\n\n\n\n# 问题\n\n\n# 如何读取本地 txt/csv 文件作为请求参数\n\n参考：jmeter 读取本地 txt/csv 文件作为请求参数，实现接口自动化\n\n（1）依次点击【添加】=>【配置元件】=>【csv 数据文件设置】\n\n配置如下所示：\n\n\n\n重要配置说明（其他配置根据实际情况填）：\n\n * 文件名：输入需要导入的数据文件位置。\n * 文件编码：设为 utf-8，避免乱码。\n * 变量名称：使用 , 分隔输入变量列表。如截图中设置了两个变量 a 和 b\n\n（2）在 http 请求的消息体数据中配置参数\n\n[{"a":"${a}","b":"${b}"}]\n\n\n\n# 如何有序发送数据\n\n依次点击【添加】=>【逻辑控制器】=>【事务控制器】\n\n\n# 参考资料\n\n * jmeter 官网\n * jmeter github\n * jmeter 性能测试入门\n * 易百教程 - jmeter 教程\n * jmeter 读取本地 txt/csv 文件作为请求参数，实现接口自动化',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"JMH 快速入门",frontmatter:{title:"JMH 快速入门",categories:["编程","Java","工具","测试"],tags:["Java","测试","JUnit"],abbrlink:"293b6b64",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/747d3e/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/04.%E6%B5%8B%E8%AF%95/04.JMH.html",relativePath:"12.工具/04.测试/04.JMH.md",key:"v-63d503f0",path:"/pages/747d3e/",headers:[{level:2,title:"基准测试简介",slug:"基准测试简介",normalizedTitle:"基准测试简介",charIndex:15},{level:3,title:"什么是基准测试",slug:"什么是基准测试",normalizedTitle:"什么是基准测试",charIndex:26},{level:3,title:"何时需要微基准测试",slug:"何时需要微基准测试",normalizedTitle:"何时需要微基准测试",charIndex:351},{level:2,title:"JMH 简介",slug:"jmh-简介",normalizedTitle:"jmh 简介",charIndex:466},{level:3,title:"为什么需要 JMH",slug:"为什么需要-jmh",normalizedTitle:"为什么需要 jmh",charIndex:699},{level:4,title:"死码消除",slug:"死码消除",normalizedTitle:"死码消除",charIndex:712},{level:4,title:"常量折叠与常量传播",slug:"常量折叠与常量传播",normalizedTitle:"常量折叠与常量传播",charIndex:757},{level:3,title:"JMH 的注意点",slug:"jmh-的注意点",normalizedTitle:"jmh 的注意点",charIndex:888},{level:3,title:"应用场景",slug:"应用场景",normalizedTitle:"应用场景",charIndex:952},{level:3,title:"JMH 概念",slug:"jmh-概念",normalizedTitle:"jmh 概念",charIndex:1126},{level:2,title:"JMH 快速入门",slug:"jmh-快速入门-2",normalizedTitle:"jmh 快速入门",charIndex:2},{level:3,title:"添加 maven 依赖",slug:"添加-maven-依赖",normalizedTitle:"添加 maven 依赖",charIndex:1452},{level:3,title:"测试代码",slug:"测试代码",normalizedTitle:"测试代码",charIndex:1798},{level:3,title:"执行 JMH",slug:"执行-jmh",normalizedTitle:"执行 jmh",charIndex:2846},{level:4,title:"命令行",slug:"命令行",normalizedTitle:"命令行",charIndex:2856},{level:4,title:"执行 main 方法",slug:"执行-main-方法",normalizedTitle:"执行 main 方法",charIndex:3246},{level:2,title:"JMH API",slug:"jmh-api",normalizedTitle:"jmh api",charIndex:7822},{level:3,title:"@BenchmarkMode",slug:"benchmarkmode",normalizedTitle:"@benchmarkmode",charIndex:1915},{level:3,title:"@Warmup",slug:"warmup",normalizedTitle:"@warmup",charIndex:1947},{level:3,title:"@Measurement",slug:"measurement",normalizedTitle:"@measurement",charIndex:1971},{level:3,title:"@Threads",slug:"threads",normalizedTitle:"@threads",charIndex:2040},{level:3,title:"@Fork",slug:"fork",normalizedTitle:"@fork",charIndex:2052},{level:3,title:"@OutputTimeUnit",slug:"outputtimeunit",normalizedTitle:"@outputtimeunit",charIndex:2061},{level:3,title:"@Benchmark",slug:"benchmark",normalizedTitle:"@benchmark",charIndex:1915},{level:3,title:"@Param",slug:"param",normalizedTitle:"@param",charIndex:8843},{level:3,title:"@Setup",slug:"setup",normalizedTitle:"@setup",charIndex:8913},{level:3,title:"@TearDown",slug:"teardown",normalizedTitle:"@teardown",charIndex:8974},{level:3,title:"@State",slug:"state",normalizedTitle:"@state",charIndex:9050},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:9352}],headersStr:"基准测试简介 什么是基准测试 何时需要微基准测试 JMH 简介 为什么需要 JMH 死码消除 常量折叠与常量传播 JMH 的注意点 应用场景 JMH 概念 JMH 快速入门 添加 maven 依赖 测试代码 执行 JMH 命令行 执行 main 方法 JMH API @BenchmarkMode @Warmup @Measurement @Threads @Fork @OutputTimeUnit @Benchmark @Param @Setup @TearDown @State 参考资料",content:'# JMH 快速入门\n\n\n# 基准测试简介\n\n\n# 什么是基准测试\n\n基准测试是指通过设计科学的测试方法、测试工具和测试系统，实现对一类测试对象的某项性能指标进行定量的和可对比的测试。\n\n现代软件常常都把高性能作为目标。那么，何为高性能，性能就是快，更快吗？显然，如果没有一个量化的标准，难以衡量性能的好坏。\n\n不同的基准测试其具体内容和范围也存在很大的不同。如果是专业的性能工程师，更加熟悉的可能是类似 SPEC 提供的工业标准的系统级测试；而对于大多数 Java 开发者，更熟悉的则是范围相对较小、关注点更加细节的微基准测试（Micro-Benchmark）。何谓 Micro Benchmark 呢？ 简单地说就是在 method 层面上的 benchmark，精度可以精确到 微秒级。\n\n\n# 何时需要微基准测试\n\n微基准测试大多是 API 级别的性能测试。\n\n微基准测试的适用场景：\n\n * 如果开发公共类库、中间件，会被其他模块经常调用的 API。\n * 对于性能，如响应延迟、吞吐量有严格要求的核心 API。\n\n\n# JMH 简介\n\nJMH(即 Java Microbenchmark Harness)，是目前主流的微基准测试框架。JMH 是由 Hotspot JVM 团队专家开发的，除了支持完整的基准测试过程，包括预热、运行、统计和报告等，还支持 Java 和其他 JVM 语言。更重要的是，它针对 Hotspot JVM 提供了各种特性，以保证基准测试的正确性，整体准确性大大优于其他框架，并且，JMH 还提供了用近乎白盒的方式进行 Profiling 等工作的能力。\n\n\n# 为什么需要 JMH\n\n# 死码消除\n\n所谓死码，是指注释的代码，不可达的代码块，可达但不被使用的代码等等 。\n\n# 常量折叠与常量传播\n\n常量折叠 (Constant folding) 是一个在编译时期简化常数的一个过程，常数在表示式中仅仅代表一个简单的数值，就像是整数 2，若是一个变数从未被修改也可作为常数，或者直接将一个变数被明确地被标注为常数，例如下面的描述：\n\n\n# JMH 的注意点\n\n * 测试前需要预热。\n * 防止无用代码进入测试方法中。\n * 并发测试。\n * 测试结果呈现。\n\n\n# 应用场景\n\n 1. 当你已经找出了热点函数，而需要对热点函数进行进一步的优化时，就可以使用 JMH 对优化的效果进行定量的分析。\n 2. 想定量地知道某个函数需要执行多长时间，以及执行时间和输入 n 的相关性\n 3. 一个函数有两种不同实现（例如 JSON 序列化/反序列化有 Jackson 和 Gson 实现），不知道哪种实现性能更好\n\n\n# JMH 概念\n\n * Iteration - iteration 是 JMH 进行测试的最小单位，包含一组 invocations。\n * Invocation - 一次 benchmark 方法调用。\n * Operation - benchmark 方法中，被测量操作的执行。如果被测试的操作在 benchmark 方法中循环执行，可以使用@OperationsPerInvocation表明循环次数，使测试结果为单次 operation 的性能。\n * Warmup - 在实际进行 benchmark 前先进行预热。因为某个函数被调用多次之后，JIT 会对其进行编译，通过预热可以使测量结果更加接近真实情况。\n\n\n# JMH 快速入门\n\n\n# 添加 maven 依赖\n\n<dependency>\n    <groupId>org.openjdk.jmh</groupId>\n    <artifactId>jmh-core</artifactId>\n    <version>${jmh.version}</version>\n</dependency>\n<dependency>\n    <groupId>org.openjdk.jmh</groupId>\n    <artifactId>jmh-generator-annprocess</artifactId>\n    <version>${jmh.version}</version>\n    <scope>provided</scope>\n</dependency>\n\n\n\n# 测试代码\n\nimport org.openjdk.jmh.annotations.*;\nimport org.openjdk.jmh.runner.*;\n\nimport java.util.concurrent.TimeUnit;\n\n@BenchmarkMode(Mode.Throughput)\n@Warmup(iterations = 3)\n@Measurement(iterations = 10, time = 5, timeUnit = TimeUnit.SECONDS)\n@Threads(8)\n@Fork(2)\n@OutputTimeUnit(TimeUnit.MILLISECONDS)\npublic class StringBuilderBenchmark {\n\n    @Benchmark\n    public void testStringAdd() {\n        String a = "";\n        for (int i = 0; i < 10; i++) {\n            a += i;\n        }\n        // System.out.println(a);\n    }\n\n    @Benchmark\n    public void testStringBuilderAdd() {\n        StringBuilder sb = new StringBuilder();\n        for (int i = 0; i < 10; i++) {\n            sb.append(i);\n        }\n        // System.out.println(sb.toString());\n    }\n\n    public static void main(String[] args) throws RunnerException {\n        Options options = new OptionsBuilder()\n            .include(StringBuilderBenchmark.class.getSimpleName())\n            .output("d:/Benchmark.log")\n            .build();\n        new Runner(options).run();\n    }\n\n}\n\n\n\n# 执行 JMH\n\n# 命令行\n\n（1）初始化 benchmarking 工程\n\n$ mvn archetype:generate \\\n          -DinteractiveMode=false \\\n          -DarchetypeGroupId=org.openjdk.jmh \\\n          -DarchetypeArtifactId=jmh-java-benchmark-archetype \\\n          -DgroupId=org.sample \\\n          -DartifactId=test \\\n          -Dversion=1.0\n\n\n（2）构建 benchmark\n\ncd test/\nmvn clean install\n\n\n（3）运行 benchmark\n\njava -jar target/benchmarks.jar\n\n\n# 执行 main 方法\n\n执行 main 方法，耐心等待测试结果，最终会生成一个测试报告，内容大致如下；\n\n# JMH version: 1.22\n# VM version: JDK 1.8.0_181, Java HotSpot(TM) 64-Bit Server VM, 25.181-b13\n# VM invoker: C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\bin\\java.exe\n# VM options: -javaagent:D:\\Program Files\\JetBrains\\IntelliJ IDEA 2019.2.3\\lib\\idea_rt.jar=58635:D:\\Program Files\\JetBrains\\IntelliJ IDEA 2019.2.3\\bin -Dfile.encoding=UTF-8\n# Warmup: 3 iterations, 10 s each\n# Measurement: 10 iterations, 5 s each\n# Timeout: 10 min per iteration\n# Threads: 8 threads, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: io.github.dunwu.javatech.jmh.StringBuilderBenchmark.testStringAdd\n\n# Run progress: 0.00% complete, ETA 00:05:20\n# Fork: 1 of 2\n# Warmup Iteration   1: 21803.050 ops/ms\n# Warmup Iteration   2: 22501.860 ops/ms\n# Warmup Iteration   3: 20953.944 ops/ms\nIteration   1: 21627.645 ops/ms\nIteration   2: 21215.269 ops/ms\nIteration   3: 20863.282 ops/ms\nIteration   4: 21617.715 ops/ms\nIteration   5: 21695.645 ops/ms\nIteration   6: 21886.784 ops/ms\nIteration   7: 21986.899 ops/ms\nIteration   8: 22389.540 ops/ms\nIteration   9: 22507.313 ops/ms\nIteration  10: 22124.133 ops/ms\n\n# Run progress: 25.00% complete, ETA 00:04:02\n# Fork: 2 of 2\n# Warmup Iteration   1: 22262.108 ops/ms\n# Warmup Iteration   2: 21567.804 ops/ms\n# Warmup Iteration   3: 21787.002 ops/ms\nIteration   1: 21598.970 ops/ms\nIteration   2: 22486.133 ops/ms\nIteration   3: 22157.834 ops/ms\nIteration   4: 22321.827 ops/ms\nIteration   5: 22477.063 ops/ms\nIteration   6: 22154.760 ops/ms\nIteration   7: 21561.095 ops/ms\nIteration   8: 22194.863 ops/ms\nIteration   9: 22493.844 ops/ms\nIteration  10: 22568.078 ops/ms\n\n\nResult "io.github.dunwu.javatech.jmh.StringBuilderBenchmark.testStringAdd":\n  21996.435 ±(99.9%) 412.955 ops/ms [Average]\n  (min, avg, max) = (20863.282, 21996.435, 22568.078), stdev = 475.560\n  CI (99.9%): [21583.480, 22409.390] (assumes normal distribution)\n\n\n# JMH version: 1.22\n# VM version: JDK 1.8.0_181, Java HotSpot(TM) 64-Bit Server VM, 25.181-b13\n# VM invoker: C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\bin\\java.exe\n# VM options: -javaagent:D:\\Program Files\\JetBrains\\IntelliJ IDEA 2019.2.3\\lib\\idea_rt.jar=58635:D:\\Program Files\\JetBrains\\IntelliJ IDEA 2019.2.3\\bin -Dfile.encoding=UTF-8\n# Warmup: 3 iterations, 10 s each\n# Measurement: 10 iterations, 5 s each\n# Timeout: 10 min per iteration\n# Threads: 8 threads, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: io.github.dunwu.javatech.jmh.StringBuilderBenchmark.testStringBuilderAdd\n\n# Run progress: 50.00% complete, ETA 00:02:41\n# Fork: 1 of 2\n# Warmup Iteration   1: 241500.886 ops/ms\n# Warmup Iteration   2: 134206.032 ops/ms\n# Warmup Iteration   3: 86907.846 ops/ms\nIteration   1: 86143.339 ops/ms\nIteration   2: 74725.356 ops/ms\nIteration   3: 72316.121 ops/ms\nIteration   4: 77319.716 ops/ms\nIteration   5: 83469.256 ops/ms\nIteration   6: 87712.360 ops/ms\nIteration   7: 79421.899 ops/ms\nIteration   8: 80867.839 ops/ms\nIteration   9: 82619.163 ops/ms\nIteration  10: 87026.928 ops/ms\n\n# Run progress: 75.00% complete, ETA 00:01:20\n# Fork: 2 of 2\n# Warmup Iteration   1: 228342.337 ops/ms\n# Warmup Iteration   2: 124737.248 ops/ms\n# Warmup Iteration   3: 82598.851 ops/ms\nIteration   1: 86877.318 ops/ms\nIteration   2: 89388.624 ops/ms\nIteration   3: 88523.558 ops/ms\nIteration   4: 87547.332 ops/ms\nIteration   5: 88376.087 ops/ms\nIteration   6: 88848.837 ops/ms\nIteration   7: 85998.124 ops/ms\nIteration   8: 86796.998 ops/ms\nIteration   9: 87994.726 ops/ms\nIteration  10: 87784.453 ops/ms\n\n\nResult "io.github.dunwu.javatech.jmh.StringBuilderBenchmark.testStringBuilderAdd":\n  84487.902 ±(99.9%) 4355.525 ops/ms [Average]\n  (min, avg, max) = (72316.121, 84487.902, 89388.624), stdev = 5015.829\n  CI (99.9%): [80132.377, 88843.427] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:05:23\n\nREMEMBER: The numbers below are just data. To gain reusable insights, you need to follow up on\nwhy the numbers are the way they are. Use profilers (see -prof, -lprof), design factorial\nexperiments, perform baseline and negative tests that provide experimental control, make sure\nthe benchmarking environment is safe on JVM/OS/HW level, ask for reviews from the domain experts.\nDo not assume the numbers tell you what you want them to tell.\n\nBenchmark                                     Mode  Cnt      Score      Error   Units\nStringBuilderBenchmark.testStringAdd         thrpt   20  21996.435 ±  412.955  ops/ms\nStringBuilderBenchmark.testStringBuilderAdd  thrpt   20  84487.902 ± 4355.525  ops/ms\n\n\n\n# JMH API\n\n下面来了解一下 jmh 常用 API\n\n\n# @BenchmarkMode\n\n基准测试类型。这里选择的是 Throughput 也就是吞吐量。根据源码点进去，每种类型后面都有对应的解释，比较好理解，吞吐量会得到单位时间内可以进行的操作数。\n\n * Throughput - 整体吞吐量，例如“1 秒内可以执行多少次调用”。\n * AverageTime - 调用的平均时间，例如“每次调用平均耗时 xxx 毫秒”。\n * SampleTime - 随机取样，最后输出取样结果的分布，例如“99%的调用在 xxx 毫秒以内，99.99%的调用在 xxx 毫秒以内”\n * SingleShotTime - 以上模式都是默认一次 iteration 是 1s，唯有 SingleShotTime 是只运行一次。往往同时把 warmup 次数设为 0，用于测试冷启动时的性能。\n * All - 所有模式\n\n\n# @Warmup\n\n上面我们提到了，进行基准测试前需要进行预热。一般我们前几次进行程序测试的时候都会比较慢， 所以要让程序进行几轮预热，保证测试的准确性。其中的参数 iterations 也就非常好理解了，就是预热轮数。\n\n为什么需要预热？因为 JVM 的 JIT 机制的存在，如果某个函数被调用多次之后，JVM 会尝试将其编译成为机器码从而提高执行速度。所以为了让 benchmark 的结果更加接近真实情况就需要进行预热。\n\n\n# @Measurement\n\n度量，其实就是一些基本的测试参数。\n\n * iterations - 进行测试的轮次\n * time - 每轮进行的时长\n * timeUnit - 时长单位\n\n都是一些基本的参数，可以根据具体情况调整。一般比较重的东西可以进行大量的测试，放到服务器上运行。\n\n\n# @Threads\n\n每个进程中的测试线程，这个非常好理解，根据具体情况选择，一般为 cpu 乘以 2。\n\n\n# @Fork\n\n进行 fork 的次数。如果 fork 数是 2 的话，则 JMH 会 fork 出两个进程来进行测试。\n\n\n# @OutputTimeUnit\n\n这个比较简单了，基准测试结果的时间类型。一般选择秒、毫秒、微秒。\n\n\n# @Benchmark\n\n方法级注解，表示该方法是需要进行 benchmark 的对象，用法和 JUnit 的 @Test 类似。\n\n\n# @Param\n\n属性级注解，@Param 可以用来指定某项参数的多种情况。特别适合用来测试一个函数在不同的参数输入的情况下的性能。\n\n\n# @Setup\n\n方法级注解，这个注解的作用就是我们需要在测试之前进行一些准备工作，比如对一些数据的初始化之类的。\n\n\n# @TearDown\n\n方法级注解，这个注解的作用就是我们需要在测试之后进行一些结束工作，比如关闭线程池，数据库连接等的，主要用于资源的回收等。\n\n\n# @State\n\n当使用 @Setup 参数的时候，必须在类上加这个参数，不然会提示无法运行。\n\nState 用于声明某个类是一个“状态”，然后接受一个 Scope 参数用来表示该状态的共享范围。 因为很多 benchmark 会需要一些表示状态的类，JMH 允许你把这些类以依赖注入的方式注入到 benchmark 函数里。Scope 主要分为三种。\n\n * Thread - 该状态为每个线程独享。\n * Group - 该状态为同一个组里面所有线程共享。\n * Benchmark - 该状态在所有线程间共享。\n\n关于 State 的用法，官方的 code sample 里有比较好的例子。\n\n\n# 参考资料\n\n * jmh 官方示例\n * Java 微基准测试框架 JMH\n * JAVA 拾遗 — JMH 与 8 个测试陷阱',normalizedContent:'# jmh 快速入门\n\n\n# 基准测试简介\n\n\n# 什么是基准测试\n\n基准测试是指通过设计科学的测试方法、测试工具和测试系统，实现对一类测试对象的某项性能指标进行定量的和可对比的测试。\n\n现代软件常常都把高性能作为目标。那么，何为高性能，性能就是快，更快吗？显然，如果没有一个量化的标准，难以衡量性能的好坏。\n\n不同的基准测试其具体内容和范围也存在很大的不同。如果是专业的性能工程师，更加熟悉的可能是类似 spec 提供的工业标准的系统级测试；而对于大多数 java 开发者，更熟悉的则是范围相对较小、关注点更加细节的微基准测试（micro-benchmark）。何谓 micro benchmark 呢？ 简单地说就是在 method 层面上的 benchmark，精度可以精确到 微秒级。\n\n\n# 何时需要微基准测试\n\n微基准测试大多是 api 级别的性能测试。\n\n微基准测试的适用场景：\n\n * 如果开发公共类库、中间件，会被其他模块经常调用的 api。\n * 对于性能，如响应延迟、吞吐量有严格要求的核心 api。\n\n\n# jmh 简介\n\njmh(即 java microbenchmark harness)，是目前主流的微基准测试框架。jmh 是由 hotspot jvm 团队专家开发的，除了支持完整的基准测试过程，包括预热、运行、统计和报告等，还支持 java 和其他 jvm 语言。更重要的是，它针对 hotspot jvm 提供了各种特性，以保证基准测试的正确性，整体准确性大大优于其他框架，并且，jmh 还提供了用近乎白盒的方式进行 profiling 等工作的能力。\n\n\n# 为什么需要 jmh\n\n# 死码消除\n\n所谓死码，是指注释的代码，不可达的代码块，可达但不被使用的代码等等 。\n\n# 常量折叠与常量传播\n\n常量折叠 (constant folding) 是一个在编译时期简化常数的一个过程，常数在表示式中仅仅代表一个简单的数值，就像是整数 2，若是一个变数从未被修改也可作为常数，或者直接将一个变数被明确地被标注为常数，例如下面的描述：\n\n\n# jmh 的注意点\n\n * 测试前需要预热。\n * 防止无用代码进入测试方法中。\n * 并发测试。\n * 测试结果呈现。\n\n\n# 应用场景\n\n 1. 当你已经找出了热点函数，而需要对热点函数进行进一步的优化时，就可以使用 jmh 对优化的效果进行定量的分析。\n 2. 想定量地知道某个函数需要执行多长时间，以及执行时间和输入 n 的相关性\n 3. 一个函数有两种不同实现（例如 json 序列化/反序列化有 jackson 和 gson 实现），不知道哪种实现性能更好\n\n\n# jmh 概念\n\n * iteration - iteration 是 jmh 进行测试的最小单位，包含一组 invocations。\n * invocation - 一次 benchmark 方法调用。\n * operation - benchmark 方法中，被测量操作的执行。如果被测试的操作在 benchmark 方法中循环执行，可以使用@operationsperinvocation表明循环次数，使测试结果为单次 operation 的性能。\n * warmup - 在实际进行 benchmark 前先进行预热。因为某个函数被调用多次之后，jit 会对其进行编译，通过预热可以使测量结果更加接近真实情况。\n\n\n# jmh 快速入门\n\n\n# 添加 maven 依赖\n\n<dependency>\n    <groupid>org.openjdk.jmh</groupid>\n    <artifactid>jmh-core</artifactid>\n    <version>${jmh.version}</version>\n</dependency>\n<dependency>\n    <groupid>org.openjdk.jmh</groupid>\n    <artifactid>jmh-generator-annprocess</artifactid>\n    <version>${jmh.version}</version>\n    <scope>provided</scope>\n</dependency>\n\n\n\n# 测试代码\n\nimport org.openjdk.jmh.annotations.*;\nimport org.openjdk.jmh.runner.*;\n\nimport java.util.concurrent.timeunit;\n\n@benchmarkmode(mode.throughput)\n@warmup(iterations = 3)\n@measurement(iterations = 10, time = 5, timeunit = timeunit.seconds)\n@threads(8)\n@fork(2)\n@outputtimeunit(timeunit.milliseconds)\npublic class stringbuilderbenchmark {\n\n    @benchmark\n    public void teststringadd() {\n        string a = "";\n        for (int i = 0; i < 10; i++) {\n            a += i;\n        }\n        // system.out.println(a);\n    }\n\n    @benchmark\n    public void teststringbuilderadd() {\n        stringbuilder sb = new stringbuilder();\n        for (int i = 0; i < 10; i++) {\n            sb.append(i);\n        }\n        // system.out.println(sb.tostring());\n    }\n\n    public static void main(string[] args) throws runnerexception {\n        options options = new optionsbuilder()\n            .include(stringbuilderbenchmark.class.getsimplename())\n            .output("d:/benchmark.log")\n            .build();\n        new runner(options).run();\n    }\n\n}\n\n\n\n# 执行 jmh\n\n# 命令行\n\n（1）初始化 benchmarking 工程\n\n$ mvn archetype:generate \\\n          -dinteractivemode=false \\\n          -darchetypegroupid=org.openjdk.jmh \\\n          -darchetypeartifactid=jmh-java-benchmark-archetype \\\n          -dgroupid=org.sample \\\n          -dartifactid=test \\\n          -dversion=1.0\n\n\n（2）构建 benchmark\n\ncd test/\nmvn clean install\n\n\n（3）运行 benchmark\n\njava -jar target/benchmarks.jar\n\n\n# 执行 main 方法\n\n执行 main 方法，耐心等待测试结果，最终会生成一个测试报告，内容大致如下；\n\n# jmh version: 1.22\n# vm version: jdk 1.8.0_181, java hotspot(tm) 64-bit server vm, 25.181-b13\n# vm invoker: c:\\program files\\java\\jdk1.8.0_181\\jre\\bin\\java.exe\n# vm options: -javaagent:d:\\program files\\jetbrains\\intellij idea 2019.2.3\\lib\\idea_rt.jar=58635:d:\\program files\\jetbrains\\intellij idea 2019.2.3\\bin -dfile.encoding=utf-8\n# warmup: 3 iterations, 10 s each\n# measurement: 10 iterations, 5 s each\n# timeout: 10 min per iteration\n# threads: 8 threads, will synchronize iterations\n# benchmark mode: throughput, ops/time\n# benchmark: io.github.dunwu.javatech.jmh.stringbuilderbenchmark.teststringadd\n\n# run progress: 0.00% complete, eta 00:05:20\n# fork: 1 of 2\n# warmup iteration   1: 21803.050 ops/ms\n# warmup iteration   2: 22501.860 ops/ms\n# warmup iteration   3: 20953.944 ops/ms\niteration   1: 21627.645 ops/ms\niteration   2: 21215.269 ops/ms\niteration   3: 20863.282 ops/ms\niteration   4: 21617.715 ops/ms\niteration   5: 21695.645 ops/ms\niteration   6: 21886.784 ops/ms\niteration   7: 21986.899 ops/ms\niteration   8: 22389.540 ops/ms\niteration   9: 22507.313 ops/ms\niteration  10: 22124.133 ops/ms\n\n# run progress: 25.00% complete, eta 00:04:02\n# fork: 2 of 2\n# warmup iteration   1: 22262.108 ops/ms\n# warmup iteration   2: 21567.804 ops/ms\n# warmup iteration   3: 21787.002 ops/ms\niteration   1: 21598.970 ops/ms\niteration   2: 22486.133 ops/ms\niteration   3: 22157.834 ops/ms\niteration   4: 22321.827 ops/ms\niteration   5: 22477.063 ops/ms\niteration   6: 22154.760 ops/ms\niteration   7: 21561.095 ops/ms\niteration   8: 22194.863 ops/ms\niteration   9: 22493.844 ops/ms\niteration  10: 22568.078 ops/ms\n\n\nresult "io.github.dunwu.javatech.jmh.stringbuilderbenchmark.teststringadd":\n  21996.435 ±(99.9%) 412.955 ops/ms [average]\n  (min, avg, max) = (20863.282, 21996.435, 22568.078), stdev = 475.560\n  ci (99.9%): [21583.480, 22409.390] (assumes normal distribution)\n\n\n# jmh version: 1.22\n# vm version: jdk 1.8.0_181, java hotspot(tm) 64-bit server vm, 25.181-b13\n# vm invoker: c:\\program files\\java\\jdk1.8.0_181\\jre\\bin\\java.exe\n# vm options: -javaagent:d:\\program files\\jetbrains\\intellij idea 2019.2.3\\lib\\idea_rt.jar=58635:d:\\program files\\jetbrains\\intellij idea 2019.2.3\\bin -dfile.encoding=utf-8\n# warmup: 3 iterations, 10 s each\n# measurement: 10 iterations, 5 s each\n# timeout: 10 min per iteration\n# threads: 8 threads, will synchronize iterations\n# benchmark mode: throughput, ops/time\n# benchmark: io.github.dunwu.javatech.jmh.stringbuilderbenchmark.teststringbuilderadd\n\n# run progress: 50.00% complete, eta 00:02:41\n# fork: 1 of 2\n# warmup iteration   1: 241500.886 ops/ms\n# warmup iteration   2: 134206.032 ops/ms\n# warmup iteration   3: 86907.846 ops/ms\niteration   1: 86143.339 ops/ms\niteration   2: 74725.356 ops/ms\niteration   3: 72316.121 ops/ms\niteration   4: 77319.716 ops/ms\niteration   5: 83469.256 ops/ms\niteration   6: 87712.360 ops/ms\niteration   7: 79421.899 ops/ms\niteration   8: 80867.839 ops/ms\niteration   9: 82619.163 ops/ms\niteration  10: 87026.928 ops/ms\n\n# run progress: 75.00% complete, eta 00:01:20\n# fork: 2 of 2\n# warmup iteration   1: 228342.337 ops/ms\n# warmup iteration   2: 124737.248 ops/ms\n# warmup iteration   3: 82598.851 ops/ms\niteration   1: 86877.318 ops/ms\niteration   2: 89388.624 ops/ms\niteration   3: 88523.558 ops/ms\niteration   4: 87547.332 ops/ms\niteration   5: 88376.087 ops/ms\niteration   6: 88848.837 ops/ms\niteration   7: 85998.124 ops/ms\niteration   8: 86796.998 ops/ms\niteration   9: 87994.726 ops/ms\niteration  10: 87784.453 ops/ms\n\n\nresult "io.github.dunwu.javatech.jmh.stringbuilderbenchmark.teststringbuilderadd":\n  84487.902 ±(99.9%) 4355.525 ops/ms [average]\n  (min, avg, max) = (72316.121, 84487.902, 89388.624), stdev = 5015.829\n  ci (99.9%): [80132.377, 88843.427] (assumes normal distribution)\n\n\n# run complete. total time: 00:05:23\n\nremember: the numbers below are just data. to gain reusable insights, you need to follow up on\nwhy the numbers are the way they are. use profilers (see -prof, -lprof), design factorial\nexperiments, perform baseline and negative tests that provide experimental control, make sure\nthe benchmarking environment is safe on jvm/os/hw level, ask for reviews from the domain experts.\ndo not assume the numbers tell you what you want them to tell.\n\nbenchmark                                     mode  cnt      score      error   units\nstringbuilderbenchmark.teststringadd         thrpt   20  21996.435 ±  412.955  ops/ms\nstringbuilderbenchmark.teststringbuilderadd  thrpt   20  84487.902 ± 4355.525  ops/ms\n\n\n\n# jmh api\n\n下面来了解一下 jmh 常用 api\n\n\n# @benchmarkmode\n\n基准测试类型。这里选择的是 throughput 也就是吞吐量。根据源码点进去，每种类型后面都有对应的解释，比较好理解，吞吐量会得到单位时间内可以进行的操作数。\n\n * throughput - 整体吞吐量，例如“1 秒内可以执行多少次调用”。\n * averagetime - 调用的平均时间，例如“每次调用平均耗时 xxx 毫秒”。\n * sampletime - 随机取样，最后输出取样结果的分布，例如“99%的调用在 xxx 毫秒以内，99.99%的调用在 xxx 毫秒以内”\n * singleshottime - 以上模式都是默认一次 iteration 是 1s，唯有 singleshottime 是只运行一次。往往同时把 warmup 次数设为 0，用于测试冷启动时的性能。\n * all - 所有模式\n\n\n# @warmup\n\n上面我们提到了，进行基准测试前需要进行预热。一般我们前几次进行程序测试的时候都会比较慢， 所以要让程序进行几轮预热，保证测试的准确性。其中的参数 iterations 也就非常好理解了，就是预热轮数。\n\n为什么需要预热？因为 jvm 的 jit 机制的存在，如果某个函数被调用多次之后，jvm 会尝试将其编译成为机器码从而提高执行速度。所以为了让 benchmark 的结果更加接近真实情况就需要进行预热。\n\n\n# @measurement\n\n度量，其实就是一些基本的测试参数。\n\n * iterations - 进行测试的轮次\n * time - 每轮进行的时长\n * timeunit - 时长单位\n\n都是一些基本的参数，可以根据具体情况调整。一般比较重的东西可以进行大量的测试，放到服务器上运行。\n\n\n# @threads\n\n每个进程中的测试线程，这个非常好理解，根据具体情况选择，一般为 cpu 乘以 2。\n\n\n# @fork\n\n进行 fork 的次数。如果 fork 数是 2 的话，则 jmh 会 fork 出两个进程来进行测试。\n\n\n# @outputtimeunit\n\n这个比较简单了，基准测试结果的时间类型。一般选择秒、毫秒、微秒。\n\n\n# @benchmark\n\n方法级注解，表示该方法是需要进行 benchmark 的对象，用法和 junit 的 @test 类似。\n\n\n# @param\n\n属性级注解，@param 可以用来指定某项参数的多种情况。特别适合用来测试一个函数在不同的参数输入的情况下的性能。\n\n\n# @setup\n\n方法级注解，这个注解的作用就是我们需要在测试之前进行一些准备工作，比如对一些数据的初始化之类的。\n\n\n# @teardown\n\n方法级注解，这个注解的作用就是我们需要在测试之后进行一些结束工作，比如关闭线程池，数据库连接等的，主要用于资源的回收等。\n\n\n# @state\n\n当使用 @setup 参数的时候，必须在类上加这个参数，不然会提示无法运行。\n\nstate 用于声明某个类是一个“状态”，然后接受一个 scope 参数用来表示该状态的共享范围。 因为很多 benchmark 会需要一些表示状态的类，jmh 允许你把这些类以依赖注入的方式注入到 benchmark 函数里。scope 主要分为三种。\n\n * thread - 该状态为每个线程独享。\n * group - 该状态为同一个组里面所有线程共享。\n * benchmark - 该状态在所有线程间共享。\n\n关于 state 的用法，官方的 code sample 里有比较好的例子。\n\n\n# 参考资料\n\n * jmh 官方示例\n * java 微基准测试框架 jmh\n * java 拾遗 — jmh 与 8 个测试陷阱',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"javalib-log",frontmatter:{title:"javalib-log",categories:["编程","Java","工具"],tags:["Java","日志"],abbrlink:"da18907e",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/337701/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/99.%E5%85%B6%E4%BB%96/01.Java%E6%97%A5%E5%BF%97.html",relativePath:"12.工具/99.其他/01.Java日志.md",key:"v-f2154a58",path:"/pages/337701/",headers:[{level:2,title:"日志框架",slug:"日志框架",normalizedTitle:"日志框架",charIndex:125},{level:3,title:"java.util.logging (JUL)",slug:"java-util-logging-jul",normalizedTitle:"java.util.logging (jul)",charIndex:134},{level:3,title:"Log4j",slug:"log4j",normalizedTitle:"log4j",charIndex:218},{level:3,title:"Logback",slug:"logback",normalizedTitle:"logback",charIndex:555},{level:3,title:"Log4j2",slug:"log4j2",normalizedTitle:"log4j2",charIndex:902},{level:3,title:"Log4j vs Logback vs Log4j2",slug:"log4j-vs-logback-vs-log4j2",normalizedTitle:"log4j vs logback vs log4j2",charIndex:972},{level:2,title:"日志门面",slug:"日志门面",normalizedTitle:"日志门面",charIndex:1753},{level:3,title:"common-logging",slug:"common-logging",normalizedTitle:"common-logging",charIndex:1826},{level:3,title:"slf4j",slug:"slf4j",normalizedTitle:"slf4j",charIndex:2072},{level:3,title:"common-logging vs slf4j",slug:"common-logging-vs-slf4j",normalizedTitle:"common-logging vs slf4j",charIndex:2376},{level:3,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:2636},{level:2,title:"实施日志解决方案",slug:"实施日志解决方案",normalizedTitle:"实施日志解决方案",charIndex:2704},{level:3,title:"引入 jar 包",slug:"引入-jar-包",normalizedTitle:"引入 jar 包",charIndex:2736},{level:4,title:"slf4j 直接绑定日志组件",slug:"slf4j-直接绑定日志组件",normalizedTitle:"slf4j 直接绑定日志组件",charIndex:3130},{level:4,title:"slf4j 兼容非 slf4j 日志组件",slug:"slf4j-兼容非-slf4j-日志组件",normalizedTitle:"slf4j 兼容非 slf4j 日志组件",charIndex:3893},{level:4,title:"spring 集成 slf4j",slug:"spring-集成-slf4j",normalizedTitle:"spring 集成 slf4j",charIndex:4662},{level:4,title:"common-logging 绑定日志组件",slug:"common-logging-绑定日志组件",normalizedTitle:"common-logging 绑定日志组件",charIndex:5203},{level:3,title:"使用 API",slug:"使用-api",normalizedTitle:"使用 api",charIndex:2756},{level:4,title:"slf4j 用法",slug:"slf4j-用法",normalizedTitle:"slf4j 用法",charIndex:5532},{level:4,title:"common-logging 用法",slug:"common-logging-用法",normalizedTitle:"common-logging 用法",charIndex:6039},{level:2,title:"log4j2 配置",slug:"log4j2-配置",normalizedTitle:"log4j2 配置",charIndex:6649},{level:2,title:"logback 配置",slug:"logback-配置",normalizedTitle:"logback 配置",charIndex:8907},{level:3,title:"<configuration>",slug:"configuration",normalizedTitle:"<configuration>",charIndex:8922},{level:3,title:"<appender>",slug:"appender",normalizedTitle:"<appender>",charIndex:8995},{level:4,title:"<file>",slug:"file",normalizedTitle:"<file>",charIndex:9111},{level:4,title:"<filter>",slug:"filter",normalizedTitle:"<filter>",charIndex:9118},{level:4,title:"<layout>",slug:"layout",normalizedTitle:"<layout>",charIndex:9127},{level:4,title:"<encoder>",slug:"encoder",normalizedTitle:"<encoder>",charIndex:9136},{level:3,title:"<logger>",slug:"logger",normalizedTitle:"<logger>",charIndex:9006},{level:4,title:"<appender-ref>",slug:"appender-ref",normalizedTitle:"<appender-ref>",charIndex:9614},{level:3,title:"<root>",slug:"root",normalizedTitle:"<root>",charIndex:9015},{level:3,title:"完整的 logback.xml 参考示例",slug:"完整的-logback-xml-参考示例",normalizedTitle:"完整的 logback.xml 参考示例",charIndex:9815},{level:2,title:"log4j 配置",slug:"log4j-配置",normalizedTitle:"log4j 配置",charIndex:16371},{level:3,title:"完整的 log4j.xml 参考示例",slug:"完整的-log4j-xml-参考示例",normalizedTitle:"完整的 log4j.xml 参考示例",charIndex:16384},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:9831}],headersStr:"日志框架 java.util.logging (JUL) Log4j Logback Log4j2 Log4j vs Logback vs Log4j2 日志门面 common-logging slf4j common-logging vs slf4j 总结 实施日志解决方案 引入 jar 包 slf4j 直接绑定日志组件 slf4j 兼容非 slf4j 日志组件 spring 集成 slf4j common-logging 绑定日志组件 使用 API slf4j 用法 common-logging 用法 log4j2 配置 logback 配置 <configuration> <appender> <file> <filter> <layout> <encoder> <logger> <appender-ref> <root> 完整的 logback.xml 参考示例 log4j 配置 完整的 log4j.xml 参考示例 参考",content:'# 细说 Java 主流日志工具库\n\n> 在项目开发中，为了跟踪代码的运行情况，常常要使用日志来记录信息。\n> \n> 在 Java 世界，有很多的日志工具库来实现日志功能，避免了我们重复造轮子。\n> \n> 我们先来逐一了解一下主流日志工具。\n\n\n# 日志框架\n\n\n# java.util.logging (JUL)\n\nJDK1.4 开始，通过 java.util.logging 提供日志功能。\n\n它能满足基本的日志需要，但是功能没有 Log4j 强大，而且使用范围也没有 Log4j 广泛。\n\n\n# Log4j\n\nLog4j 是 apache 的一个开源项目，创始人 Ceki Gulcu。\n\nLog4j 应该说是 Java 领域资格最老，应用最广的日志工具。从诞生之日到现在一直广受业界欢迎。\n\nLog4j 是高度可配置的，并可通过在运行时的外部文件配置。它根据记录的优先级别，并提供机制，以指示记录信息到许多的目的地，诸如：数据库，文件，控制台，UNIX 系统日志等。\n\nLog4j 中有三个主要组成部分：\n\n * loggers - 负责捕获记录信息。\n * appenders - 负责发布日志信息，以不同的首选目的地。\n * layouts - 负责格式化不同风格的日志信息。\n\n官网地址\n\n\n# Logback\n\nLogback 是由 log4j 创始人 Ceki Gulcu 设计的又一个开源日记组件，目标是替代 log4j。\n\nlogback 当前分成三个模块：logback-core、logback-classic 和 logback-access。\n\n * logback-core - 是其它两个模块的基础模块。\n * logback-classic - 是 log4j 的一个 改良版本。此外 logback-classic 完整实现 SLF4J API 使你可以很方便地更换成其它日记系统如 log4j 或 JDK14 Logging。\n * logback-access - 访问模块与 Servlet 容器集成提供通过 Http 来访问日记的功能。\n\n官网地址\n\n\n# Log4j2\n\n官网地址\n\n按照官方的说法，Log4j2 是 Log4j 和 Logback 的替代。\n\nLog4j2 架构：\n\n\n\n\n# Log4j vs Logback vs Log4j2\n\n按照官方的说法，Log4j2 大大优于 Log4j 和 Logback。\n\n那么，Log4j2 相比于先问世的 Log4j 和 Logback，它具有哪些优势呢？\n\n 1.  Log4j2 旨在用作审计日志记录框架。 Log4j 1.x 和 Logback 都会在重新配置时丢失事件。 Log4j 2 不会。在 Logback 中，Appender 中的异常永远不会对应用程序可见。在 Log4j 中，可以将 Appender 配置为允许异常渗透到应用程序。\n 2.  Log4j2 在多线程场景中，异步 Loggers 的吞吐量比 Log4j 1.x 和 Logback 高 10 倍，延迟低几个数量级。\n 3.  Log4j2 对于独立应用程序是无垃圾的，对于稳定状态日志记录期间的 Web 应用程序来说是低垃圾。这减少了垃圾收集器的压力，并且可以提供更好的响应时间性能。\n 4.  Log4j2 使用插件系统，通过添加新的 Appender、Filter、Layout、Lookup 和 Pattern Converter，可以非常轻松地扩展框架，而无需对 Log4j 进行任何更改。\n 5.  由于插件系统配置更简单。配置中的条目不需要指定类名。\n 6.  支持自定义日志等级。\n 7.  支持 lambda 表达式。\n 8.  支持消息对象。\n 9.  Log4j 和 Logback 的 Layout 返回的是字符串，而 Log4j2 返回的是二进制数组，这使得它能被各种 Appender 使用。\n 10. Syslog Appender 支持 TCP 和 UDP 并且支持 BSD 系统日志。\n 11. Log4j2 利用 Java5 并发特性，尽量小粒度的使用锁，减少锁的开销。\n\n\n# 日志门面\n\n何谓日志门面？\n\n日志门面是对不同日志框架提供的一个 API 封装，可以在部署的时候不修改任何配置即可接入一种日志实现方案。\n\n\n# common-logging\n\ncommon-logging 是 apache 的一个开源项目。也称Jakarta Commons Logging，缩写 JCL。\n\ncommon-logging 的功能是提供日志功能的 API 接口，本身并不提供日志的具体实现（当然，common-logging 内部有一个 Simple logger 的简单实现，但是功能很弱，直接忽略），而是在运行时动态的绑定日志实现组件来工作（如 log4j、java.util.loggin）。\n\n官网地址\n\n\n# slf4j\n\n全称为 Simple Logging Facade for Java，即 java 简单日志门面。\n\n什么，作者又是 Ceki Gulcu！这位大神写了 Log4j、Logback 和 slf4j，专注日志组件开发五百年，一直只能超越自己。\n\n类似于 Common-Logging，slf4j 是对不同日志框架提供的一个 API 封装，可以在部署的时候不修改任何配置即可接入一种日志实现方案。但是，slf4j 在编译时静态绑定真正的 Log 库。使用 SLF4J 时，如果你需要使用某一种日志实现，那么你必须选择正确的 SLF4J 的 jar 包的集合（各种桥接包）。\n\n官网地址\n\n\n\n\n# common-logging vs slf4j\n\nslf4j 库类似于 Apache Common-Logging。但是，他在编译时静态绑定真正的日志库。这点似乎很麻烦，其实也不过是导入桥接 jar 包而已。\n\nslf4j 一大亮点是提供了更方便的日志记录方式：\n\n不需要使用logger.isDebugEnabled()来解决日志因为字符拼接产生的性能问题。slf4j 的方式是使用{}作为字符串替换符，形式如下：\n\nlogger.debug("id: {}, name: {} ", id, name);\n\n\n\n# 总结\n\n综上所述，使用 slf4j + Logback 可谓是目前最理想的日志解决方案了。\n\n接下来，就是如何在项目中实施了。\n\n\n# 实施日志解决方案\n\n使用日志解决方案基本可分为三步：\n\n 1. 引入 jar 包\n 2. 配置\n 3. 使用 API\n\n常见的各种日志解决方案的第 2 步和第 3 步基本一样，实施上的差别主要在第 1 步，也就是使用不同的库。\n\n\n# 引入 jar 包\n\n这里首选推荐使用 slf4j + logback 的组合。\n\n如果你习惯了 common-logging，可以选择 common-logging+log4j。\n\n强烈建议不要直接使用日志实现组件(logback、log4j、java.util.logging)，理由前面也说过，就是无法灵活替换日志库。\n\n还有一种情况：你的老项目使用了 common-logging，或是直接使用日志实现组件。如果修改老的代码，工作量太大，需要兼容处理。在下文，都将看到各种应对方法。\n\n注：据我所知，当前仍没有方法可以将 slf4j 桥接到 common-logging。如果我孤陋寡闻了，请不吝赐教。\n\n# slf4j 直接绑定日志组件\n\nslf4j + logback\n\n添加依赖到 pom.xml 中即可。\n\nlogback-classic-1.0.13.jar 会自动将 slf4j-api-1.7.21.jar 和 logback-core-1.0.13.jar 也添加到你的项目中。\n\n<dependency>\n  <groupId>ch.qos.logback</groupId>\n  <artifactId>logback-classic</artifactId>\n  <version>1.0.13</version>\n</dependency>\n\n\nslf4j + log4j\n\n添加依赖到 pom.xml 中即可。\n\nslf4j-log4j12-1.7.21.jar 会自动将 slf4j-api-1.7.21.jar 和 log4j-1.2.17.jar 也添加到你的项目中。\n\n<dependency>\n  <groupId>org.slf4j</groupId>\n  <artifactId>slf4j-log4j12</artifactId>\n  <version>1.7.21</version>\n</dependency>\n\n\nslf4j + java.util.logging\n\n添加依赖到 pom.xml 中即可。\n\nslf4j-jdk14-1.7.21.jar 会自动将 slf4j-api-1.7.21.jar 也添加到你的项目中。\n\n<dependency>\n  <groupId>org.slf4j</groupId>\n  <artifactId>slf4j-jdk14</artifactId>\n  <version>1.7.21</version>\n</dependency>\n\n\n# slf4j 兼容非 slf4j 日志组件\n\n在介绍解决方案前，先提一个概念——桥接\n\n什么是桥接呢\n\n假如你正在开发应用程序所调用的组件当中已经使用了 common-logging，这时你需要 jcl-over-slf4j.jar 把日志信息输出重定向到 slf4j-api，slf4j-api 再去调用 slf4j 实际依赖的日志组件。这个过程称为桥接。下图是官方的 slf4j 桥接策略图：\n\n\n\n从图中应该可以看出，无论你的老项目中使用的是 common-logging 或是直接使用 log4j、java.util.logging，都可以使用对应的桥接 jar 包来解决兼容问题。\n\nslf4j 兼容 common-logging\n\n<dependency>\n  <groupId>org.slf4j</groupId>\n  <artifactId>jcl-over-slf4j</artifactId>\n  <version>1.7.12</version>\n</dependency>\n\n\nslf4j 兼容 log4j\n\n<dependency>\n    <groupId>org.slf4j</groupId>\n    <artifactId>log4j-over-slf4j</artifactId>\n    <version>1.7.12</version>\n</dependency>\n\n\nslf4j 兼容 java.util.logging\n\n<dependency>\n    <groupId>org.slf4j</groupId>\n    <artifactId>jul-to-slf4j</artifactId>\n    <version>1.7.12</version>\n</dependency>\n\n\n# spring 集成 slf4j\n\n做 java web 开发，基本离不开 spring 框架。很遗憾，spring 使用的日志解决方案是 common-logging + log4j。\n\n所以，你需要一个桥接 jar 包：logback-ext-spring。\n\n<dependency>\n  <groupId>ch.qos.logback</groupId>\n  <artifactId>logback-classic</artifactId>\n  <version>1.1.3</version>\n</dependency>\n<dependency>\n  <groupId>org.logback-extensions</groupId>\n  <artifactId>logback-ext-spring</artifactId>\n  <version>0.1.2</version>\n</dependency>\n<dependency>\n  <groupId>org.slf4j</groupId>\n  <artifactId>jcl-over-slf4j</artifactId>\n  <version>1.7.12</version>\n</dependency>\n\n\n# common-logging 绑定日志组件\n\ncommon-logging + log4j\n\n添加依赖到 pom.xml 中即可。\n\n<dependency>\n  <groupId>commons-logging</groupId>\n  <artifactId>commons-logging</artifactId>\n  <version>1.2</version>\n</dependency>\n<dependency>\n  <groupId>log4j</groupId>\n  <artifactId>log4j</artifactId>\n  <version>1.2.17</version>\n</dependency>\n\n\n\n# 使用 API\n\n# slf4j 用法\n\n使用 slf4j 的 API 很简单。使用LoggerFactory初始化一个Logger实例，然后调用 Logger 对应的打印等级函数就行了。\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\npublic class App {\n    private static final Logger log = LoggerFactory.getLogger(App.class);\n    public static void main(String[] args) {\n        String msg = "print log, current level: {}";\n        log.trace(msg, "trace");\n        log.debug(msg, "debug");\n        log.info(msg, "info");\n        log.warn(msg, "warn");\n        log.error(msg, "error");\n    }\n}\n\n\n# common-logging 用法\n\ncommon-logging 用法和 slf4j 几乎一样，但是支持的打印等级多了一个更高级别的：fatal。\n\n此外，common-logging 不支持{}替换参数，你只能选择拼接字符串这种方式了。\n\nimport org.apache.commons.logging.Log;\nimport org.apache.commons.logging.LogFactory;\n\npublic class JclTest {\n    private static final Log log = LogFactory.getLog(JclTest.class);\n\n    public static void main(String[] args) {\n        String msg = "print log, current level: ";\n        log.trace(msg + "trace");\n        log.debug(msg + "debug");\n        log.info(msg + "info");\n        log.warn(msg + "warn");\n        log.error(msg + "error");\n        log.fatal(msg + "fatal");\n    }\n}\n\n\n\n# log4j2 配置\n\nlog4j2 基本配置形式如下：\n\n<?xml version="1.0" encoding="UTF-8"?>;\n<Configuration>\n  <Properties>\n    <Property name="name1">value</property>\n    <Property name="name2" value="value2"/>\n  </Properties>\n  <Filter type="type" ... />\n  <Appenders>\n    <Appender type="type" name="name">\n      <Filter type="type" ... />\n    </Appender>\n    ...\n  </Appenders>\n  <Loggers>\n    <Logger name="name1">\n      <Filter type="type" ... />\n    </Logger>\n    ...\n    <Root level="level">\n      <AppenderRef ref="name"/>\n    </Root>\n  </Loggers>\n</Configuration>\n\n\n配置示例：\n\n<?xml version="1.0" encoding="UTF-8"?>\n<Configuration status="debug" strict="true" name="XMLConfigTest"\n               packages="org.apache.logging.log4j.test">\n  <Properties>\n    <Property name="filename">target/test.log</Property>\n  </Properties>\n  <Filter type="ThresholdFilter" level="trace"/>\n\n  <Appenders>\n    <Appender type="Console" name="STDOUT">\n      <Layout type="PatternLayout" pattern="%m MDC%X%n"/>\n      <Filters>\n        <Filter type="MarkerFilter" marker="FLOW" onMatch="DENY" onMismatch="NEUTRAL"/>\n        <Filter type="MarkerFilter" marker="EXCEPTION" onMatch="DENY" onMismatch="ACCEPT"/>\n      </Filters>\n    </Appender>\n    <Appender type="Console" name="FLOW">\n      <Layout type="PatternLayout" pattern="%C{1}.%M %m %ex%n"/>\x3c!-- class and line number --\x3e\n      <Filters>\n        <Filter type="MarkerFilter" marker="FLOW" onMatch="ACCEPT" onMismatch="NEUTRAL"/>\n        <Filter type="MarkerFilter" marker="EXCEPTION" onMatch="ACCEPT" onMismatch="DENY"/>\n      </Filters>\n    </Appender>\n    <Appender type="File" name="File" fileName="${filename}">\n      <Layout type="PatternLayout">\n        <Pattern>%d %p %C{1.} [%t] %m%n</Pattern>\n      </Layout>\n    </Appender>\n  </Appenders>\n\n  <Loggers>\n    <Logger name="org.apache.logging.log4j.test1" level="debug" additivity="false">\n      <Filter type="ThreadContextMapFilter">\n        <KeyValuePair key="test" value="123"/>\n      </Filter>\n      <AppenderRef ref="STDOUT"/>\n    </Logger>\n\n    <Logger name="org.apache.logging.log4j.test2" level="debug" additivity="false">\n      <AppenderRef ref="File"/>\n    </Logger>\n\n    <Root level="trace">\n      <AppenderRef ref="STDOUT"/>\n    </Root>\n  </Loggers>\n\n</Configuration>\n\n\n\n# logback 配置\n\n\n# <configuration>\n\n * 作用：<configuration> 是 logback 配置文件的根元素。\n * 要点\n   * 它有 <appender>、<logger>、<root> 三个子元素。\n\n\n\n\n# <appender>\n\n * 作用：将记录日志的任务委托给名为 appender 的组件。\n * 要点\n   * 可以配置零个或多个。\n   * 它有 <file>、<filter>、<layout>、<encoder> 四个子元素。\n * 属性\n   * name：设置 appender 名称。\n   * class：设置具体的实例化类。\n\n# <file>\n\n * 作用：设置日志文件路径。\n\n# <filter>\n\n * 作用：设置过滤器。\n * 要点\n   * 可以配置零个或多个。\n\n# <layout>\n\n * 作用：设置 appender。\n * 要点\n   * 可以配置零个或一个。\n * 属性\n   * class：设置具体的实例化类。\n\n# <encoder>\n\n * 作用：设置编码。\n * 要点\n   * 可以配置零个或多个。\n * 属性\n   * class：设置具体的实例化类。\n\n\n\n\n# <logger>\n\n * 作用：设置 logger。\n * 要点\n   * 可以配置零个或多个。\n * 属性\n   * name\n   * level：设置日志级别。不区分大小写。可选值：TRACE、DEBUG、INFO、WARN、ERROR、ALL、OFF。\n   * additivity：可选值：true 或 false。\n\n# <appender-ref>\n\n * 作用：appender 引用。\n * 要点\n   * 可以配置零个或多个。\n\n\n# <root>\n\n * 作用：设置根 logger。\n * 要点\n   * 只能配置一个。\n   * 除了 level，不支持任何属性。level 属性和 <logger> 中的相同。\n   * 有一个子元素 <appender-ref>，与 <logger> 中的相同。\n\n\n# 完整的 logback.xml 参考示例\n\n在下面的配置文件中，我为自己的项目代码（根目录：org.zp.notes.spring）设置了五种等级：\n\nTRACE、DEBUG、INFO、WARN、ERROR，优先级依次从低到高。\n\n因为关注 spring 框架本身的一些信息，我增加了专门打印 spring WARN 及以上等级的日志。\n\n<?xml version="1.0" encoding="UTF-8" ?>\n\n\x3c!-- logback中一共有5种有效级别，分别是TRACE、DEBUG、INFO、WARN、ERROR，优先级依次从低到高 --\x3e\n<configuration scan="true" scanPeriod="60 seconds" debug="false">\n\n  <property name="DIR_NAME" value="spring-helloworld"/>\n\n  \x3c!-- 将记录日志打印到控制台 --\x3e\n  <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">\n    <encoder>\n      <pattern>%d{HH:mm:ss.SSS} [%thread] [%-5p] %c{36}.%M - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  \x3c!-- RollingFileAppender begin --\x3e\n  <appender name="ALL" class="ch.qos.logback.core.rolling.RollingFileAppender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">\n      <fileNamePattern>${user.dir}/logs/${DIR_NAME}/all.%d{yyyy-MM-dd}.log</fileNamePattern>\n      <maxHistory>30</maxHistory>\n    </rollingPolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">\n      <maxFileSize>30MB</maxFileSize>\n    </triggeringPolicy>\n\n    <encoder>\n      <pattern>%d{HH:mm:ss.SSS} [%thread] [%-5p] %c{36}.%M - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  <appender name="ERROR" class="ch.qos.logback.core.rolling.RollingFileAppender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">\n      <fileNamePattern>${user.dir}/logs/${DIR_NAME}/error.%d{yyyy-MM-dd}.log</fileNamePattern>\n      <maxHistory>30</maxHistory>\n    </rollingPolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">\n      <maxFileSize>10MB</maxFileSize>\n    </triggeringPolicy>\n\n    <filter class="ch.qos.logback.classic.filter.LevelFilter">\n      <level>ERROR</level>\n      <onMatch>ACCEPT</onMatch>\n      <onMismatch>DENY</onMismatch>\n    </filter>\n\n    <encoder>\n      <pattern>%d{HH:mm:ss.SSS} [%thread] [%-5p] %c{36}.%M - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  <appender name="WARN" class="ch.qos.logback.core.rolling.RollingFileAppender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">\n      <fileNamePattern>${user.dir}/logs/${DIR_NAME}/warn.%d{yyyy-MM-dd}.log</fileNamePattern>\n      <maxHistory>30</maxHistory>\n    </rollingPolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">\n      <maxFileSize>10MB</maxFileSize>\n    </triggeringPolicy>\n\n    <filter class="ch.qos.logback.classic.filter.LevelFilter">\n      <level>WARN</level>\n      <onMatch>ACCEPT</onMatch>\n      <onMismatch>DENY</onMismatch>\n    </filter>\n\n    <encoder>\n      <pattern>%d{HH:mm:ss.SSS} [%thread] [%-5p] %c{36}.%M - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  <appender name="INFO" class="ch.qos.logback.core.rolling.RollingFileAppender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">\n      <fileNamePattern>${user.dir}/logs/${DIR_NAME}/info.%d{yyyy-MM-dd}.log</fileNamePattern>\n      <maxHistory>30</maxHistory>\n    </rollingPolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">\n      <maxFileSize>10MB</maxFileSize>\n    </triggeringPolicy>\n\n    <filter class="ch.qos.logback.classic.filter.LevelFilter">\n      <level>INFO</level>\n      <onMatch>ACCEPT</onMatch>\n      <onMismatch>DENY</onMismatch>\n    </filter>\n\n    <encoder>\n      <pattern>%d{HH:mm:ss.SSS} [%thread] [%-5p] %c{36}.%M - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  <appender name="DEBUG" class="ch.qos.logback.core.rolling.RollingFileAppender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">\n      <fileNamePattern>${user.dir}/logs/${DIR_NAME}/debug.%d{yyyy-MM-dd}.log</fileNamePattern>\n      <maxHistory>30</maxHistory>\n    </rollingPolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">\n      <maxFileSize>10MB</maxFileSize>\n    </triggeringPolicy>\n\n    <filter class="ch.qos.logback.classic.filter.LevelFilter">\n      <level>DEBUG</level>\n      <onMatch>ACCEPT</onMatch>\n      <onMismatch>DENY</onMismatch>\n    </filter>\n\n    <encoder>\n      <pattern>%d{HH:mm:ss.SSS} [%thread] [%-5p] %c{36}.%M - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  <appender name="TRACE" class="ch.qos.logback.core.rolling.RollingFileAppender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">\n      <fileNamePattern>${user.dir}/logs/${DIR_NAME}/trace.%d{yyyy-MM-dd}.log</fileNamePattern>\n      <maxHistory>30</maxHistory>\n    </rollingPolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">\n      <maxFileSize>10MB</maxFileSize>\n    </triggeringPolicy>\n\n    <filter class="ch.qos.logback.classic.filter.LevelFilter">\n      <level>TRACE</level>\n      <onMatch>ACCEPT</onMatch>\n      <onMismatch>DENY</onMismatch>\n    </filter>\n\n    <encoder>\n      <pattern>%d{HH:mm:ss.SSS} [%thread] [%-5p] %c{36}.%M - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  <appender name="SPRING" class="ch.qos.logback.core.rolling.RollingFileAppender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">\n      <fileNamePattern>${user.dir}/logs/${DIR_NAME}/springframework.%d{yyyy-MM-dd}.log\n      </fileNamePattern>\n      <maxHistory>30</maxHistory>\n    </rollingPolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">\n      <maxFileSize>10MB</maxFileSize>\n    </triggeringPolicy>\n\n    <encoder>\n      <pattern>%d{HH:mm:ss.SSS} [%thread] [%-5p] %c{36}.%M - %m%n</pattern>\n    </encoder>\n  </appender>\n  \x3c!-- RollingFileAppender end --\x3e\n\n  \x3c!-- logger begin --\x3e\n  \x3c!-- 本项目的日志记录，分级打印 --\x3e\n  <logger name="org.zp.notes.spring" level="TRACE" additivity="false">\n    <appender-ref ref="STDOUT"/>\n    <appender-ref ref="ERROR"/>\n    <appender-ref ref="WARN"/>\n    <appender-ref ref="INFO"/>\n    <appender-ref ref="DEBUG"/>\n    <appender-ref ref="TRACE"/>\n  </logger>\n\n  \x3c!-- SPRING框架日志 --\x3e\n  <logger name="org.springframework" level="WARN" additivity="false">\n    <appender-ref ref="SPRING"/>\n  </logger>\n\n  <root level="TRACE">\n    <appender-ref ref="ALL"/>\n  </root>\n  \x3c!-- logger end --\x3e\n\n</configuration>\n\n\n\n# log4j 配置\n\n\n# 完整的 log4j.xml 参考示例\n\nlog4j 的配置文件一般有 xml 格式或 properties 格式。这里为了和 logback.xml 做个对比，就不介绍 properties 了，其实也没太大差别。\n\n<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE log4j:configuration SYSTEM "log4j.dtd">\n\n<log4j:configuration xmlns:log4j=\'http://jakarta.apache.org/log4j/\'>\n\n  <appender name="STDOUT" class="org.apache.log4j.ConsoleAppender">\n    <layout class="org.apache.log4j.PatternLayout">\n      <param name="ConversionPattern"\n             value="%d{yyyy-MM-dd HH:mm:ss,SSS\\} [%-5p] [%t] %c{36\\}.%M - %m%n"/>\n    </layout>\n\n    \x3c!--过滤器设置输出的级别--\x3e\n    <filter class="org.apache.log4j.varia.LevelRangeFilter">\n      <param name="levelMin" value="debug"/>\n      <param name="levelMax" value="fatal"/>\n      <param name="AcceptOnMatch" value="true"/>\n    </filter>\n  </appender>\n\n\n  <appender name="ALL" class="org.apache.log4j.DailyRollingFileAppender">\n    <param name="File" value="${user.dir}/logs/spring-common/jcl/all"/>\n    <param name="Append" value="true"/>\n    \x3c!-- 每天重新生成日志文件 --\x3e\n    <param name="DatePattern" value="\'-\'yyyy-MM-dd\'.log\'"/>\n    \x3c!-- 每小时重新生成日志文件 --\x3e\n    \x3c!--<param name="DatePattern" value="\'-\'yyyy-MM-dd-HH\'.log\'"/>--\x3e\n    <layout class="org.apache.log4j.PatternLayout">\n      <param name="ConversionPattern"\n             value="%d{yyyy-MM-dd HH:mm:ss,SSS\\} [%-5p] [%t] %c{36\\}.%M - %m%n"/>\n    </layout>\n  </appender>\n\n  \x3c!-- 指定logger的设置，additivity指示是否遵循缺省的继承机制--\x3e\n  <logger name="org.zp.notes.spring" additivity="false">\n    <level value="error"/>\n    <appender-ref ref="STDOUT"/>\n    <appender-ref ref="ALL"/>\n  </logger>\n\n  \x3c!-- 根logger的设置--\x3e\n  <root>\n    <level value="warn"/>\n    <appender-ref ref="STDOUT"/>\n  </root>\n</log4j:configuration>\n\n\n\n# 参考\n\n * slf4 官方文档\n * logback 官方文档\n * log4j 官方文档\n * commons-logging 官方文档\n * http://blog.csdn.net/yycdaizi/article/details/8276265',normalizedContent:'# 细说 java 主流日志工具库\n\n> 在项目开发中，为了跟踪代码的运行情况，常常要使用日志来记录信息。\n> \n> 在 java 世界，有很多的日志工具库来实现日志功能，避免了我们重复造轮子。\n> \n> 我们先来逐一了解一下主流日志工具。\n\n\n# 日志框架\n\n\n# java.util.logging (jul)\n\njdk1.4 开始，通过 java.util.logging 提供日志功能。\n\n它能满足基本的日志需要，但是功能没有 log4j 强大，而且使用范围也没有 log4j 广泛。\n\n\n# log4j\n\nlog4j 是 apache 的一个开源项目，创始人 ceki gulcu。\n\nlog4j 应该说是 java 领域资格最老，应用最广的日志工具。从诞生之日到现在一直广受业界欢迎。\n\nlog4j 是高度可配置的，并可通过在运行时的外部文件配置。它根据记录的优先级别，并提供机制，以指示记录信息到许多的目的地，诸如：数据库，文件，控制台，unix 系统日志等。\n\nlog4j 中有三个主要组成部分：\n\n * loggers - 负责捕获记录信息。\n * appenders - 负责发布日志信息，以不同的首选目的地。\n * layouts - 负责格式化不同风格的日志信息。\n\n官网地址\n\n\n# logback\n\nlogback 是由 log4j 创始人 ceki gulcu 设计的又一个开源日记组件，目标是替代 log4j。\n\nlogback 当前分成三个模块：logback-core、logback-classic 和 logback-access。\n\n * logback-core - 是其它两个模块的基础模块。\n * logback-classic - 是 log4j 的一个 改良版本。此外 logback-classic 完整实现 slf4j api 使你可以很方便地更换成其它日记系统如 log4j 或 jdk14 logging。\n * logback-access - 访问模块与 servlet 容器集成提供通过 http 来访问日记的功能。\n\n官网地址\n\n\n# log4j2\n\n官网地址\n\n按照官方的说法，log4j2 是 log4j 和 logback 的替代。\n\nlog4j2 架构：\n\n\n\n\n# log4j vs logback vs log4j2\n\n按照官方的说法，log4j2 大大优于 log4j 和 logback。\n\n那么，log4j2 相比于先问世的 log4j 和 logback，它具有哪些优势呢？\n\n 1.  log4j2 旨在用作审计日志记录框架。 log4j 1.x 和 logback 都会在重新配置时丢失事件。 log4j 2 不会。在 logback 中，appender 中的异常永远不会对应用程序可见。在 log4j 中，可以将 appender 配置为允许异常渗透到应用程序。\n 2.  log4j2 在多线程场景中，异步 loggers 的吞吐量比 log4j 1.x 和 logback 高 10 倍，延迟低几个数量级。\n 3.  log4j2 对于独立应用程序是无垃圾的，对于稳定状态日志记录期间的 web 应用程序来说是低垃圾。这减少了垃圾收集器的压力，并且可以提供更好的响应时间性能。\n 4.  log4j2 使用插件系统，通过添加新的 appender、filter、layout、lookup 和 pattern converter，可以非常轻松地扩展框架，而无需对 log4j 进行任何更改。\n 5.  由于插件系统配置更简单。配置中的条目不需要指定类名。\n 6.  支持自定义日志等级。\n 7.  支持 lambda 表达式。\n 8.  支持消息对象。\n 9.  log4j 和 logback 的 layout 返回的是字符串，而 log4j2 返回的是二进制数组，这使得它能被各种 appender 使用。\n 10. syslog appender 支持 tcp 和 udp 并且支持 bsd 系统日志。\n 11. log4j2 利用 java5 并发特性，尽量小粒度的使用锁，减少锁的开销。\n\n\n# 日志门面\n\n何谓日志门面？\n\n日志门面是对不同日志框架提供的一个 api 封装，可以在部署的时候不修改任何配置即可接入一种日志实现方案。\n\n\n# common-logging\n\ncommon-logging 是 apache 的一个开源项目。也称jakarta commons logging，缩写 jcl。\n\ncommon-logging 的功能是提供日志功能的 api 接口，本身并不提供日志的具体实现（当然，common-logging 内部有一个 simple logger 的简单实现，但是功能很弱，直接忽略），而是在运行时动态的绑定日志实现组件来工作（如 log4j、java.util.loggin）。\n\n官网地址\n\n\n# slf4j\n\n全称为 simple logging facade for java，即 java 简单日志门面。\n\n什么，作者又是 ceki gulcu！这位大神写了 log4j、logback 和 slf4j，专注日志组件开发五百年，一直只能超越自己。\n\n类似于 common-logging，slf4j 是对不同日志框架提供的一个 api 封装，可以在部署的时候不修改任何配置即可接入一种日志实现方案。但是，slf4j 在编译时静态绑定真正的 log 库。使用 slf4j 时，如果你需要使用某一种日志实现，那么你必须选择正确的 slf4j 的 jar 包的集合（各种桥接包）。\n\n官网地址\n\n\n\n\n# common-logging vs slf4j\n\nslf4j 库类似于 apache common-logging。但是，他在编译时静态绑定真正的日志库。这点似乎很麻烦，其实也不过是导入桥接 jar 包而已。\n\nslf4j 一大亮点是提供了更方便的日志记录方式：\n\n不需要使用logger.isdebugenabled()来解决日志因为字符拼接产生的性能问题。slf4j 的方式是使用{}作为字符串替换符，形式如下：\n\nlogger.debug("id: {}, name: {} ", id, name);\n\n\n\n# 总结\n\n综上所述，使用 slf4j + logback 可谓是目前最理想的日志解决方案了。\n\n接下来，就是如何在项目中实施了。\n\n\n# 实施日志解决方案\n\n使用日志解决方案基本可分为三步：\n\n 1. 引入 jar 包\n 2. 配置\n 3. 使用 api\n\n常见的各种日志解决方案的第 2 步和第 3 步基本一样，实施上的差别主要在第 1 步，也就是使用不同的库。\n\n\n# 引入 jar 包\n\n这里首选推荐使用 slf4j + logback 的组合。\n\n如果你习惯了 common-logging，可以选择 common-logging+log4j。\n\n强烈建议不要直接使用日志实现组件(logback、log4j、java.util.logging)，理由前面也说过，就是无法灵活替换日志库。\n\n还有一种情况：你的老项目使用了 common-logging，或是直接使用日志实现组件。如果修改老的代码，工作量太大，需要兼容处理。在下文，都将看到各种应对方法。\n\n注：据我所知，当前仍没有方法可以将 slf4j 桥接到 common-logging。如果我孤陋寡闻了，请不吝赐教。\n\n# slf4j 直接绑定日志组件\n\nslf4j + logback\n\n添加依赖到 pom.xml 中即可。\n\nlogback-classic-1.0.13.jar 会自动将 slf4j-api-1.7.21.jar 和 logback-core-1.0.13.jar 也添加到你的项目中。\n\n<dependency>\n  <groupid>ch.qos.logback</groupid>\n  <artifactid>logback-classic</artifactid>\n  <version>1.0.13</version>\n</dependency>\n\n\nslf4j + log4j\n\n添加依赖到 pom.xml 中即可。\n\nslf4j-log4j12-1.7.21.jar 会自动将 slf4j-api-1.7.21.jar 和 log4j-1.2.17.jar 也添加到你的项目中。\n\n<dependency>\n  <groupid>org.slf4j</groupid>\n  <artifactid>slf4j-log4j12</artifactid>\n  <version>1.7.21</version>\n</dependency>\n\n\nslf4j + java.util.logging\n\n添加依赖到 pom.xml 中即可。\n\nslf4j-jdk14-1.7.21.jar 会自动将 slf4j-api-1.7.21.jar 也添加到你的项目中。\n\n<dependency>\n  <groupid>org.slf4j</groupid>\n  <artifactid>slf4j-jdk14</artifactid>\n  <version>1.7.21</version>\n</dependency>\n\n\n# slf4j 兼容非 slf4j 日志组件\n\n在介绍解决方案前，先提一个概念——桥接\n\n什么是桥接呢\n\n假如你正在开发应用程序所调用的组件当中已经使用了 common-logging，这时你需要 jcl-over-slf4j.jar 把日志信息输出重定向到 slf4j-api，slf4j-api 再去调用 slf4j 实际依赖的日志组件。这个过程称为桥接。下图是官方的 slf4j 桥接策略图：\n\n\n\n从图中应该可以看出，无论你的老项目中使用的是 common-logging 或是直接使用 log4j、java.util.logging，都可以使用对应的桥接 jar 包来解决兼容问题。\n\nslf4j 兼容 common-logging\n\n<dependency>\n  <groupid>org.slf4j</groupid>\n  <artifactid>jcl-over-slf4j</artifactid>\n  <version>1.7.12</version>\n</dependency>\n\n\nslf4j 兼容 log4j\n\n<dependency>\n    <groupid>org.slf4j</groupid>\n    <artifactid>log4j-over-slf4j</artifactid>\n    <version>1.7.12</version>\n</dependency>\n\n\nslf4j 兼容 java.util.logging\n\n<dependency>\n    <groupid>org.slf4j</groupid>\n    <artifactid>jul-to-slf4j</artifactid>\n    <version>1.7.12</version>\n</dependency>\n\n\n# spring 集成 slf4j\n\n做 java web 开发，基本离不开 spring 框架。很遗憾，spring 使用的日志解决方案是 common-logging + log4j。\n\n所以，你需要一个桥接 jar 包：logback-ext-spring。\n\n<dependency>\n  <groupid>ch.qos.logback</groupid>\n  <artifactid>logback-classic</artifactid>\n  <version>1.1.3</version>\n</dependency>\n<dependency>\n  <groupid>org.logback-extensions</groupid>\n  <artifactid>logback-ext-spring</artifactid>\n  <version>0.1.2</version>\n</dependency>\n<dependency>\n  <groupid>org.slf4j</groupid>\n  <artifactid>jcl-over-slf4j</artifactid>\n  <version>1.7.12</version>\n</dependency>\n\n\n# common-logging 绑定日志组件\n\ncommon-logging + log4j\n\n添加依赖到 pom.xml 中即可。\n\n<dependency>\n  <groupid>commons-logging</groupid>\n  <artifactid>commons-logging</artifactid>\n  <version>1.2</version>\n</dependency>\n<dependency>\n  <groupid>log4j</groupid>\n  <artifactid>log4j</artifactid>\n  <version>1.2.17</version>\n</dependency>\n\n\n\n# 使用 api\n\n# slf4j 用法\n\n使用 slf4j 的 api 很简单。使用loggerfactory初始化一个logger实例，然后调用 logger 对应的打印等级函数就行了。\n\nimport org.slf4j.logger;\nimport org.slf4j.loggerfactory;\n\npublic class app {\n    private static final logger log = loggerfactory.getlogger(app.class);\n    public static void main(string[] args) {\n        string msg = "print log, current level: {}";\n        log.trace(msg, "trace");\n        log.debug(msg, "debug");\n        log.info(msg, "info");\n        log.warn(msg, "warn");\n        log.error(msg, "error");\n    }\n}\n\n\n# common-logging 用法\n\ncommon-logging 用法和 slf4j 几乎一样，但是支持的打印等级多了一个更高级别的：fatal。\n\n此外，common-logging 不支持{}替换参数，你只能选择拼接字符串这种方式了。\n\nimport org.apache.commons.logging.log;\nimport org.apache.commons.logging.logfactory;\n\npublic class jcltest {\n    private static final log log = logfactory.getlog(jcltest.class);\n\n    public static void main(string[] args) {\n        string msg = "print log, current level: ";\n        log.trace(msg + "trace");\n        log.debug(msg + "debug");\n        log.info(msg + "info");\n        log.warn(msg + "warn");\n        log.error(msg + "error");\n        log.fatal(msg + "fatal");\n    }\n}\n\n\n\n# log4j2 配置\n\nlog4j2 基本配置形式如下：\n\n<?xml version="1.0" encoding="utf-8"?>;\n<configuration>\n  <properties>\n    <property name="name1">value</property>\n    <property name="name2" value="value2"/>\n  </properties>\n  <filter type="type" ... />\n  <appenders>\n    <appender type="type" name="name">\n      <filter type="type" ... />\n    </appender>\n    ...\n  </appenders>\n  <loggers>\n    <logger name="name1">\n      <filter type="type" ... />\n    </logger>\n    ...\n    <root level="level">\n      <appenderref ref="name"/>\n    </root>\n  </loggers>\n</configuration>\n\n\n配置示例：\n\n<?xml version="1.0" encoding="utf-8"?>\n<configuration status="debug" strict="true" name="xmlconfigtest"\n               packages="org.apache.logging.log4j.test">\n  <properties>\n    <property name="filename">target/test.log</property>\n  </properties>\n  <filter type="thresholdfilter" level="trace"/>\n\n  <appenders>\n    <appender type="console" name="stdout">\n      <layout type="patternlayout" pattern="%m mdc%x%n"/>\n      <filters>\n        <filter type="markerfilter" marker="flow" onmatch="deny" onmismatch="neutral"/>\n        <filter type="markerfilter" marker="exception" onmatch="deny" onmismatch="accept"/>\n      </filters>\n    </appender>\n    <appender type="console" name="flow">\n      <layout type="patternlayout" pattern="%c{1}.%m %m %ex%n"/>\x3c!-- class and line number --\x3e\n      <filters>\n        <filter type="markerfilter" marker="flow" onmatch="accept" onmismatch="neutral"/>\n        <filter type="markerfilter" marker="exception" onmatch="accept" onmismatch="deny"/>\n      </filters>\n    </appender>\n    <appender type="file" name="file" filename="${filename}">\n      <layout type="patternlayout">\n        <pattern>%d %p %c{1.} [%t] %m%n</pattern>\n      </layout>\n    </appender>\n  </appenders>\n\n  <loggers>\n    <logger name="org.apache.logging.log4j.test1" level="debug" additivity="false">\n      <filter type="threadcontextmapfilter">\n        <keyvaluepair key="test" value="123"/>\n      </filter>\n      <appenderref ref="stdout"/>\n    </logger>\n\n    <logger name="org.apache.logging.log4j.test2" level="debug" additivity="false">\n      <appenderref ref="file"/>\n    </logger>\n\n    <root level="trace">\n      <appenderref ref="stdout"/>\n    </root>\n  </loggers>\n\n</configuration>\n\n\n\n# logback 配置\n\n\n# <configuration>\n\n * 作用：<configuration> 是 logback 配置文件的根元素。\n * 要点\n   * 它有 <appender>、<logger>、<root> 三个子元素。\n\n\n\n\n# <appender>\n\n * 作用：将记录日志的任务委托给名为 appender 的组件。\n * 要点\n   * 可以配置零个或多个。\n   * 它有 <file>、<filter>、<layout>、<encoder> 四个子元素。\n * 属性\n   * name：设置 appender 名称。\n   * class：设置具体的实例化类。\n\n# <file>\n\n * 作用：设置日志文件路径。\n\n# <filter>\n\n * 作用：设置过滤器。\n * 要点\n   * 可以配置零个或多个。\n\n# <layout>\n\n * 作用：设置 appender。\n * 要点\n   * 可以配置零个或一个。\n * 属性\n   * class：设置具体的实例化类。\n\n# <encoder>\n\n * 作用：设置编码。\n * 要点\n   * 可以配置零个或多个。\n * 属性\n   * class：设置具体的实例化类。\n\n\n\n\n# <logger>\n\n * 作用：设置 logger。\n * 要点\n   * 可以配置零个或多个。\n * 属性\n   * name\n   * level：设置日志级别。不区分大小写。可选值：trace、debug、info、warn、error、all、off。\n   * additivity：可选值：true 或 false。\n\n# <appender-ref>\n\n * 作用：appender 引用。\n * 要点\n   * 可以配置零个或多个。\n\n\n# <root>\n\n * 作用：设置根 logger。\n * 要点\n   * 只能配置一个。\n   * 除了 level，不支持任何属性。level 属性和 <logger> 中的相同。\n   * 有一个子元素 <appender-ref>，与 <logger> 中的相同。\n\n\n# 完整的 logback.xml 参考示例\n\n在下面的配置文件中，我为自己的项目代码（根目录：org.zp.notes.spring）设置了五种等级：\n\ntrace、debug、info、warn、error，优先级依次从低到高。\n\n因为关注 spring 框架本身的一些信息，我增加了专门打印 spring warn 及以上等级的日志。\n\n<?xml version="1.0" encoding="utf-8" ?>\n\n\x3c!-- logback中一共有5种有效级别，分别是trace、debug、info、warn、error，优先级依次从低到高 --\x3e\n<configuration scan="true" scanperiod="60 seconds" debug="false">\n\n  <property name="dir_name" value="spring-helloworld"/>\n\n  \x3c!-- 将记录日志打印到控制台 --\x3e\n  <appender name="stdout" class="ch.qos.logback.core.consoleappender">\n    <encoder>\n      <pattern>%d{hh:mm:ss.sss} [%thread] [%-5p] %c{36}.%m - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  \x3c!-- rollingfileappender begin --\x3e\n  <appender name="all" class="ch.qos.logback.core.rolling.rollingfileappender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingpolicy class="ch.qos.logback.core.rolling.timebasedrollingpolicy">\n      <filenamepattern>${user.dir}/logs/${dir_name}/all.%d{yyyy-mm-dd}.log</filenamepattern>\n      <maxhistory>30</maxhistory>\n    </rollingpolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringpolicy class="ch.qos.logback.core.rolling.sizebasedtriggeringpolicy">\n      <maxfilesize>30mb</maxfilesize>\n    </triggeringpolicy>\n\n    <encoder>\n      <pattern>%d{hh:mm:ss.sss} [%thread] [%-5p] %c{36}.%m - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  <appender name="error" class="ch.qos.logback.core.rolling.rollingfileappender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingpolicy class="ch.qos.logback.core.rolling.timebasedrollingpolicy">\n      <filenamepattern>${user.dir}/logs/${dir_name}/error.%d{yyyy-mm-dd}.log</filenamepattern>\n      <maxhistory>30</maxhistory>\n    </rollingpolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringpolicy class="ch.qos.logback.core.rolling.sizebasedtriggeringpolicy">\n      <maxfilesize>10mb</maxfilesize>\n    </triggeringpolicy>\n\n    <filter class="ch.qos.logback.classic.filter.levelfilter">\n      <level>error</level>\n      <onmatch>accept</onmatch>\n      <onmismatch>deny</onmismatch>\n    </filter>\n\n    <encoder>\n      <pattern>%d{hh:mm:ss.sss} [%thread] [%-5p] %c{36}.%m - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  <appender name="warn" class="ch.qos.logback.core.rolling.rollingfileappender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingpolicy class="ch.qos.logback.core.rolling.timebasedrollingpolicy">\n      <filenamepattern>${user.dir}/logs/${dir_name}/warn.%d{yyyy-mm-dd}.log</filenamepattern>\n      <maxhistory>30</maxhistory>\n    </rollingpolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringpolicy class="ch.qos.logback.core.rolling.sizebasedtriggeringpolicy">\n      <maxfilesize>10mb</maxfilesize>\n    </triggeringpolicy>\n\n    <filter class="ch.qos.logback.classic.filter.levelfilter">\n      <level>warn</level>\n      <onmatch>accept</onmatch>\n      <onmismatch>deny</onmismatch>\n    </filter>\n\n    <encoder>\n      <pattern>%d{hh:mm:ss.sss} [%thread] [%-5p] %c{36}.%m - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  <appender name="info" class="ch.qos.logback.core.rolling.rollingfileappender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingpolicy class="ch.qos.logback.core.rolling.timebasedrollingpolicy">\n      <filenamepattern>${user.dir}/logs/${dir_name}/info.%d{yyyy-mm-dd}.log</filenamepattern>\n      <maxhistory>30</maxhistory>\n    </rollingpolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringpolicy class="ch.qos.logback.core.rolling.sizebasedtriggeringpolicy">\n      <maxfilesize>10mb</maxfilesize>\n    </triggeringpolicy>\n\n    <filter class="ch.qos.logback.classic.filter.levelfilter">\n      <level>info</level>\n      <onmatch>accept</onmatch>\n      <onmismatch>deny</onmismatch>\n    </filter>\n\n    <encoder>\n      <pattern>%d{hh:mm:ss.sss} [%thread] [%-5p] %c{36}.%m - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  <appender name="debug" class="ch.qos.logback.core.rolling.rollingfileappender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingpolicy class="ch.qos.logback.core.rolling.timebasedrollingpolicy">\n      <filenamepattern>${user.dir}/logs/${dir_name}/debug.%d{yyyy-mm-dd}.log</filenamepattern>\n      <maxhistory>30</maxhistory>\n    </rollingpolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringpolicy class="ch.qos.logback.core.rolling.sizebasedtriggeringpolicy">\n      <maxfilesize>10mb</maxfilesize>\n    </triggeringpolicy>\n\n    <filter class="ch.qos.logback.classic.filter.levelfilter">\n      <level>debug</level>\n      <onmatch>accept</onmatch>\n      <onmismatch>deny</onmismatch>\n    </filter>\n\n    <encoder>\n      <pattern>%d{hh:mm:ss.sss} [%thread] [%-5p] %c{36}.%m - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  <appender name="trace" class="ch.qos.logback.core.rolling.rollingfileappender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingpolicy class="ch.qos.logback.core.rolling.timebasedrollingpolicy">\n      <filenamepattern>${user.dir}/logs/${dir_name}/trace.%d{yyyy-mm-dd}.log</filenamepattern>\n      <maxhistory>30</maxhistory>\n    </rollingpolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringpolicy class="ch.qos.logback.core.rolling.sizebasedtriggeringpolicy">\n      <maxfilesize>10mb</maxfilesize>\n    </triggeringpolicy>\n\n    <filter class="ch.qos.logback.classic.filter.levelfilter">\n      <level>trace</level>\n      <onmatch>accept</onmatch>\n      <onmismatch>deny</onmismatch>\n    </filter>\n\n    <encoder>\n      <pattern>%d{hh:mm:ss.sss} [%thread] [%-5p] %c{36}.%m - %m%n</pattern>\n    </encoder>\n  </appender>\n\n  <appender name="spring" class="ch.qos.logback.core.rolling.rollingfileappender">\n    \x3c!-- 根据时间来制定滚动策略 --\x3e\n    <rollingpolicy class="ch.qos.logback.core.rolling.timebasedrollingpolicy">\n      <filenamepattern>${user.dir}/logs/${dir_name}/springframework.%d{yyyy-mm-dd}.log\n      </filenamepattern>\n      <maxhistory>30</maxhistory>\n    </rollingpolicy>\n\n    \x3c!-- 根据文件大小来制定滚动策略 --\x3e\n    <triggeringpolicy class="ch.qos.logback.core.rolling.sizebasedtriggeringpolicy">\n      <maxfilesize>10mb</maxfilesize>\n    </triggeringpolicy>\n\n    <encoder>\n      <pattern>%d{hh:mm:ss.sss} [%thread] [%-5p] %c{36}.%m - %m%n</pattern>\n    </encoder>\n  </appender>\n  \x3c!-- rollingfileappender end --\x3e\n\n  \x3c!-- logger begin --\x3e\n  \x3c!-- 本项目的日志记录，分级打印 --\x3e\n  <logger name="org.zp.notes.spring" level="trace" additivity="false">\n    <appender-ref ref="stdout"/>\n    <appender-ref ref="error"/>\n    <appender-ref ref="warn"/>\n    <appender-ref ref="info"/>\n    <appender-ref ref="debug"/>\n    <appender-ref ref="trace"/>\n  </logger>\n\n  \x3c!-- spring框架日志 --\x3e\n  <logger name="org.springframework" level="warn" additivity="false">\n    <appender-ref ref="spring"/>\n  </logger>\n\n  <root level="trace">\n    <appender-ref ref="all"/>\n  </root>\n  \x3c!-- logger end --\x3e\n\n</configuration>\n\n\n\n# log4j 配置\n\n\n# 完整的 log4j.xml 参考示例\n\nlog4j 的配置文件一般有 xml 格式或 properties 格式。这里为了和 logback.xml 做个对比，就不介绍 properties 了，其实也没太大差别。\n\n<?xml version="1.0" encoding="utf-8"?>\n<!doctype log4j:configuration system "log4j.dtd">\n\n<log4j:configuration xmlns:log4j=\'http://jakarta.apache.org/log4j/\'>\n\n  <appender name="stdout" class="org.apache.log4j.consoleappender">\n    <layout class="org.apache.log4j.patternlayout">\n      <param name="conversionpattern"\n             value="%d{yyyy-mm-dd hh:mm:ss,sss\\} [%-5p] [%t] %c{36\\}.%m - %m%n"/>\n    </layout>\n\n    \x3c!--过滤器设置输出的级别--\x3e\n    <filter class="org.apache.log4j.varia.levelrangefilter">\n      <param name="levelmin" value="debug"/>\n      <param name="levelmax" value="fatal"/>\n      <param name="acceptonmatch" value="true"/>\n    </filter>\n  </appender>\n\n\n  <appender name="all" class="org.apache.log4j.dailyrollingfileappender">\n    <param name="file" value="${user.dir}/logs/spring-common/jcl/all"/>\n    <param name="append" value="true"/>\n    \x3c!-- 每天重新生成日志文件 --\x3e\n    <param name="datepattern" value="\'-\'yyyy-mm-dd\'.log\'"/>\n    \x3c!-- 每小时重新生成日志文件 --\x3e\n    \x3c!--<param name="datepattern" value="\'-\'yyyy-mm-dd-hh\'.log\'"/>--\x3e\n    <layout class="org.apache.log4j.patternlayout">\n      <param name="conversionpattern"\n             value="%d{yyyy-mm-dd hh:mm:ss,sss\\} [%-5p] [%t] %c{36\\}.%m - %m%n"/>\n    </layout>\n  </appender>\n\n  \x3c!-- 指定logger的设置，additivity指示是否遵循缺省的继承机制--\x3e\n  <logger name="org.zp.notes.spring" additivity="false">\n    <level value="error"/>\n    <appender-ref ref="stdout"/>\n    <appender-ref ref="all"/>\n  </logger>\n\n  \x3c!-- 根logger的设置--\x3e\n  <root>\n    <level value="warn"/>\n    <appender-ref ref="stdout"/>\n  </root>\n</log4j:configuration>\n\n\n\n# 参考\n\n * slf4 官方文档\n * logback 官方文档\n * log4j 官方文档\n * commons-logging 官方文档\n * http://blog.csdn.net/yycdaizi/article/details/8276265',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"javalib-util",frontmatter:{title:"javalib-util",categories:["编程","Java","工具"],tags:["Java","工具包"],abbrlink:"8280ff5f",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/14e432/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/99.%E5%85%B6%E4%BB%96/02.Java%E5%B7%A5%E5%85%B7%E5%8C%85.html",relativePath:"12.工具/99.其他/02.Java工具包.md",key:"v-dbf118bc",path:"/pages/14e432/",headersStr:null,content:"# 细说 Java 主流工具包\n\n * apache.commons\n   * commons-lang\n   * commons-collections\n   * common-io\n * guava",normalizedContent:"# 细说 java 主流工具包\n\n * apache.commons\n   * commons-lang\n   * commons-collections\n   * common-io\n * guava",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Reflections 快速入门",frontmatter:{title:"Reflections 快速入门",categories:["编程","Java","工具"],tags:["Java","反射","Reflections"],abbrlink:"3e51d2b2",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/ea4914/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/99.%E5%85%B6%E4%BB%96/03.Reflections.html",relativePath:"12.工具/99.其他/03.Reflections.md",key:"v-65004ca6",path:"/pages/ea4914/",headers:[{level:2,title:"使用",slug:"使用",normalizedTitle:"使用",charIndex:403},{level:2,title:"ReflectionUtils",slug:"reflectionutils",normalizedTitle:"reflectionutils",charIndex:2194}],headersStr:"使用 ReflectionUtils",content:'# Reflections 快速入门\n\n引入 pom\n\n<dependency>\n    <groupId>org.reflections</groupId>\n    <artifactId>reflections</artifactId>\n    <version>0.9.11</version>\n</dependency>\n\n\n典型应用\n\nReflections reflections = new Reflections("my.project");\nSet<Class<? extends SomeType>> subTypes = reflections.getSubTypesOf(SomeType.class);\nSet<Class<?>> annotated = reflections.getTypesAnnotatedWith(SomeAnnotation.class);\n\n\n\n# 使用\n\n基本上，使用 Reflections 首先使用 urls 和 scanners 对其进行实例化\n\n//scan urls that contain \'my.package\', include inputs starting with \'my.package\', use the default scanners\nReflections reflections = new Reflections("my.package");\n\n//or using ConfigurationBuilder\nnew Reflections(new ConfigurationBuilder()\n     .setUrls(ClasspathHelper.forPackage("my.project.prefix"))\n     .setScanners(new SubTypesScanner(),\n                  new TypeAnnotationsScanner().filterResultsBy(optionalFilter), ...),\n     .filterInputsBy(new FilterBuilder().includePackage("my.project.prefix"))\n     ...);\n\n\n然后，使用方便的查询方法\n\n// 子类型扫描\nSet<Class<? extends Module>> modules =\n    reflections.getSubTypesOf(com.google.inject.Module.class);\n// 类型注解扫描\nSet<Class<?>> singletons =\n    reflections.getTypesAnnotatedWith(javax.inject.Singleton.class);\n// 资源扫描\nSet<String> properties =\n    reflections.getResources(Pattern.compile(".*\\\\.properties"));\n// 方法注解扫描\nSet<Method> resources =\n    reflections.getMethodsAnnotatedWith(javax.ws.rs.Path.class);\nSet<Constructor> injectables =\n    reflections.getConstructorsAnnotatedWith(javax.inject.Inject.class);\n// 字段注解扫描\nSet<Field> ids =\n    reflections.getFieldsAnnotatedWith(javax.persistence.Id.class);\n// 方法参数扫描\nSet<Method> someMethods =\n    reflections.getMethodsMatchParams(long.class, int.class);\nSet<Method> voidMethods =\n    reflections.getMethodsReturn(void.class);\nSet<Method> pathParamMethods =\n    reflections.getMethodsWithAnyParamAnnotated(PathParam.class);\n// 方法参数名扫描\nList<String> parameterNames =\n    reflections.getMethodParamNames(Method.class)\n// 方法使用扫描\nSet<Member> usages =\n    reflections.getMethodUsages(Method.class)\n\n\n说明：\n\n * 如果未配置扫描程序，则将使用默认值 - SubTypesScanner 和 TypeAnnotationsScanner。\n * 还可以配置类加载器，它将用于从名称中解析运行时类。\n * Reflection 默认情况下会扩展超类型。 这解决了传输 URL 不被扫描的一些问题。\n\n\n# ReflectionUtils\n\nimport static org.reflections.ReflectionUtils.*;\n\nSet<Method> getters = getAllMethods(someClass,\n  withModifier(Modifier.PUBLIC), withPrefix("get"), withParametersCount(0));\n\n//or\nSet<Method> listMethodsFromCollectionToBoolean =\n  getAllMethods(List.class,\n    withParametersAssignableTo(Collection.class), withReturnType(boolean.class));\n\nSet<Field> fields = getAllFields(SomeClass.class, withAnnotation(annotation), withTypeAssignableTo(type));\n',normalizedContent:'# reflections 快速入门\n\n引入 pom\n\n<dependency>\n    <groupid>org.reflections</groupid>\n    <artifactid>reflections</artifactid>\n    <version>0.9.11</version>\n</dependency>\n\n\n典型应用\n\nreflections reflections = new reflections("my.project");\nset<class<? extends sometype>> subtypes = reflections.getsubtypesof(sometype.class);\nset<class<?>> annotated = reflections.gettypesannotatedwith(someannotation.class);\n\n\n\n# 使用\n\n基本上，使用 reflections 首先使用 urls 和 scanners 对其进行实例化\n\n//scan urls that contain \'my.package\', include inputs starting with \'my.package\', use the default scanners\nreflections reflections = new reflections("my.package");\n\n//or using configurationbuilder\nnew reflections(new configurationbuilder()\n     .seturls(classpathhelper.forpackage("my.project.prefix"))\n     .setscanners(new subtypesscanner(),\n                  new typeannotationsscanner().filterresultsby(optionalfilter), ...),\n     .filterinputsby(new filterbuilder().includepackage("my.project.prefix"))\n     ...);\n\n\n然后，使用方便的查询方法\n\n// 子类型扫描\nset<class<? extends module>> modules =\n    reflections.getsubtypesof(com.google.inject.module.class);\n// 类型注解扫描\nset<class<?>> singletons =\n    reflections.gettypesannotatedwith(javax.inject.singleton.class);\n// 资源扫描\nset<string> properties =\n    reflections.getresources(pattern.compile(".*\\\\.properties"));\n// 方法注解扫描\nset<method> resources =\n    reflections.getmethodsannotatedwith(javax.ws.rs.path.class);\nset<constructor> injectables =\n    reflections.getconstructorsannotatedwith(javax.inject.inject.class);\n// 字段注解扫描\nset<field> ids =\n    reflections.getfieldsannotatedwith(javax.persistence.id.class);\n// 方法参数扫描\nset<method> somemethods =\n    reflections.getmethodsmatchparams(long.class, int.class);\nset<method> voidmethods =\n    reflections.getmethodsreturn(void.class);\nset<method> pathparammethods =\n    reflections.getmethodswithanyparamannotated(pathparam.class);\n// 方法参数名扫描\nlist<string> parameternames =\n    reflections.getmethodparamnames(method.class)\n// 方法使用扫描\nset<member> usages =\n    reflections.getmethodusages(method.class)\n\n\n说明：\n\n * 如果未配置扫描程序，则将使用默认值 - subtypesscanner 和 typeannotationsscanner。\n * 还可以配置类加载器，它将用于从名称中解析运行时类。\n * reflection 默认情况下会扩展超类型。 这解决了传输 url 不被扫描的一些问题。\n\n\n# reflectionutils\n\nimport static org.reflections.reflectionutils.*;\n\nset<method> getters = getallmethods(someclass,\n  withmodifier(modifier.public), withprefix("get"), withparameterscount(0));\n\n//or\nset<method> listmethodsfromcollectiontoboolean =\n  getallmethods(list.class,\n    withparametersassignableto(collection.class), withreturntype(boolean.class));\n\nset<field> fields = getallfields(someclass.class, withannotation(annotation), withtypeassignableto(type));\n',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"JavaMail 快速入门",frontmatter:{title:"JavaMail 快速入门",categories:["编程","Java","工具"],tags:["Java","邮件"],abbrlink:"83e73e",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/da3f07/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/99.%E5%85%B6%E4%BB%96/04.JavaMail.html",relativePath:"12.工具/99.其他/04.JavaMail.md",key:"v-35c0dec5",path:"/pages/da3f07/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:20},{level:3,title:"邮件相关的标准",slug:"邮件相关的标准",normalizedTitle:"邮件相关的标准",charIndex:27},{level:3,title:"JavaMail 简介",slug:"javamail-简介",normalizedTitle:"javamail 简介",charIndex:458},{level:3,title:"邮件传输过程",slug:"邮件传输过程",normalizedTitle:"邮件传输过程",charIndex:780},{level:3,title:"Message 结构",slug:"message-结构",normalizedTitle:"message 结构",charIndex:1016},{level:2,title:"JavaMail 的核心类",slug:"javamail-的核心类",normalizedTitle:"javamail 的核心类",charIndex:1144},{level:3,title:"java.util.Properties 类（属性对象）",slug:"java-util-properties-类-属性对象",normalizedTitle:"java.util.properties 类（属性对象）",charIndex:1232},{level:3,title:"javax.mail.Session 类（会话对象）",slug:"javax-mail-session-类-会话对象",normalizedTitle:"javax.mail.session 类（会话对象）",charIndex:2117},{level:3,title:"javax.mail.Transport 类（邮件传输）",slug:"javax-mail-transport-类-邮件传输",normalizedTitle:"javax.mail.transport 类（邮件传输）",charIndex:2597},{level:3,title:"javax.mail.Store 类（邮件存储 ）",slug:"javax-mail-store-类-邮件存储",normalizedTitle:"javax.mail.store 类（邮件存储 ）",charIndex:3011},{level:3,title:"javax.mail.Message 类（消息对象）",slug:"javax-mail-message-类-消息对象",normalizedTitle:"javax.mail.message 类（消息对象）",charIndex:3292},{level:3,title:"javax.mail.Address 类（地址）",slug:"javax-mail-address-类-地址",normalizedTitle:"javax.mail.address 类（地址）",charIndex:3840},{level:3,title:"Authenticator 类（认证者）",slug:"authenticator-类-认证者",normalizedTitle:"authenticator 类（认证者）",charIndex:4102},{level:2,title:"实例",slug:"实例",normalizedTitle:"实例",charIndex:2301},{level:3,title:"发送文本邮件",slug:"发送文本邮件",normalizedTitle:"发送文本邮件",charIndex:4759},{level:3,title:"发送 HTML 格式的邮件",slug:"发送-html-格式的邮件",normalizedTitle:"发送 html 格式的邮件",charIndex:5899},{level:3,title:"发送带附件的邮件",slug:"发送带附件的邮件",normalizedTitle:"发送带附件的邮件",charIndex:7594},{level:3,title:"获取邮箱中的邮件",slug:"获取邮箱中的邮件",normalizedTitle:"获取邮箱中的邮件",charIndex:9240},{level:3,title:"转发邮件",slug:"转发邮件",normalizedTitle:"转发邮件",charIndex:10289}],headersStr:"简介 邮件相关的标准 JavaMail 简介 邮件传输过程 Message 结构 JavaMail 的核心类 java.util.Properties 类（属性对象） javax.mail.Session 类（会话对象） javax.mail.Transport 类（邮件传输） javax.mail.Store 类（邮件存储 ） javax.mail.Message 类（消息对象） javax.mail.Address 类（地址） Authenticator 类（认证者） 实例 发送文本邮件 发送 HTML 格式的邮件 发送带附件的邮件 获取邮箱中的邮件 转发邮件",content:'# JavaMail 快速入门\n\n\n# 简介\n\n\n# 邮件相关的标准\n\n厂商所提供的 JavaMail 服务程序可以有选择地实现某些邮件协议，常见的邮件协议包括：\n\n * SMTP(Simple Mail Transfer Protocol) ：即简单邮件传输协议，它是一组用于由源地址到目的地址传送邮件的规则，由它来控制信件的中转方式。\n * POP3(Post Office Protocol - Version 3) ：即邮局协议版本 3 ，用于接收电子邮件的标准协议。\n * IMAP(Internet Mail Access Protocol) ：即 Internet 邮件访问协议。是 POP3 的替代协议。\n\n这三种协议都有对应 SSL 加密传输的协议，分别是 SMTPS， POP3S和 IMAPS。\n\nMIME(Multipurpose Internet Mail Extensions) ：即多用途因特网邮件扩展标准。它不是邮件传输协议。但对传输内容的消息、附件及其它的内容定义了格式。\n\n\n# JavaMail 简介\n\nJavaMail 是由 Sun 发布的用来处理 email 的 API 。它并没有包含在 Java SE 中，而是作为 Java EE 的一部分。\n\n * mail.jar ：此 JAR 文件包含 JavaMail API 和 Sun 提供的 SMTP 、 IMAP 和 POP3 服务提供程序；\n * activation.jar ：此 JAR 文件包含 JAF API 和 Sun 的实现。\n\nJavaMail 包中用于处理电子邮件的核心类是： Properties 、 Session 、 Message 、 Address 、 Authenticator 、 Transport 、 Store 等。\n\n\n# 邮件传输过程\n\n如上图，电子邮件的处理步骤如下：\n\n 1. 创建一个 Session 对象。\n 2. Session 对象创建一个 Transport 对象 /Store 对象，用来发送 / 保存邮件。\n 3. Transport 对象 /Store 对象连接邮件服务器。\n 4. Transport 对象 /Store 对象创建一个 Message 对象 ( 也就是邮件内容 ) 。\n 5. Transport 对象发送邮件； Store 对象获取邮箱的邮件。\n\n\n# Message 结构\n\n * MimeMessage 类：代表整封邮件。\n * MimeBodyPart 类：代表邮件的一个 MIME 信息。\n * MimeMultipart 类：代表一个由多个 MIME 信息组合成的组合 MIME 信息。\n\n\n\n\n# JavaMail 的核心类\n\nJavaMail 对收发邮件进行了高级的抽象，形成了一些关键的的接口和类，它们构成了程序的基础，下面我们分别来了解一下这些最常见的对象。\n\n\n# java.util.Properties 类（属性对象）\n\njava.util.Properties 类代表一组属性集合。\n\n它的每一个键和值都是 String 类型。\n\n由于 JavaMail 需要和邮件服务器进行通信，这就要求程序提供许多诸如服务器地址、端口、用户名、密码等信息， JavaMail 通过 Properties 对象封装这些属性信息。\n\n例： 如下面的代码封装了几个属性信息：\n\nProperties prop = new Properties();\nprop.setProperty("mail.debug", "true");\nprop.setProperty("mail.host", "[email protected]");\nprop.setProperty("mail.transport.protocol", "smtp");\nprop.setProperty("mail.smtp.auth", "true");\n\n\n针对不同的的邮件协议， JavaMail 规定了服务提供者必须支持一系列属性，\n\n下表是一些常见属性（属性值都以 String 类型进行设置，属性类型栏仅表示属性是如何被解析的）：\n\n关键词                       类型        描述\nmail.debug                boolean   debug 开关。\nmail.host                 String    指定发送、接收邮件的默认邮箱服务器。\nmail.store.protocol       String    指定接收邮件的协议。\nmail.transport.protocol   String    指定发送邮件的协议。\nmail.debug.auth           boolean   debug 输出中是否包含认证命令。默认是 false 。\n\n详情请参考官方 API 文档：\n\nhttps://javamail.java.net/nonav/docs/api/ 。\n\n\n# javax.mail.Session 类（会话对象）\n\nSession 表示一个邮件会话。\n\nSession 的主要作用包括两个方面：\n\n * 接收各种配置属性信息：通过 Properties 对象设置的属性信息；\n * 初始化 JavaMail 环境：根据 JavaMail 的配置文件，初始化 JavaMail 环境，以便通过 Session 对象创建其他重要类的实例。\n\nJavaMail 在 Jar 包的 META-INF 目录下，通过以下文件提供了基本配置信息，以便 session 能够根据这个配置文件加载提供者的实现类：\n\n * javamail.default.providers\n * javamail.default.address.map\n\n\n\n例：\n\nProperties props = new Properties();\nprops.setProperty("mail.transport.protocol", "smtp");\nSession session = Session.getInstance(props);\n\n\n\n# javax.mail.Transport 类（邮件传输）\n\n邮件操作只有发送或接收两种处理方式。\n\nJavaMail 将这两种不同操作描述为传输（ javax.mail.Transport ）和存储（ javax.mail.Store ），传输对应邮件的发送，而存储对应邮件的接收。\n\n * getTransport - Session 类中的 **getTransport()**有多个重载方法，可以用来创建 Transport 对象。\n * connect - 如果设置了认证命令—— mail.smtp.auth ，那么使用 Transport 类的 connect 方法连接服务器时，则必须加上用户名和密码。\n * sendMessage - Transport 类的 sendMessage 方法用来发送邮件消息。\n * close - Transport 类的 close 方法用来关闭和邮件服务器的连接。\n\n\n# javax.mail.Store 类（邮件存储 ）\n\n * getStore - Session 类中的 getStore () 有多个重载方法，可以用来创建 Store 对象。\n * connect - 如果设置了认证命令—— mail.smtp.auth ，那么使用 Store 类的 connect 方法连接服务器时，则必须加上用户名和密码。\n * getFolder - Store 类的 getFolder 方法可以 获取邮箱内的邮件夹 Folder 对象\n * close - Store 类的 close 方法用来关闭和邮件服务器的连接。\n\n\n# javax.mail.Message 类（消息对象）\n\n * javax.mail.Message - 是个抽象类，只能用子类去实例化，多数情况下为 javax.mail.internet.MimeMessage。\n * MimeMessage - 代表 MIME 类型的电子邮件消息。\n\n要创建一个 Message ，需要将 Session 对象传递给 MimeMessage 构造器：\n\nMimeMessage message = new MimeMessage(session);\n\n\n注意：还存在其它构造器，如用按 RFC822 格式的输入流来创建消息。\n\n * setFrom - 设置邮件的发件人\n * setRecipient - 设置邮件的发送人、抄送人、密送人\n\n三种预定义的地址类型是：\n\n * Message.RecipientType.TO - 收件人\n * Message.RecipientType.CC - 抄送人\n * Message.RecipientType.BCC - 密送人\n * setSubject - 设置邮件的主题\n * setContent - 设置邮件内容\n * setText - 如果邮件内容是纯文本，可以使用此接口设置文本内容。\n\n\n# javax.mail.Address 类（地址）\n\n一旦您创建了 Session 和 Message ，并将内容填入消息后，就可以用 Address 确定信件地址了。和 Message 一样， Address 也是个抽象类。您用的是 javax.mail.internet.InternetAddress 类。\n\n若创建的地址只包含电子邮件地址，只要传递电子邮件地址到构造器就行了。\n\n例：\n\nAddress address = new InternetAddress("[email protected]");\n\n\n\n# Authenticator 类（认证者）\n\n与 java.net 类一样， JavaMail API 也可以利用 Authenticator 通过用户名和密码访问受保护的资源。对于 JavaMail API 来说，这些资源就是邮件服务器。Authenticator 在 javax.mail 包中，而且它和 java.net 中同名的类 Authenticator 不同。两者并不共享同一个 Authenticator ，因为 JavaMail API 用于 Java 1.1 ，它没有 java.net 类别。\n\n要使用 Authenticator ，先创建一个抽象类的子类，并从 getPasswordAuthentication() 方法中返回 PasswordAuthentication 实例。创建完成后，您必需向 session 注册 Authenticator 。然后，在需要认证的时候，就会通知 Authenticator 。您可以弹出窗口，也可以从配置文件中（虽然没有加密是不安全的）读取用户名和密码，将它们作为 PasswordAuthentication 对象返回给调用程序。\n\n例：\n\nProperties props = new Properties();\nAuthenticator auth = new MyAuthenticator();\nSession session = Session.getDefaultInstance(props, auth);\n\n\n\n# 实例\n\n\n# 发送文本邮件\n\npublic static void main(String[] args) throws Exception {\n    Properties prop = new Properties();\n    prop.setProperty("mail.debug", "true");\n    prop.setProperty("mail.host", MAIL_SERVER_HOST);\n    prop.setProperty("mail.transport.protocol", "smtp");\n    prop.setProperty("mail.smtp.auth", "true");\n\n    // 1、创建session\n    Session session = Session.getInstance(prop);\n    Transport ts = null;\n\n    // 2、通过session得到transport对象\n    ts = session.getTransport();\n\n    // 3、连上邮件服务器\n    ts.connect(MAIL_SERVER_HOST, USER, PASSWORD);\n\n    // 4、创建邮件\n    MimeMessage message = new MimeMessage(session);\n\n    // 邮件消息头\n    message.setFrom(new InternetAddress(MAIL_FROM)); // 邮件的发件人\n    message.setRecipient(Message.RecipientType.TO, new InternetAddress(MAIL_TO)); // 邮件的收件人\n    message.setRecipient(Message.RecipientType.CC, new InternetAddress(MAIL_CC)); // 邮件的抄送人\n    message.setRecipient(Message.RecipientType.BCC, new InternetAddress(MAIL_BCC)); // 邮件的密送人\n    message.setSubject("测试文本邮件"); // 邮件的标题\n\n    // 邮件消息体\n    message.setText("天下无双。");\n\n    // 5、发送邮件\n    ts.sendMessage(message, message.getAllRecipients());\n    ts.close();\n}\n\n\n\n# 发送 HTML 格式的邮件\n\npublic static void main(String[] args) throws Exception {\n    Properties prop = new Properties();\n    prop.setProperty("mail.debug", "true");\n    prop.setProperty("mail.host", MAIL_SERVER_HOST);\n    prop.setProperty("mail.transport.protocol", "smtp");\n    prop.setProperty("mail.smtp.auth", "true");\n\n    // 1、创建session\n    Session session = Session.getInstance(prop);\n    Transport ts = null;\n\n    // 2、通过session得到transport对象\n    ts = session.getTransport();\n\n    // 3、连上邮件服务器\n    ts.connect(MAIL_SERVER_HOST, USER, PASSWORD);\n\n    // 4、创建邮件\n    MimeMessage message = new MimeMessage(session);\n\n    // 邮件消息头\n    message.setFrom(new InternetAddress(MAIL_FROM)); // 邮件的发件人\n    message.setRecipient(Message.RecipientType.TO, new InternetAddress(MAIL_TO)); // 邮件的收件人\n    message.setRecipient(Message.RecipientType.CC, new InternetAddress(MAIL_CC)); // 邮件的抄送人\n    message.setRecipient(Message.RecipientType.BCC, new InternetAddress(MAIL_BCC)); // 邮件的密送人\n    message.setSubject("测试HTML邮件"); // 邮件的标题\n\n    String htmlContent = "<h1>Hello</h1>" + "<p>显示图片<img src=\'cid:abc.jpg\'>1.jpg</p>";\n    MimeBodyPart text = new MimeBodyPart();\n    text.setContent(htmlContent, "text/html;charset=UTF-8");\n    MimeBodyPart image = new MimeBodyPart();\n    DataHandler dh = new DataHandler(new FileDataSource("D:\\\\05_Datas\\\\图库\\\\吉他少年背影.png"));\n    image.setDataHandler(dh);\n    image.setContentID("abc.jpg");\n\n    // 描述数据关系\n    MimeMultipart mm = new MimeMultipart();\n    mm.addBodyPart(text);\n    mm.addBodyPart(image);\n    mm.setSubType("related");\n    message.setContent(mm);\n    message.saveChanges();\n\n    // 5、发送邮件\n    ts.sendMessage(message, message.getAllRecipients());\n    ts.close();\n}\n\n\n\n# 发送带附件的邮件\n\npublic static void main(String[] args) throws Exception {\n    Properties prop = new Properties();\n    prop.setProperty("mail.debug", "true");\n    prop.setProperty("mail.host", MAIL_SERVER_HOST);\n    prop.setProperty("mail.transport.protocol", "smtp");\n    prop.setProperty("mail.smtp.auth", "true");\n\n    // 1、创建session\n    Session session = Session.getInstance(prop);\n\n    // 2、通过session得到transport对象\n    Transport ts = session.getTransport();\n\n    // 3、连上邮件服务器\n    ts.connect(MAIL_SERVER_HOST, USER, PASSWORD);\n\n    // 4、创建邮件\n    MimeMessage message = new MimeMessage(session);\n\n    // 邮件消息头\n    message.setFrom(new InternetAddress(MAIL_FROM)); // 邮件的发件人\n    message.setRecipient(Message.RecipientType.TO, new InternetAddress(MAIL_TO)); // 邮件的收件人\n    message.setRecipient(Message.RecipientType.CC, new InternetAddress(MAIL_CC)); // 邮件的抄送人\n    message.setRecipient(Message.RecipientType.BCC, new InternetAddress(MAIL_BCC)); // 邮件的密送人\n    message.setSubject("测试带附件邮件"); // 邮件的标题\n\n    MimeBodyPart text = new MimeBodyPart();\n    text.setContent("邮件中有两个附件。", "text/html;charset=UTF-8");\n\n    // 描述数据关系\n    MimeMultipart mm = new MimeMultipart();\n    mm.setSubType("related");\n    mm.addBodyPart(text);\n    String[] files = {\n            "D:\\\\00_Temp\\\\temp\\\\1.jpg", "D:\\\\00_Temp\\\\temp\\\\2.png"\n    };\n\n    // 添加邮件附件\n    for (String filename : files) {\n        MimeBodyPart attachPart = new MimeBodyPart();\n        attachPart.attachFile(filename);\n        mm.addBodyPart(attachPart);\n    }\n\n    message.setContent(mm);\n    message.saveChanges();\n\n    // 5、发送邮件\n    ts.sendMessage(message, message.getAllRecipients());\n    ts.close();\n}\n\n\n\n# 获取邮箱中的邮件\n\n public static void main(String[] args) throws Exception {\n\n    // 创建一个有具体连接信息的Properties对象\n    Properties prop = new Properties();\n    prop.setProperty("mail.debug", "true");\n    prop.setProperty("mail.store.protocol", "pop3");\n    prop.setProperty("mail.pop3.host", MAIL_SERVER_HOST);\n\n    // 1、创建session\n    Session session = Session.getInstance(prop);\n\n    // 2、通过session得到Store对象\n    Store store = session.getStore();\n\n    // 3、连上邮件服务器\n    store.connect(MAIL_SERVER_HOST, USER, PASSWORD);\n\n    // 4、获得邮箱内的邮件夹\n    Folder folder = store.getFolder("inbox");\n    folder.open(Folder.READ_ONLY);\n\n    // 获得邮件夹Folder内的所有邮件Message对象\n    Message[] messages = folder.getMessages();\n    for (int i = 0; i < messages.length; i++) {\n        String subject = messages[i].getSubject();\n        String from = (messages[i].getFrom()[0]).toString();\n        System.out.println("第 " + (i + 1) + "封邮件的主题：" + subject);\n        System.out.println("第 " + (i + 1) + "封邮件的发件人地址：" + from);\n    }\n\n    // 5、关闭\n    folder.close(false);\n    store.close();\n}\n\n\n\n# 转发邮件\n\n例：获取指定邮件夹下的第一封邮件并转发\n\n public static void main(String[] args) throws Exception {\n    Properties prop = new Properties();\n    prop.put("mail.store.protocol", "pop3");\n    prop.put("mail.pop3.host", MAIL_SERVER_POP3);\n    prop.put("mail.pop3.starttls.enable", "true");\n    prop.put("mail.smtp.auth", "true");\n    prop.put("mail.smtp.host", MAIL_SERVER_SMTP);\n\n    // 1、创建session\n    Session session = Session.getDefaultInstance(prop);\n\n    // 2、读取邮件夹\n    Store store = session.getStore("pop3");\n    store.connect(MAIL_SERVER_POP3, USER, PASSWORD);\n    Folder folder = store.getFolder("inbox");\n    folder.open(Folder.READ_ONLY);\n\n    // 获取邮件夹中第1封邮件信息\n    Message[] messages = folder.getMessages();\n    if (messages.length <= 0) {\n        return;\n    }\n    Message message = messages[0];\n\n    // 打印邮件关键信息\n    String from = InternetAddress.toString(message.getFrom());\n    if (from != null) {\n        System.out.println("From: " + from);\n    }\n\n    String replyTo = InternetAddress.toString(message.getReplyTo());\n    if (replyTo != null) {\n        System.out.println("Reply-to: " + replyTo);\n    }\n\n    String to = InternetAddress.toString(message.getRecipients(Message.RecipientType.TO));\n    if (to != null) {\n        System.out.println("To: " + to);\n    }\n\n    String subject = message.getSubject();\n    if (subject != null) {\n        System.out.println("Subject: " + subject);\n    }\n\n    Date sent = message.getSentDate();\n    if (sent != null) {\n        System.out.println("Sent: " + sent);\n    }\n\n    // 设置转发邮件信息头\n    Message forward = new MimeMessage(session);\n    forward.setFrom(new InternetAddress(MAIL_FROM));\n    forward.setRecipient(Message.RecipientType.TO, new InternetAddress(MAIL_TO));\n    forward.setSubject("Fwd: " + message.getSubject());\n\n    // 设置转发邮件内容\n    MimeBodyPart bodyPart = new MimeBodyPart();\n    bodyPart.setContent(message, "message/rfc822");\n\n    Multipart multipart = new MimeMultipart();\n    multipart.addBodyPart(bodyPart);\n    forward.setContent(multipart);\n    forward.saveChanges();\n\n    Transport ts = session.getTransport("smtp");\n    ts.connect(USER, PASSWORD);\n    ts.sendMessage(forward, forward.getAllRecipients());\n\n    folder.close(false);\n    store.close();\n    ts.close();\n    System.out.println("message forwarded successfully....");\n}\n',normalizedContent:'# javamail 快速入门\n\n\n# 简介\n\n\n# 邮件相关的标准\n\n厂商所提供的 javamail 服务程序可以有选择地实现某些邮件协议，常见的邮件协议包括：\n\n * smtp(simple mail transfer protocol) ：即简单邮件传输协议，它是一组用于由源地址到目的地址传送邮件的规则，由它来控制信件的中转方式。\n * pop3(post office protocol - version 3) ：即邮局协议版本 3 ，用于接收电子邮件的标准协议。\n * imap(internet mail access protocol) ：即 internet 邮件访问协议。是 pop3 的替代协议。\n\n这三种协议都有对应 ssl 加密传输的协议，分别是 smtps， pop3s和 imaps。\n\nmime(multipurpose internet mail extensions) ：即多用途因特网邮件扩展标准。它不是邮件传输协议。但对传输内容的消息、附件及其它的内容定义了格式。\n\n\n# javamail 简介\n\njavamail 是由 sun 发布的用来处理 email 的 api 。它并没有包含在 java se 中，而是作为 java ee 的一部分。\n\n * mail.jar ：此 jar 文件包含 javamail api 和 sun 提供的 smtp 、 imap 和 pop3 服务提供程序；\n * activation.jar ：此 jar 文件包含 jaf api 和 sun 的实现。\n\njavamail 包中用于处理电子邮件的核心类是： properties 、 session 、 message 、 address 、 authenticator 、 transport 、 store 等。\n\n\n# 邮件传输过程\n\n如上图，电子邮件的处理步骤如下：\n\n 1. 创建一个 session 对象。\n 2. session 对象创建一个 transport 对象 /store 对象，用来发送 / 保存邮件。\n 3. transport 对象 /store 对象连接邮件服务器。\n 4. transport 对象 /store 对象创建一个 message 对象 ( 也就是邮件内容 ) 。\n 5. transport 对象发送邮件； store 对象获取邮箱的邮件。\n\n\n# message 结构\n\n * mimemessage 类：代表整封邮件。\n * mimebodypart 类：代表邮件的一个 mime 信息。\n * mimemultipart 类：代表一个由多个 mime 信息组合成的组合 mime 信息。\n\n\n\n\n# javamail 的核心类\n\njavamail 对收发邮件进行了高级的抽象，形成了一些关键的的接口和类，它们构成了程序的基础，下面我们分别来了解一下这些最常见的对象。\n\n\n# java.util.properties 类（属性对象）\n\njava.util.properties 类代表一组属性集合。\n\n它的每一个键和值都是 string 类型。\n\n由于 javamail 需要和邮件服务器进行通信，这就要求程序提供许多诸如服务器地址、端口、用户名、密码等信息， javamail 通过 properties 对象封装这些属性信息。\n\n例： 如下面的代码封装了几个属性信息：\n\nproperties prop = new properties();\nprop.setproperty("mail.debug", "true");\nprop.setproperty("mail.host", "[email protected]");\nprop.setproperty("mail.transport.protocol", "smtp");\nprop.setproperty("mail.smtp.auth", "true");\n\n\n针对不同的的邮件协议， javamail 规定了服务提供者必须支持一系列属性，\n\n下表是一些常见属性（属性值都以 string 类型进行设置，属性类型栏仅表示属性是如何被解析的）：\n\n关键词                       类型        描述\nmail.debug                boolean   debug 开关。\nmail.host                 string    指定发送、接收邮件的默认邮箱服务器。\nmail.store.protocol       string    指定接收邮件的协议。\nmail.transport.protocol   string    指定发送邮件的协议。\nmail.debug.auth           boolean   debug 输出中是否包含认证命令。默认是 false 。\n\n详情请参考官方 api 文档：\n\nhttps://javamail.java.net/nonav/docs/api/ 。\n\n\n# javax.mail.session 类（会话对象）\n\nsession 表示一个邮件会话。\n\nsession 的主要作用包括两个方面：\n\n * 接收各种配置属性信息：通过 properties 对象设置的属性信息；\n * 初始化 javamail 环境：根据 javamail 的配置文件，初始化 javamail 环境，以便通过 session 对象创建其他重要类的实例。\n\njavamail 在 jar 包的 meta-inf 目录下，通过以下文件提供了基本配置信息，以便 session 能够根据这个配置文件加载提供者的实现类：\n\n * javamail.default.providers\n * javamail.default.address.map\n\n\n\n例：\n\nproperties props = new properties();\nprops.setproperty("mail.transport.protocol", "smtp");\nsession session = session.getinstance(props);\n\n\n\n# javax.mail.transport 类（邮件传输）\n\n邮件操作只有发送或接收两种处理方式。\n\njavamail 将这两种不同操作描述为传输（ javax.mail.transport ）和存储（ javax.mail.store ），传输对应邮件的发送，而存储对应邮件的接收。\n\n * gettransport - session 类中的 **gettransport()**有多个重载方法，可以用来创建 transport 对象。\n * connect - 如果设置了认证命令—— mail.smtp.auth ，那么使用 transport 类的 connect 方法连接服务器时，则必须加上用户名和密码。\n * sendmessage - transport 类的 sendmessage 方法用来发送邮件消息。\n * close - transport 类的 close 方法用来关闭和邮件服务器的连接。\n\n\n# javax.mail.store 类（邮件存储 ）\n\n * getstore - session 类中的 getstore () 有多个重载方法，可以用来创建 store 对象。\n * connect - 如果设置了认证命令—— mail.smtp.auth ，那么使用 store 类的 connect 方法连接服务器时，则必须加上用户名和密码。\n * getfolder - store 类的 getfolder 方法可以 获取邮箱内的邮件夹 folder 对象\n * close - store 类的 close 方法用来关闭和邮件服务器的连接。\n\n\n# javax.mail.message 类（消息对象）\n\n * javax.mail.message - 是个抽象类，只能用子类去实例化，多数情况下为 javax.mail.internet.mimemessage。\n * mimemessage - 代表 mime 类型的电子邮件消息。\n\n要创建一个 message ，需要将 session 对象传递给 mimemessage 构造器：\n\nmimemessage message = new mimemessage(session);\n\n\n注意：还存在其它构造器，如用按 rfc822 格式的输入流来创建消息。\n\n * setfrom - 设置邮件的发件人\n * setrecipient - 设置邮件的发送人、抄送人、密送人\n\n三种预定义的地址类型是：\n\n * message.recipienttype.to - 收件人\n * message.recipienttype.cc - 抄送人\n * message.recipienttype.bcc - 密送人\n * setsubject - 设置邮件的主题\n * setcontent - 设置邮件内容\n * settext - 如果邮件内容是纯文本，可以使用此接口设置文本内容。\n\n\n# javax.mail.address 类（地址）\n\n一旦您创建了 session 和 message ，并将内容填入消息后，就可以用 address 确定信件地址了。和 message 一样， address 也是个抽象类。您用的是 javax.mail.internet.internetaddress 类。\n\n若创建的地址只包含电子邮件地址，只要传递电子邮件地址到构造器就行了。\n\n例：\n\naddress address = new internetaddress("[email protected]");\n\n\n\n# authenticator 类（认证者）\n\n与 java.net 类一样， javamail api 也可以利用 authenticator 通过用户名和密码访问受保护的资源。对于 javamail api 来说，这些资源就是邮件服务器。authenticator 在 javax.mail 包中，而且它和 java.net 中同名的类 authenticator 不同。两者并不共享同一个 authenticator ，因为 javamail api 用于 java 1.1 ，它没有 java.net 类别。\n\n要使用 authenticator ，先创建一个抽象类的子类，并从 getpasswordauthentication() 方法中返回 passwordauthentication 实例。创建完成后，您必需向 session 注册 authenticator 。然后，在需要认证的时候，就会通知 authenticator 。您可以弹出窗口，也可以从配置文件中（虽然没有加密是不安全的）读取用户名和密码，将它们作为 passwordauthentication 对象返回给调用程序。\n\n例：\n\nproperties props = new properties();\nauthenticator auth = new myauthenticator();\nsession session = session.getdefaultinstance(props, auth);\n\n\n\n# 实例\n\n\n# 发送文本邮件\n\npublic static void main(string[] args) throws exception {\n    properties prop = new properties();\n    prop.setproperty("mail.debug", "true");\n    prop.setproperty("mail.host", mail_server_host);\n    prop.setproperty("mail.transport.protocol", "smtp");\n    prop.setproperty("mail.smtp.auth", "true");\n\n    // 1、创建session\n    session session = session.getinstance(prop);\n    transport ts = null;\n\n    // 2、通过session得到transport对象\n    ts = session.gettransport();\n\n    // 3、连上邮件服务器\n    ts.connect(mail_server_host, user, password);\n\n    // 4、创建邮件\n    mimemessage message = new mimemessage(session);\n\n    // 邮件消息头\n    message.setfrom(new internetaddress(mail_from)); // 邮件的发件人\n    message.setrecipient(message.recipienttype.to, new internetaddress(mail_to)); // 邮件的收件人\n    message.setrecipient(message.recipienttype.cc, new internetaddress(mail_cc)); // 邮件的抄送人\n    message.setrecipient(message.recipienttype.bcc, new internetaddress(mail_bcc)); // 邮件的密送人\n    message.setsubject("测试文本邮件"); // 邮件的标题\n\n    // 邮件消息体\n    message.settext("天下无双。");\n\n    // 5、发送邮件\n    ts.sendmessage(message, message.getallrecipients());\n    ts.close();\n}\n\n\n\n# 发送 html 格式的邮件\n\npublic static void main(string[] args) throws exception {\n    properties prop = new properties();\n    prop.setproperty("mail.debug", "true");\n    prop.setproperty("mail.host", mail_server_host);\n    prop.setproperty("mail.transport.protocol", "smtp");\n    prop.setproperty("mail.smtp.auth", "true");\n\n    // 1、创建session\n    session session = session.getinstance(prop);\n    transport ts = null;\n\n    // 2、通过session得到transport对象\n    ts = session.gettransport();\n\n    // 3、连上邮件服务器\n    ts.connect(mail_server_host, user, password);\n\n    // 4、创建邮件\n    mimemessage message = new mimemessage(session);\n\n    // 邮件消息头\n    message.setfrom(new internetaddress(mail_from)); // 邮件的发件人\n    message.setrecipient(message.recipienttype.to, new internetaddress(mail_to)); // 邮件的收件人\n    message.setrecipient(message.recipienttype.cc, new internetaddress(mail_cc)); // 邮件的抄送人\n    message.setrecipient(message.recipienttype.bcc, new internetaddress(mail_bcc)); // 邮件的密送人\n    message.setsubject("测试html邮件"); // 邮件的标题\n\n    string htmlcontent = "<h1>hello</h1>" + "<p>显示图片<img src=\'cid:abc.jpg\'>1.jpg</p>";\n    mimebodypart text = new mimebodypart();\n    text.setcontent(htmlcontent, "text/html;charset=utf-8");\n    mimebodypart image = new mimebodypart();\n    datahandler dh = new datahandler(new filedatasource("d:\\\\05_datas\\\\图库\\\\吉他少年背影.png"));\n    image.setdatahandler(dh);\n    image.setcontentid("abc.jpg");\n\n    // 描述数据关系\n    mimemultipart mm = new mimemultipart();\n    mm.addbodypart(text);\n    mm.addbodypart(image);\n    mm.setsubtype("related");\n    message.setcontent(mm);\n    message.savechanges();\n\n    // 5、发送邮件\n    ts.sendmessage(message, message.getallrecipients());\n    ts.close();\n}\n\n\n\n# 发送带附件的邮件\n\npublic static void main(string[] args) throws exception {\n    properties prop = new properties();\n    prop.setproperty("mail.debug", "true");\n    prop.setproperty("mail.host", mail_server_host);\n    prop.setproperty("mail.transport.protocol", "smtp");\n    prop.setproperty("mail.smtp.auth", "true");\n\n    // 1、创建session\n    session session = session.getinstance(prop);\n\n    // 2、通过session得到transport对象\n    transport ts = session.gettransport();\n\n    // 3、连上邮件服务器\n    ts.connect(mail_server_host, user, password);\n\n    // 4、创建邮件\n    mimemessage message = new mimemessage(session);\n\n    // 邮件消息头\n    message.setfrom(new internetaddress(mail_from)); // 邮件的发件人\n    message.setrecipient(message.recipienttype.to, new internetaddress(mail_to)); // 邮件的收件人\n    message.setrecipient(message.recipienttype.cc, new internetaddress(mail_cc)); // 邮件的抄送人\n    message.setrecipient(message.recipienttype.bcc, new internetaddress(mail_bcc)); // 邮件的密送人\n    message.setsubject("测试带附件邮件"); // 邮件的标题\n\n    mimebodypart text = new mimebodypart();\n    text.setcontent("邮件中有两个附件。", "text/html;charset=utf-8");\n\n    // 描述数据关系\n    mimemultipart mm = new mimemultipart();\n    mm.setsubtype("related");\n    mm.addbodypart(text);\n    string[] files = {\n            "d:\\\\00_temp\\\\temp\\\\1.jpg", "d:\\\\00_temp\\\\temp\\\\2.png"\n    };\n\n    // 添加邮件附件\n    for (string filename : files) {\n        mimebodypart attachpart = new mimebodypart();\n        attachpart.attachfile(filename);\n        mm.addbodypart(attachpart);\n    }\n\n    message.setcontent(mm);\n    message.savechanges();\n\n    // 5、发送邮件\n    ts.sendmessage(message, message.getallrecipients());\n    ts.close();\n}\n\n\n\n# 获取邮箱中的邮件\n\n public static void main(string[] args) throws exception {\n\n    // 创建一个有具体连接信息的properties对象\n    properties prop = new properties();\n    prop.setproperty("mail.debug", "true");\n    prop.setproperty("mail.store.protocol", "pop3");\n    prop.setproperty("mail.pop3.host", mail_server_host);\n\n    // 1、创建session\n    session session = session.getinstance(prop);\n\n    // 2、通过session得到store对象\n    store store = session.getstore();\n\n    // 3、连上邮件服务器\n    store.connect(mail_server_host, user, password);\n\n    // 4、获得邮箱内的邮件夹\n    folder folder = store.getfolder("inbox");\n    folder.open(folder.read_only);\n\n    // 获得邮件夹folder内的所有邮件message对象\n    message[] messages = folder.getmessages();\n    for (int i = 0; i < messages.length; i++) {\n        string subject = messages[i].getsubject();\n        string from = (messages[i].getfrom()[0]).tostring();\n        system.out.println("第 " + (i + 1) + "封邮件的主题：" + subject);\n        system.out.println("第 " + (i + 1) + "封邮件的发件人地址：" + from);\n    }\n\n    // 5、关闭\n    folder.close(false);\n    store.close();\n}\n\n\n\n# 转发邮件\n\n例：获取指定邮件夹下的第一封邮件并转发\n\n public static void main(string[] args) throws exception {\n    properties prop = new properties();\n    prop.put("mail.store.protocol", "pop3");\n    prop.put("mail.pop3.host", mail_server_pop3);\n    prop.put("mail.pop3.starttls.enable", "true");\n    prop.put("mail.smtp.auth", "true");\n    prop.put("mail.smtp.host", mail_server_smtp);\n\n    // 1、创建session\n    session session = session.getdefaultinstance(prop);\n\n    // 2、读取邮件夹\n    store store = session.getstore("pop3");\n    store.connect(mail_server_pop3, user, password);\n    folder folder = store.getfolder("inbox");\n    folder.open(folder.read_only);\n\n    // 获取邮件夹中第1封邮件信息\n    message[] messages = folder.getmessages();\n    if (messages.length <= 0) {\n        return;\n    }\n    message message = messages[0];\n\n    // 打印邮件关键信息\n    string from = internetaddress.tostring(message.getfrom());\n    if (from != null) {\n        system.out.println("from: " + from);\n    }\n\n    string replyto = internetaddress.tostring(message.getreplyto());\n    if (replyto != null) {\n        system.out.println("reply-to: " + replyto);\n    }\n\n    string to = internetaddress.tostring(message.getrecipients(message.recipienttype.to));\n    if (to != null) {\n        system.out.println("to: " + to);\n    }\n\n    string subject = message.getsubject();\n    if (subject != null) {\n        system.out.println("subject: " + subject);\n    }\n\n    date sent = message.getsentdate();\n    if (sent != null) {\n        system.out.println("sent: " + sent);\n    }\n\n    // 设置转发邮件信息头\n    message forward = new mimemessage(session);\n    forward.setfrom(new internetaddress(mail_from));\n    forward.setrecipient(message.recipienttype.to, new internetaddress(mail_to));\n    forward.setsubject("fwd: " + message.getsubject());\n\n    // 设置转发邮件内容\n    mimebodypart bodypart = new mimebodypart();\n    bodypart.setcontent(message, "message/rfc822");\n\n    multipart multipart = new mimemultipart();\n    multipart.addbodypart(bodypart);\n    forward.setcontent(multipart);\n    forward.savechanges();\n\n    transport ts = session.gettransport("smtp");\n    ts.connect(user, password);\n    ts.sendmessage(forward, forward.getallrecipients());\n\n    folder.close(false);\n    store.close();\n    ts.close();\n    system.out.println("message forwarded successfully....");\n}\n',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Jsoup 快速入门",frontmatter:{title:"Jsoup 快速入门",categories:["编程","Java","工具"],tags:["Java","Html","Jsoup"],abbrlink:"2dece711",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/c516cc/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/99.%E5%85%B6%E4%BB%96/05.Jsoup.html",relativePath:"12.工具/99.其他/05.Jsoup.md",key:"v-066da6f7",path:"/pages/c516cc/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:17},{level:2,title:"加载",slug:"加载",normalizedTitle:"加载",charIndex:175},{level:3,title:"从 HTML 字符串加载一个文档",slug:"从-html-字符串加载一个文档",normalizedTitle:"从 html 字符串加载一个文档",charIndex:288},{level:3,title:"解析一个 body 片断",slug:"解析一个-body-片断",normalizedTitle:"解析一个 body 片断",charIndex:865},{level:4,title:"保证安全 Stay safe",slug:"保证安全-stay-safe",normalizedTitle:"保证安全 stay safe",charIndex:1408},{level:3,title:"从 URL 加载一个文档",slug:"从-url-加载一个文档",normalizedTitle:"从 url 加载一个文档",charIndex:1541},{level:3,title:"从一个文件加载一个文档",slug:"从一个文件加载一个文档",normalizedTitle:"从一个文件加载一个文档",charIndex:1967},{level:2,title:"解析",slug:"解析",normalizedTitle:"解析",charIndex:43},{level:3,title:"使用 DOM 方法来遍历一个文档",slug:"使用-dom-方法来遍历一个文档",normalizedTitle:"使用 dom 方法来遍历一个文档",charIndex:2456},{level:4,title:"查找元素",slug:"查找元素",normalizedTitle:"查找元素",charIndex:2919},{level:4,title:"元素数据",slug:"元素数据",normalizedTitle:"元素数据",charIndex:3296},{level:4,title:"操作 HTML 和文本",slug:"操作-html-和文本",normalizedTitle:"操作 html 和文本",charIndex:3605},{level:3,title:"使用选择器语法来查找元素",slug:"使用选择器语法来查找元素",normalizedTitle:"使用选择器语法来查找元素",charIndex:3807},{level:4,title:"Selector 选择器概述",slug:"selector-选择器概述",normalizedTitle:"selector 选择器概述",charIndex:4520},{level:4,title:"Selector 选择器组合使用",slug:"selector-选择器组合使用",normalizedTitle:"selector 选择器组合使用",charIndex:5007},{level:4,title:"伪选择器 selectors",slug:"伪选择器-selectors",normalizedTitle:"伪选择器 selectors",charIndex:5499},{level:3,title:"从元素抽取属性，文本和 HTML",slug:"从元素抽取属性-文本和-html",normalizedTitle:"从元素抽取属性，文本和 html",charIndex:6175},{level:3,title:"处理 URLs",slug:"处理-urls",normalizedTitle:"处理 urls",charIndex:7200},{level:2,title:"数据修改",slug:"数据修改",normalizedTitle:"数据修改",charIndex:7884},{level:3,title:"设置属性的值",slug:"设置属性的值",normalizedTitle:"设置属性的值",charIndex:7893},{level:3,title:"设置一个元素的 HTML 内容",slug:"设置一个元素的-html-内容",normalizedTitle:"设置一个元素的 html 内容",charIndex:8479},{level:3,title:"设置元素的文本内容",slug:"设置元素的文本内容",normalizedTitle:"设置元素的文本内容",charIndex:9372},{level:2,title:"HTML 清理",slug:"html-清理",normalizedTitle:"html 清理",charIndex:9877},{level:3,title:"消除不受信任的 HTML (来防止 XSS 攻击)",slug:"消除不受信任的-html-来防止-xss-攻击",normalizedTitle:"消除不受信任的 html (来防止 xss 攻击)",charIndex:9889},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:6159}],headersStr:"简介 加载 从 HTML 字符串加载一个文档 解析一个 body 片断 保证安全 Stay safe 从 URL 加载一个文档 从一个文件加载一个文档 解析 使用 DOM 方法来遍历一个文档 查找元素 元素数据 操作 HTML 和文本 使用选择器语法来查找元素 Selector 选择器概述 Selector 选择器组合使用 伪选择器 selectors 从元素抽取属性，文本和 HTML 处理 URLs 数据修改 设置属性的值 设置一个元素的 HTML 内容 设置元素的文本内容 HTML 清理 消除不受信任的 HTML (来防止 XSS 攻击) 参考",content:'# Jsoup 快速入门\n\n\n# 简介\n\njsoup 是一款 Java 的 HTML 解析器，可直接解析某个 URL 地址、HTML 文本内容。它提供了一套非常省力的 API，可通过 DOM，CSS 以及类似于 JQuery 的操作方法来取出和操作数据。\n\njsoup 工作的流程主要如下：\n\n 1. 从一个 URL，文件或字符串中解析 HTML，并加载为一个 Document 对象。\n 2. 使用 DOM 或 CSS 选择器来取出数据；\n 3. 可操作 HTML 元素、属性、文本。\n\njsoup 是基于 MIT 协议发布的，可放心使用于商业项目。\n\n\n# 加载\n\n\n# 从 HTML 字符串加载一个文档\n\n使用静态 Jsoup.parse(String html) 方法或 Jsoup.parse(String html, String baseUri) 示例代码：\n\nString html = "<html><head><title>First parse</title></head>"\n  + "<body><p>Parsed HTML into a doc.</p></body></html>";\nDocument doc = Jsoup.parse(html);\n\n\n> 说明\n> \n> parse(String html, String baseUri) 这方法能够将输入的 HTML 解析为一个新的文档 (Document），参数 baseUri 是用来将相对 URL 转成绝对 URL，并指定从哪个网站获取文档。如这个方法不适用，你可以使用 parse(String html) 方法来解析成 HTML 字符串如上面的示例。\n> \n> 只要解析的不是空字符串，就能返回一个结构合理的文档，其中包含(至少) 一个 head 和一个 body 元素。\n> \n> 一旦拥有了一个 Document，你就可以使用 Document 中适当的方法或它父类 Element和Node中的方法来取得相关数据。\n\n\n# 解析一个 body 片断\n\n问题\n\n假如你有一个 HTML 片断 (比如. 一个 div 包含一对 p 标签; 一个不完整的 HTML 文档) 想对它进行解析。这个 HTML 片断可以是用户提交的一条评论或在一个 CMS 页面中编辑 body 部分。\n\n办法\n\n使用Jsoup.parseBodyFragment(String html)方法.\n\nString html = "<div><p>Lorem ipsum.</p>";\nDocument doc = Jsoup.parseBodyFragment(html);\nElement body = doc.body();\n\n\n> 说明\n> \n> parseBodyFragment 方法创建一个空壳的文档，并插入解析过的 HTML 到body元素中。假如你使用正常的 Jsoup.parse(String html) 方法，通常你也可以得到相同的结果，但是明确将用户输入作为 body 片段处理，以确保用户所提供的任何糟糕的 HTML 都将被解析成 body 元素。\n> \n> Document.body() 方法能够取得文档 body 元素的所有子元素，与 doc.getElementsByTag("body")相同。\n\n# 保证安全 Stay safe\n\n假如你可以让用户输入 HTML 内容，那么要小心避免跨站脚本攻击。利用基于 Whitelist 的清除器和 clean(String bodyHtml, Whitelist whitelist)方法来清除用户输入的恶意内容。\n\n\n# 从 URL 加载一个文档\n\n使用 Jsoup.connect(String url)方法\n\nDocument doc = Jsoup.connect("http://example.com/").get();\n\n\n> 说明\n> \n> connect(String url) 方法创建一个新的 Connection, 和 get() 取得和解析一个 HTML 文件。如果从该 URL 获取 HTML 时发生错误，便会抛出 IOException，应适当处理。\n\nConnection 接口还提供一个方法链来解决特殊请求，具体如下：\n\nDocument doc = Jsoup.connect("http://example.com")\n  .data("query", "Java")\n  .userAgent("Mozilla")\n  .cookie("auth", "token")\n  .timeout(3000)\n  .post();\n\n\n\n# 从一个文件加载一个文档\n\n可以使用静态 Jsoup.parse(File in, String charsetName, String baseUri) 方法\n\nFile input = new File("/tmp/input.html");\nDocument doc = Jsoup.parse(input, "UTF-8", "http://example.com/");\n\n\n> 说明\n> \n> parse(File in, String charsetName, String baseUri) 这个方法用来加载和解析一个 HTML 文件。如在加载文件的时候发生错误，将抛出 IOException，应作适当处理。\n> \n> baseUri 参数用于解决文件中 URLs 是相对路径的问题。如果不需要可以传入一个空的字符串。\n> \n> 另外还有一个方法parse(File in, String charsetName) ，它使用文件的路径做为 baseUri。 这个方法适用于如果被解析文件位于网站的本地文件系统，且相关链接也指向该文件系统。\n\n\n# 解析\n\n\n# 使用 DOM 方法来遍历一个文档\n\n问题\n\n你有一个 HTML 文档要从中提取数据，并了解这个 HTML 文档的结构。\n\n方法\n\n将 HTML 解析成一个Document之后，就可以使用类似于 DOM 的方法进行操作。示例代码：\n\nFile input = new File("/tmp/input.html");\nDocument doc = Jsoup.parse(input, "UTF-8", "http://example.com/");\n\nElement content = doc.getElementById("content");\nElements links = content.getElementsByTag("a");\nfor (Element link : links) {\n  String linkHref = link.attr("href");\n  String linkText = link.text();\n}\n\n\n说明\n\nElements 这个对象提供了一系列类似于 DOM 的方法来查找元素，抽取并处理其中的数据。\n\n具体如下：\n\n# 查找元素\n\n * getElementById(String id)\n * getElementsByTag(String tag)\n * getElementsByClass(String className)\n * getElementsByAttribute(String key) (and related methods)\n * Element siblings: siblingElements(), firstElementSibling(), lastElementSibling();nextElementSibling(), previousElementSibling()\n * Graph: parent(), children(), child(int index)\n\n# 元素数据\n\n * attr(String key)获取属性attr(String key, String value)设置属性\n * attributes()获取所有属性\n * id(), className() and classNames()\n * text()获取文本内容text(String value) 设置文本内容\n * html()获取元素内 HTMLhtml(String value)设置元素内的 HTML 内容\n * outerHtml()获取元素外 HTML 内容\n * data()获取数据内容（例如：script 和 style 标签)\n * tag() and tagName()\n\n# 操作 HTML 和文本\n\n * append(String html), prepend(String html)\n * appendText(String text), prependText(String text)\n * appendElement(String tagName), prependElement(String tagName)\n * html(String value)\n\n\n# 使用选择器语法来查找元素\n\n问题\n\n你想使用类似于 CSS 或 jQuery 的语法来查找和操作元素。\n\n方法\n\n可以使用Element.select(String selector) 和 Elements.select(String selector) 方法实现：\n\nFile input = new File("/tmp/input.html");\nDocument doc = Jsoup.parse(input, "UTF-8", "http://example.com/");\n\nElements links = doc.select("a[href]"); //带有href属性的a元素\nElements pngs = doc.select("img[src$=.png]");\n  //扩展名为.png的图片\n\nElement masthead = doc.select("div.masthead").first();\n  //class等于masthead的div标签\n\nElements resultLinks = doc.select("h3.r > a"); //在h3元素之后的a元素\n\n\n> 说明\n> \n> jsoup elements 对象支持类似于CSS (或jquery)的选择器语法，来实现非常强大和灵活的查找功能。.\n> \n> 这个select 方法在Document, Element,或Elements对象中都可以使用。且是上下文相关的，因此可实现指定元素的过滤，或者链式选择访问。\n> \n> Select 方法将返回一个Elements集合，并提供一组方法来抽取和处理结果。\n\n# Selector 选择器概述\n\n * tagname: 通过标签查找元素，比如：a\n * ns|tag: 通过标签在命名空间查找元素，比如：可以用 fb|name 语法来查找 `` 元素\n * #id: 通过 ID 查找元素，比如：#logo\n * .class: 通过 class 名称查找元素，比如：.masthead\n * [attribute]: 利用属性查找元素，比如：[href]\n * [^attr]: 利用属性名前缀来查找元素，比如：可以用[^data-] 来查找带有 HTML5 Dataset 属性的元素\n * [attr=value]: 利用属性值来查找元素，比如：[width=500]\n * [attr^=value], [attr$=value], [attr*=value]: 利用匹配属性值开头、结尾或包含属性值来查找元素，比如：[href*=/path/]\n * [attr\\~=regex]: 利用属性值匹配正则表达式来查找元素，比如： img[src\\~=(?i)\\.(png|jpe?g)]\n * *: 这个符号将匹配所有元素\n\n# Selector 选择器组合使用\n\n * el##id: 元素+ID，比如： div##logo\n * el.class: 元素+class，比如： div.masthead\n * el[attr]: 元素+class，比如： a[href]\n * 任意组合，比如：a[href].highlight\n * ancestor child: 查找某个元素下子元素，比如：可以用.body p 查找在"body"元素下的所有p元素\n * parent > child: 查找某个父元素下的直接子元素，比如：可以用div.content > p 查找 p 元素，也可以用body > * 查找 body 标签下所有直接子元素\n * siblingA + siblingB: 查找在 A 元素之前第一个同级元素 B，比如：div.head + div\n * siblingA \\~ siblingX: 查找 A 元素之前的同级 X 元素，比如：h1 \\~ p\n * el, el, el:多个选择器组合，查找匹配任一选择器的唯一元素，例如：div.masthead, div.logo\n\n# 伪选择器 selectors\n\n * :lt(n): 查找哪些元素的同级索引值（它的位置在 DOM 树中是相对于它的父节点）小于 n，比如：td:lt(3) 表示小于三列的元素\n * :gt(n):查找哪些元素的同级索引值大于n``，比如： div p:gt(2)表示哪些 div 中有包含 2 个以上的 p 元素\n * :eq(n): 查找哪些元素的同级索引值与n相等，比如：form input:eq(1)表示包含一个 input 标签的 Form 元素\n * :has(seletor): 查找匹配选择器包含元素的元素，比如：div:has(p)表示哪些 div 包含了 p 元素\n * :not(selector): 查找与选择器不匹配的元素，比如： div:not(.logo) 表示不包含 class=logo 元素的所有 div 列表\n * :contains(text): 查找包含给定文本的元素，搜索不区分大不写，比如： p:contains(jsoup)\n * :containsOwn(text): 查找直接包含给定文本的元素\n * :matches(regex): 查找哪些元素的文本匹配指定的正则表达式，比如：div:matches((?i)login)\n * :matchesOwn(regex): 查找自身包含文本匹配指定正则表达式的元素\n * 注意：上述伪选择器索引是从 0 开始的，也就是说第一个元素索引值为 0，第二个元素 index 为 1 等\n\n可以查看Selector API 参考来了解更详细的内容\n\n\n# 从元素抽取属性，文本和 HTML\n\n问题\n\n在解析获得一个 Document 实例对象，并查找到一些元素之后，你希望取得在这些元素中的数据。\n\n方法\n\n * 要取得一个属性的值，可以使用Node.attr(String key) 方法\n * 对于一个元素中的文本，可以使用Element.text()方法\n * 对于要取得元素或属性中的 HTML 内容，可以使用Element.html(), 或 Node.outerHtml()方法\n\n示例：\n\nString html = "<p>An <a href=\'http://example.com/\'><b>example</b></a> link.</p>";\nDocument doc = Jsoup.parse(html);//解析HTML字符串返回一个Document实现\nElement link = doc.select("a").first();//查找第一个a元素\n\nString text = doc.body().text(); // "An example link"//取得字符串中的文本\nString linkHref = link.attr("href"); // "http://example.com/"//取得链接地址\nString linkText = link.text(); // "example""//取得链接地址中的文本\n\nString linkOuterH = link.outerHtml();\n    // "<a href="http://example.com"><b>example</b></a>"\nString linkInnerH = link.html(); // "<b>example</b>"//取得链接内的html内容\n\n\n> 说明\n> \n> 上述方法是元素数据访问的核心办法。此外还其它一些方法可以使用：\n> \n>  * Element.id()\n>  * Element.tagName()\n>  * Element.className() and Element.hasClass(String className)\n> \n> 这些访问器方法都有相应的 setter 方法来更改数据\n\n参见\n\n * Element和Elements集合类的参考文档\n * URLs 处理\n * 使用 CSS 选择器语法来查找元素\n\n\n# 处理 URLs\n\n问题\n\n你有一个包含相对 URLs 路径的 HTML 文档，需要将这些相对路径转换成绝对路径的 URLs。\n\n方法\n\n 1. 在你解析文档时确保有指定base URI，然后\n 2. 使用 abs: 属性前缀来取得包含base URI的绝对路径。代码如下：\n\nDocument doc = Jsoup.connect("http://www.open-open.com").get();\n\nElement link = doc.select("a").first();\nString relHref = link.attr("href"); // == "/"\nString absHref = link.attr("abs:href"); // "http://www.open-open.com/"\n\n\n\n> 说明\n> \n> 在 HTML 元素中，URLs 经常写成相对于文档位置的相对路径： <a href="/download">...</a>. 当你使用 Node.attr(String key) 方法来取得 a 元素的 href 属性时，它将直接返回在 HTML 源码中指定定的值。\n> \n> 假如你需要取得一个绝对路径，需要在属性名前加 abs: 前缀。这样就可以返回包含根路径的 URL 地址attr("abs:href")\n> \n> 因此，在解析 HTML 文档时，定义 base URI 非常重要。\n> \n> 如果你不想使用abs: 前缀，还有一个方法能够实现同样的功能 Node.absUrl(String key)。\n\n\n# 数据修改\n\n\n# 设置属性的值\n\n问题\n\n在你解析一个 Document 之后可能想修改其中的某些属性值，然后再保存到磁盘或都输出到前台页面。\n\n方法\n\n可以使用属性设置方法 Element.attr(String key, String value), 和 Elements.attr(String key, String value).\n\n假如你需要修改一个元素的 class 属性，可以使用 Element.addClass(String className) 和Element.removeClass(String className) 方法。\n\nElements 提供了批量操作元素属性和 class 的方法，比如：要为 div 中的每一个 a 元素都添加一个rel="nofollow" 可以使用如下方法：\n\ndoc.select("div.comments a").attr("rel", "nofollow");\n\n\n\n> 说明\n> \n> 与Element中的其它方法一样，attr 方法也是返回当 Element (或在使用选择器是返回 Elements集合)。这样能够很方便使用方法连用的书写方式。比如：\n> \n> doc.select("div.masthead").attr("title", "jsoup").addClass("round-box");\n\n\n# 设置一个元素的 HTML 内容\n\n问题\n\n你需要一个元素中的 HTML 内容\n\n方法\n\n可以使用Element中的 HTML 设置方法具体如下：\n\nElement div = doc.select("div").first(); // <div></div>\ndiv.html("<p>lorem ipsum</p>"); // <div><p>lorem ipsum</p></div>\ndiv.prepend("<p>First</p>");//在div前添加html内容\ndiv.append("<p>Last</p>");//在div之后添加html内容\n// 添完后的结果: <div><p>First</p><p>lorem ipsum</p><p>Last</p></div>\n\nElement span = doc.select("span").first(); // <span>One</span>\nspan.wrap("<li><a href=\'http://example.com/\'></a></li>");\n// 添完后的结果: <li><a href="http://example.com"><span>One</span></a></li>\n\n\n> 说明\n> \n>  * Element.html(String html) 这个方法将先清除元素中的 HTML 内容，然后用传入的 HTML 代替。\n>  * Element.prepend(String first) 和 Element.append(String last) 方法用于在分别在元素内部 HTML 的前面和后面添加 HTML 内容\n>  * Element.wrap(String around) 对元素包裹一个外部 HTML 内容。\n> \n> 参见\n> \n> 可以查看 API 参考文档中 Element.prependElement(String tag)和Element.appendElement(String tag) 方法来创建新的元素并作为文档的子元素插入其中。\n\n\n# 设置元素的文本内容\n\n问题\n\n你需要修改一个 HTML 文档中的文本内容\n\n方法\n\n可以使用Element的设置方法：:\n\nElement div = doc.select("div").first(); // <div></div>\ndiv.text("five > four"); // <div>five &gt; four</div>\ndiv.prepend("First ");\ndiv.append(" Last");\n// now: <div>First five &gt; four Last</div>\n\n\n> 说明\n> \n> 文本设置方法与 HTML setter 方法一样：\n> \n>  * Element.text(String text) 将清除一个元素中的内部 HTML 内容，然后提供的文本进行代替\n>  * Element.prepend(String first) 和 Element.append(String last) 将分别在元素的内部 html 前后添加文本节点。\n> \n> 对于传入的文本如果含有像 <, > 等这样的字符，将以文本处理，而非 HTML。\n\n\n# HTML 清理\n\n\n# 消除不受信任的 HTML (来防止 XSS 攻击)\n\n问题\n\n在做网站的时候，经常会提供用户评论的功能。有些不怀好意的用户，会搞一些脚本到评论内容中，而这些脚本可能会破坏整个页面的行为，更严重的是获取一些机要信息，此时需要清理该 HTML，以避免跨站脚本cross-site scripting攻击（XSS）。\n\n方法\n\n使用 jsoup HTML Cleaner 方法进行清除，但需要指定一个可配置的 Whitelist。\n\nString unsafe =\n  "<p><a href=\'http://example.com/\' onclick=\'stealCookies()\'>Link</a></p>";\nString safe = Jsoup.clean(unsafe, Whitelist.basic());\n// now: <p><a href="http://example.com/" rel="nofollow">Link</a></p>\n\n\n说明\n\nXSS 又叫 CSS (Cross Site Script) ，跨站脚本攻击。它指的是恶意攻击者往 Web 页面里插入恶意 html 代码，当用户浏览该页之时，嵌入其中 Web 里面的 html 代码会被执行，从而达到恶意攻击用户的特殊目的。XSS 属于被动式的攻击，因为其被动且不好利用，所以许多人常忽略其危害性。所以我们经常只让用户输入纯文本的内容，但这样用户体验就比较差了。\n\n一个更好的解决方法就是使用一个富文本编辑器 WYSIWYG 如 CKEditor 和 TinyMCE。这些可以输出 HTML 并能够让用户可视化编辑。虽然他们可以在客户端进行校验，但是这样还不够安全，需要在服务器端进行校验并清除有害的 HTML 代码，这样才能确保输入到你网站的 HTML 是安全的。否则，攻击者能够绕过客户端的 Javascript 验证，并注入不安全的 HMTL 直接进入您的网站。\n\njsoup 的 whitelist 清理器能够在服务器端对用户输入的 HTML 进行过滤，只输出一些安全的标签和属性。\n\njsoup 提供了一系列的 Whitelist 基本配置，能够满足大多数要求；但如有必要，也可以进行修改，不过要小心。\n\n这个 cleaner 非常好用不仅可以避免 XSS 攻击，还可以限制用户可以输入的标签范围。\n\n参见\n\n * 参阅XSS cheat sheet ，有一个例子可以了解为什么不能使用正则表达式，而采用安全的 whitelist parser-based 清理器才是正确的选择。\n * 参阅Cleaner ，了解如何返回一个 Document 对象，而不是字符串\n * 参阅Whitelist，了解如何创建一个自定义的 whitelist\n * nofollow 链接属性了解\n\n\n# 参考\n\n * jsoup github 托管代码\n * jsoup Cookbook\n * jsoup Cookbook(中文版)\n * 不错的 jsoup 学习笔记',normalizedContent:'# jsoup 快速入门\n\n\n# 简介\n\njsoup 是一款 java 的 html 解析器，可直接解析某个 url 地址、html 文本内容。它提供了一套非常省力的 api，可通过 dom，css 以及类似于 jquery 的操作方法来取出和操作数据。\n\njsoup 工作的流程主要如下：\n\n 1. 从一个 url，文件或字符串中解析 html，并加载为一个 document 对象。\n 2. 使用 dom 或 css 选择器来取出数据；\n 3. 可操作 html 元素、属性、文本。\n\njsoup 是基于 mit 协议发布的，可放心使用于商业项目。\n\n\n# 加载\n\n\n# 从 html 字符串加载一个文档\n\n使用静态 jsoup.parse(string html) 方法或 jsoup.parse(string html, string baseuri) 示例代码：\n\nstring html = "<html><head><title>first parse</title></head>"\n  + "<body><p>parsed html into a doc.</p></body></html>";\ndocument doc = jsoup.parse(html);\n\n\n> 说明\n> \n> parse(string html, string baseuri) 这方法能够将输入的 html 解析为一个新的文档 (document），参数 baseuri 是用来将相对 url 转成绝对 url，并指定从哪个网站获取文档。如这个方法不适用，你可以使用 parse(string html) 方法来解析成 html 字符串如上面的示例。\n> \n> 只要解析的不是空字符串，就能返回一个结构合理的文档，其中包含(至少) 一个 head 和一个 body 元素。\n> \n> 一旦拥有了一个 document，你就可以使用 document 中适当的方法或它父类 element和node中的方法来取得相关数据。\n\n\n# 解析一个 body 片断\n\n问题\n\n假如你有一个 html 片断 (比如. 一个 div 包含一对 p 标签; 一个不完整的 html 文档) 想对它进行解析。这个 html 片断可以是用户提交的一条评论或在一个 cms 页面中编辑 body 部分。\n\n办法\n\n使用jsoup.parsebodyfragment(string html)方法.\n\nstring html = "<div><p>lorem ipsum.</p>";\ndocument doc = jsoup.parsebodyfragment(html);\nelement body = doc.body();\n\n\n> 说明\n> \n> parsebodyfragment 方法创建一个空壳的文档，并插入解析过的 html 到body元素中。假如你使用正常的 jsoup.parse(string html) 方法，通常你也可以得到相同的结果，但是明确将用户输入作为 body 片段处理，以确保用户所提供的任何糟糕的 html 都将被解析成 body 元素。\n> \n> document.body() 方法能够取得文档 body 元素的所有子元素，与 doc.getelementsbytag("body")相同。\n\n# 保证安全 stay safe\n\n假如你可以让用户输入 html 内容，那么要小心避免跨站脚本攻击。利用基于 whitelist 的清除器和 clean(string bodyhtml, whitelist whitelist)方法来清除用户输入的恶意内容。\n\n\n# 从 url 加载一个文档\n\n使用 jsoup.connect(string url)方法\n\ndocument doc = jsoup.connect("http://example.com/").get();\n\n\n> 说明\n> \n> connect(string url) 方法创建一个新的 connection, 和 get() 取得和解析一个 html 文件。如果从该 url 获取 html 时发生错误，便会抛出 ioexception，应适当处理。\n\nconnection 接口还提供一个方法链来解决特殊请求，具体如下：\n\ndocument doc = jsoup.connect("http://example.com")\n  .data("query", "java")\n  .useragent("mozilla")\n  .cookie("auth", "token")\n  .timeout(3000)\n  .post();\n\n\n\n# 从一个文件加载一个文档\n\n可以使用静态 jsoup.parse(file in, string charsetname, string baseuri) 方法\n\nfile input = new file("/tmp/input.html");\ndocument doc = jsoup.parse(input, "utf-8", "http://example.com/");\n\n\n> 说明\n> \n> parse(file in, string charsetname, string baseuri) 这个方法用来加载和解析一个 html 文件。如在加载文件的时候发生错误，将抛出 ioexception，应作适当处理。\n> \n> baseuri 参数用于解决文件中 urls 是相对路径的问题。如果不需要可以传入一个空的字符串。\n> \n> 另外还有一个方法parse(file in, string charsetname) ，它使用文件的路径做为 baseuri。 这个方法适用于如果被解析文件位于网站的本地文件系统，且相关链接也指向该文件系统。\n\n\n# 解析\n\n\n# 使用 dom 方法来遍历一个文档\n\n问题\n\n你有一个 html 文档要从中提取数据，并了解这个 html 文档的结构。\n\n方法\n\n将 html 解析成一个document之后，就可以使用类似于 dom 的方法进行操作。示例代码：\n\nfile input = new file("/tmp/input.html");\ndocument doc = jsoup.parse(input, "utf-8", "http://example.com/");\n\nelement content = doc.getelementbyid("content");\nelements links = content.getelementsbytag("a");\nfor (element link : links) {\n  string linkhref = link.attr("href");\n  string linktext = link.text();\n}\n\n\n说明\n\nelements 这个对象提供了一系列类似于 dom 的方法来查找元素，抽取并处理其中的数据。\n\n具体如下：\n\n# 查找元素\n\n * getelementbyid(string id)\n * getelementsbytag(string tag)\n * getelementsbyclass(string classname)\n * getelementsbyattribute(string key) (and related methods)\n * element siblings: siblingelements(), firstelementsibling(), lastelementsibling();nextelementsibling(), previouselementsibling()\n * graph: parent(), children(), child(int index)\n\n# 元素数据\n\n * attr(string key)获取属性attr(string key, string value)设置属性\n * attributes()获取所有属性\n * id(), classname() and classnames()\n * text()获取文本内容text(string value) 设置文本内容\n * html()获取元素内 htmlhtml(string value)设置元素内的 html 内容\n * outerhtml()获取元素外 html 内容\n * data()获取数据内容（例如：script 和 style 标签)\n * tag() and tagname()\n\n# 操作 html 和文本\n\n * append(string html), prepend(string html)\n * appendtext(string text), prependtext(string text)\n * appendelement(string tagname), prependelement(string tagname)\n * html(string value)\n\n\n# 使用选择器语法来查找元素\n\n问题\n\n你想使用类似于 css 或 jquery 的语法来查找和操作元素。\n\n方法\n\n可以使用element.select(string selector) 和 elements.select(string selector) 方法实现：\n\nfile input = new file("/tmp/input.html");\ndocument doc = jsoup.parse(input, "utf-8", "http://example.com/");\n\nelements links = doc.select("a[href]"); //带有href属性的a元素\nelements pngs = doc.select("img[src$=.png]");\n  //扩展名为.png的图片\n\nelement masthead = doc.select("div.masthead").first();\n  //class等于masthead的div标签\n\nelements resultlinks = doc.select("h3.r > a"); //在h3元素之后的a元素\n\n\n> 说明\n> \n> jsoup elements 对象支持类似于css (或jquery)的选择器语法，来实现非常强大和灵活的查找功能。.\n> \n> 这个select 方法在document, element,或elements对象中都可以使用。且是上下文相关的，因此可实现指定元素的过滤，或者链式选择访问。\n> \n> select 方法将返回一个elements集合，并提供一组方法来抽取和处理结果。\n\n# selector 选择器概述\n\n * tagname: 通过标签查找元素，比如：a\n * ns|tag: 通过标签在命名空间查找元素，比如：可以用 fb|name 语法来查找 `` 元素\n * #id: 通过 id 查找元素，比如：#logo\n * .class: 通过 class 名称查找元素，比如：.masthead\n * [attribute]: 利用属性查找元素，比如：[href]\n * [^attr]: 利用属性名前缀来查找元素，比如：可以用[^data-] 来查找带有 html5 dataset 属性的元素\n * [attr=value]: 利用属性值来查找元素，比如：[width=500]\n * [attr^=value], [attr$=value], [attr*=value]: 利用匹配属性值开头、结尾或包含属性值来查找元素，比如：[href*=/path/]\n * [attr\\~=regex]: 利用属性值匹配正则表达式来查找元素，比如： img[src\\~=(?i)\\.(png|jpe?g)]\n * *: 这个符号将匹配所有元素\n\n# selector 选择器组合使用\n\n * el##id: 元素+id，比如： div##logo\n * el.class: 元素+class，比如： div.masthead\n * el[attr]: 元素+class，比如： a[href]\n * 任意组合，比如：a[href].highlight\n * ancestor child: 查找某个元素下子元素，比如：可以用.body p 查找在"body"元素下的所有p元素\n * parent > child: 查找某个父元素下的直接子元素，比如：可以用div.content > p 查找 p 元素，也可以用body > * 查找 body 标签下所有直接子元素\n * siblinga + siblingb: 查找在 a 元素之前第一个同级元素 b，比如：div.head + div\n * siblinga \\~ siblingx: 查找 a 元素之前的同级 x 元素，比如：h1 \\~ p\n * el, el, el:多个选择器组合，查找匹配任一选择器的唯一元素，例如：div.masthead, div.logo\n\n# 伪选择器 selectors\n\n * :lt(n): 查找哪些元素的同级索引值（它的位置在 dom 树中是相对于它的父节点）小于 n，比如：td:lt(3) 表示小于三列的元素\n * :gt(n):查找哪些元素的同级索引值大于n``，比如： div p:gt(2)表示哪些 div 中有包含 2 个以上的 p 元素\n * :eq(n): 查找哪些元素的同级索引值与n相等，比如：form input:eq(1)表示包含一个 input 标签的 form 元素\n * :has(seletor): 查找匹配选择器包含元素的元素，比如：div:has(p)表示哪些 div 包含了 p 元素\n * :not(selector): 查找与选择器不匹配的元素，比如： div:not(.logo) 表示不包含 class=logo 元素的所有 div 列表\n * :contains(text): 查找包含给定文本的元素，搜索不区分大不写，比如： p:contains(jsoup)\n * :containsown(text): 查找直接包含给定文本的元素\n * :matches(regex): 查找哪些元素的文本匹配指定的正则表达式，比如：div:matches((?i)login)\n * :matchesown(regex): 查找自身包含文本匹配指定正则表达式的元素\n * 注意：上述伪选择器索引是从 0 开始的，也就是说第一个元素索引值为 0，第二个元素 index 为 1 等\n\n可以查看selector api 参考来了解更详细的内容\n\n\n# 从元素抽取属性，文本和 html\n\n问题\n\n在解析获得一个 document 实例对象，并查找到一些元素之后，你希望取得在这些元素中的数据。\n\n方法\n\n * 要取得一个属性的值，可以使用node.attr(string key) 方法\n * 对于一个元素中的文本，可以使用element.text()方法\n * 对于要取得元素或属性中的 html 内容，可以使用element.html(), 或 node.outerhtml()方法\n\n示例：\n\nstring html = "<p>an <a href=\'http://example.com/\'><b>example</b></a> link.</p>";\ndocument doc = jsoup.parse(html);//解析html字符串返回一个document实现\nelement link = doc.select("a").first();//查找第一个a元素\n\nstring text = doc.body().text(); // "an example link"//取得字符串中的文本\nstring linkhref = link.attr("href"); // "http://example.com/"//取得链接地址\nstring linktext = link.text(); // "example""//取得链接地址中的文本\n\nstring linkouterh = link.outerhtml();\n    // "<a href="http://example.com"><b>example</b></a>"\nstring linkinnerh = link.html(); // "<b>example</b>"//取得链接内的html内容\n\n\n> 说明\n> \n> 上述方法是元素数据访问的核心办法。此外还其它一些方法可以使用：\n> \n>  * element.id()\n>  * element.tagname()\n>  * element.classname() and element.hasclass(string classname)\n> \n> 这些访问器方法都有相应的 setter 方法来更改数据\n\n参见\n\n * element和elements集合类的参考文档\n * urls 处理\n * 使用 css 选择器语法来查找元素\n\n\n# 处理 urls\n\n问题\n\n你有一个包含相对 urls 路径的 html 文档，需要将这些相对路径转换成绝对路径的 urls。\n\n方法\n\n 1. 在你解析文档时确保有指定base uri，然后\n 2. 使用 abs: 属性前缀来取得包含base uri的绝对路径。代码如下：\n\ndocument doc = jsoup.connect("http://www.open-open.com").get();\n\nelement link = doc.select("a").first();\nstring relhref = link.attr("href"); // == "/"\nstring abshref = link.attr("abs:href"); // "http://www.open-open.com/"\n\n\n\n> 说明\n> \n> 在 html 元素中，urls 经常写成相对于文档位置的相对路径： <a href="/download">...</a>. 当你使用 node.attr(string key) 方法来取得 a 元素的 href 属性时，它将直接返回在 html 源码中指定定的值。\n> \n> 假如你需要取得一个绝对路径，需要在属性名前加 abs: 前缀。这样就可以返回包含根路径的 url 地址attr("abs:href")\n> \n> 因此，在解析 html 文档时，定义 base uri 非常重要。\n> \n> 如果你不想使用abs: 前缀，还有一个方法能够实现同样的功能 node.absurl(string key)。\n\n\n# 数据修改\n\n\n# 设置属性的值\n\n问题\n\n在你解析一个 document 之后可能想修改其中的某些属性值，然后再保存到磁盘或都输出到前台页面。\n\n方法\n\n可以使用属性设置方法 element.attr(string key, string value), 和 elements.attr(string key, string value).\n\n假如你需要修改一个元素的 class 属性，可以使用 element.addclass(string classname) 和element.removeclass(string classname) 方法。\n\nelements 提供了批量操作元素属性和 class 的方法，比如：要为 div 中的每一个 a 元素都添加一个rel="nofollow" 可以使用如下方法：\n\ndoc.select("div.comments a").attr("rel", "nofollow");\n\n\n\n> 说明\n> \n> 与element中的其它方法一样，attr 方法也是返回当 element (或在使用选择器是返回 elements集合)。这样能够很方便使用方法连用的书写方式。比如：\n> \n> doc.select("div.masthead").attr("title", "jsoup").addclass("round-box");\n\n\n# 设置一个元素的 html 内容\n\n问题\n\n你需要一个元素中的 html 内容\n\n方法\n\n可以使用element中的 html 设置方法具体如下：\n\nelement div = doc.select("div").first(); // <div></div>\ndiv.html("<p>lorem ipsum</p>"); // <div><p>lorem ipsum</p></div>\ndiv.prepend("<p>first</p>");//在div前添加html内容\ndiv.append("<p>last</p>");//在div之后添加html内容\n// 添完后的结果: <div><p>first</p><p>lorem ipsum</p><p>last</p></div>\n\nelement span = doc.select("span").first(); // <span>one</span>\nspan.wrap("<li><a href=\'http://example.com/\'></a></li>");\n// 添完后的结果: <li><a href="http://example.com"><span>one</span></a></li>\n\n\n> 说明\n> \n>  * element.html(string html) 这个方法将先清除元素中的 html 内容，然后用传入的 html 代替。\n>  * element.prepend(string first) 和 element.append(string last) 方法用于在分别在元素内部 html 的前面和后面添加 html 内容\n>  * element.wrap(string around) 对元素包裹一个外部 html 内容。\n> \n> 参见\n> \n> 可以查看 api 参考文档中 element.prependelement(string tag)和element.appendelement(string tag) 方法来创建新的元素并作为文档的子元素插入其中。\n\n\n# 设置元素的文本内容\n\n问题\n\n你需要修改一个 html 文档中的文本内容\n\n方法\n\n可以使用element的设置方法：:\n\nelement div = doc.select("div").first(); // <div></div>\ndiv.text("five > four"); // <div>five &gt; four</div>\ndiv.prepend("first ");\ndiv.append(" last");\n// now: <div>first five &gt; four last</div>\n\n\n> 说明\n> \n> 文本设置方法与 html setter 方法一样：\n> \n>  * element.text(string text) 将清除一个元素中的内部 html 内容，然后提供的文本进行代替\n>  * element.prepend(string first) 和 element.append(string last) 将分别在元素的内部 html 前后添加文本节点。\n> \n> 对于传入的文本如果含有像 <, > 等这样的字符，将以文本处理，而非 html。\n\n\n# html 清理\n\n\n# 消除不受信任的 html (来防止 xss 攻击)\n\n问题\n\n在做网站的时候，经常会提供用户评论的功能。有些不怀好意的用户，会搞一些脚本到评论内容中，而这些脚本可能会破坏整个页面的行为，更严重的是获取一些机要信息，此时需要清理该 html，以避免跨站脚本cross-site scripting攻击（xss）。\n\n方法\n\n使用 jsoup html cleaner 方法进行清除，但需要指定一个可配置的 whitelist。\n\nstring unsafe =\n  "<p><a href=\'http://example.com/\' onclick=\'stealcookies()\'>link</a></p>";\nstring safe = jsoup.clean(unsafe, whitelist.basic());\n// now: <p><a href="http://example.com/" rel="nofollow">link</a></p>\n\n\n说明\n\nxss 又叫 css (cross site script) ，跨站脚本攻击。它指的是恶意攻击者往 web 页面里插入恶意 html 代码，当用户浏览该页之时，嵌入其中 web 里面的 html 代码会被执行，从而达到恶意攻击用户的特殊目的。xss 属于被动式的攻击，因为其被动且不好利用，所以许多人常忽略其危害性。所以我们经常只让用户输入纯文本的内容，但这样用户体验就比较差了。\n\n一个更好的解决方法就是使用一个富文本编辑器 wysiwyg 如 ckeditor 和 tinymce。这些可以输出 html 并能够让用户可视化编辑。虽然他们可以在客户端进行校验，但是这样还不够安全，需要在服务器端进行校验并清除有害的 html 代码，这样才能确保输入到你网站的 html 是安全的。否则，攻击者能够绕过客户端的 javascript 验证，并注入不安全的 hmtl 直接进入您的网站。\n\njsoup 的 whitelist 清理器能够在服务器端对用户输入的 html 进行过滤，只输出一些安全的标签和属性。\n\njsoup 提供了一系列的 whitelist 基本配置，能够满足大多数要求；但如有必要，也可以进行修改，不过要小心。\n\n这个 cleaner 非常好用不仅可以避免 xss 攻击，还可以限制用户可以输入的标签范围。\n\n参见\n\n * 参阅xss cheat sheet ，有一个例子可以了解为什么不能使用正则表达式，而采用安全的 whitelist parser-based 清理器才是正确的选择。\n * 参阅cleaner ，了解如何返回一个 document 对象，而不是字符串\n * 参阅whitelist，了解如何创建一个自定义的 whitelist\n * nofollow 链接属性了解\n\n\n# 参考\n\n * jsoup github 托管代码\n * jsoup cookbook\n * jsoup cookbook(中文版)\n * 不错的 jsoup 学习笔记',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Thumbnailator 快速入门",frontmatter:{title:"Thumbnailator 快速入门",categories:["编程","Java","工具"],tags:["Java","图形处理","Thumbnailator"],abbrlink:"950b94a1",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/aa9f61/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/99.%E5%85%B6%E4%BB%96/06.Thumbnailator.html",relativePath:"12.工具/99.其他/06.Thumbnailator.md",key:"v-aab99b9a",path:"/pages/aa9f61/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:25},{level:2,title:"核心 API",slug:"核心-api",normalizedTitle:"核心 api",charIndex:311},{level:3,title:"Thumbnails",slug:"thumbnails",normalizedTitle:"thumbnails",charIndex:124},{level:3,title:"Thumbnails.Builder",slug:"thumbnails-builder",normalizedTitle:"thumbnails.builder",charIndex:385},{level:4,title:"设置参数的函数",slug:"设置参数的函数",normalizedTitle:"设置参数的函数",charIndex:1500},{level:4,title:"输出函数",slug:"输出函数",normalizedTitle:"输出函数",charIndex:2140},{level:3,title:"工作流",slug:"工作流",normalizedTitle:"工作流",charIndex:3099},{level:2,title:"实战",slug:"实战",normalizedTitle:"实战",charIndex:3307},{level:3,title:"安装",slug:"安装",normalizedTitle:"安装",charIndex:3420},{level:3,title:"图片缩放",slug:"图片缩放",normalizedTitle:"图片缩放",charIndex:3578},{level:3,title:"图片旋转",slug:"图片旋转",normalizedTitle:"图片旋转",charIndex:3945},{level:3,title:"加水印",slug:"加水印",normalizedTitle:"加水印",charIndex:85},{level:3,title:"批量处理图片",slug:"批量处理图片",normalizedTitle:"批量处理图片",charIndex:4569},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:3274}],headersStr:"简介 核心 API Thumbnails Thumbnails.Builder 设置参数的函数 输出函数 工作流 实战 安装 图片缩放 图片旋转 加水印 批量处理图片 参考",content:'# Thumbnailator 快速入门\n\n\n# 简介\n\nThumbnailator 是一个开源的 Java 项目，它提供了非常简单的 API 来对图片进行缩放、旋转以及加水印的处理。\n\n有多简单呢？简单到一行代码就可以完成图片处理。形式如下：\n\nThumbnails.of(new File("path/to/directory").listFiles())\n    .size(640, 480)\n    .outputFormat("jpg")\n    .toFiles(Rename.PREFIX_DOT_THUMBNAIL);\n\n\n当然，Thumbnailator 还有一些使用细节，下面我会一一道来。\n\n\n# 核心 API\n\n\n# Thumbnails\n\nThumbnails 是使用 Thumbnailator 创建缩略图的主入口。\n\n它提供了一组初始化 Thumbnails.Builder 的接口。\n\n先看下这组接口的声明：\n\n// 可变长度参数列表\npublic static Builder<File> of(String... files) {...}\npublic static Builder<File> of(File... files) {...}\npublic static Builder<URL> of(URL... urls) {...}\npublic static Builder<? extends InputStream> of(InputStream... inputStreams) {...}\npublic static Builder<BufferedImage> of(BufferedImage... images) {...}\n// 迭代器（所有实现 Iterable 接口的 Java 对象都可以，当然也包括 List、Set）\npublic static Builder<File> fromFilenames(Iterable<String> files) {...}\npublic static Builder<File> fromFiles(Iterable<File> files) {...}\npublic static Builder<URL> fromURLs(Iterable<URL> urls) {...}\npublic static Builder<InputStream> fromInputStreams(Iterable<? extends InputStream> inputStreams) {...}\npublic static Builder<BufferedImage> fromImages(Iterable<BufferedImage> images) {...}\n\n\n很显然，Thumbnails 允许通过传入文件名、文件、网络图的 URL、图片流、图片缓存多种方式来初始化构造器。\n\n因此，你可以根据实际需求来灵活的选择图片的输入方式。\n\n需要注意一点：如果输入是多个对象（无论你是直接输入容器对象或使用可变参数方式传入多个对象），则输出也必须选用输出多个对象的方式，否则会报异常。\n\n\n# Thumbnails.Builder\n\nThumbnails.Builder 是 Thumbnails 的内部静态类。它用于设置生成缩略图任务的相关参数。\n\n注：Thumbnails.Builder 的构造函数是私有函数。所以，它只允许通过 Thumbnails 的实例化函数来进行初始化。\n\n# 设置参数的函数\n\nThumbnails.Builder 提供了一组函数链形式的接口来设置缩放图参数。\n\n以设置大小函数为例：\n\npublic Builder<T> size(int width, int height)\n{\n updateStatus(Properties.SIZE, Status.ALREADY_SET);\n updateStatus(Properties.SCALE, Status.CANNOT_SET);\n\n validateDimensions(width, height);\n this.width = width;\n this.height = height;\n\n return this;\n}\n\n\n通过返回 this 指针，使得设置参数函数可以以链式调用的方式来使用，形式如下：\n\nThumbnails.of(new File("original.jpg"))\n        .size(160, 160)\n        .rotate(90)\n        .watermark(Positions.BOTTOM_RIGHT, ImageIO.read(new File("watermark.png")), 0.5f)\n        .outputQuality(0.8)\n        .toFile(new File("image-with-watermark.jpg"));\n\n\n好处，不言自明：那就是大大简化了代码。\n\n# 输出函数\n\nThumbnails.Builder 提供了一组重载函数来输出生成的缩放图。\n\n函数声明如下：\n\n// 返回图片缓存\npublic List<BufferedImage> asBufferedImages() throws IOException {...}\npublic BufferedImage asBufferedImage() throws IOException {...}\n// 返回文件列表\npublic List<File> asFiles(Iterable<File> iterable) throws IOException {...}\npublic List<File> asFiles(Rename rename) throws IOException {...}\npublic List<File> asFiles(File destinationDir, Rename rename) throws IOException {...}\n// 创建文件\npublic void toFile(File outFile) throws IOException {...}\npublic void toFile(String outFilepath) throws IOException {...}\npublic void toFiles(Iterable<File> iterable) throws IOException {...}\npublic void toFiles(Rename rename) throws IOException {...}\npublic void toFiles(File destinationDir, Rename rename) throws IOException {...}\n// 创建输出流\npublic void toOutputStream(OutputStream os) throws IOException {...}\npublic void toOutputStreams(Iterable<? extends OutputStream> iterable) throws IOException {...}\n\n\n\n# 工作流\n\nThumbnailator 的工作步骤十分简单，可分为三步：\n\n 1. 输入：Thumbnails 根据输入初始化构造器—— Thumbnails.Builder 。\n\n 2. 设置：Thumbnails.Builder 设置缩放图片的参数。\n\n 3. 输出：Thumbnails.Builder 输出图片文件或图片流。\n\n> 更多详情可以参考： Thumbnailator 官网 javadoc\n\n\n# 实战\n\n前文介绍了 Thumbnailator 的核心 API，接下来我们就可以通过实战来看看 Thumbnailator 究竟可以做些什么。\n\nThumbnailator 生成什么样的图片，是根据设置参数来决定的。\n\n\n# 安装\n\nmaven 项目中引入依赖：\n\n<dependency>\n  <groupId>net.coobird</groupId>\n  <artifactId>thumbnailator</artifactId>\n  <version>[0.4, 0.5)</version>\n</dependency>\n\n\n\n# 图片缩放\n\nThumbnails.Builder 的 size 函数可以设置新图片精确的宽度和高度，也可以用 scale 函数设置缩放比例。\n\nThumbnails.of("oldFile.png")\n  .size(16, 16)\n  .toFile("newFile_16_16.png");\n\nThumbnails.of("oldFile.png")\n  .scale(2.0)\n  .toFile("newFile_scale_2.0.png");\n\nThumbnails.of("oldFile.png")\n  .scale(1.0, 0.5)\n  .toFile("newFile_scale_1.0_0.5.png");\n\n\noldFile.png\n\n\n\nnewFile_scale_1.0_0.5.png\n\n\n\n\n# 图片旋转\n\nThumbnails.Builder 的 size 函数可以设置新图片的旋转角度。\n\nThumbnails.of("oldFile.png")\n  .scale(0.8)\n  .rotate(90)\n  .toFile("newFile_rotate_90.png");\n\nThumbnails.of("oldFile.png")\n  .scale(0.8)\n  .rotate(180)\n  .toFile("newFile_rotate_180.png");\n\n\nnewFile_rotate_90.png\n\n\n\n\n# 加水印\n\nThumbnails.Builder 的 watermark 函数可以为图片添加水印图片。第一个参数是水印的位置；第二个参数是水印图片的缓存数据；第三个参数是透明度。\n\nBufferedImage watermarkImage = ImageIO.read(new File("wartermarkFile.png"));\nThumbnails.of("oldFile.png")\n  .scale(0.8)\n  .watermark(Positions.BOTTOM_LEFT, watermarkImage, 0.5f)\n  .toFile("newFile_watermark.png");\n\n\nwartermarkFile.png\n\n\n\nnewFile_watermark.png\n\n\n\n\n# 批量处理图片\n\n下面以批量给图片加水印来展示一下如何处理多个图片文件。\n\nBufferedImage watermarkImage = ImageIO.read(new File("wartermarkFile.png"));\n\nFile destinationDir = new File("D:\\\\watermark\\\\");\nThumbnails.of("oldFile.png", "oldFile2.png")\n  .scale(0.8)\n  .watermark(Positions.BOTTOM_LEFT, watermarkImage, 0.5f)\n  .toFiles(destinationDir, Rename.PREFIX_DOT_THUMBNAIL);\n\n\n> 需要参考完整测试例代码请 点击这里\n\n\n# 参考\n\nThumbnailator 官方示例文档',normalizedContent:'# thumbnailator 快速入门\n\n\n# 简介\n\nthumbnailator 是一个开源的 java 项目，它提供了非常简单的 api 来对图片进行缩放、旋转以及加水印的处理。\n\n有多简单呢？简单到一行代码就可以完成图片处理。形式如下：\n\nthumbnails.of(new file("path/to/directory").listfiles())\n    .size(640, 480)\n    .outputformat("jpg")\n    .tofiles(rename.prefix_dot_thumbnail);\n\n\n当然，thumbnailator 还有一些使用细节，下面我会一一道来。\n\n\n# 核心 api\n\n\n# thumbnails\n\nthumbnails 是使用 thumbnailator 创建缩略图的主入口。\n\n它提供了一组初始化 thumbnails.builder 的接口。\n\n先看下这组接口的声明：\n\n// 可变长度参数列表\npublic static builder<file> of(string... files) {...}\npublic static builder<file> of(file... files) {...}\npublic static builder<url> of(url... urls) {...}\npublic static builder<? extends inputstream> of(inputstream... inputstreams) {...}\npublic static builder<bufferedimage> of(bufferedimage... images) {...}\n// 迭代器（所有实现 iterable 接口的 java 对象都可以，当然也包括 list、set）\npublic static builder<file> fromfilenames(iterable<string> files) {...}\npublic static builder<file> fromfiles(iterable<file> files) {...}\npublic static builder<url> fromurls(iterable<url> urls) {...}\npublic static builder<inputstream> frominputstreams(iterable<? extends inputstream> inputstreams) {...}\npublic static builder<bufferedimage> fromimages(iterable<bufferedimage> images) {...}\n\n\n很显然，thumbnails 允许通过传入文件名、文件、网络图的 url、图片流、图片缓存多种方式来初始化构造器。\n\n因此，你可以根据实际需求来灵活的选择图片的输入方式。\n\n需要注意一点：如果输入是多个对象（无论你是直接输入容器对象或使用可变参数方式传入多个对象），则输出也必须选用输出多个对象的方式，否则会报异常。\n\n\n# thumbnails.builder\n\nthumbnails.builder 是 thumbnails 的内部静态类。它用于设置生成缩略图任务的相关参数。\n\n注：thumbnails.builder 的构造函数是私有函数。所以，它只允许通过 thumbnails 的实例化函数来进行初始化。\n\n# 设置参数的函数\n\nthumbnails.builder 提供了一组函数链形式的接口来设置缩放图参数。\n\n以设置大小函数为例：\n\npublic builder<t> size(int width, int height)\n{\n updatestatus(properties.size, status.already_set);\n updatestatus(properties.scale, status.cannot_set);\n\n validatedimensions(width, height);\n this.width = width;\n this.height = height;\n\n return this;\n}\n\n\n通过返回 this 指针，使得设置参数函数可以以链式调用的方式来使用，形式如下：\n\nthumbnails.of(new file("original.jpg"))\n        .size(160, 160)\n        .rotate(90)\n        .watermark(positions.bottom_right, imageio.read(new file("watermark.png")), 0.5f)\n        .outputquality(0.8)\n        .tofile(new file("image-with-watermark.jpg"));\n\n\n好处，不言自明：那就是大大简化了代码。\n\n# 输出函数\n\nthumbnails.builder 提供了一组重载函数来输出生成的缩放图。\n\n函数声明如下：\n\n// 返回图片缓存\npublic list<bufferedimage> asbufferedimages() throws ioexception {...}\npublic bufferedimage asbufferedimage() throws ioexception {...}\n// 返回文件列表\npublic list<file> asfiles(iterable<file> iterable) throws ioexception {...}\npublic list<file> asfiles(rename rename) throws ioexception {...}\npublic list<file> asfiles(file destinationdir, rename rename) throws ioexception {...}\n// 创建文件\npublic void tofile(file outfile) throws ioexception {...}\npublic void tofile(string outfilepath) throws ioexception {...}\npublic void tofiles(iterable<file> iterable) throws ioexception {...}\npublic void tofiles(rename rename) throws ioexception {...}\npublic void tofiles(file destinationdir, rename rename) throws ioexception {...}\n// 创建输出流\npublic void tooutputstream(outputstream os) throws ioexception {...}\npublic void tooutputstreams(iterable<? extends outputstream> iterable) throws ioexception {...}\n\n\n\n# 工作流\n\nthumbnailator 的工作步骤十分简单，可分为三步：\n\n 1. 输入：thumbnails 根据输入初始化构造器—— thumbnails.builder 。\n\n 2. 设置：thumbnails.builder 设置缩放图片的参数。\n\n 3. 输出：thumbnails.builder 输出图片文件或图片流。\n\n> 更多详情可以参考： thumbnailator 官网 javadoc\n\n\n# 实战\n\n前文介绍了 thumbnailator 的核心 api，接下来我们就可以通过实战来看看 thumbnailator 究竟可以做些什么。\n\nthumbnailator 生成什么样的图片，是根据设置参数来决定的。\n\n\n# 安装\n\nmaven 项目中引入依赖：\n\n<dependency>\n  <groupid>net.coobird</groupid>\n  <artifactid>thumbnailator</artifactid>\n  <version>[0.4, 0.5)</version>\n</dependency>\n\n\n\n# 图片缩放\n\nthumbnails.builder 的 size 函数可以设置新图片精确的宽度和高度，也可以用 scale 函数设置缩放比例。\n\nthumbnails.of("oldfile.png")\n  .size(16, 16)\n  .tofile("newfile_16_16.png");\n\nthumbnails.of("oldfile.png")\n  .scale(2.0)\n  .tofile("newfile_scale_2.0.png");\n\nthumbnails.of("oldfile.png")\n  .scale(1.0, 0.5)\n  .tofile("newfile_scale_1.0_0.5.png");\n\n\noldfile.png\n\n\n\nnewfile_scale_1.0_0.5.png\n\n\n\n\n# 图片旋转\n\nthumbnails.builder 的 size 函数可以设置新图片的旋转角度。\n\nthumbnails.of("oldfile.png")\n  .scale(0.8)\n  .rotate(90)\n  .tofile("newfile_rotate_90.png");\n\nthumbnails.of("oldfile.png")\n  .scale(0.8)\n  .rotate(180)\n  .tofile("newfile_rotate_180.png");\n\n\nnewfile_rotate_90.png\n\n\n\n\n# 加水印\n\nthumbnails.builder 的 watermark 函数可以为图片添加水印图片。第一个参数是水印的位置；第二个参数是水印图片的缓存数据；第三个参数是透明度。\n\nbufferedimage watermarkimage = imageio.read(new file("wartermarkfile.png"));\nthumbnails.of("oldfile.png")\n  .scale(0.8)\n  .watermark(positions.bottom_left, watermarkimage, 0.5f)\n  .tofile("newfile_watermark.png");\n\n\nwartermarkfile.png\n\n\n\nnewfile_watermark.png\n\n\n\n\n# 批量处理图片\n\n下面以批量给图片加水印来展示一下如何处理多个图片文件。\n\nbufferedimage watermarkimage = imageio.read(new file("wartermarkfile.png"));\n\nfile destinationdir = new file("d:\\\\watermark\\\\");\nthumbnails.of("oldfile.png", "oldfile2.png")\n  .scale(0.8)\n  .watermark(positions.bottom_left, watermarkimage, 0.5f)\n  .tofiles(destinationdir, rename.prefix_dot_thumbnail);\n\n\n> 需要参考完整测试例代码请 点击这里\n\n\n# 参考\n\nthumbnailator 官方示例文档',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"ZXing 快速入门",frontmatter:{title:"ZXing 快速入门",categories:["编程","Java","工具"],tags:["Java","条形码","ZXing"],abbrlink:"b465c57d",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/cc8ce5/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/99.%E5%85%B6%E4%BB%96/07.Zxing.html",relativePath:"12.工具/99.其他/07.Zxing.md",key:"v-4c05d3a6",path:"/pages/cc8ce5/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:17},{level:2,title:"实战",slug:"实战",normalizedTitle:"实战",charIndex:164},{level:3,title:"安装",slug:"安装",normalizedTitle:"安装",charIndex:223},{level:3,title:"生成二维码图片",slug:"生成二维码图片",normalizedTitle:"生成二维码图片",charIndex:529},{level:3,title:"解析二维码图片",slug:"解析二维码图片",normalizedTitle:"解析二维码图片",charIndex:210},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:2066}],headersStr:"简介 实战 安装 生成二维码图片 解析二维码图片 参考",content:'# ZXing 快速入门\n\n\n# 简介\n\nZXing 是一个开源 Java 类库用于解析多种格式的 1D/2D 条形码。目标是能够对 QR 编码、Data Matrix、UPC 的 1D 条形码进行解码。 其提供了多种平台下的客户端包括：J2ME、J2SE 和 Android。\n\n官网：ZXing github 仓库\n\n\n# 实战\n\n本例演示如何在一个非 android 的 Java 项目中使用 ZXing 来生成、解析二维码图片。\n\n\n# 安装\n\nmaven 项目只需引入依赖：\n\n<dependency>\n  <groupId>com.google.zxing</groupId>\n  <artifactId>core</artifactId>\n  <version>3.3.0</version>\n</dependency>\n<dependency>\n  <groupId>com.google.zxing</groupId>\n  <artifactId>javase</artifactId>\n  <version>3.3.0</version>\n</dependency>\n\n\n如果非 maven 项目，就去官网下载发布版本：下载地址\n\n\n# 生成二维码图片\n\nZXing 生成二维码图片有以下步骤：\n\n 1. com.google.zxing.MultiFormatWriter 根据内容以及图像编码参数生成图像 2D 矩阵。\n 2. com.google.zxing.client.j2se.MatrixToImageWriter 根据图像矩阵生成图片文件或图片缓存 BufferedImage 。\n\npublic void encode(String content, String filepath) throws WriterException, IOException {\n int width = 100;\n int height = 100;\n Map<EncodeHintType, Object> encodeHints = new HashMap<EncodeHintType, Object>();\n encodeHints.put(EncodeHintType.CHARACTER_SET, "UTF-8");\n BitMatrix bitMatrix = new MultiFormatWriter().encode(content, BarcodeFormat.QR_CODE, width, height, encodeHints);\n Path path = FileSystems.getDefault().getPath(filepath);\n MatrixToImageWriter.writeToPath(bitMatrix, "png", path);\n}\n\n\n\n# 解析二维码图片\n\nZXing 解析二维码图片有以下步骤：\n\n 1. 使用 javax.imageio.ImageIO 读取图片文件，并存为一个 java.awt.image.BufferedImage 对象。\n\n 2. 将 java.awt.image.BufferedImage 转换为 ZXing 能识别的 com.google.zxing.BinaryBitmap 对象。\n\n 3. com.google.zxing.MultiFormatReader 根据图像解码参数来解析 com.google.zxing.BinaryBitmap 。\n\npublic String decode(String filepath) throws IOException, NotFoundException {\n BufferedImage bufferedImage = ImageIO.read(new FileInputStream(filepath));\n LuminanceSource source = new BufferedImageLuminanceSource(bufferedImage);\n Binarizer binarizer = new HybridBinarizer(source);\n BinaryBitmap bitmap = new BinaryBitmap(binarizer);\n HashMap<DecodeHintType, Object> decodeHints = new HashMap<DecodeHintType, Object>();\n decodeHints.put(DecodeHintType.CHARACTER_SET, "UTF-8");\n Result result = new MultiFormatReader().decode(bitmap, decodeHints);\n return result.getText();\n}\n\n\n完整参考示例：测试例代码\n\n以下是一个生成的二维码图片示例：\n\n\n\n\n# 参考\n\nZXing github 仓库',normalizedContent:'# zxing 快速入门\n\n\n# 简介\n\nzxing 是一个开源 java 类库用于解析多种格式的 1d/2d 条形码。目标是能够对 qr 编码、data matrix、upc 的 1d 条形码进行解码。 其提供了多种平台下的客户端包括：j2me、j2se 和 android。\n\n官网：zxing github 仓库\n\n\n# 实战\n\n本例演示如何在一个非 android 的 java 项目中使用 zxing 来生成、解析二维码图片。\n\n\n# 安装\n\nmaven 项目只需引入依赖：\n\n<dependency>\n  <groupid>com.google.zxing</groupid>\n  <artifactid>core</artifactid>\n  <version>3.3.0</version>\n</dependency>\n<dependency>\n  <groupid>com.google.zxing</groupid>\n  <artifactid>javase</artifactid>\n  <version>3.3.0</version>\n</dependency>\n\n\n如果非 maven 项目，就去官网下载发布版本：下载地址\n\n\n# 生成二维码图片\n\nzxing 生成二维码图片有以下步骤：\n\n 1. com.google.zxing.multiformatwriter 根据内容以及图像编码参数生成图像 2d 矩阵。\n 2. com.google.zxing.client.j2se.matrixtoimagewriter 根据图像矩阵生成图片文件或图片缓存 bufferedimage 。\n\npublic void encode(string content, string filepath) throws writerexception, ioexception {\n int width = 100;\n int height = 100;\n map<encodehinttype, object> encodehints = new hashmap<encodehinttype, object>();\n encodehints.put(encodehinttype.character_set, "utf-8");\n bitmatrix bitmatrix = new multiformatwriter().encode(content, barcodeformat.qr_code, width, height, encodehints);\n path path = filesystems.getdefault().getpath(filepath);\n matrixtoimagewriter.writetopath(bitmatrix, "png", path);\n}\n\n\n\n# 解析二维码图片\n\nzxing 解析二维码图片有以下步骤：\n\n 1. 使用 javax.imageio.imageio 读取图片文件，并存为一个 java.awt.image.bufferedimage 对象。\n\n 2. 将 java.awt.image.bufferedimage 转换为 zxing 能识别的 com.google.zxing.binarybitmap 对象。\n\n 3. com.google.zxing.multiformatreader 根据图像解码参数来解析 com.google.zxing.binarybitmap 。\n\npublic string decode(string filepath) throws ioexception, notfoundexception {\n bufferedimage bufferedimage = imageio.read(new fileinputstream(filepath));\n luminancesource source = new bufferedimageluminancesource(bufferedimage);\n binarizer binarizer = new hybridbinarizer(source);\n binarybitmap bitmap = new binarybitmap(binarizer);\n hashmap<decodehinttype, object> decodehints = new hashmap<decodehinttype, object>();\n decodehints.put(decodehinttype.character_set, "utf-8");\n result result = new multiformatreader().decode(bitmap, decodehints);\n return result.gettext();\n}\n\n\n完整参考示例：测试例代码\n\n以下是一个生成的二维码图片示例：\n\n\n\n\n# 参考\n\nzxing github 仓库',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 工具",frontmatter:{title:"Java 工具",categories:["编程","Java","工具"],tags:["Java","工具"],abbrlink:13035347,date:"2022-02-18T08:53:11.000Z",hidden:!0,permalink:"/pages/4b6820/"},regularPath:"/12.%E5%B7%A5%E5%85%B7/",relativePath:"12.工具/README.md",key:"v-ed73b8ba",path:"/pages/4b6820/",headers:[{level:2,title:"📖 内容",slug:"📖-内容",normalizedTitle:"📖 内容",charIndex:14},{level:3,title:"Java IO",slug:"java-io",normalizedTitle:"java io",charIndex:24},{level:3,title:"JavaBean 工具",slug:"javabean-工具",normalizedTitle:"javabean 工具",charIndex:118},{level:3,title:"Java 模板引擎",slug:"java-模板引擎",normalizedTitle:"java 模板引擎",charIndex:154},{level:3,title:"Java 测试工具",slug:"java-测试工具",normalizedTitle:"java 测试工具",charIndex:206},{level:3,title:"其他",slug:"其他",normalizedTitle:"其他",charIndex:258},{level:2,title:"📚 资料",slug:"📚-资料",normalizedTitle:"📚 资料",charIndex:351},{level:2,title:"🚪 传送",slug:"🚪-传送",normalizedTitle:"🚪 传送",charIndex:361}],headersStr:"📖 内容 Java IO JavaBean 工具 Java 模板引擎 Java 测试工具 其他 📚 资料 🚪 传送",content:"# Java 工具\n\n\n# 📖 内容\n\n\n# Java IO\n\n * JSON 序列化 - fastjson、Jackson、Gson\n * 二进制序列化 - Protobuf、Thrift、Hessian、Kryo、FST\n\n\n# JavaBean 工具\n\n * Lombok\n * Dozer\n\n\n# Java 模板引擎\n\n * Freemark\n * Velocity\n * Thymeleaf\n\n\n# Java 测试工具\n\n * Junit\n * Mockito\n * Jmeter\n * JMH\n\n\n# 其他\n\n * Java 日志\n * Java 工具包\n * Reflections\n * JavaMail\n * Jsoup\n * Thumbnailator\n * Zxing\n\n\n# 📚 资料\n\n\n# 🚪 传送\n\n◾ 🏠 JAVA-TUTORIAL 首页 ◾ 🎯 我的博客 ◾",normalizedContent:"# java 工具\n\n\n# 📖 内容\n\n\n# java io\n\n * json 序列化 - fastjson、jackson、gson\n * 二进制序列化 - protobuf、thrift、hessian、kryo、fst\n\n\n# javabean 工具\n\n * lombok\n * dozer\n\n\n# java 模板引擎\n\n * freemark\n * velocity\n * thymeleaf\n\n\n# java 测试工具\n\n * junit\n * mockito\n * jmeter\n * jmh\n\n\n# 其他\n\n * java 日志\n * java 工具包\n * reflections\n * javamail\n * jsoup\n * thumbnailator\n * zxing\n\n\n# 📚 资料\n\n\n# 🚪 传送\n\n◾ 🏠 java-tutorial 首页 ◾ 🎯 我的博客 ◾",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Mybatis快速入门",frontmatter:{title:"Mybatis快速入门",categories:["编程","Java","框架","ORM"],tags:["Java","框架","ORM","Mybatis"],abbrlink:"a7445586",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/538358/"},regularPath:"/13.%E6%A1%86%E6%9E%B6/11.ORM/01.Mybatis%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8.html",relativePath:"13.框架/11.ORM/01.Mybatis快速入门.md",key:"v-af4ff908",path:"/pages/538358/",headers:[{level:2,title:"Mybatis 简介",slug:"mybatis-简介",normalizedTitle:"mybatis 简介",charIndex:102},{level:3,title:"什么是 MyBatis",slug:"什么是-mybatis",normalizedTitle:"什么是 mybatis",charIndex:119},{level:3,title:"MyBatis vs. Hibernate",slug:"mybatis-vs-hibernate",normalizedTitle:"mybatis vs. hibernate",charIndex:310},{level:2,title:"快速入门",slug:"快速入门",normalizedTitle:"快速入门",charIndex:10},{level:3,title:"数据库准备",slug:"数据库准备",normalizedTitle:"数据库准备",charIndex:821},{level:3,title:"添加 Mybatis",slug:"添加-mybatis",normalizedTitle:"添加 mybatis",charIndex:1448},{level:3,title:"Mybatis 配置",slug:"mybatis-配置",normalizedTitle:"mybatis 配置",charIndex:1631},{level:3,title:"Mapper",slug:"mapper",normalizedTitle:"mapper",charIndex:2506},{level:4,title:"Mapper.xml",slug:"mapper-xml",normalizedTitle:"mapper.xml",charIndex:2506},{level:4,title:"Mapper.java",slug:"mapper-java",normalizedTitle:"mapper.java",charIndex:4443},{level:4,title:"数据实体.java",slug:"数据实体-java",normalizedTitle:"数据实体.java",charIndex:4914},{level:3,title:"测试程序",slug:"测试程序",normalizedTitle:"测试程序",charIndex:5237},{level:2,title:"Mybatis xml 配置",slug:"mybatis-xml-配置",normalizedTitle:"mybatis xml 配置",charIndex:6290},{level:2,title:"Mybatis xml 映射器",slug:"mybatis-xml-映射器",normalizedTitle:"mybatis xml 映射器",charIndex:6662},{level:2,title:"Mybatis 扩展",slug:"mybatis-扩展",normalizedTitle:"mybatis 扩展",charIndex:7030},{level:3,title:"Mybatis 类型处理器",slug:"mybatis-类型处理器",normalizedTitle:"mybatis 类型处理器",charIndex:7045},{level:3,title:"Mybatis 插件",slug:"mybatis-插件",normalizedTitle:"mybatis 插件",charIndex:8426},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:9825}],headersStr:"Mybatis 简介 什么是 MyBatis MyBatis vs. Hibernate 快速入门 数据库准备 添加 Mybatis Mybatis 配置 Mapper Mapper.xml Mapper.java 数据实体.java 测试程序 Mybatis xml 配置 Mybatis xml 映射器 Mybatis 扩展 Mybatis 类型处理器 Mybatis 插件 参考资料",content:'# MyBatis 快速入门\n\n> MyBatis 的前身就是 iBatis ，是一个作用在数据持久层的对象关系映射（Object Relational Mapping，简称 ORM）框架。\n\n\n\n\n# Mybatis 简介\n\n\n\n\n# 什么是 MyBatis\n\nMyBatis 是一款持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生类型、接口和 Java 的 POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。\n\n\n# MyBatis vs. Hibernate\n\nMyBatis 和 Hibernate 都是 Java 世界中比较流行的 ORM 框架。我们应该了解其各自的优势，根据项目的需要去抉择在开发中使用哪个框架。\n\nMybatis 优势\n\n * MyBatis 可以进行更为细致的 SQL 优化，可以减少查询字段。\n * MyBatis 容易掌握，而 Hibernate 门槛较高。\n\nHibernate 优势\n\n * Hibernate 的 DAO 层开发比 MyBatis 简单，Mybatis 需要维护 SQL 和结果映射。\n * Hibernate 对对象的维护和缓存要比 MyBatis 好，对增删改查的对象的维护要方便。\n * Hibernate 数据库移植性很好，MyBatis 的数据库移植性不好，不同的数据库需要写不同 SQL。\n * Hibernate 有更好的二级缓存机制，可以使用第三方缓存。MyBatis 本身提供的缓存机制不佳。\n\n\n# 快速入门\n\n> 这里，我将以一个入门级的示例来演示 Mybatis 是如何工作的。\n> \n> 注：本文后面章节中的原理、源码部分也将基于这个示例来进行讲解。\n\n\n# 数据库准备\n\n在本示例中，需要针对一张用户表进行 CRUD 操作。其数据模型如下：\n\nCREATE TABLE IF NOT EXISTS user (\n    id      BIGINT(10) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT \'Id\',\n    name    VARCHAR(10)         NOT NULL DEFAULT \'\' COMMENT \'用户名\',\n    age     INT(3)              NOT NULL DEFAULT 0 COMMENT \'年龄\',\n    address VARCHAR(32)         NOT NULL DEFAULT \'\' COMMENT \'地址\',\n    email   VARCHAR(32)         NOT NULL DEFAULT \'\' COMMENT \'邮件\',\n    PRIMARY KEY (id)\n) COMMENT = \'用户表\';\n\nINSERT INTO user (name, age, address, email)\nVALUES (\'张三\', 18, \'北京\', \'xxx@163.com\');\nINSERT INTO user (name, age, address, email)\nVALUES (\'李四\', 19, \'上海\', \'xxx@163.com\');\n\n\n\n# 添加 Mybatis\n\n如果使用 Maven 来构建项目，则需将下面的依赖代码置于 pom.xml 文件中：\n\n<dependency>\n  <groupId>org.mybatis</groupId>\n  <artifactId>mybatis</artifactId>\n  <version>x.x.x</version>\n</dependency>\n\n\n\n# Mybatis 配置\n\nXML 配置文件中包含了对 MyBatis 系统的核心设置，包括获取数据库连接实例的数据源（DataSource）以及决定事务作用域和控制方式的事务管理器（TransactionManager）。\n\n本示例中只是给出最简化的配置。\n\n【示例】mybatis-config.xml 文件\n\n<?xml version="1.0" encoding="utf-8"?>\n<!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN"\n  "http://mybatis.org/dtd/mybatis-3-config.dtd">\n<configuration>\n  <environments default="development">\n    <environment id="development">\n      <transactionManager type="JDBC" />\n      <dataSource type="POOLED">\n        <property name="driver" value="com.mysql.cj.jdbc.Driver" />\n        <property name="url"\n                  value="jdbc:mysql://127.0.0.1:3306/spring_tutorial?serverTimezone=UTC" />\n        <property name="username" value="root" />\n        <property name="password" value="root" />\n      </dataSource>\n    </environment>\n  </environments>\n  <mappers>\n    <mapper resource="mybatis/mapper/UserMapper.xml" />\n  </mappers>\n</configuration>\n\n\n> 说明：上面的配置文件中仅仅指定了数据源连接方式和 User 表的映射配置文件。\n\n\n# Mapper\n\n# Mapper.xml\n\n个人理解，Mapper.xml 文件可以看做是 Mybatis 的 JDBC SQL 模板。\n\n【示例】UserMapper.xml 文件\n\n下面是一个通过 Mybatis Generator 自动生成的完整的 Mapper 文件。\n\n<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">\n<mapper namespace="io.github.dunwu.spring.orm.mapper.UserMapper">\n  <resultMap id="BaseResultMap" type="io.github.dunwu.spring.orm.entity.User">\n    <id column="id" jdbcType="BIGINT" property="id" />\n    <result column="name" jdbcType="VARCHAR" property="name" />\n    <result column="age" jdbcType="INTEGER" property="age" />\n    <result column="address" jdbcType="VARCHAR" property="address" />\n    <result column="email" jdbcType="VARCHAR" property="email" />\n  </resultMap>\n  <delete id="deleteByPrimaryKey" parameterType="java.lang.Long">\n    delete from user\n    where id = #{id,jdbcType=BIGINT}\n  </delete>\n  <insert id="insert" parameterType="io.github.dunwu.spring.orm.entity.User">\n    insert into user (id, name, age,\n      address, email)\n    values (#{id,jdbcType=BIGINT}, #{name,jdbcType=VARCHAR}, #{age,jdbcType=INTEGER},\n      #{address,jdbcType=VARCHAR}, #{email,jdbcType=VARCHAR})\n  </insert>\n  <update id="updateByPrimaryKey" parameterType="io.github.dunwu.spring.orm.entity.User">\n    update user\n    set name = #{name,jdbcType=VARCHAR},\n      age = #{age,jdbcType=INTEGER},\n      address = #{address,jdbcType=VARCHAR},\n      email = #{email,jdbcType=VARCHAR}\n    where id = #{id,jdbcType=BIGINT}\n  </update>\n  <select id="selectByPrimaryKey" parameterType="java.lang.Long" resultMap="BaseResultMap">\n    select id, name, age, address, email\n    from user\n    where id = #{id,jdbcType=BIGINT}\n  </select>\n  <select id="selectAll" resultMap="BaseResultMap">\n    select id, name, age, address, email\n    from user\n  </select>\n</mapper>\n\n\n# Mapper.java\n\nMapper.java 文件是 Mapper.xml 对应的 Java 对象。\n\n【示例】UserMapper.java 文件\n\npublic interface UserMapper {\n\n    int deleteByPrimaryKey(Long id);\n\n    int insert(User record);\n\n    User selectByPrimaryKey(Long id);\n\n    List<User> selectAll();\n\n    int updateByPrimaryKey(User record);\n\n}\n\n\n对比 UserMapper.java 和 UserMapper.xml 文件，不难发现：\n\nUserMapper.java 中的方法和 UserMapper.xml 的 CRUD 语句元素（ <insert>、<delete>、<update>、<select>）存在一一对应关系。\n\n在 Mybatis 中，正是通过方法的全限定名，将二者绑定在一起。\n\n# 数据实体.java\n\n【示例】User.java 文件\n\npublic class User {\n    private Long id;\n\n    private String name;\n\n    private Integer age;\n\n    private String address;\n\n    private String email;\n\n}\n\n\n<insert>、<delete>、<update>、<select> 的 parameterType 属性以及 <resultMap> 的 type 属性都可能会绑定到数据实体。这样就可以把 JDBC 操作的输入输出和 JavaBean 结合起来，更加方便、易于理解。\n\n\n# 测试程序\n\n【示例】MybatisDemo.java 文件\n\npublic class MybatisDemo {\n\n    public static void main(String[] args) throws Exception {\n        // 1. 加载 mybatis 配置文件，创建 SqlSessionFactory\n        // 注：在实际的应用中，SqlSessionFactory 应该是单例\n        InputStream inputStream = Resources.getResourceAsStream("mybatis/mybatis-config.xml");\n        SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder();\n        SqlSessionFactory factory = builder.build(inputStream);\n\n        // 2. 创建一个 SqlSession 实例，进行数据库操作\n        SqlSession sqlSession = factory.openSession();\n\n        // 3. Mapper 映射并执行\n        Long params = 1L;\n        List<User> list = sqlSession.selectList("io.github.dunwu.spring.orm.mapper.UserMapper.selectByPrimaryKey", params);\n        for (User user : list) {\n            System.out.println("user name: " + user.getName());\n        }\n        // 输出：user name: 张三\n    }\n\n}\n\n\n> 说明：\n> \n> SqlSession 接口是 Mybatis API 核心中的核心，它代表了 Mybatis 和数据库的一次完整会话。\n> \n>  * Mybatis 会解析配置，并根据配置创建 SqlSession 。\n>  * 然后，Mybatis 将 Mapper 映射为 SqlSession，然后传递参数，执行 SQL 语句并获取结果。\n\n\n# Mybatis xml 配置\n\n> 配置的详细内容请参考：「 Mybatis 官方文档之配置 」 。\n\nMyBatis 的配置文件包含了会深深影响 MyBatis 行为的设置和属性信息。主要配置项有以下：\n\n * properties（属性）\n * settings（设置）\n * typeAliases（类型别名）\n * typeHandlers（类型处理器）\n * objectFactory（对象工厂）\n * plugins（插件）\n * environments（环境配置）\n   * environment（环境变量）\n     * transactionManager（事务管理器）\n     * dataSource（数据源）\n * databaseIdProvider（数据库厂商标识）\n * mappers（映射器）\n\n\n# Mybatis xml 映射器\n\n> SQL XML 映射文件详细内容请参考：「 Mybatis 官方文档之 XML 映射文件 」。\n\nXML 映射文件只有几个顶级元素：\n\n * cache – 对给定命名空间的缓存配置。\n * cache-ref – 对其他命名空间缓存配置的引用。\n * resultMap – 是最复杂也是最强大的元素，用来描述如何从数据库结果集中来加载对象。\n * parameterMap – 已被废弃！老式风格的参数映射。更好的办法是使用内联参数，此元素可能在将来被移除。文档中不会介绍此元素。\n * sql – 可被其他语句引用的可重用语句块。\n * insert – 映射插入语句\n * update – 映射更新语句\n * delete – 映射删除语句\n * select – 映射查询语句\n\n\n# Mybatis 扩展\n\n\n# Mybatis 类型处理器\n\nMyBatis 在设置预处理语句（PreparedStatement）中的参数或从结果集中取出一个值时， 都会用类型处理器将获取到的值以合适的方式转换成 Java 类型。下表描述了一些默认的类型处理器。\n\n从 3.4.5 开始，MyBatis 默认支持 JSR-310（日期和时间 API） 。\n\n你可以重写已有的类型处理器或创建你自己的类型处理器来处理不支持的或非标准的类型。 具体做法为：实现 org.apache.ibatis.type.TypeHandler 接口， 或继承一个很便利的类 org.apache.ibatis.type.BaseTypeHandler， 并且可以（可选地）将它映射到一个 JDBC 类型。比如：\n\n// ExampleTypeHandler.java\n@MappedJdbcTypes(JdbcType.VARCHAR)\npublic class ExampleTypeHandler extends BaseTypeHandler<String> {\n\n  @Override\n  public void setNonNullParameter(PreparedStatement ps, int i, String parameter, JdbcType jdbcType) throws SQLException {\n    ps.setString(i, parameter);\n  }\n\n  @Override\n  public String getNullableResult(ResultSet rs, String columnName) throws SQLException {\n    return rs.getString(columnName);\n  }\n\n  @Override\n  public String getNullableResult(ResultSet rs, int columnIndex) throws SQLException {\n    return rs.getString(columnIndex);\n  }\n\n  @Override\n  public String getNullableResult(CallableStatement cs, int columnIndex) throws SQLException {\n    return cs.getString(columnIndex);\n  }\n}\n\n\n\x3c!-- mybatis-config.xml --\x3e\n<typeHandlers>\n  <typeHandler handler="org.mybatis.example.ExampleTypeHandler"/>\n</typeHandlers>\n\n\n使用上述的类型处理器将会覆盖已有的处理 Java String 类型的属性以及 VARCHAR 类型的参数和结果的类型处理器。 要注意 MyBatis 不会通过检测数据库元信息来决定使用哪种类型，所以你必须在参数和结果映射中指明字段是 VARCHAR 类型， 以使其能够绑定到正确的类型处理器上。这是因为 MyBatis 直到语句被执行时才清楚数据类型。\n\n\n# Mybatis 插件\n\nMyBatis 允许你在映射语句执行过程中的某一点进行拦截调用。默认情况下，MyBatis 允许使用插件来拦截的方法调用包括：\n\n * Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed)\n * ParameterHandler (getParameterObject, setParameters)\n * ResultSetHandler (handleResultSets, handleOutputParameters)\n * StatementHandler (prepare, parameterize, batch, update, query)\n\n这些类中方法的细节可以通过查看每个方法的签名来发现，或者直接查看 MyBatis 发行包中的源代码。 如果你想做的不仅仅是监控方法的调用，那么你最好相当了解要重写的方法的行为。 因为在试图修改或重写已有方法的行为时，很可能会破坏 MyBatis 的核心模块。 这些都是更底层的类和方法，所以使用插件的时候要特别当心。\n\n通过 MyBatis 提供的强大机制，使用插件是非常简单的，只需实现 Interceptor 接口，并指定想要拦截的方法签名即可。\n\n// ExamplePlugin.java\n@Intercepts({@Signature(\n  type= Executor.class,\n  method = "update",\n  args = {MappedStatement.class,Object.class})})\npublic class ExamplePlugin implements Interceptor {\n  private Properties properties = new Properties();\n  public Object intercept(Invocation invocation) throws Throwable {\n    // implement pre processing if need\n    Object returnObject = invocation.proceed();\n    // implement post processing if need\n    return returnObject;\n  }\n  public void setProperties(Properties properties) {\n    this.properties = properties;\n  }\n}\n\n\n\x3c!-- mybatis-config.xml --\x3e\n<plugins>\n  <plugin interceptor="org.mybatis.example.ExamplePlugin">\n    <property name="someProperty" value="100"/>\n  </plugin>\n</plugins>\n\n\n上面的插件将会拦截在 Executor 实例中所有的 “update” 方法调用， 这里的 Executor 是负责执行底层映射语句的内部对象。\n\n\n# 参考资料\n\n * 官方\n   * Mybatis Github\n   * Mybatis 官网\n   * MyBatis 官方代码生成（mybatis-generator）\n   * MyBatis 官方集成 Spring（mybatis-spring）\n   * Mybatis 官方集成 Spring Boot（mybatis-spring-boot）\n * 扩展插件\n   * MyBatis-Plus - CRUD 扩展插件、代码生成器、分页器等多功能\n   * Mapper - CRUD 扩展插件\n   * Mybatis-PageHelper - Mybatis 通用分页插件\n * 文章\n   * 深入理解 mybatis 原理\n   * mybatis 源码中文注释\n   * MyBatis Generator 详解\n   * Mybatis 常见面试题\n   * Mybatis 中强大的 resultMap',normalizedContent:'# mybatis 快速入门\n\n> mybatis 的前身就是 ibatis ，是一个作用在数据持久层的对象关系映射（object relational mapping，简称 orm）框架。\n\n\n\n\n# mybatis 简介\n\n\n\n\n# 什么是 mybatis\n\nmybatis 是一款持久层框架，它支持定制化 sql、存储过程以及高级映射。mybatis 避免了几乎所有的 jdbc 代码和手动设置参数以及获取结果集。mybatis 可以使用简单的 xml 或注解来配置和映射原生类型、接口和 java 的 pojo（plain old java objects，普通老式 java 对象）为数据库中的记录。\n\n\n# mybatis vs. hibernate\n\nmybatis 和 hibernate 都是 java 世界中比较流行的 orm 框架。我们应该了解其各自的优势，根据项目的需要去抉择在开发中使用哪个框架。\n\nmybatis 优势\n\n * mybatis 可以进行更为细致的 sql 优化，可以减少查询字段。\n * mybatis 容易掌握，而 hibernate 门槛较高。\n\nhibernate 优势\n\n * hibernate 的 dao 层开发比 mybatis 简单，mybatis 需要维护 sql 和结果映射。\n * hibernate 对对象的维护和缓存要比 mybatis 好，对增删改查的对象的维护要方便。\n * hibernate 数据库移植性很好，mybatis 的数据库移植性不好，不同的数据库需要写不同 sql。\n * hibernate 有更好的二级缓存机制，可以使用第三方缓存。mybatis 本身提供的缓存机制不佳。\n\n\n# 快速入门\n\n> 这里，我将以一个入门级的示例来演示 mybatis 是如何工作的。\n> \n> 注：本文后面章节中的原理、源码部分也将基于这个示例来进行讲解。\n\n\n# 数据库准备\n\n在本示例中，需要针对一张用户表进行 crud 操作。其数据模型如下：\n\ncreate table if not exists user (\n    id      bigint(10) unsigned not null auto_increment comment \'id\',\n    name    varchar(10)         not null default \'\' comment \'用户名\',\n    age     int(3)              not null default 0 comment \'年龄\',\n    address varchar(32)         not null default \'\' comment \'地址\',\n    email   varchar(32)         not null default \'\' comment \'邮件\',\n    primary key (id)\n) comment = \'用户表\';\n\ninsert into user (name, age, address, email)\nvalues (\'张三\', 18, \'北京\', \'xxx@163.com\');\ninsert into user (name, age, address, email)\nvalues (\'李四\', 19, \'上海\', \'xxx@163.com\');\n\n\n\n# 添加 mybatis\n\n如果使用 maven 来构建项目，则需将下面的依赖代码置于 pom.xml 文件中：\n\n<dependency>\n  <groupid>org.mybatis</groupid>\n  <artifactid>mybatis</artifactid>\n  <version>x.x.x</version>\n</dependency>\n\n\n\n# mybatis 配置\n\nxml 配置文件中包含了对 mybatis 系统的核心设置，包括获取数据库连接实例的数据源（datasource）以及决定事务作用域和控制方式的事务管理器（transactionmanager）。\n\n本示例中只是给出最简化的配置。\n\n【示例】mybatis-config.xml 文件\n\n<?xml version="1.0" encoding="utf-8"?>\n<!doctype configuration public "-//mybatis.org//dtd config 3.0//en"\n  "http://mybatis.org/dtd/mybatis-3-config.dtd">\n<configuration>\n  <environments default="development">\n    <environment id="development">\n      <transactionmanager type="jdbc" />\n      <datasource type="pooled">\n        <property name="driver" value="com.mysql.cj.jdbc.driver" />\n        <property name="url"\n                  value="jdbc:mysql://127.0.0.1:3306/spring_tutorial?servertimezone=utc" />\n        <property name="username" value="root" />\n        <property name="password" value="root" />\n      </datasource>\n    </environment>\n  </environments>\n  <mappers>\n    <mapper resource="mybatis/mapper/usermapper.xml" />\n  </mappers>\n</configuration>\n\n\n> 说明：上面的配置文件中仅仅指定了数据源连接方式和 user 表的映射配置文件。\n\n\n# mapper\n\n# mapper.xml\n\n个人理解，mapper.xml 文件可以看做是 mybatis 的 jdbc sql 模板。\n\n【示例】usermapper.xml 文件\n\n下面是一个通过 mybatis generator 自动生成的完整的 mapper 文件。\n\n<?xml version="1.0" encoding="utf-8"?>\n<!doctype mapper public "-//mybatis.org//dtd mapper 3.0//en" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">\n<mapper namespace="io.github.dunwu.spring.orm.mapper.usermapper">\n  <resultmap id="baseresultmap" type="io.github.dunwu.spring.orm.entity.user">\n    <id column="id" jdbctype="bigint" property="id" />\n    <result column="name" jdbctype="varchar" property="name" />\n    <result column="age" jdbctype="integer" property="age" />\n    <result column="address" jdbctype="varchar" property="address" />\n    <result column="email" jdbctype="varchar" property="email" />\n  </resultmap>\n  <delete id="deletebyprimarykey" parametertype="java.lang.long">\n    delete from user\n    where id = #{id,jdbctype=bigint}\n  </delete>\n  <insert id="insert" parametertype="io.github.dunwu.spring.orm.entity.user">\n    insert into user (id, name, age,\n      address, email)\n    values (#{id,jdbctype=bigint}, #{name,jdbctype=varchar}, #{age,jdbctype=integer},\n      #{address,jdbctype=varchar}, #{email,jdbctype=varchar})\n  </insert>\n  <update id="updatebyprimarykey" parametertype="io.github.dunwu.spring.orm.entity.user">\n    update user\n    set name = #{name,jdbctype=varchar},\n      age = #{age,jdbctype=integer},\n      address = #{address,jdbctype=varchar},\n      email = #{email,jdbctype=varchar}\n    where id = #{id,jdbctype=bigint}\n  </update>\n  <select id="selectbyprimarykey" parametertype="java.lang.long" resultmap="baseresultmap">\n    select id, name, age, address, email\n    from user\n    where id = #{id,jdbctype=bigint}\n  </select>\n  <select id="selectall" resultmap="baseresultmap">\n    select id, name, age, address, email\n    from user\n  </select>\n</mapper>\n\n\n# mapper.java\n\nmapper.java 文件是 mapper.xml 对应的 java 对象。\n\n【示例】usermapper.java 文件\n\npublic interface usermapper {\n\n    int deletebyprimarykey(long id);\n\n    int insert(user record);\n\n    user selectbyprimarykey(long id);\n\n    list<user> selectall();\n\n    int updatebyprimarykey(user record);\n\n}\n\n\n对比 usermapper.java 和 usermapper.xml 文件，不难发现：\n\nusermapper.java 中的方法和 usermapper.xml 的 crud 语句元素（ <insert>、<delete>、<update>、<select>）存在一一对应关系。\n\n在 mybatis 中，正是通过方法的全限定名，将二者绑定在一起。\n\n# 数据实体.java\n\n【示例】user.java 文件\n\npublic class user {\n    private long id;\n\n    private string name;\n\n    private integer age;\n\n    private string address;\n\n    private string email;\n\n}\n\n\n<insert>、<delete>、<update>、<select> 的 parametertype 属性以及 <resultmap> 的 type 属性都可能会绑定到数据实体。这样就可以把 jdbc 操作的输入输出和 javabean 结合起来，更加方便、易于理解。\n\n\n# 测试程序\n\n【示例】mybatisdemo.java 文件\n\npublic class mybatisdemo {\n\n    public static void main(string[] args) throws exception {\n        // 1. 加载 mybatis 配置文件，创建 sqlsessionfactory\n        // 注：在实际的应用中，sqlsessionfactory 应该是单例\n        inputstream inputstream = resources.getresourceasstream("mybatis/mybatis-config.xml");\n        sqlsessionfactorybuilder builder = new sqlsessionfactorybuilder();\n        sqlsessionfactory factory = builder.build(inputstream);\n\n        // 2. 创建一个 sqlsession 实例，进行数据库操作\n        sqlsession sqlsession = factory.opensession();\n\n        // 3. mapper 映射并执行\n        long params = 1l;\n        list<user> list = sqlsession.selectlist("io.github.dunwu.spring.orm.mapper.usermapper.selectbyprimarykey", params);\n        for (user user : list) {\n            system.out.println("user name: " + user.getname());\n        }\n        // 输出：user name: 张三\n    }\n\n}\n\n\n> 说明：\n> \n> sqlsession 接口是 mybatis api 核心中的核心，它代表了 mybatis 和数据库的一次完整会话。\n> \n>  * mybatis 会解析配置，并根据配置创建 sqlsession 。\n>  * 然后，mybatis 将 mapper 映射为 sqlsession，然后传递参数，执行 sql 语句并获取结果。\n\n\n# mybatis xml 配置\n\n> 配置的详细内容请参考：「 mybatis 官方文档之配置 」 。\n\nmybatis 的配置文件包含了会深深影响 mybatis 行为的设置和属性信息。主要配置项有以下：\n\n * properties（属性）\n * settings（设置）\n * typealiases（类型别名）\n * typehandlers（类型处理器）\n * objectfactory（对象工厂）\n * plugins（插件）\n * environments（环境配置）\n   * environment（环境变量）\n     * transactionmanager（事务管理器）\n     * datasource（数据源）\n * databaseidprovider（数据库厂商标识）\n * mappers（映射器）\n\n\n# mybatis xml 映射器\n\n> sql xml 映射文件详细内容请参考：「 mybatis 官方文档之 xml 映射文件 」。\n\nxml 映射文件只有几个顶级元素：\n\n * cache – 对给定命名空间的缓存配置。\n * cache-ref – 对其他命名空间缓存配置的引用。\n * resultmap – 是最复杂也是最强大的元素，用来描述如何从数据库结果集中来加载对象。\n * parametermap – 已被废弃！老式风格的参数映射。更好的办法是使用内联参数，此元素可能在将来被移除。文档中不会介绍此元素。\n * sql – 可被其他语句引用的可重用语句块。\n * insert – 映射插入语句\n * update – 映射更新语句\n * delete – 映射删除语句\n * select – 映射查询语句\n\n\n# mybatis 扩展\n\n\n# mybatis 类型处理器\n\nmybatis 在设置预处理语句（preparedstatement）中的参数或从结果集中取出一个值时， 都会用类型处理器将获取到的值以合适的方式转换成 java 类型。下表描述了一些默认的类型处理器。\n\n从 3.4.5 开始，mybatis 默认支持 jsr-310（日期和时间 api） 。\n\n你可以重写已有的类型处理器或创建你自己的类型处理器来处理不支持的或非标准的类型。 具体做法为：实现 org.apache.ibatis.type.typehandler 接口， 或继承一个很便利的类 org.apache.ibatis.type.basetypehandler， 并且可以（可选地）将它映射到一个 jdbc 类型。比如：\n\n// exampletypehandler.java\n@mappedjdbctypes(jdbctype.varchar)\npublic class exampletypehandler extends basetypehandler<string> {\n\n  @override\n  public void setnonnullparameter(preparedstatement ps, int i, string parameter, jdbctype jdbctype) throws sqlexception {\n    ps.setstring(i, parameter);\n  }\n\n  @override\n  public string getnullableresult(resultset rs, string columnname) throws sqlexception {\n    return rs.getstring(columnname);\n  }\n\n  @override\n  public string getnullableresult(resultset rs, int columnindex) throws sqlexception {\n    return rs.getstring(columnindex);\n  }\n\n  @override\n  public string getnullableresult(callablestatement cs, int columnindex) throws sqlexception {\n    return cs.getstring(columnindex);\n  }\n}\n\n\n\x3c!-- mybatis-config.xml --\x3e\n<typehandlers>\n  <typehandler handler="org.mybatis.example.exampletypehandler"/>\n</typehandlers>\n\n\n使用上述的类型处理器将会覆盖已有的处理 java string 类型的属性以及 varchar 类型的参数和结果的类型处理器。 要注意 mybatis 不会通过检测数据库元信息来决定使用哪种类型，所以你必须在参数和结果映射中指明字段是 varchar 类型， 以使其能够绑定到正确的类型处理器上。这是因为 mybatis 直到语句被执行时才清楚数据类型。\n\n\n# mybatis 插件\n\nmybatis 允许你在映射语句执行过程中的某一点进行拦截调用。默认情况下，mybatis 允许使用插件来拦截的方法调用包括：\n\n * executor (update, query, flushstatements, commit, rollback, gettransaction, close, isclosed)\n * parameterhandler (getparameterobject, setparameters)\n * resultsethandler (handleresultsets, handleoutputparameters)\n * statementhandler (prepare, parameterize, batch, update, query)\n\n这些类中方法的细节可以通过查看每个方法的签名来发现，或者直接查看 mybatis 发行包中的源代码。 如果你想做的不仅仅是监控方法的调用，那么你最好相当了解要重写的方法的行为。 因为在试图修改或重写已有方法的行为时，很可能会破坏 mybatis 的核心模块。 这些都是更底层的类和方法，所以使用插件的时候要特别当心。\n\n通过 mybatis 提供的强大机制，使用插件是非常简单的，只需实现 interceptor 接口，并指定想要拦截的方法签名即可。\n\n// exampleplugin.java\n@intercepts({@signature(\n  type= executor.class,\n  method = "update",\n  args = {mappedstatement.class,object.class})})\npublic class exampleplugin implements interceptor {\n  private properties properties = new properties();\n  public object intercept(invocation invocation) throws throwable {\n    // implement pre processing if need\n    object returnobject = invocation.proceed();\n    // implement post processing if need\n    return returnobject;\n  }\n  public void setproperties(properties properties) {\n    this.properties = properties;\n  }\n}\n\n\n\x3c!-- mybatis-config.xml --\x3e\n<plugins>\n  <plugin interceptor="org.mybatis.example.exampleplugin">\n    <property name="someproperty" value="100"/>\n  </plugin>\n</plugins>\n\n\n上面的插件将会拦截在 executor 实例中所有的 “update” 方法调用， 这里的 executor 是负责执行底层映射语句的内部对象。\n\n\n# 参考资料\n\n * 官方\n   * mybatis github\n   * mybatis 官网\n   * mybatis 官方代码生成（mybatis-generator）\n   * mybatis 官方集成 spring（mybatis-spring）\n   * mybatis 官方集成 spring boot（mybatis-spring-boot）\n * 扩展插件\n   * mybatis-plus - crud 扩展插件、代码生成器、分页器等多功能\n   * mapper - crud 扩展插件\n   * mybatis-pagehelper - mybatis 通用分页插件\n * 文章\n   * 深入理解 mybatis 原理\n   * mybatis 源码中文注释\n   * mybatis generator 详解\n   * mybatis 常见面试题\n   * mybatis 中强大的 resultmap',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Mybatis原理",frontmatter:{title:"Mybatis原理",categories:["编程","Java","框架","ORM"],tags:["Java","框架","ORM","Mybatis"],abbrlink:"b18bb060",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/3f3dba/"},regularPath:"/13.%E6%A1%86%E6%9E%B6/11.ORM/02.Mybatis%E5%8E%9F%E7%90%86.html",relativePath:"13.框架/11.ORM/02.Mybatis原理.md",key:"v-96ecc776",path:"/pages/3f3dba/",headers:[{level:2,title:"Mybatis 完整示例",slug:"mybatis-完整示例",normalizedTitle:"mybatis 完整示例",charIndex:78},{level:3,title:"数据库准备",slug:"数据库准备",normalizedTitle:"数据库准备",charIndex:247},{level:3,title:"添加 Mybatis",slug:"添加-mybatis",normalizedTitle:"添加 mybatis",charIndex:874},{level:3,title:"Mybatis 配置",slug:"mybatis-配置",normalizedTitle:"mybatis 配置",charIndex:1057},{level:3,title:"Mapper",slug:"mapper",normalizedTitle:"mapper",charIndex:1932},{level:4,title:"Mapper.xml",slug:"mapper-xml",normalizedTitle:"mapper.xml",charIndex:1932},{level:4,title:"Mapper.java",slug:"mapper-java",normalizedTitle:"mapper.java",charIndex:3869},{level:4,title:"数据实体.java",slug:"数据实体-java",normalizedTitle:"数据实体.java",charIndex:4340},{level:3,title:"测试程序",slug:"测试程序",normalizedTitle:"测试程序",charIndex:4663},{level:2,title:"Mybatis 生命周期",slug:"mybatis-生命周期",normalizedTitle:"mybatis 生命周期",charIndex:5716},{level:3,title:"SqlSessionFactoryBuilder",slug:"sqlsessionfactorybuilder",normalizedTitle:"sqlsessionfactorybuilder",charIndex:4983},{level:4,title:"SqlSessionFactoryBuilder 的职责",slug:"sqlsessionfactorybuilder-的职责",normalizedTitle:"sqlsessionfactorybuilder 的职责",charIndex:5763},{level:4,title:"SqlSessionFactoryBuilder 的生命周期",slug:"sqlsessionfactorybuilder-的生命周期",normalizedTitle:"sqlsessionfactorybuilder 的生命周期",charIndex:6397},{level:3,title:"SqlSessionFactory",slug:"sqlsessionfactory",normalizedTitle:"sqlsessionfactory",charIndex:4817},{level:4,title:"SqlSessionFactory 职责",slug:"sqlsessionfactory-职责",normalizedTitle:"sqlsessionfactory 职责",charIndex:6680},{level:4,title:"SqlSessionFactory 生命周期",slug:"sqlsessionfactory-生命周期",normalizedTitle:"sqlsessionfactory 生命周期",charIndex:7734},{level:3,title:"SqlSession",slug:"sqlsession",normalizedTitle:"sqlsession",charIndex:4817},{level:4,title:"SqlSession 职责",slug:"sqlsession-职责",normalizedTitle:"sqlsession 职责",charIndex:7815},{level:4,title:"SqlSession 生命周期",slug:"sqlsession-生命周期",normalizedTitle:"sqlsession 生命周期",charIndex:7968},{level:3,title:"映射器",slug:"映射器",normalizedTitle:"映射器",charIndex:7876},{level:4,title:"映射器职责",slug:"映射器职责",normalizedTitle:"映射器职责",charIndex:8576},{level:4,title:"映射器生命周期",slug:"映射器生命周期",normalizedTitle:"映射器生命周期",charIndex:9331},{level:2,title:"Mybatis 的架构",slug:"mybatis-的架构",normalizedTitle:"mybatis 的架构",charIndex:9864},{level:3,title:"配置层",slug:"配置层",normalizedTitle:"配置层",charIndex:10601},{level:3,title:"接口层",slug:"接口层",normalizedTitle:"接口层",charIndex:10782},{level:3,title:"数据处理层",slug:"数据处理层",normalizedTitle:"数据处理层",charIndex:11128},{level:3,title:"框架支撑层",slug:"框架支撑层",normalizedTitle:"框架支撑层",charIndex:11658},{level:2,title:"SqlSession 内部工作机制",slug:"sqlsession-内部工作机制",normalizedTitle:"sqlsession 内部工作机制",charIndex:12447},{level:3,title:"SqlSession 子组件",slug:"sqlsession-子组件",normalizedTitle:"sqlsession 子组件",charIndex:12720},{level:4,title:"Executor",slug:"executor",normalizedTitle:"executor",charIndex:6994},{level:4,title:"StatementHandler",slug:"statementhandler",normalizedTitle:"statementhandler",charIndex:10051},{level:4,title:"ParameterHandler",slug:"parameterhandler",normalizedTitle:"parameterhandler",charIndex:10152},{level:4,title:"ResultSetHandler",slug:"resultsethandler",normalizedTitle:"resultsethandler",charIndex:10211},{level:4,title:"TypeHandler",slug:"typehandler",normalizedTitle:"typehandler",charIndex:10277},{level:3,title:"SqlSession 和 Mapper",slug:"sqlsession-和-mapper",normalizedTitle:"sqlsession 和 mapper",charIndex:14308},{level:3,title:"SqlSession 和 Executor",slug:"sqlsession-和-executor",normalizedTitle:"sqlsession 和 executor",charIndex:15167},{level:3,title:"Executor 工作流程",slug:"executor-工作流程",normalizedTitle:"executor 工作流程",charIndex:16589},{level:3,title:"StatementHandler 工作流程",slug:"statementhandler-工作流程",normalizedTitle:"statementhandler 工作流程",charIndex:20173},{level:3,title:"ParameterHandler 工作流程",slug:"parameterhandler-工作流程",normalizedTitle:"parameterhandler 工作流程",charIndex:21804},{level:3,title:"ResultSetHandler 工作流程",slug:"resultsethandler-工作流程",normalizedTitle:"resultsethandler 工作流程",charIndex:23661},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:25345}],headersStr:"Mybatis 完整示例 数据库准备 添加 Mybatis Mybatis 配置 Mapper Mapper.xml Mapper.java 数据实体.java 测试程序 Mybatis 生命周期 SqlSessionFactoryBuilder SqlSessionFactoryBuilder 的职责 SqlSessionFactoryBuilder 的生命周期 SqlSessionFactory SqlSessionFactory 职责 SqlSessionFactory 生命周期 SqlSession SqlSession 职责 SqlSession 生命周期 映射器 映射器职责 映射器生命周期 Mybatis 的架构 配置层 接口层 数据处理层 框架支撑层 SqlSession 内部工作机制 SqlSession 子组件 Executor StatementHandler ParameterHandler ResultSetHandler TypeHandler SqlSession 和 Mapper SqlSession 和 Executor Executor 工作流程 StatementHandler 工作流程 ParameterHandler 工作流程 ResultSetHandler 工作流程 参考资料",content:'# Mybatis 原理\n\n> Mybatis 的前身就是 iBatis ，是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。本文以一个 Mybatis 完整示例为切入点，结合 Mybatis 底层源码分析，图文并茂的讲解 Mybatis 的核心工作机制。\n\n\n# Mybatis 完整示例\n\n> 这里，我将以一个入门级的示例来演示 Mybatis 是如何工作的。\n> \n> 注：本文后面章节中的原理、源码部分也将基于这个示例来进行讲解。\n> \n> 完整示例源码地址\n\n\n# 数据库准备\n\n在本示例中，需要针对一张用户表进行 CRUD 操作。其数据模型如下：\n\nCREATE TABLE IF NOT EXISTS user (\n    id      BIGINT(10) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT \'Id\',\n    name    VARCHAR(10)         NOT NULL DEFAULT \'\' COMMENT \'用户名\',\n    age     INT(3)              NOT NULL DEFAULT 0 COMMENT \'年龄\',\n    address VARCHAR(32)         NOT NULL DEFAULT \'\' COMMENT \'地址\',\n    email   VARCHAR(32)         NOT NULL DEFAULT \'\' COMMENT \'邮件\',\n    PRIMARY KEY (id)\n) COMMENT = \'用户表\';\n\nINSERT INTO user (name, age, address, email)\nVALUES (\'张三\', 18, \'北京\', \'xxx@163.com\');\nINSERT INTO user (name, age, address, email)\nVALUES (\'李四\', 19, \'上海\', \'xxx@163.com\');\n\n\n\n# 添加 Mybatis\n\n如果使用 Maven 来构建项目，则需将下面的依赖代码置于 pom.xml 文件中：\n\n<dependency>\n  <groupId>org.Mybatis</groupId>\n  <artifactId>Mybatis</artifactId>\n  <version>x.x.x</version>\n</dependency>\n\n\n\n# Mybatis 配置\n\nXML 配置文件中包含了对 Mybatis 系统的核心设置，包括获取数据库连接实例的数据源（DataSource）以及决定事务作用域和控制方式的事务管理器（TransactionManager）。\n\n本示例中只是给出最简化的配置。\n\n【示例】Mybatis-config.xml 文件\n\n<?xml version="1.0" encoding="utf-8"?>\n<!DOCTYPE configuration PUBLIC "-//Mybatis.org//DTD Config 3.0//EN"\n  "http://Mybatis.org/dtd/Mybatis-3-config.dtd">\n<configuration>\n  <environments default="development">\n    <environment id="development">\n      <transactionManager type="JDBC" />\n      <dataSource type="POOLED">\n        <property name="driver" value="com.mysql.cj.jdbc.Driver" />\n        <property name="url"\n                  value="jdbc:mysql://127.0.0.1:3306/spring_tutorial?serverTimezone=UTC" />\n        <property name="username" value="root" />\n        <property name="password" value="root" />\n      </dataSource>\n    </environment>\n  </environments>\n  <mappers>\n    <mapper resource="Mybatis/mapper/UserMapper.xml" />\n  </mappers>\n</configuration>\n\n\n> 说明：上面的配置文件中仅仅指定了数据源连接方式和 User 表的映射配置文件。\n\n\n# Mapper\n\n# Mapper.xml\n\n个人理解，Mapper.xml 文件可以看做是 Mybatis 的 JDBC SQL 模板。\n\n【示例】UserMapper.xml 文件\n\n下面是一个通过 Mybatis Generator 自动生成的完整的 Mapper 文件。\n\n<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE mapper PUBLIC "-//Mybatis.org//DTD Mapper 3.0//EN" "http://Mybatis.org/dtd/Mybatis-3-mapper.dtd">\n<mapper namespace="io.github.dunwu.spring.orm.mapper.UserMapper">\n  <resultMap id="BaseResultMap" type="io.github.dunwu.spring.orm.entity.User">\n    <id column="id" jdbcType="BIGINT" property="id" />\n    <result column="name" jdbcType="VARCHAR" property="name" />\n    <result column="age" jdbcType="INTEGER" property="age" />\n    <result column="address" jdbcType="VARCHAR" property="address" />\n    <result column="email" jdbcType="VARCHAR" property="email" />\n  </resultMap>\n  <delete id="deleteByPrimaryKey" parameterType="java.lang.Long">\n    delete from user\n    where id = #{id,jdbcType=BIGINT}\n  </delete>\n  <insert id="insert" parameterType="io.github.dunwu.spring.orm.entity.User">\n    insert into user (id, name, age,\n      address, email)\n    values (#{id,jdbcType=BIGINT}, #{name,jdbcType=VARCHAR}, #{age,jdbcType=INTEGER},\n      #{address,jdbcType=VARCHAR}, #{email,jdbcType=VARCHAR})\n  </insert>\n  <update id="updateByPrimaryKey" parameterType="io.github.dunwu.spring.orm.entity.User">\n    update user\n    set name = #{name,jdbcType=VARCHAR},\n      age = #{age,jdbcType=INTEGER},\n      address = #{address,jdbcType=VARCHAR},\n      email = #{email,jdbcType=VARCHAR}\n    where id = #{id,jdbcType=BIGINT}\n  </update>\n  <select id="selectByPrimaryKey" parameterType="java.lang.Long" resultMap="BaseResultMap">\n    select id, name, age, address, email\n    from user\n    where id = #{id,jdbcType=BIGINT}\n  </select>\n  <select id="selectAll" resultMap="BaseResultMap">\n    select id, name, age, address, email\n    from user\n  </select>\n</mapper>\n\n\n# Mapper.java\n\nMapper.java 文件是 Mapper.xml 对应的 Java 对象。\n\n【示例】UserMapper.java 文件\n\npublic interface UserMapper {\n\n    int deleteByPrimaryKey(Long id);\n\n    int insert(User record);\n\n    User selectByPrimaryKey(Long id);\n\n    List<User> selectAll();\n\n    int updateByPrimaryKey(User record);\n\n}\n\n\n对比 UserMapper.java 和 UserMapper.xml 文件，不难发现：\n\nUserMapper.java 中的方法和 UserMapper.xml 的 CRUD 语句元素（ <insert>、<delete>、<update>、<select>）存在一一对应关系。\n\n在 Mybatis 中，正是通过方法的全限定名，将二者绑定在一起。\n\n# 数据实体.java\n\n【示例】User.java 文件\n\npublic class User {\n    private Long id;\n\n    private String name;\n\n    private Integer age;\n\n    private String address;\n\n    private String email;\n\n}\n\n\n<insert>、<delete>、<update>、<select> 的 parameterType 属性以及 <resultMap> 的 type 属性都可能会绑定到数据实体。这样就可以把 JDBC 操作的输入输出和 JavaBean 结合起来，更加方便、易于理解。\n\n\n# 测试程序\n\n【示例】MybatisDemo.java 文件\n\npublic class MybatisDemo {\n\n    public static void main(String[] args) throws Exception {\n        // 1. 加载 Mybatis 配置文件，创建 SqlSessionFactory\n        // 注：在实际的应用中，SqlSessionFactory 应该是单例\n        InputStream inputStream = Resources.getResourceAsStream("Mybatis/Mybatis-config.xml");\n        SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder();\n        SqlSessionFactory factory = builder.build(inputStream);\n\n        // 2. 创建一个 SqlSession 实例，进行数据库操作\n        SqlSession sqlSession = factory.openSession();\n\n        // 3. Mapper 映射并执行\n        Long params = 1L;\n        List<User> list = sqlSession.selectList("io.github.dunwu.spring.orm.mapper.UserMapper.selectByPrimaryKey", params);\n        for (User user : list) {\n            System.out.println("user name: " + user.getName());\n        }\n        // 输出：user name: 张三\n    }\n\n}\n\n\n> 说明：\n> \n> SqlSession 接口是 Mybatis API 核心中的核心，它代表了 Mybatis 和数据库的一次完整会话。\n> \n>  * Mybatis 会解析配置，并根据配置创建 SqlSession 。\n>  * 然后，Mybatis 将 Mapper 映射为 SqlSession，然后传递参数，执行 SQL 语句并获取结果。\n\n\n# Mybatis 生命周期\n\n\n\n\n# SqlSessionFactoryBuilder\n\n# SqlSessionFactoryBuilder 的职责\n\nSqlSessionFactoryBuilder 负责创建 SqlSessionFactory 实例。SqlSessionFactoryBuilder 可以从 XML 配置文件或一个预先定制的 Configuration 的实例构建出 SqlSessionFactory 的实例。\n\nConfiguration 类包含了对一个 SqlSessionFactory 实例你可能关心的所有内容。\n\n\n\nSqlSessionFactoryBuilder 应用了建造者设计模式，它有五个 build 方法，允许你通过不同的资源创建 SqlSessionFactory 实例。\n\nSqlSessionFactory build(InputStream inputStream)\nSqlSessionFactory build(InputStream inputStream, String environment)\nSqlSessionFactory build(InputStream inputStream, Properties properties)\nSqlSessionFactory build(InputStream inputStream, String env, Properties props)\nSqlSessionFactory build(Configuration config)\n\n\n# SqlSessionFactoryBuilder 的生命周期\n\nSqlSessionFactoryBuilder 可以被实例化、使用和丢弃，一旦创建了 SqlSessionFactory，就不再需要它了。 因此 SqlSessionFactoryBuilder 实例的最佳作用域是方法作用域（也就是局部方法变量）。你可以重用 SqlSessionFactoryBuilder 来创建多个 SqlSessionFactory 实例，但最好还是不要一直保留着它，以保证所有的 XML 解析资源可以被释放给更重要的事情。\n\n\n# SqlSessionFactory\n\n# SqlSessionFactory 职责\n\nSqlSessionFactory 负责创建 SqlSession 实例。\n\n\n\nSqlSessionFactory 应用了工厂设计模式，它提供了一组方法，用于创建 SqlSession 实例。\n\nSqlSession openSession()\nSqlSession openSession(boolean autoCommit)\nSqlSession openSession(Connection connection)\nSqlSession openSession(TransactionIsolationLevel level)\nSqlSession openSession(ExecutorType execType, TransactionIsolationLevel level)\nSqlSession openSession(ExecutorType execType)\nSqlSession openSession(ExecutorType execType, boolean autoCommit)\nSqlSession openSession(ExecutorType execType, Connection connection)\nConfiguration getConfiguration();\n\n\n方法说明：\n\n * 默认的 openSession() 方法没有参数，它会创建具备如下特性的 SqlSession：\n   * 事务作用域将会开启（也就是不自动提交）。\n   * 将由当前环境配置的 DataSource 实例中获取 Connection 对象。\n   * 事务隔离级别将会使用驱动或数据源的默认设置。\n   * 预处理语句不会被复用，也不会批量处理更新。\n * TransactionIsolationLevel 表示事务隔离级别，它对应着 JDBC 的五个事务隔离级别。\n * ExecutorType 枚举类型定义了三个值:\n   * ExecutorType.SIMPLE：该类型的执行器没有特别的行为。它为每个语句的执行创建一个新的预处理语句。\n   * ExecutorType.REUSE：该类型的执行器会复用预处理语句。\n   * ExecutorType.BATCH：该类型的执行器会批量执行所有更新语句，如果 SELECT 在多个更新中间执行，将在必要时将多条更新语句分隔开来，以方便理解。\n\n# SqlSessionFactory 生命周期\n\nSqlSessionFactory 应该以单例形式在应用的运行期间一直存在。\n\n\n# SqlSession\n\n# SqlSession 职责\n\nMybatis 的主要 Java 接口就是 SqlSession。它包含了所有执行语句，获取映射器和管理事务等方法。\n\n> 详细内容可以参考：「 Mybatis 官方文档之 SqlSessions 」 。\n\nSqlSession 类的方法可以按照下图进行大致分类：\n\n\n\n# SqlSession 生命周期\n\nSqlSessions 是由 SqlSessionFactory 实例创建的；而 SqlSessionFactory 是由 SqlSessionFactoryBuilder 创建的。\n\n> 🔔 注意：当 Mybatis 与一些依赖注入框架（如 Spring 或者 Guice）同时使用时，SqlSessions 将被依赖注入框架所创建，所以你不需要使用 SqlSessionFactoryBuilder 或者 SqlSessionFactory。\n\n每个线程都应该有它自己的 SqlSession 实例。\n\nSqlSession 的实例不是线程安全的，因此是不能被共享的，所以它的最佳的作用域是请求或方法作用域。 绝对不能将 SqlSession 实例的引用放在一个类的静态域，甚至一个类的实例变量也不行。 也绝不能将 SqlSession 实例的引用放在任何类型的托管作用域中，比如 Servlet 框架中的 HttpSession。 正确在 Web 中使用 SqlSession 的场景是：每次收到的 HTTP 请求，就可以打开一个 SqlSession，返回一个响应，就关闭它。\n\n编程模式：\n\ntry (SqlSession session = sqlSessionFactory.openSession()) {\n  // 你的应用逻辑代码\n}\n\n\n\n# 映射器\n\n# 映射器职责\n\n映射器是一些由用户创建的、绑定 SQL 语句的接口。\n\nSqlSession 中的 insert、update、delete 和 select 方法都很强大，但也有些繁琐。更通用的方式是使用映射器类来执行映射语句。一个映射器类就是一个仅需声明与 SqlSession 方法相匹配的方法的接口类。\n\nMybatis 将配置文件中的每一个 <mapper> 节点抽象为一个 Mapper 接口，而这个接口中声明的方法和跟 <mapper> 节点中的 <select|update|delete|insert> 节点相对应，即 <select|update|delete|insert> 节点的 id 值为 Mapper 接口中的方法名称，parameterType 值表示 Mapper 对应方法的入参类型，而 resultMap 值则对应了 Mapper 接口表示的返回值类型或者返回结果集的元素类型。\n\nMybatis 会根据相应的接口声明的方法信息，通过动态代理机制生成一个 Mapper 实例；Mybatis 会根据这个方法的方法名和参数类型，确定 Statement Id，然后和 SqlSession 进行映射，底层还是通过 SqlSession 完成和数据库的交互。\n\n下面的示例展示了一些方法签名以及它们是如何映射到 SqlSession 上的。\n\n\n\n> 注意\n> \n>  * 映射器接口不需要去实现任何接口或继承自任何类。只要方法可以被唯一标识对应的映射语句就可以了。\n>  * 映射器接口可以继承自其他接口。当使用 XML 来构建映射器接口时要保证语句被包含在合适的命名空间中。而且，唯一的限制就是你不能在两个继承关系的接口中拥有相同的方法签名（潜在的危险做法不可取）。\n\n# 映射器生命周期\n\n映射器接口的实例是从 SqlSession 中获得的。因此从技术层面讲，任何映射器实例的最大作用域是和请求它们的 SqlSession 相同的。尽管如此，映射器实例的最佳作用域是方法作用域。 也就是说，映射器实例应该在调用它们的方法中被请求，用过之后即可丢弃。\n\n编程模式：\n\ntry (SqlSession session = sqlSessionFactory.openSession()) {\n  BlogMapper mapper = session.getMapper(BlogMapper.class);\n  // 你的应用逻辑代码\n}\n\n\n * 映射器注解\n\nMybatis 是一个 XML 驱动的框架。配置信息是基于 XML 的，而且映射语句也是定义在 XML 中的。Mybatis 3 以后，支持注解配置。注解配置基于配置 API；而配置 API 基于 XML 配置。\n\nMybatis 支持诸如 @Insert、@Update、@Delete、@Select、@Result 等注解。\n\n> 详细内容请参考：Mybatis 官方文档之 sqlSessions，其中列举了 Mybatis 支持的注解清单，以及基本用法。\n\n\n# Mybatis 的架构\n\n从 Mybatis 代码实现的角度来看，Mybatis 的主要组件有以下几个：\n\n * SqlSession - 作为 Mybatis 工作的主要顶层 API，表示和数据库交互的会话，完成必要数据库增删改查功能。\n * Executor - Mybatis 执行器，是 Mybatis 调度的核心，负责 SQL 语句的生成和查询缓存的维护。\n * StatementHandler - 封装了 JDBC Statement 操作，负责对 JDBC statement 的操作，如设置参数、将 Statement 结果集转换成 List 集合。\n * ParameterHandler - 负责对用户传递的参数转换成 JDBC Statement 所需要的参数。\n * ResultSetHandler - 负责将 JDBC 返回的 ResultSet 结果集对象转换成 List 类型的集合。\n * TypeHandler - 负责 java 数据类型和 jdbc 数据类型之间的映射和转换。\n * MappedStatement - MappedStatement 维护了一条 <select|update|delete|insert> 节点的封装。\n * SqlSource - 负责根据用户传递的 parameterObject，动态地生成 SQL 语句，将信息封装到 BoundSql 对象中，并返回。\n * BoundSql - 表示动态生成的 SQL 语句以及相应的参数信息。\n * Configuration - Mybatis 所有的配置信息都维持在 Configuration 对象之中。\n\n这些组件的架构层次如下：\n\n\n\n\n# 配置层\n\n配置层决定了 Mybatis 的工作方式。\n\nMybatis 提供了两种配置方式：\n\n * 基于 XML 配置文件的方式\n * 基于 Java API 的方式\n\nSqlSessionFactoryBuilder 会根据配置创建 SqlSessionFactory ；\n\nSqlSessionFactory 负责创建 SqlSessions 。\n\n\n# 接口层\n\n接口层负责和数据库交互的方式。\n\nMybatis 和数据库的交互有两种方式：\n\n * 使用 SqlSession：SqlSession 封装了所有执行语句，获取映射器和管理事务的方法。\n   * 用户只需要传入 Statement Id 和查询参数给 SqlSession 对象，就可以很方便的和数据库进行交互。\n   * 这种方式的缺点是不符合面向对象编程的范式。\n * 使用 Mapper 接口：Mybatis 会根据相应的接口声明的方法信息，通过动态代理机制生成一个 Mapper 实例；Mybatis 会根据这个方法的方法名和参数类型，确定 Statement Id，然后和 SqlSession 进行映射，底层还是通过 SqlSession 完成和数据库的交互。\n\n\n# 数据处理层\n\n数据处理层可以说是 Mybatis 的核心，从大的方面上讲，它要完成两个功能：\n\n * 根据传参 Statement 和参数构建动态 SQL 语句\n   * 动态语句生成可以说是 Mybatis 框架非常优雅的一个设计，Mybatis 通过传入的参数值，使用 Ognl 来动态地构造 SQL 语句，使得 Mybatis 有很强的灵活性和扩展性。\n   * 参数映射指的是对于 java 数据类型和 jdbc 数据类型之间的转换：这里有包括两个过程：查询阶段，我们要将 java 类型的数据，转换成 jdbc 类型的数据，通过 preparedStatement.setXXX() 来设值；另一个就是对 resultset 查询结果集的 jdbcType 数据转换成 java 数据类型。\n * 执行 SQL 语句以及处理响应结果集 ResultSet\n   * 动态 SQL 语句生成之后，Mybatis 将执行 SQL 语句，并将可能返回的结果集转换成 List<E> 列表。\n   * Mybatis 在对结果集的处理中，支持结果集关系一对多和多对一的转换，并且有两种支持方式，一种为嵌套查询语句的查询，还有一种是嵌套结果集的查询。\n\n\n# 框架支撑层\n\n * 事务管理机制 - Mybatis 将事务抽象成了 Transaction 接口。Mybatis 的事务管理分为两种形式：\n   \n   * 使用 JDBC 的事务管理机制：即利用 java.sql.Connection 对象完成对事务的提交（commit）、回滚（rollback）、关闭（close）等。\n   * 使用 MANAGED 的事务管理机制：Mybatis 自身不会去实现事务管理，而是让程序的容器如（JBOSS，Weblogic）来实现对事务的管理。\n\n * 连接池管理\n\n * SQL 语句的配置 - 支持两种方式：\n   \n   * xml 配置\n   * 注解配置\n\n * 缓存机制 - Mybatis 采用两级缓存结构\n   \n   * 一级缓存是 Session 会话级别的缓存 - 一级缓存又被称之为本地缓存。一般而言，一个 SqlSession 对象会使用一个 Executor 对象来完成会话操作，Executor 对象会维护一个 Cache 缓存，以提高查询性能。\n     * 一级缓存的生命周期是 Session 会话级别的。\n   * 二级缓存是 Application 应用级别的缓存 - 用户配置了 "cacheEnabled=true"，才会开启二级缓存。\n     * 如果开启了二级缓存，SqlSession 会先使用 CachingExecutor 对象来处理查询请求。CachingExecutor 会在二级缓存中查看是否有匹配的数据，如果匹配，则直接返回缓存结果；如果缓存中没有，再交给真正的 Executor 对象来完成查询，之后 CachingExecutor 会将真正 Executor 返回的查询结果放置到缓存中，然后在返回给用户。\n     * 二级缓存的生命周期是应用级别的。\n\n\n\n\n# SqlSession 内部工作机制\n\n从前文，我们已经了解了，Mybatis 封装了对数据库的访问，把对数据库的会话和事务控制放到了 SqlSession 对象中。那么具体是如何工作的呢？接下来，我们通过源码解读来进行分析。\n\n\n\nSqlSession 对于 insert、update、delete、select 的内部处理机制基本上大同小异。所以，接下来，我会以一次完整的 select 查询流程为例讲解 SqlSession 内部的工作机制。相信读者如果理解了 select 的处理流程，对于其他 CRUD 操作也能做到一通百通。\n\n\n# SqlSession 子组件\n\n前面的内容已经介绍了：SqlSession 是 Mybatis 的顶层接口，它提供了所有执行语句，获取映射器和管理事务等方法。\n\n实际上，SqlSession 是通过聚合多个子组件，让每个子组件负责各自功能的方式，实现了任务的下发。\n\n在了解各个子组件工作机制前，先让我们简单认识一下 SqlSession 的核心子组件。\n\n# Executor\n\nExecutor 即执行器，它负责生成动态 SQL 以及管理缓存。\n\n\n\n * Executor 即执行器接口。\n * BaseExecutor 是 Executor 的抽象类，它采用了模板方法设计模式，内置了一些共性方法，而将定制化方法留给子类去实现。\n * SimpleExecutor 是最简单的执行器。它只会直接执行 SQL，不会做额外的事。\n * BatchExecutor 是批处理执行器。它的作用是通过批处理来优化性能。值得注意的是，批量更新操作，由于内部有缓存机制，使用完后需要调用 flushStatements 来清除缓存。\n * ReuseExecutor 是可重用的执行器。重用的对象是 Statement，也就是说，该执行器会缓存同一个 SQL 的 Statement，避免重复创建 Statement。其内部的实现是通过一个 HashMap 来维护 Statement 对象的。由于当前 Map 只在该 session 中有效，所以使用完后需要调用 flushStatements 来清除 Map。\n * CachingExecutor 是缓存执行器。它只在启用二级缓存时才会用到。\n\n# StatementHandler\n\nStatementHandler 对象负责设置 Statement 对象中的查询参数、处理 JDBC 返回的 resultSet，将 resultSet 加工为 List 集合返回。\n\nStatementHandler 的家族成员：\n\n\n\n * StatementHandler 是接口；\n * BaseStatementHandler 是实现 StatementHandler 的抽象类，内置一些共性方法；\n * SimpleStatementHandler 负责处理 Statement；\n * PreparedStatementHandler 负责处理 PreparedStatement；\n * CallableStatementHandler 负责处理 CallableStatement。\n * RoutingStatementHandler 负责代理 StatementHandler 具体子类，根据 Statement 类型，选择实例化 SimpleStatementHandler、PreparedStatementHandler、CallableStatementHandler。\n\n# ParameterHandler\n\nParameterHandler 负责将传入的 Java 对象转换 JDBC 类型对象，并为 PreparedStatement 的动态 SQL 填充数值。\n\nParameterHandler 只有一个具体实现类，即 DefaultParameterHandler。\n\n# ResultSetHandler\n\nResultSetHandler 负责两件事：\n\n * 处理 Statement 执行后产生的结果集，生成结果列表\n * 处理存储过程执行后的输出参数\n\nResultSetHandler 只有一个具体实现类，即 DefaultResultSetHandler。\n\n# TypeHandler\n\nTypeHandler 负责将 Java 对象类型和 JDBC 类型进行相互转换。\n\n\n# SqlSession 和 Mapper\n\n先来回忆一下 Mybatis 完整示例章节的 测试程序部分的代码。\n\nMybatisDemo.java 文件中的代码片段：\n\n// 2. 创建一个 SqlSession 实例，进行数据库操作\nSqlSession sqlSession = factory.openSession();\n\n// 3. Mapper 映射并执行\nLong params = 1L;\nList<User> list = sqlSession.selectList("io.github.dunwu.spring.orm.mapper.UserMapper.selectByPrimaryKey", params);\nfor (User user : list) {\n    System.out.println("user name: " + user.getName());\n}\n\n\n示例代码中，给 sqlSession 对象的传递一个配置的 Sql 语句的 Statement Id 和参数，然后返回结果\n\nio.github.dunwu.spring.orm.mapper.UserMapper.selectByPrimaryKey 是配置在 UserMapper.xml 的 Statement ID，params 是 SQL 参数。\n\nUserMapper.xml 文件中的代码片段：\n\n  <select id="selectByPrimaryKey" parameterType="java.lang.Long" resultMap="BaseResultMap">\n    select id, name, age, address, email\n    from user\n    where id = #{id,jdbcType=BIGINT}\n  </select>\n\n\nMybatis 通过方法的全限定名，将 SqlSession 和 Mapper 相互映射起来。\n\n\n# SqlSession 和 Executor\n\norg.apache.ibatis.session.defaults.DefaultSqlSession 中 selectList 方法的源码：\n\n@Override\npublic <E> List<E> selectList(String statement) {\n  return this.selectList(statement, null);\n}\n\n@Override\npublic <E> List<E> selectList(String statement, Object parameter) {\n  return this.selectList(statement, parameter, RowBounds.DEFAULT);\n}\n\n@Override\npublic <E> List<E> selectList(String statement, Object parameter, RowBounds rowBounds) {\n  try {\n    // 1. 根据 Statement Id，在配置对象 Configuration 中查找和配置文件相对应的 MappedStatement\n    MappedStatement ms = configuration.getMappedStatement(statement);\n    // 2. 将 SQL 语句交由执行器 Executor 处理\n    return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);\n  } catch (Exception e) {\n    throw ExceptionFactory.wrapException("Error querying database.  Cause: " + e, e);\n  } finally {\n    ErrorContext.instance().reset();\n  }\n}\n\n\n说明：\n\nMybatis 所有的配置信息都维持在 Configuration 对象之中。中维护了一个 Map<String, MappedStatement> 对象。其中，key 为 Mapper 方法的全限定名（对于本例而言，key 就是 io.github.dunwu.spring.orm.mapper.UserMapper.selectByPrimaryKey ），value 为 MappedStatement 对象。所以，传入 Statement Id 就可以从 Map 中找到对应的 MappedStatement。\n\nMappedStatement 维护了一个 Mapper 方法的元数据信息，其数据组织可以参考下面的 debug 截图：\n\n\n\n> 小结：\n> \n> 通过 "SqlSession 和 Mapper" 以及 "SqlSession 和 Executor" 这两节，我们已经知道：\n> \n> SqlSession 的职能是：根据 Statement ID, 在 Configuration 中获取到对应的 MappedStatement 对象，然后调用 Executor 来执行具体的操作。\n\n\n# Executor 工作流程\n\n继续上一节的流程，SqlSession 将 SQL 语句交由执行器 Executor 处理。Executor 又做了哪些事儿呢？\n\n（1）执行器查询入口\n\npublic <E> List<E> query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException {\n\t// 1. 根据传参，动态生成需要执行的 SQL 语句，用 BoundSql 对象表示\n    BoundSql boundSql = ms.getBoundSql(parameter);\n    // 2. 根据传参，创建一个缓存Key\n    CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql);\n    return query(ms, parameter, rowBounds, resultHandler, key, boundSql);\n }\n\n\n执行器查询入口主要做两件事：\n\n * 生成动态 SQL：根据传参，动态生成需要执行的 SQL 语句，用 BoundSql 对象表示。\n * 管理缓存：根据传参，创建一个缓存 Key。\n\n（2）执行器查询第二入口\n\n  @SuppressWarnings("unchecked")\n  @Override\n  public <E> List<E> query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {\n    // 略\n    List<E> list;\n    try {\n      queryStack++;\n      list = resultHandler == null ? (List<E>) localCache.getObject(key) : null;\n      // 3. 缓存中有值，则直接从缓存中取数据；否则，查询数据库\n      if (list != null) {\n        handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);\n      } else {\n        list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);\n      }\n    } finally {\n      queryStack--;\n    }\n    // 略\n    return list;\n  }\n\n\n实际查询方法主要的职能是判断缓存 key 是否能命中缓存：\n\n * 命中，则将缓存中数据返回；\n * 不命中，则查询数据库：\n\n（3）查询数据库\n\n  private <E> List<E> queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {\n    List<E> list;\n    localCache.putObject(key, EXECUTION_PLACEHOLDER);\n    try {\n      // 4. 执行查询，获取 List 结果，并将查询的结果更新本地缓存中\n      list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql);\n    } finally {\n      localCache.removeObject(key);\n    }\n    localCache.putObject(key, list);\n    if (ms.getStatementType() == StatementType.CALLABLE) {\n      localOutputParameterCache.putObject(key, parameter);\n    }\n    return list;\n  }\n\n\nqueryFromDatabase 方法的职责是调用 doQuery，向数据库发起查询，并将返回的结果更新到本地缓存。\n\n（4）实际查询方法\n\nSimpleExecutor 类的 doQuery()方法实现\n\n  @Override\n  public <E> List<E> doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException {\n    Statement stmt = null;\n    try {\n      Configuration configuration = ms.getConfiguration();\n      // 5. 根据既有的参数，创建StatementHandler对象来执行查询操作\n      StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql);\n      // 6. 创建java.Sql.Statement对象，传递给StatementHandler对象\n      stmt = prepareStatement(handler, ms.getStatementLog());\n      // 7. 调用StatementHandler.query()方法，返回List结果\n      return handler.query(stmt, resultHandler);\n    } finally {\n      closeStatement(stmt);\n    }\n  }\n\n\n上述的 Executor.query()方法几经转折，最后会创建一个 StatementHandler 对象，然后将必要的参数传递给 StatementHandler，使用 StatementHandler 来完成对数据库的查询，最终返回 List 结果集。 从上面的代码中我们可以看出，Executor 的功能和作用是：\n\n 1. 根据传递的参数，完成 SQL 语句的动态解析，生成 BoundSql 对象，供 StatementHandler 使用；\n\n 2. 为查询创建缓存，以提高性能\n\n 3. 创建 JDBC 的 Statement 连接对象，传递给 StatementHandler 对象，返回 List 查询结果。\n\nprepareStatement() 方法的实现：\n\n  private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException {\n    Statement stmt;\n    Connection connection = getConnection(statementLog);\n    stmt = handler.prepare(connection, transaction.getTimeout());\n    //对创建的Statement对象设置参数，即设置SQL 语句中 ? 设置为指定的参数\n    handler.parameterize(stmt);\n    return stmt;\n  }\n\n\n对于 JDBC 的 PreparedStatement 类型的对象，创建的过程中，我们使用的是 SQL 语句字符串会包含 若干个? 占位符，我们其后再对占位符进行设值。\n\n\n# StatementHandler 工作流程\n\nStatementHandler 有一个子类 RoutingStatementHandler，它负责代理其他 StatementHandler 子类的工作。\n\n它会根据配置的 Statement 类型，选择实例化相应的 StatementHandler，然后由其代理对象完成工作。\n\n【源码】RoutingStatementHandler\n\npublic RoutingStatementHandler(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) {\n\n  switch (ms.getStatementType()) {\n    case STATEMENT:\n      delegate = new SimpleStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql);\n      break;\n    case PREPARED:\n      delegate = new PreparedStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql);\n      break;\n    case CALLABLE:\n      delegate = new CallableStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql);\n      break;\n    default:\n      throw new ExecutorException("Unknown statement type: " + ms.getStatementType());\n  }\n\n}\n\n\n【源码】RoutingStatementHandler 的 parameterize 方法源码\n\n【源码】PreparedStatementHandler 的 parameterize 方法源码\n\nStatementHandler 使用 ParameterHandler 对象来完成对 Statement 的赋值。\n\n@Override\npublic void parameterize(Statement statement) throws SQLException {\n  // 使用 ParameterHandler 对象来完成对 Statement 的设值\n  parameterHandler.setParameters((PreparedStatement) statement);\n}\n\n\n【源码】StatementHandler 的 query 方法源码\n\nStatementHandler 使用 ResultSetHandler 对象来完成对 ResultSet 的处理。\n\n@Override\npublic <E> List<E> query(Statement statement, ResultHandler resultHandler) throws SQLException {\n  PreparedStatement ps = (PreparedStatement) statement;\n  ps.execute();\n  // 使用ResultHandler来处理ResultSet\n  return resultSetHandler.handleResultSets(ps);\n}\n\n\n\n# ParameterHandler 工作流程\n\n【源码】DefaultParameterHandler 的 setParameters 方法\n\n  @Override\n  public void setParameters(PreparedStatement ps) {\n\t// parameterMappings 是对占位符 #{} 对应参数的封装\n    List<ParameterMapping> parameterMappings = boundSql.getParameterMappings();\n    if (parameterMappings != null) {\n      for (int i = 0; i < parameterMappings.size(); i++) {\n        ParameterMapping parameterMapping = parameterMappings.get(i);\n        // 不处理存储过程中的参数\n        if (parameterMapping.getMode() != ParameterMode.OUT) {\n          Object value;\n          String propertyName = parameterMapping.getProperty();\n          if (boundSql.hasAdditionalParameter(propertyName)) { // issue #448 ask first for additional params\n            // 获取对应的实际数值\n            value = boundSql.getAdditionalParameter(propertyName);\n          } else if (parameterObject == null) {\n            value = null;\n          } else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) {\n            value = parameterObject;\n          } else {\n            // 获取对象中相应的属性或查找 Map 对象中的值\n            MetaObject metaObject = configuration.newMetaObject(parameterObject);\n            value = metaObject.getValue(propertyName);\n          }\n\n          TypeHandler typeHandler = parameterMapping.getTypeHandler();\n          JdbcType jdbcType = parameterMapping.getJdbcType();\n          if (value == null && jdbcType == null) {\n            jdbcType = configuration.getJdbcTypeForNull();\n          }\n          try {\n            // 通过 TypeHandler 将 Java 对象参数转为 JDBC 类型的参数\n            // 然后，将数值动态绑定到 PreparedStaement 中\n            typeHandler.setParameter(ps, i + 1, value, jdbcType);\n          } catch (TypeException | SQLException e) {\n            throw new TypeException("Could not set parameters for mapping: " + parameterMapping + ". Cause: " + e, e);\n          }\n        }\n      }\n    }\n  }\n\n\n\n# ResultSetHandler 工作流程\n\nResultSetHandler 的实现可以概括为：将 Statement 执行后的结果集，按照 Mapper 文件中配置的 ResultType 或 ResultMap 来转换成对应的 JavaBean 对象，最后将结果返回。\n\n【源码】DefaultResultSetHandler 的 handleResultSets 方法\n\nhandleResultSets 方法是 DefaultResultSetHandler 的最关键方法。其实现如下：\n\n@Override\npublic List<Object> handleResultSets(Statement stmt) throws SQLException {\n  ErrorContext.instance().activity("handling results").object(mappedStatement.getId());\n\n  final List<Object> multipleResults = new ArrayList<>();\n\n  int resultSetCount = 0;\n  // 第一个结果集\n  ResultSetWrapper rsw = getFirstResultSet(stmt);\n  List<ResultMap> resultMaps = mappedStatement.getResultMaps();\n  // 判断结果集的数量\n  int resultMapCount = resultMaps.size();\n  validateResultMapsCount(rsw, resultMapCount);\n  // 遍历处理结果集\n  while (rsw != null && resultMapCount > resultSetCount) {\n    ResultMap resultMap = resultMaps.get(resultSetCount);\n    handleResultSet(rsw, resultMap, multipleResults, null);\n    rsw = getNextResultSet(stmt);\n    cleanUpAfterHandlingResultSet();\n    resultSetCount++;\n  }\n\n  String[] resultSets = mappedStatement.getResultSets();\n  if (resultSets != null) {\n    while (rsw != null && resultSetCount < resultSets.length) {\n      ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]);\n      if (parentMapping != null) {\n        String nestedResultMapId = parentMapping.getNestedResultMapId();\n        ResultMap resultMap = configuration.getResultMap(nestedResultMapId);\n        handleResultSet(rsw, resultMap, null, parentMapping);\n      }\n      rsw = getNextResultSet(stmt);\n      cleanUpAfterHandlingResultSet();\n      resultSetCount++;\n    }\n  }\n\n  return collapseSingleResultList(multipleResults);\n}\n\n\n\n# 参考资料\n\n * 官方\n   * Mybatis Github\n   * Mybatis 官网\n * 文章\n   * 深入理解 Mybatis 原理\n   * Mybatis 源码中文注释\n   * Mybatis 中强大的 resultMap',normalizedContent:'# mybatis 原理\n\n> mybatis 的前身就是 ibatis ，是一款优秀的持久层框架，它支持自定义 sql、存储过程以及高级映射。本文以一个 mybatis 完整示例为切入点，结合 mybatis 底层源码分析，图文并茂的讲解 mybatis 的核心工作机制。\n\n\n# mybatis 完整示例\n\n> 这里，我将以一个入门级的示例来演示 mybatis 是如何工作的。\n> \n> 注：本文后面章节中的原理、源码部分也将基于这个示例来进行讲解。\n> \n> 完整示例源码地址\n\n\n# 数据库准备\n\n在本示例中，需要针对一张用户表进行 crud 操作。其数据模型如下：\n\ncreate table if not exists user (\n    id      bigint(10) unsigned not null auto_increment comment \'id\',\n    name    varchar(10)         not null default \'\' comment \'用户名\',\n    age     int(3)              not null default 0 comment \'年龄\',\n    address varchar(32)         not null default \'\' comment \'地址\',\n    email   varchar(32)         not null default \'\' comment \'邮件\',\n    primary key (id)\n) comment = \'用户表\';\n\ninsert into user (name, age, address, email)\nvalues (\'张三\', 18, \'北京\', \'xxx@163.com\');\ninsert into user (name, age, address, email)\nvalues (\'李四\', 19, \'上海\', \'xxx@163.com\');\n\n\n\n# 添加 mybatis\n\n如果使用 maven 来构建项目，则需将下面的依赖代码置于 pom.xml 文件中：\n\n<dependency>\n  <groupid>org.mybatis</groupid>\n  <artifactid>mybatis</artifactid>\n  <version>x.x.x</version>\n</dependency>\n\n\n\n# mybatis 配置\n\nxml 配置文件中包含了对 mybatis 系统的核心设置，包括获取数据库连接实例的数据源（datasource）以及决定事务作用域和控制方式的事务管理器（transactionmanager）。\n\n本示例中只是给出最简化的配置。\n\n【示例】mybatis-config.xml 文件\n\n<?xml version="1.0" encoding="utf-8"?>\n<!doctype configuration public "-//mybatis.org//dtd config 3.0//en"\n  "http://mybatis.org/dtd/mybatis-3-config.dtd">\n<configuration>\n  <environments default="development">\n    <environment id="development">\n      <transactionmanager type="jdbc" />\n      <datasource type="pooled">\n        <property name="driver" value="com.mysql.cj.jdbc.driver" />\n        <property name="url"\n                  value="jdbc:mysql://127.0.0.1:3306/spring_tutorial?servertimezone=utc" />\n        <property name="username" value="root" />\n        <property name="password" value="root" />\n      </datasource>\n    </environment>\n  </environments>\n  <mappers>\n    <mapper resource="mybatis/mapper/usermapper.xml" />\n  </mappers>\n</configuration>\n\n\n> 说明：上面的配置文件中仅仅指定了数据源连接方式和 user 表的映射配置文件。\n\n\n# mapper\n\n# mapper.xml\n\n个人理解，mapper.xml 文件可以看做是 mybatis 的 jdbc sql 模板。\n\n【示例】usermapper.xml 文件\n\n下面是一个通过 mybatis generator 自动生成的完整的 mapper 文件。\n\n<?xml version="1.0" encoding="utf-8"?>\n<!doctype mapper public "-//mybatis.org//dtd mapper 3.0//en" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">\n<mapper namespace="io.github.dunwu.spring.orm.mapper.usermapper">\n  <resultmap id="baseresultmap" type="io.github.dunwu.spring.orm.entity.user">\n    <id column="id" jdbctype="bigint" property="id" />\n    <result column="name" jdbctype="varchar" property="name" />\n    <result column="age" jdbctype="integer" property="age" />\n    <result column="address" jdbctype="varchar" property="address" />\n    <result column="email" jdbctype="varchar" property="email" />\n  </resultmap>\n  <delete id="deletebyprimarykey" parametertype="java.lang.long">\n    delete from user\n    where id = #{id,jdbctype=bigint}\n  </delete>\n  <insert id="insert" parametertype="io.github.dunwu.spring.orm.entity.user">\n    insert into user (id, name, age,\n      address, email)\n    values (#{id,jdbctype=bigint}, #{name,jdbctype=varchar}, #{age,jdbctype=integer},\n      #{address,jdbctype=varchar}, #{email,jdbctype=varchar})\n  </insert>\n  <update id="updatebyprimarykey" parametertype="io.github.dunwu.spring.orm.entity.user">\n    update user\n    set name = #{name,jdbctype=varchar},\n      age = #{age,jdbctype=integer},\n      address = #{address,jdbctype=varchar},\n      email = #{email,jdbctype=varchar}\n    where id = #{id,jdbctype=bigint}\n  </update>\n  <select id="selectbyprimarykey" parametertype="java.lang.long" resultmap="baseresultmap">\n    select id, name, age, address, email\n    from user\n    where id = #{id,jdbctype=bigint}\n  </select>\n  <select id="selectall" resultmap="baseresultmap">\n    select id, name, age, address, email\n    from user\n  </select>\n</mapper>\n\n\n# mapper.java\n\nmapper.java 文件是 mapper.xml 对应的 java 对象。\n\n【示例】usermapper.java 文件\n\npublic interface usermapper {\n\n    int deletebyprimarykey(long id);\n\n    int insert(user record);\n\n    user selectbyprimarykey(long id);\n\n    list<user> selectall();\n\n    int updatebyprimarykey(user record);\n\n}\n\n\n对比 usermapper.java 和 usermapper.xml 文件，不难发现：\n\nusermapper.java 中的方法和 usermapper.xml 的 crud 语句元素（ <insert>、<delete>、<update>、<select>）存在一一对应关系。\n\n在 mybatis 中，正是通过方法的全限定名，将二者绑定在一起。\n\n# 数据实体.java\n\n【示例】user.java 文件\n\npublic class user {\n    private long id;\n\n    private string name;\n\n    private integer age;\n\n    private string address;\n\n    private string email;\n\n}\n\n\n<insert>、<delete>、<update>、<select> 的 parametertype 属性以及 <resultmap> 的 type 属性都可能会绑定到数据实体。这样就可以把 jdbc 操作的输入输出和 javabean 结合起来，更加方便、易于理解。\n\n\n# 测试程序\n\n【示例】mybatisdemo.java 文件\n\npublic class mybatisdemo {\n\n    public static void main(string[] args) throws exception {\n        // 1. 加载 mybatis 配置文件，创建 sqlsessionfactory\n        // 注：在实际的应用中，sqlsessionfactory 应该是单例\n        inputstream inputstream = resources.getresourceasstream("mybatis/mybatis-config.xml");\n        sqlsessionfactorybuilder builder = new sqlsessionfactorybuilder();\n        sqlsessionfactory factory = builder.build(inputstream);\n\n        // 2. 创建一个 sqlsession 实例，进行数据库操作\n        sqlsession sqlsession = factory.opensession();\n\n        // 3. mapper 映射并执行\n        long params = 1l;\n        list<user> list = sqlsession.selectlist("io.github.dunwu.spring.orm.mapper.usermapper.selectbyprimarykey", params);\n        for (user user : list) {\n            system.out.println("user name: " + user.getname());\n        }\n        // 输出：user name: 张三\n    }\n\n}\n\n\n> 说明：\n> \n> sqlsession 接口是 mybatis api 核心中的核心，它代表了 mybatis 和数据库的一次完整会话。\n> \n>  * mybatis 会解析配置，并根据配置创建 sqlsession 。\n>  * 然后，mybatis 将 mapper 映射为 sqlsession，然后传递参数，执行 sql 语句并获取结果。\n\n\n# mybatis 生命周期\n\n\n\n\n# sqlsessionfactorybuilder\n\n# sqlsessionfactorybuilder 的职责\n\nsqlsessionfactorybuilder 负责创建 sqlsessionfactory 实例。sqlsessionfactorybuilder 可以从 xml 配置文件或一个预先定制的 configuration 的实例构建出 sqlsessionfactory 的实例。\n\nconfiguration 类包含了对一个 sqlsessionfactory 实例你可能关心的所有内容。\n\n\n\nsqlsessionfactorybuilder 应用了建造者设计模式，它有五个 build 方法，允许你通过不同的资源创建 sqlsessionfactory 实例。\n\nsqlsessionfactory build(inputstream inputstream)\nsqlsessionfactory build(inputstream inputstream, string environment)\nsqlsessionfactory build(inputstream inputstream, properties properties)\nsqlsessionfactory build(inputstream inputstream, string env, properties props)\nsqlsessionfactory build(configuration config)\n\n\n# sqlsessionfactorybuilder 的生命周期\n\nsqlsessionfactorybuilder 可以被实例化、使用和丢弃，一旦创建了 sqlsessionfactory，就不再需要它了。 因此 sqlsessionfactorybuilder 实例的最佳作用域是方法作用域（也就是局部方法变量）。你可以重用 sqlsessionfactorybuilder 来创建多个 sqlsessionfactory 实例，但最好还是不要一直保留着它，以保证所有的 xml 解析资源可以被释放给更重要的事情。\n\n\n# sqlsessionfactory\n\n# sqlsessionfactory 职责\n\nsqlsessionfactory 负责创建 sqlsession 实例。\n\n\n\nsqlsessionfactory 应用了工厂设计模式，它提供了一组方法，用于创建 sqlsession 实例。\n\nsqlsession opensession()\nsqlsession opensession(boolean autocommit)\nsqlsession opensession(connection connection)\nsqlsession opensession(transactionisolationlevel level)\nsqlsession opensession(executortype exectype, transactionisolationlevel level)\nsqlsession opensession(executortype exectype)\nsqlsession opensession(executortype exectype, boolean autocommit)\nsqlsession opensession(executortype exectype, connection connection)\nconfiguration getconfiguration();\n\n\n方法说明：\n\n * 默认的 opensession() 方法没有参数，它会创建具备如下特性的 sqlsession：\n   * 事务作用域将会开启（也就是不自动提交）。\n   * 将由当前环境配置的 datasource 实例中获取 connection 对象。\n   * 事务隔离级别将会使用驱动或数据源的默认设置。\n   * 预处理语句不会被复用，也不会批量处理更新。\n * transactionisolationlevel 表示事务隔离级别，它对应着 jdbc 的五个事务隔离级别。\n * executortype 枚举类型定义了三个值:\n   * executortype.simple：该类型的执行器没有特别的行为。它为每个语句的执行创建一个新的预处理语句。\n   * executortype.reuse：该类型的执行器会复用预处理语句。\n   * executortype.batch：该类型的执行器会批量执行所有更新语句，如果 select 在多个更新中间执行，将在必要时将多条更新语句分隔开来，以方便理解。\n\n# sqlsessionfactory 生命周期\n\nsqlsessionfactory 应该以单例形式在应用的运行期间一直存在。\n\n\n# sqlsession\n\n# sqlsession 职责\n\nmybatis 的主要 java 接口就是 sqlsession。它包含了所有执行语句，获取映射器和管理事务等方法。\n\n> 详细内容可以参考：「 mybatis 官方文档之 sqlsessions 」 。\n\nsqlsession 类的方法可以按照下图进行大致分类：\n\n\n\n# sqlsession 生命周期\n\nsqlsessions 是由 sqlsessionfactory 实例创建的；而 sqlsessionfactory 是由 sqlsessionfactorybuilder 创建的。\n\n> 🔔 注意：当 mybatis 与一些依赖注入框架（如 spring 或者 guice）同时使用时，sqlsessions 将被依赖注入框架所创建，所以你不需要使用 sqlsessionfactorybuilder 或者 sqlsessionfactory。\n\n每个线程都应该有它自己的 sqlsession 实例。\n\nsqlsession 的实例不是线程安全的，因此是不能被共享的，所以它的最佳的作用域是请求或方法作用域。 绝对不能将 sqlsession 实例的引用放在一个类的静态域，甚至一个类的实例变量也不行。 也绝不能将 sqlsession 实例的引用放在任何类型的托管作用域中，比如 servlet 框架中的 httpsession。 正确在 web 中使用 sqlsession 的场景是：每次收到的 http 请求，就可以打开一个 sqlsession，返回一个响应，就关闭它。\n\n编程模式：\n\ntry (sqlsession session = sqlsessionfactory.opensession()) {\n  // 你的应用逻辑代码\n}\n\n\n\n# 映射器\n\n# 映射器职责\n\n映射器是一些由用户创建的、绑定 sql 语句的接口。\n\nsqlsession 中的 insert、update、delete 和 select 方法都很强大，但也有些繁琐。更通用的方式是使用映射器类来执行映射语句。一个映射器类就是一个仅需声明与 sqlsession 方法相匹配的方法的接口类。\n\nmybatis 将配置文件中的每一个 <mapper> 节点抽象为一个 mapper 接口，而这个接口中声明的方法和跟 <mapper> 节点中的 <select|update|delete|insert> 节点相对应，即 <select|update|delete|insert> 节点的 id 值为 mapper 接口中的方法名称，parametertype 值表示 mapper 对应方法的入参类型，而 resultmap 值则对应了 mapper 接口表示的返回值类型或者返回结果集的元素类型。\n\nmybatis 会根据相应的接口声明的方法信息，通过动态代理机制生成一个 mapper 实例；mybatis 会根据这个方法的方法名和参数类型，确定 statement id，然后和 sqlsession 进行映射，底层还是通过 sqlsession 完成和数据库的交互。\n\n下面的示例展示了一些方法签名以及它们是如何映射到 sqlsession 上的。\n\n\n\n> 注意\n> \n>  * 映射器接口不需要去实现任何接口或继承自任何类。只要方法可以被唯一标识对应的映射语句就可以了。\n>  * 映射器接口可以继承自其他接口。当使用 xml 来构建映射器接口时要保证语句被包含在合适的命名空间中。而且，唯一的限制就是你不能在两个继承关系的接口中拥有相同的方法签名（潜在的危险做法不可取）。\n\n# 映射器生命周期\n\n映射器接口的实例是从 sqlsession 中获得的。因此从技术层面讲，任何映射器实例的最大作用域是和请求它们的 sqlsession 相同的。尽管如此，映射器实例的最佳作用域是方法作用域。 也就是说，映射器实例应该在调用它们的方法中被请求，用过之后即可丢弃。\n\n编程模式：\n\ntry (sqlsession session = sqlsessionfactory.opensession()) {\n  blogmapper mapper = session.getmapper(blogmapper.class);\n  // 你的应用逻辑代码\n}\n\n\n * 映射器注解\n\nmybatis 是一个 xml 驱动的框架。配置信息是基于 xml 的，而且映射语句也是定义在 xml 中的。mybatis 3 以后，支持注解配置。注解配置基于配置 api；而配置 api 基于 xml 配置。\n\nmybatis 支持诸如 @insert、@update、@delete、@select、@result 等注解。\n\n> 详细内容请参考：mybatis 官方文档之 sqlsessions，其中列举了 mybatis 支持的注解清单，以及基本用法。\n\n\n# mybatis 的架构\n\n从 mybatis 代码实现的角度来看，mybatis 的主要组件有以下几个：\n\n * sqlsession - 作为 mybatis 工作的主要顶层 api，表示和数据库交互的会话，完成必要数据库增删改查功能。\n * executor - mybatis 执行器，是 mybatis 调度的核心，负责 sql 语句的生成和查询缓存的维护。\n * statementhandler - 封装了 jdbc statement 操作，负责对 jdbc statement 的操作，如设置参数、将 statement 结果集转换成 list 集合。\n * parameterhandler - 负责对用户传递的参数转换成 jdbc statement 所需要的参数。\n * resultsethandler - 负责将 jdbc 返回的 resultset 结果集对象转换成 list 类型的集合。\n * typehandler - 负责 java 数据类型和 jdbc 数据类型之间的映射和转换。\n * mappedstatement - mappedstatement 维护了一条 <select|update|delete|insert> 节点的封装。\n * sqlsource - 负责根据用户传递的 parameterobject，动态地生成 sql 语句，将信息封装到 boundsql 对象中，并返回。\n * boundsql - 表示动态生成的 sql 语句以及相应的参数信息。\n * configuration - mybatis 所有的配置信息都维持在 configuration 对象之中。\n\n这些组件的架构层次如下：\n\n\n\n\n# 配置层\n\n配置层决定了 mybatis 的工作方式。\n\nmybatis 提供了两种配置方式：\n\n * 基于 xml 配置文件的方式\n * 基于 java api 的方式\n\nsqlsessionfactorybuilder 会根据配置创建 sqlsessionfactory ；\n\nsqlsessionfactory 负责创建 sqlsessions 。\n\n\n# 接口层\n\n接口层负责和数据库交互的方式。\n\nmybatis 和数据库的交互有两种方式：\n\n * 使用 sqlsession：sqlsession 封装了所有执行语句，获取映射器和管理事务的方法。\n   * 用户只需要传入 statement id 和查询参数给 sqlsession 对象，就可以很方便的和数据库进行交互。\n   * 这种方式的缺点是不符合面向对象编程的范式。\n * 使用 mapper 接口：mybatis 会根据相应的接口声明的方法信息，通过动态代理机制生成一个 mapper 实例；mybatis 会根据这个方法的方法名和参数类型，确定 statement id，然后和 sqlsession 进行映射，底层还是通过 sqlsession 完成和数据库的交互。\n\n\n# 数据处理层\n\n数据处理层可以说是 mybatis 的核心，从大的方面上讲，它要完成两个功能：\n\n * 根据传参 statement 和参数构建动态 sql 语句\n   * 动态语句生成可以说是 mybatis 框架非常优雅的一个设计，mybatis 通过传入的参数值，使用 ognl 来动态地构造 sql 语句，使得 mybatis 有很强的灵活性和扩展性。\n   * 参数映射指的是对于 java 数据类型和 jdbc 数据类型之间的转换：这里有包括两个过程：查询阶段，我们要将 java 类型的数据，转换成 jdbc 类型的数据，通过 preparedstatement.setxxx() 来设值；另一个就是对 resultset 查询结果集的 jdbctype 数据转换成 java 数据类型。\n * 执行 sql 语句以及处理响应结果集 resultset\n   * 动态 sql 语句生成之后，mybatis 将执行 sql 语句，并将可能返回的结果集转换成 list<e> 列表。\n   * mybatis 在对结果集的处理中，支持结果集关系一对多和多对一的转换，并且有两种支持方式，一种为嵌套查询语句的查询，还有一种是嵌套结果集的查询。\n\n\n# 框架支撑层\n\n * 事务管理机制 - mybatis 将事务抽象成了 transaction 接口。mybatis 的事务管理分为两种形式：\n   \n   * 使用 jdbc 的事务管理机制：即利用 java.sql.connection 对象完成对事务的提交（commit）、回滚（rollback）、关闭（close）等。\n   * 使用 managed 的事务管理机制：mybatis 自身不会去实现事务管理，而是让程序的容器如（jboss，weblogic）来实现对事务的管理。\n\n * 连接池管理\n\n * sql 语句的配置 - 支持两种方式：\n   \n   * xml 配置\n   * 注解配置\n\n * 缓存机制 - mybatis 采用两级缓存结构\n   \n   * 一级缓存是 session 会话级别的缓存 - 一级缓存又被称之为本地缓存。一般而言，一个 sqlsession 对象会使用一个 executor 对象来完成会话操作，executor 对象会维护一个 cache 缓存，以提高查询性能。\n     * 一级缓存的生命周期是 session 会话级别的。\n   * 二级缓存是 application 应用级别的缓存 - 用户配置了 "cacheenabled=true"，才会开启二级缓存。\n     * 如果开启了二级缓存，sqlsession 会先使用 cachingexecutor 对象来处理查询请求。cachingexecutor 会在二级缓存中查看是否有匹配的数据，如果匹配，则直接返回缓存结果；如果缓存中没有，再交给真正的 executor 对象来完成查询，之后 cachingexecutor 会将真正 executor 返回的查询结果放置到缓存中，然后在返回给用户。\n     * 二级缓存的生命周期是应用级别的。\n\n\n\n\n# sqlsession 内部工作机制\n\n从前文，我们已经了解了，mybatis 封装了对数据库的访问，把对数据库的会话和事务控制放到了 sqlsession 对象中。那么具体是如何工作的呢？接下来，我们通过源码解读来进行分析。\n\n\n\nsqlsession 对于 insert、update、delete、select 的内部处理机制基本上大同小异。所以，接下来，我会以一次完整的 select 查询流程为例讲解 sqlsession 内部的工作机制。相信读者如果理解了 select 的处理流程，对于其他 crud 操作也能做到一通百通。\n\n\n# sqlsession 子组件\n\n前面的内容已经介绍了：sqlsession 是 mybatis 的顶层接口，它提供了所有执行语句，获取映射器和管理事务等方法。\n\n实际上，sqlsession 是通过聚合多个子组件，让每个子组件负责各自功能的方式，实现了任务的下发。\n\n在了解各个子组件工作机制前，先让我们简单认识一下 sqlsession 的核心子组件。\n\n# executor\n\nexecutor 即执行器，它负责生成动态 sql 以及管理缓存。\n\n\n\n * executor 即执行器接口。\n * baseexecutor 是 executor 的抽象类，它采用了模板方法设计模式，内置了一些共性方法，而将定制化方法留给子类去实现。\n * simpleexecutor 是最简单的执行器。它只会直接执行 sql，不会做额外的事。\n * batchexecutor 是批处理执行器。它的作用是通过批处理来优化性能。值得注意的是，批量更新操作，由于内部有缓存机制，使用完后需要调用 flushstatements 来清除缓存。\n * reuseexecutor 是可重用的执行器。重用的对象是 statement，也就是说，该执行器会缓存同一个 sql 的 statement，避免重复创建 statement。其内部的实现是通过一个 hashmap 来维护 statement 对象的。由于当前 map 只在该 session 中有效，所以使用完后需要调用 flushstatements 来清除 map。\n * cachingexecutor 是缓存执行器。它只在启用二级缓存时才会用到。\n\n# statementhandler\n\nstatementhandler 对象负责设置 statement 对象中的查询参数、处理 jdbc 返回的 resultset，将 resultset 加工为 list 集合返回。\n\nstatementhandler 的家族成员：\n\n\n\n * statementhandler 是接口；\n * basestatementhandler 是实现 statementhandler 的抽象类，内置一些共性方法；\n * simplestatementhandler 负责处理 statement；\n * preparedstatementhandler 负责处理 preparedstatement；\n * callablestatementhandler 负责处理 callablestatement。\n * routingstatementhandler 负责代理 statementhandler 具体子类，根据 statement 类型，选择实例化 simplestatementhandler、preparedstatementhandler、callablestatementhandler。\n\n# parameterhandler\n\nparameterhandler 负责将传入的 java 对象转换 jdbc 类型对象，并为 preparedstatement 的动态 sql 填充数值。\n\nparameterhandler 只有一个具体实现类，即 defaultparameterhandler。\n\n# resultsethandler\n\nresultsethandler 负责两件事：\n\n * 处理 statement 执行后产生的结果集，生成结果列表\n * 处理存储过程执行后的输出参数\n\nresultsethandler 只有一个具体实现类，即 defaultresultsethandler。\n\n# typehandler\n\ntypehandler 负责将 java 对象类型和 jdbc 类型进行相互转换。\n\n\n# sqlsession 和 mapper\n\n先来回忆一下 mybatis 完整示例章节的 测试程序部分的代码。\n\nmybatisdemo.java 文件中的代码片段：\n\n// 2. 创建一个 sqlsession 实例，进行数据库操作\nsqlsession sqlsession = factory.opensession();\n\n// 3. mapper 映射并执行\nlong params = 1l;\nlist<user> list = sqlsession.selectlist("io.github.dunwu.spring.orm.mapper.usermapper.selectbyprimarykey", params);\nfor (user user : list) {\n    system.out.println("user name: " + user.getname());\n}\n\n\n示例代码中，给 sqlsession 对象的传递一个配置的 sql 语句的 statement id 和参数，然后返回结果\n\nio.github.dunwu.spring.orm.mapper.usermapper.selectbyprimarykey 是配置在 usermapper.xml 的 statement id，params 是 sql 参数。\n\nusermapper.xml 文件中的代码片段：\n\n  <select id="selectbyprimarykey" parametertype="java.lang.long" resultmap="baseresultmap">\n    select id, name, age, address, email\n    from user\n    where id = #{id,jdbctype=bigint}\n  </select>\n\n\nmybatis 通过方法的全限定名，将 sqlsession 和 mapper 相互映射起来。\n\n\n# sqlsession 和 executor\n\norg.apache.ibatis.session.defaults.defaultsqlsession 中 selectlist 方法的源码：\n\n@override\npublic <e> list<e> selectlist(string statement) {\n  return this.selectlist(statement, null);\n}\n\n@override\npublic <e> list<e> selectlist(string statement, object parameter) {\n  return this.selectlist(statement, parameter, rowbounds.default);\n}\n\n@override\npublic <e> list<e> selectlist(string statement, object parameter, rowbounds rowbounds) {\n  try {\n    // 1. 根据 statement id，在配置对象 configuration 中查找和配置文件相对应的 mappedstatement\n    mappedstatement ms = configuration.getmappedstatement(statement);\n    // 2. 将 sql 语句交由执行器 executor 处理\n    return executor.query(ms, wrapcollection(parameter), rowbounds, executor.no_result_handler);\n  } catch (exception e) {\n    throw exceptionfactory.wrapexception("error querying database.  cause: " + e, e);\n  } finally {\n    errorcontext.instance().reset();\n  }\n}\n\n\n说明：\n\nmybatis 所有的配置信息都维持在 configuration 对象之中。中维护了一个 map<string, mappedstatement> 对象。其中，key 为 mapper 方法的全限定名（对于本例而言，key 就是 io.github.dunwu.spring.orm.mapper.usermapper.selectbyprimarykey ），value 为 mappedstatement 对象。所以，传入 statement id 就可以从 map 中找到对应的 mappedstatement。\n\nmappedstatement 维护了一个 mapper 方法的元数据信息，其数据组织可以参考下面的 debug 截图：\n\n\n\n> 小结：\n> \n> 通过 "sqlsession 和 mapper" 以及 "sqlsession 和 executor" 这两节，我们已经知道：\n> \n> sqlsession 的职能是：根据 statement id, 在 configuration 中获取到对应的 mappedstatement 对象，然后调用 executor 来执行具体的操作。\n\n\n# executor 工作流程\n\n继续上一节的流程，sqlsession 将 sql 语句交由执行器 executor 处理。executor 又做了哪些事儿呢？\n\n（1）执行器查询入口\n\npublic <e> list<e> query(mappedstatement ms, object parameter, rowbounds rowbounds, resulthandler resulthandler) throws sqlexception {\n\t// 1. 根据传参，动态生成需要执行的 sql 语句，用 boundsql 对象表示\n    boundsql boundsql = ms.getboundsql(parameter);\n    // 2. 根据传参，创建一个缓存key\n    cachekey key = createcachekey(ms, parameter, rowbounds, boundsql);\n    return query(ms, parameter, rowbounds, resulthandler, key, boundsql);\n }\n\n\n执行器查询入口主要做两件事：\n\n * 生成动态 sql：根据传参，动态生成需要执行的 sql 语句，用 boundsql 对象表示。\n * 管理缓存：根据传参，创建一个缓存 key。\n\n（2）执行器查询第二入口\n\n  @suppresswarnings("unchecked")\n  @override\n  public <e> list<e> query(mappedstatement ms, object parameter, rowbounds rowbounds, resulthandler resulthandler, cachekey key, boundsql boundsql) throws sqlexception {\n    // 略\n    list<e> list;\n    try {\n      querystack++;\n      list = resulthandler == null ? (list<e>) localcache.getobject(key) : null;\n      // 3. 缓存中有值，则直接从缓存中取数据；否则，查询数据库\n      if (list != null) {\n        handlelocallycachedoutputparameters(ms, key, parameter, boundsql);\n      } else {\n        list = queryfromdatabase(ms, parameter, rowbounds, resulthandler, key, boundsql);\n      }\n    } finally {\n      querystack--;\n    }\n    // 略\n    return list;\n  }\n\n\n实际查询方法主要的职能是判断缓存 key 是否能命中缓存：\n\n * 命中，则将缓存中数据返回；\n * 不命中，则查询数据库：\n\n（3）查询数据库\n\n  private <e> list<e> queryfromdatabase(mappedstatement ms, object parameter, rowbounds rowbounds, resulthandler resulthandler, cachekey key, boundsql boundsql) throws sqlexception {\n    list<e> list;\n    localcache.putobject(key, execution_placeholder);\n    try {\n      // 4. 执行查询，获取 list 结果，并将查询的结果更新本地缓存中\n      list = doquery(ms, parameter, rowbounds, resulthandler, boundsql);\n    } finally {\n      localcache.removeobject(key);\n    }\n    localcache.putobject(key, list);\n    if (ms.getstatementtype() == statementtype.callable) {\n      localoutputparametercache.putobject(key, parameter);\n    }\n    return list;\n  }\n\n\nqueryfromdatabase 方法的职责是调用 doquery，向数据库发起查询，并将返回的结果更新到本地缓存。\n\n（4）实际查询方法\n\nsimpleexecutor 类的 doquery()方法实现\n\n  @override\n  public <e> list<e> doquery(mappedstatement ms, object parameter, rowbounds rowbounds, resulthandler resulthandler, boundsql boundsql) throws sqlexception {\n    statement stmt = null;\n    try {\n      configuration configuration = ms.getconfiguration();\n      // 5. 根据既有的参数，创建statementhandler对象来执行查询操作\n      statementhandler handler = configuration.newstatementhandler(wrapper, ms, parameter, rowbounds, resulthandler, boundsql);\n      // 6. 创建java.sql.statement对象，传递给statementhandler对象\n      stmt = preparestatement(handler, ms.getstatementlog());\n      // 7. 调用statementhandler.query()方法，返回list结果\n      return handler.query(stmt, resulthandler);\n    } finally {\n      closestatement(stmt);\n    }\n  }\n\n\n上述的 executor.query()方法几经转折，最后会创建一个 statementhandler 对象，然后将必要的参数传递给 statementhandler，使用 statementhandler 来完成对数据库的查询，最终返回 list 结果集。 从上面的代码中我们可以看出，executor 的功能和作用是：\n\n 1. 根据传递的参数，完成 sql 语句的动态解析，生成 boundsql 对象，供 statementhandler 使用；\n\n 2. 为查询创建缓存，以提高性能\n\n 3. 创建 jdbc 的 statement 连接对象，传递给 statementhandler 对象，返回 list 查询结果。\n\npreparestatement() 方法的实现：\n\n  private statement preparestatement(statementhandler handler, log statementlog) throws sqlexception {\n    statement stmt;\n    connection connection = getconnection(statementlog);\n    stmt = handler.prepare(connection, transaction.gettimeout());\n    //对创建的statement对象设置参数，即设置sql 语句中 ? 设置为指定的参数\n    handler.parameterize(stmt);\n    return stmt;\n  }\n\n\n对于 jdbc 的 preparedstatement 类型的对象，创建的过程中，我们使用的是 sql 语句字符串会包含 若干个? 占位符，我们其后再对占位符进行设值。\n\n\n# statementhandler 工作流程\n\nstatementhandler 有一个子类 routingstatementhandler，它负责代理其他 statementhandler 子类的工作。\n\n它会根据配置的 statement 类型，选择实例化相应的 statementhandler，然后由其代理对象完成工作。\n\n【源码】routingstatementhandler\n\npublic routingstatementhandler(executor executor, mappedstatement ms, object parameter, rowbounds rowbounds, resulthandler resulthandler, boundsql boundsql) {\n\n  switch (ms.getstatementtype()) {\n    case statement:\n      delegate = new simplestatementhandler(executor, ms, parameter, rowbounds, resulthandler, boundsql);\n      break;\n    case prepared:\n      delegate = new preparedstatementhandler(executor, ms, parameter, rowbounds, resulthandler, boundsql);\n      break;\n    case callable:\n      delegate = new callablestatementhandler(executor, ms, parameter, rowbounds, resulthandler, boundsql);\n      break;\n    default:\n      throw new executorexception("unknown statement type: " + ms.getstatementtype());\n  }\n\n}\n\n\n【源码】routingstatementhandler 的 parameterize 方法源码\n\n【源码】preparedstatementhandler 的 parameterize 方法源码\n\nstatementhandler 使用 parameterhandler 对象来完成对 statement 的赋值。\n\n@override\npublic void parameterize(statement statement) throws sqlexception {\n  // 使用 parameterhandler 对象来完成对 statement 的设值\n  parameterhandler.setparameters((preparedstatement) statement);\n}\n\n\n【源码】statementhandler 的 query 方法源码\n\nstatementhandler 使用 resultsethandler 对象来完成对 resultset 的处理。\n\n@override\npublic <e> list<e> query(statement statement, resulthandler resulthandler) throws sqlexception {\n  preparedstatement ps = (preparedstatement) statement;\n  ps.execute();\n  // 使用resulthandler来处理resultset\n  return resultsethandler.handleresultsets(ps);\n}\n\n\n\n# parameterhandler 工作流程\n\n【源码】defaultparameterhandler 的 setparameters 方法\n\n  @override\n  public void setparameters(preparedstatement ps) {\n\t// parametermappings 是对占位符 #{} 对应参数的封装\n    list<parametermapping> parametermappings = boundsql.getparametermappings();\n    if (parametermappings != null) {\n      for (int i = 0; i < parametermappings.size(); i++) {\n        parametermapping parametermapping = parametermappings.get(i);\n        // 不处理存储过程中的参数\n        if (parametermapping.getmode() != parametermode.out) {\n          object value;\n          string propertyname = parametermapping.getproperty();\n          if (boundsql.hasadditionalparameter(propertyname)) { // issue #448 ask first for additional params\n            // 获取对应的实际数值\n            value = boundsql.getadditionalparameter(propertyname);\n          } else if (parameterobject == null) {\n            value = null;\n          } else if (typehandlerregistry.hastypehandler(parameterobject.getclass())) {\n            value = parameterobject;\n          } else {\n            // 获取对象中相应的属性或查找 map 对象中的值\n            metaobject metaobject = configuration.newmetaobject(parameterobject);\n            value = metaobject.getvalue(propertyname);\n          }\n\n          typehandler typehandler = parametermapping.gettypehandler();\n          jdbctype jdbctype = parametermapping.getjdbctype();\n          if (value == null && jdbctype == null) {\n            jdbctype = configuration.getjdbctypefornull();\n          }\n          try {\n            // 通过 typehandler 将 java 对象参数转为 jdbc 类型的参数\n            // 然后，将数值动态绑定到 preparedstaement 中\n            typehandler.setparameter(ps, i + 1, value, jdbctype);\n          } catch (typeexception | sqlexception e) {\n            throw new typeexception("could not set parameters for mapping: " + parametermapping + ". cause: " + e, e);\n          }\n        }\n      }\n    }\n  }\n\n\n\n# resultsethandler 工作流程\n\nresultsethandler 的实现可以概括为：将 statement 执行后的结果集，按照 mapper 文件中配置的 resulttype 或 resultmap 来转换成对应的 javabean 对象，最后将结果返回。\n\n【源码】defaultresultsethandler 的 handleresultsets 方法\n\nhandleresultsets 方法是 defaultresultsethandler 的最关键方法。其实现如下：\n\n@override\npublic list<object> handleresultsets(statement stmt) throws sqlexception {\n  errorcontext.instance().activity("handling results").object(mappedstatement.getid());\n\n  final list<object> multipleresults = new arraylist<>();\n\n  int resultsetcount = 0;\n  // 第一个结果集\n  resultsetwrapper rsw = getfirstresultset(stmt);\n  list<resultmap> resultmaps = mappedstatement.getresultmaps();\n  // 判断结果集的数量\n  int resultmapcount = resultmaps.size();\n  validateresultmapscount(rsw, resultmapcount);\n  // 遍历处理结果集\n  while (rsw != null && resultmapcount > resultsetcount) {\n    resultmap resultmap = resultmaps.get(resultsetcount);\n    handleresultset(rsw, resultmap, multipleresults, null);\n    rsw = getnextresultset(stmt);\n    cleanupafterhandlingresultset();\n    resultsetcount++;\n  }\n\n  string[] resultsets = mappedstatement.getresultsets();\n  if (resultsets != null) {\n    while (rsw != null && resultsetcount < resultsets.length) {\n      resultmapping parentmapping = nextresultmaps.get(resultsets[resultsetcount]);\n      if (parentmapping != null) {\n        string nestedresultmapid = parentmapping.getnestedresultmapid();\n        resultmap resultmap = configuration.getresultmap(nestedresultmapid);\n        handleresultset(rsw, resultmap, null, parentmapping);\n      }\n      rsw = getnextresultset(stmt);\n      cleanupafterhandlingresultset();\n      resultsetcount++;\n    }\n  }\n\n  return collapsesingleresultlist(multipleresults);\n}\n\n\n\n# 参考资料\n\n * 官方\n   * mybatis github\n   * mybatis 官网\n * 文章\n   * 深入理解 mybatis 原理\n   * mybatis 源码中文注释\n   * mybatis 中强大的 resultmap',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java ORM 框架",frontmatter:{title:"Java ORM 框架",categories:["编程","Java","框架","ORM"],tags:["Java","框架","ORM"],abbrlink:"2f780626",date:"2022-02-17T22:34:30.000Z",hidden:!0,permalink:"/pages/e873e1/"},regularPath:"/13.%E6%A1%86%E6%9E%B6/11.ORM/",relativePath:"13.框架/11.ORM/README.md",key:"v-58178384",path:"/pages/e873e1/",headers:[{level:2,title:"📖 内容",slug:"📖-内容",normalizedTitle:"📖 内容",charIndex:18},{level:3,title:"Mybatis 快速入门",slug:"mybatis-快速入门",normalizedTitle:"mybatis 快速入门",charIndex:155},{level:3,title:"Mybatis 原理",slug:"mybatis-原理",normalizedTitle:"mybatis 原理",charIndex:172},{level:2,title:"📚 资料",slug:"📚-资料",normalizedTitle:"📚 资料",charIndex:187},{level:2,title:"🚪 传送",slug:"🚪-传送",normalizedTitle:"🚪 传送",charIndex:608}],headersStr:"📖 内容 Mybatis 快速入门 Mybatis 原理 📚 资料 🚪 传送",content:"# Java ORM 框架\n\n\n# 📖 内容\n\n> Mybatis 的前身就是 iBatis ，是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。本文以一个 Mybatis 完整示例为切入点，结合 Mybatis 底层源码分析，图文并茂的讲解 Mybatis 的核心工作机制。\n\n\n\n\n# Mybatis 快速入门\n\n\n# Mybatis 原理\n\n\n# 📚 资料\n\n * 官方\n   * Mybatis Github\n   * Mybatis 官网\n   * MyBatis 官方代码生成（mybatis-generator）\n   * MyBatis 官方集成 Spring（mybatis-spring）\n   * Mybatis 官方集成 Spring Boot（mybatis-spring-boot）\n * 扩展插件\n   * MyBatis-Plus - CRUD 扩展插件、代码生成器、分页器等多功能\n   * Mapper - CRUD 扩展插件\n   * Mybatis-PageHelper - Mybatis 通用分页插件\n * 文章\n   * 深入理解 mybatis 原理\n   * mybatis 源码中文注释\n   * MyBatis Generator 详解\n   * Mybatis 常见面试题\n   * Mybatis 中强大的 resultMap\n\n\n# 🚪 传送\n\n◾ 🏠 JAVA-TUTORIAL 首页 ◾ 🎯 我的博客 ◾",normalizedContent:"# java orm 框架\n\n\n# 📖 内容\n\n> mybatis 的前身就是 ibatis ，是一款优秀的持久层框架，它支持自定义 sql、存储过程以及高级映射。本文以一个 mybatis 完整示例为切入点，结合 mybatis 底层源码分析，图文并茂的讲解 mybatis 的核心工作机制。\n\n\n\n\n# mybatis 快速入门\n\n\n# mybatis 原理\n\n\n# 📚 资料\n\n * 官方\n   * mybatis github\n   * mybatis 官网\n   * mybatis 官方代码生成（mybatis-generator）\n   * mybatis 官方集成 spring（mybatis-spring）\n   * mybatis 官方集成 spring boot（mybatis-spring-boot）\n * 扩展插件\n   * mybatis-plus - crud 扩展插件、代码生成器、分页器等多功能\n   * mapper - crud 扩展插件\n   * mybatis-pagehelper - mybatis 通用分页插件\n * 文章\n   * 深入理解 mybatis 原理\n   * mybatis 源码中文注释\n   * mybatis generator 详解\n   * mybatis 常见面试题\n   * mybatis 中强大的 resultmap\n\n\n# 🚪 传送\n\n◾ 🏠 java-tutorial 首页 ◾ 🎯 我的博客 ◾",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Shiro 快速入门",frontmatter:{title:"Shiro 快速入门",categories:["编程","Java","框架","安全"],tags:["Java","框架","安全","Shiro"],abbrlink:"1c025fc",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/cd25bf/"},regularPath:"/13.%E6%A1%86%E6%9E%B6/12.%E5%AE%89%E5%85%A8/01.Shiro.html",relativePath:"13.框架/12.安全/01.Shiro.md",key:"v-7f048411",path:"/pages/cd25bf/",headers:[{level:2,title:"一、Shiro 简介",slug:"一、shiro-简介",normalizedTitle:"一、shiro 简介",charIndex:53},{level:3,title:"Shiro 特性",slug:"shiro-特性",normalizedTitle:"shiro 特性",charIndex:68},{level:3,title:"Shiro 架构概述",slug:"shiro-架构概述",normalizedTitle:"shiro 架构概述",charIndex:722},{level:3,title:"SecurityManager",slug:"securitymanager",normalizedTitle:"securitymanager",charIndex:1074},{level:2,title:"二、Shiro 认证",slug:"二、shiro-认证",normalizedTitle:"二、shiro 认证",charIndex:1836},{level:3,title:"认证 Subject",slug:"认证-subject",normalizedTitle:"认证 subject",charIndex:1851},{level:3,title:"Remembered 和 Authenticated",slug:"remembered-和-authenticated",normalizedTitle:"remembered 和 authenticated",charIndex:2612},{level:3,title:"登出",slug:"登出",normalizedTitle:"登出",charIndex:2920},{level:3,title:"认证流程",slug:"认证流程",normalizedTitle:"认证流程",charIndex:3009},{level:3,title:"认证策略",slug:"认证策略",normalizedTitle:"认证策略",charIndex:1568},{level:2,title:"三、Shiro 授权",slug:"三、shiro-授权",normalizedTitle:"三、shiro 授权",charIndex:4637},{level:3,title:"授权元素",slug:"授权元素",normalizedTitle:"授权元素",charIndex:4700},{level:4,title:"权限",slug:"权限",normalizedTitle:"权限",charIndex:164},{level:4,title:"角色",slug:"角色",normalizedTitle:"角色",charIndex:196},{level:4,title:"用户",slug:"用户",normalizedTitle:"用户",charIndex:112},{level:3,title:"基于角色的授权",slug:"基于角色的授权",normalizedTitle:"基于角色的授权",charIndex:5062},{level:3,title:"基于权限的授权",slug:"基于权限的授权",normalizedTitle:"基于权限的授权",charIndex:5499},{level:3,title:"基于注解的授权",slug:"基于注解的授权",normalizedTitle:"基于注解的授权",charIndex:6273},{level:4,title:"@RequiresAuthentication",slug:"requiresauthentication",normalizedTitle:"@requiresauthentication",charIndex:6316},{level:4,title:"@RequiresGuest",slug:"requiresguest",normalizedTitle:"@requiresguest",charIndex:6586},{level:3,title:"授权流程",slug:"授权流程",normalizedTitle:"授权流程",charIndex:6660},{level:2,title:"四、Shiro 会话管理",slug:"四、shiro-会话管理",normalizedTitle:"四、shiro 会话管理",charIndex:7342},{level:3,title:"会话超时",slug:"会话超时",normalizedTitle:"会话超时",charIndex:7644},{level:3,title:"会话监听",slug:"会话监听",normalizedTitle:"会话监听",charIndex:7749},{level:3,title:"会话存储",slug:"会话存储",normalizedTitle:"会话存储",charIndex:8382},{level:2,title:"五、Realm",slug:"五、realm",normalizedTitle:"五、realm",charIndex:8568},{level:3,title:"认证令牌",slug:"认证令牌",normalizedTitle:"认证令牌",charIndex:8688},{level:3,title:"加密",slug:"加密",normalizedTitle:"加密",charIndex:38},{level:2,title:"六、配置",slug:"六、配置",normalizedTitle:"六、配置",charIndex:10293},{level:3,title:"过滤链",slug:"过滤链",normalizedTitle:"过滤链",charIndex:10302},{level:3,title:"RememberMe",slug:"rememberme",normalizedTitle:"rememberme",charIndex:2115},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:11360}],headersStr:"一、Shiro 简介 Shiro 特性 Shiro 架构概述 SecurityManager 二、Shiro 认证 认证 Subject Remembered 和 Authenticated 登出 认证流程 认证策略 三、Shiro 授权 授权元素 权限 角色 用户 基于角色的授权 基于权限的授权 基于注解的授权 @RequiresAuthentication @RequiresGuest 授权流程 四、Shiro 会话管理 会话超时 会话监听 会话存储 五、Realm 认证令牌 加密 六、配置 过滤链 RememberMe 参考资料",content:'# Shiro 快速入门\n\n> Shiro 是一个安全框架，具有认证、授权、加密、会话管理功能。\n\n\n# 一、Shiro 简介\n\n\n# Shiro 特性\n\n\n\n核心功能：\n\n * Authentication - 认证。验证用户是不是拥有相应的身份。\n * Authorization - 授权。验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限。\n * Session Manager - 会话管理。即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中。会话可以是普通 JavaSE 环境的，也可以是如 Web 环境的。\n * Cryptography - 加密。保护数据的安全性，如密码加密存储到数据库，而不是明文存储。\n\n辅助功能：\n\n * Web Support - Web 支持。可以非常容易的集成到 Web 环境；\n * Caching - 缓存。比如用户登录后，其用户信息、拥有的角色 / 权限不必每次去查，这样可以提高效率；\n * Concurrency - 并发。Shiro 支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去；\n * Testing - 测试。提供测试支持；\n * Run As - 运行方式。允许一个用户假装为另一个用户（如果他们允许）的身份进行访问；\n * Remember Me - 记住我。即一次登录后，下次再访问免登录。\n\n> 🔔 注意：Shiro 不会去维护用户、维护权限；这些需要我们自己去提供；然后通过相应的接口注入给 Shiro 即可。\n\n\n# Shiro 架构概述\n\n\n\n * Subject - 主题。它代表当前用户，Subject 可以是一个人，但也可以是第三方服务、守护进程帐户、时钟守护任务或者其它——当前和软件交互的任何事件。Subject 是 Shiro 的入口。\n   \n   * Principals 是 Subject 的“识别属性”。Principals 可以是任何可以识别 Subject 的东西，例如名字（姓氏），姓氏（姓氏或姓氏），用户名，社会保险号等。当然，Principals 在应用程序中最好是惟一的。\n   * Credentials 通常是仅由 Subject 知道的秘密值，用作他们实际上“拥有”所主张身份的佐证 凭据的一些常见示例是密码，生物特征数据（例如指纹和视网膜扫描）以及 X.509 证书。\n\n * SecurityManager - 安全管理。它是 Shiro 的核心，所有与安全有关的操作（认证、授权、及会话、缓存的管理）都与 SecurityManager 交互，且它管理着所有 Subject。\n\n * Realm - 域。用于访问安全相关数据，可以视为应用自身的数据源，需要开发者自己实现。Shiro 会通过 Realm 获取安全数据（如用户、角色、权限），就是说 SecurityManager 要验证用户身份，那么它需要从 Realm 获取相应的用户进行比较以确定用户身份是否合法；也需要从 Realm 得到用户相应的角色/权限进行验证用户是否能进行操作；可以把 Realm 看成 DataSource，即安全数据源。\n\n\n# SecurityManager\n\nSecurityManager 是 Shiro 框架核心中的核心，它相当于 Shiro 的总指挥，负责调度所有行为，包括：认证、授权、获取安全数据（调用 Realm）、会话管理等。\n\n\n\nSecurityManager 聚合了以下组件：\n\n * Authenticator - 认证器，负责认证。如果用户需要定制认证策略，可以实现此接口。\n * Authorizer - 授权器，负责权限控制。用来决定主体是否有权限进行相应的操作；即控制着用户能访问应用中的哪些功能；\n * SessionManager - 会话管理器。Shiro 抽象了一个自己的 Session 来管理主体与应用之间交互的数据。\n * SessionDAO - 会话 DAO 用于存储会话，需要用户自己实现。\n * CacheManager - 缓存控制器。用于管理如用户、角色、权限等信息的缓存。\n * Cryptography - 密码器。用于对数据加密、解密。\n\n\n# 二、Shiro 认证\n\n\n# 认证 Subject\n\n验证 Subject 的过程可以有效地分为三个不同的步骤：\n\n（1）收集 Subject 提交的 Principals 和 Credentials\n\n//Example using most common scenario of username/password pair:\nUsernamePasswordToken token = new UsernamePasswordToken(username, password);\n\n//"Remember Me" built-in:\ntoken.setRememberMe(true);\n\n\n（2）提交 Principals 和 Credentials 以进行身份验证。\n\nSubject currentUser = SecurityUtils.getSubject();\n\ncurrentUser.login(token);\n\n\n（3）如果提交成功，则允许访问，否则重试身份验证或阻止访问。\n\ntry {\n    currentUser.login(token);\n} catch ( UnknownAccountException uae ) { ...\n} catch ( IncorrectCredentialsException ice ) { ...\n} catch ( LockedAccountException lae ) { ...\n} catch ( ExcessiveAttemptsException eae ) { ...\n} ... catch your own ...\n} catch ( AuthenticationException ae ) {\n    //unexpected error?\n}\n\n\n\n# Remembered 和 Authenticated\n\n * Remembered - 记住我。被记住的 Subject 不是匿名的，并且具有已知的身份（即 subject.getPrincipals() 是非空的）。 但是，在先前的会话期间，通过先前的身份验证会记住此身份。 如果 subject.isRemembered() 返回 true，则认为该主题已被记住。\n * Authenticated - 已认证。已认证的 Subject 是在当前会话期间已成功认证的 Subject。 如果 subject.isAuthenticated() 返回 true，则认为该 Subject 已通过身份验证。\n\n\n# 登出\n\n当 Subject 与应用程序完成交互后，可以调用 subject.logout() 登出，即放弃所有标识信息。\n\ncurrentUser.logout();\n\n\n\n# 认证流程\n\n\n\n 1. 应用程序代码调用 Subject.login 方法，传入构造的 AuthenticationToken 实例，该实例代表最终用户的 Principals 和 Credentials。\n\n 2. Subject 实例（通常是 DelegatingSubject（或子类））通过调用 securityManager.login（token）委托应用程序的 SecurityManager，在此处开始实际的身份验证工作。\n\n 3. SecurityManager 接收令牌，并通过调用 authenticator.authenticate（token）来简单地委派给其内部 Authenticator 实例。这几乎总是一个 ModularRealmAuthenticator 实例，它支持在身份验证期间协调一个或多个 Realm 实例。\n\n 4. 如果为该应用程序配置了多个 Realm，则 ModularRealmAuthenticator 实例将利用其配置的 AuthenticationStrategy 发起多域验证尝试。在调用领域进行身份验证之前，期间和之后，将调用 AuthenticationStrategy 以使其对每个领域的结果做出反应。\n\n 5. 请咨询每个已配置的 Realm，以查看其是否支持提交的 AuthenticationToken。 如果是这样，将使用提交的令牌调用支持 Realm 的 getAuthenticationInfo 方法。 getAuthenticationInfo 方法有效地表示对该特定 Realm 的单个身份验证尝试。\n\n\n# 认证策略\n\n当为一个应用程序配置两个或多个领域时，ModularRealmAuthenticator 依赖于内部 AuthenticationStrategy 组件来确定认证尝试成功或失败的条件。\n\n例如，如果只有一个 Realm 成功地对 AuthenticationToken 进行身份验证，而所有其他 Realm 都失败了，那么该身份验证尝试是否被视为成功？还是必须所有领域都成功进行身份验证才能将整体尝试视为成功？或者，如果某个领域成功通过身份验证，是否有必要进一步咨询其他领域？ AuthenticationStrategy 根据应用程序的需求做出适当的决定。\n\nAuthenticationStrategy 是无状态组件，在尝试进行身份验证时会被查询 4 次（这 4 种交互所需的任何必要状态都将作为方法参数给出）：\n\n * 在任何领域被调用之前\n * 在调用单个 Realm 的 getAuthenticationInfo 方法之前\n * 在调用单个 Realm 的 getAuthenticationInfo 方法之后\n * 在所有领域都被调用之后\n\nAuthenticationStrategy 还负责汇总每个成功 Realm 的结果，并将它们“捆绑”成单个 AuthenticationInfo 表示形式。最终的聚合 AuthenticationInfo 实例是 Authenticator 实例返回的结果，也是 Shiro 用来表示主体的最终身份（也称为委托人）的东西。\n\nAUTHENTICATIONSTRATEGY         描述\nAtLeastOneSuccessfulStrategy   只要有一个 Realm 成功认证，则整个尝试都被视为成功。\nFirstSuccessfulStrategy        仅使用从第一个成功通过身份验证的 Realm 返回的信息，所有其他 Realm 将被忽略。\nAllSuccessfulStrategy          只有所有 Realm 成功认证，则整个尝试才被视为成功。\n\n> 🔗 更多认证细节可以参考：Apache Shiro Authentication\n\n\n# 三、Shiro 授权\n\n授权，也称为访问控制，是管理对资源的访问的过程。 换句话说，控制谁有权访问应用程序中的内容。\n\n\n# 授权元素\n\n授权有三个核心要素：权限、角色和用户。\n\n# 权限\n\n权限示例：\n\n * 打开一个文件\n * 查看 /user/list web 页面\n * 查询记录\n * 删除一条记录\n * ...\n\n大多数资源都支持一般的 CRUD 操作。除此以外，对于一些特定的资源，任何有意义的行为都是可以的。基本的设计思路是：权限控制，至少是基于资源和行为。\n\n# 角色\n\n角色是一个命名实体，通常代表一组行为或职责。这些行为会转化为：谁可以在应用程序中执行哪些行为？谁不可以在程序中执行哪些行为？\n\n角色通常是分配给用户帐户的，因此通过关联，用户可以获得自身角色所赋予的权限。\n\n# 用户\n\n用户本质上是应用程序的“用户”。\n\n用户（即 Shiro 的 Subject）通过与角色或直接权限的关联在应用程序中执行某些行为。\n\n\n# 基于角色的授权\n\n如果授权是基于角色赋予权限的数据模型，编程模式如下：\n\n【示例一】\n\nSubject currentUser = SecurityUtils.getSubject();\n\nif (currentUser.hasRole("administrator")) {\n    //show the admin button\n} else {\n    //don\'t show the button?  Grey it out?\n}\n\n\n【示例二】\n\nSubject currentUser = SecurityUtils.getSubject();\n\n// 检查当前 Subject 是否有某种权限\n// 如果有，直接跳过；如果没有，Shiro 会抛出 AuthorizationException\ncurrentUser.checkRole("bankTeller");\nopenBankAccount();\n\n\n> 提示：方式二相比方式一，代码更简洁\n\n\n# 基于权限的授权\n\n更好的授权策略通常是基于权限的授权。基于权限的授权，由于它和应用程序的原始功能（针对具体资源上的行为）紧密相关，所以基于权限的授权源代码会在功能更改时同步更改（而不是在安全策略发生更改时）。 这意味着与类似的基于角色的授权代码相比，修改代码的影响面要小得多。\n\n【示例】基于对象的权限检查\n\nPermission printPermission = new PrinterPermission("laserjet4400n", "print");\n\nSubject currentUser = SecurityUtils.getSubject();\n\nif (currentUser.isPermitted(printPermission)) {\n    //show the Print button\n} else {\n    //don\'t show the button?  Grey it out?\n}\n\n\n在对象中存储权限控制信息，但这种方式较为繁重\n\n【示例】字符串定义权限控制信息\n\nSubject currentUser = SecurityUtils.getSubject();\n\nif (currentUser.isPermitted("printer:print:laserjet4400n")) {\n    //show the Print button\n} else {\n    //don\'t show the button?  Grey it out?\n}\n\n\n使用 : 分隔，表示资源类型、行为、资源 ID，Shiro 提供了默认实现： org.apache.shiro.authz.permission.WildcardPermission。\n\n这种权限控制方式的好处在于：轻量、灵活。\n\n\n# 基于注解的授权\n\nShiro 提供了一些用于授权的注解，来进一步简化授权代码。\n\n# @RequiresAuthentication\n\n@RequiresAuthentication 注解要求当前 Subject 必须是已认证用户才可以访问被修饰的方法。\n\n【示例】\n\n@RequiresAuthentication\npublic void updateAccount(Account userAccount) {\n    //this method will only be invoked by a\n    //Subject that is guaranteed authenticated\n    ...\n}\n\n\n# @RequiresGuest\n\n@RequiresGuest 注解要求当前 Subject 的角色是 guest 才可以访问被修饰的方法。\n\n\n# 授权流程\n\n\n\n 1. 应用程序或框架代码调用任何 Subject 的 hasRole*，checkRole*，isPermitted* 或 checkPermission* 方法，并传入所需的权限或角色。\n\n 2. Subject 实例，通常是 DelegatingSubject（或子类），通过调用 securityManager 几乎相同的各自 hasRole*，checkRole*，isPermitted* 或 checkPermission* 方法来委托 SecurityManager （实现了 org.apache.shiro.authz.Authorizer 接口）处理授权。\n\n 3. SecurityManager 通过调用授权者各自的 hasRole*，checkRole*，isPermitted* 或 checkPermission* 方法来中继/委托其内部的 org.apache.shiro.authz.Authorizer 实例。默认情况下，authorizer 实例是 ModularRealmAuthorizer 实例，该实例支持在任何授权操作期间协调一个或多个 Realm 实例。\n\n 4. 检查每个已配置的 Realm，以查看其是否实现相同的 Authorizer 接口。如果是这样，则将调用 Realm 各自的 hasRole*，checkRole*，isPermitted* 或 checkPermission* 方法。\n\n> 🔗 更多授权细节可以参考：Apache Shiro Authorization\n\n\n# 四、Shiro 会话管理\n\nShiro 提供了一套独特的会话管理方案：其 Session 可以使用 Java SE 程序，也可以使用于 Java Web 程序。\n\n在 Shiro 中，SessionManager 负责管理应用所有 Subject 的会话，如：创建、删除、失效、验证等。\n\n【示例】会话使用示例\n\nSubject currentUser = SecurityUtils.getSubject();\n\nSession session = currentUser.getSession();\nsession.setAttribute( "someKey", someValue);\n\n\n\n# 会话超时\n\n默认情况下，Shiro 中的会话有效期为 30 分钟，超时后，该会话将被 Shiro 视为无效。\n\n可以通过 globalSessionTimeout 方法设置 Shiro 会话超时时间。\n\n\n# 会话监听\n\nShiro 提供了 SessionListener 接口（或 SessionListenerAdapter 接口），用于监听重要的会话事件，并允许使用者在事件触发时做定制化处理。\n\n【示例】\n\npublic class ShiroSessionListener implements SessionListener {\n\n    private final Logger log = LoggerFactory.getLogger(this.getClass());\n\n    private final AtomicInteger sessionCount = new AtomicInteger(0);\n\n    @Override\n    public void onStart(Session session) {\n        sessionCount.incrementAndGet();\n    }\n\n    @Override\n    public void onStop(Session session) {\n        sessionCount.decrementAndGet();\n    }\n\n    @Override\n    public void onExpiration(Session session) {\n        sessionCount.decrementAndGet();\n    }\n}\n\n\n\n# 会话存储\n\n大多数情况下，应用需要保存会话信息，以便在稍后可以使用它。\n\nShiro 提供了 SessionManager 接口，负责将针对会话的 CRUD 操作委派给内部组件 SessionDAO，该组件反映了数据访问对象（DAO）设计模式。\n\n> 🔔 注意：由于会话通常具有时效性，所以一般会话天然适合存储于缓存中。存储于 Redis 中是一个不错的选择。\n\n\n# 五、Realm\n\nRealm 是 Shiro 访问程序安全相关数据（如：用户、角色、权限）的接口。\n\nRealm 是有开发者自己实现的，开发者可以通过实现 Realm 接口，接入应用的数据源，如：JDBC、文件、Nosql 等等。\n\n\n# 认证令牌\n\nShiro 支持身份验证令牌。在咨询 Realm 进行认证尝试之前，将调用其支持方法。 如果返回值为 true，则仅会调用其 getAuthenticationInfo(token) 方法。通常，Realm 会检查所提交令牌的类型（接口或类），以查看其是否可以处理它。\n\n令牌认证处理流程如下：\n\n 1. 检查用于标识 principal 的令牌（帐户标识信息）。\n 2. 根据 principal，在数据源中查找相应的帐户数据。\n 3. 确保令牌提供的凭证与数据存储中存储的凭证匹配。\n 4. 如果 credentials 匹配，则返回 AuthenticationInfo 实例。\n 5. 如果 credentials 不匹配，则抛出 AuthenticationException 异常。\n\n\n# 加密\n\n通过前文，可以了解：Shiro 需要通过一对 principal 和 credentials 来确认身份是否匹配（即认证）。\n\n一般来说，成熟软件是不允许存储账户、密码这些敏感数据时，使用明文存储。所以，通常要将密码加密后存储。\n\nShiro 提供了一些加密器，其思想就是用 MD5、SHA 这种数字签名算法，加 Salt，然后转为 Base64 字符串。为了避免被暴力破解，Shiro 使用多次加密的方式获得最终的 credentials 字符串。\n\n【示例】Shiro 加密密码示例\n\nimport org.apache.shiro.crypto.hash.Sha256Hash;\nimport org.apache.shiro.crypto.RandomNumberGenerator;\nimport org.apache.shiro.crypto.SecureRandomNumberGenerator;\n...\n\n//We\'ll use a Random Number Generator to generate salts.  This\n//is much more secure than using a username as a salt or not\n//having a salt at all.  Shiro makes this easy.\n//\n//Note that a normal app would reference an attribute rather\n//than create a new RNG every time:\nRandomNumberGenerator rng = new SecureRandomNumberGenerator();\nObject salt = rng.nextBytes();\n\n//Now hash the plain-text password with the random salt and multiple\n//iterations and then Base64-encode the value (requires less space than Hex):\nString hashedPasswordBase64 = new Sha256Hash(plainTextPassword, salt, 1024).toBase64();\n\nUser user = new User(username, hashedPasswordBase64);\n//save the salt with the new account.  The HashedCredentialsMatcher\n//will need it later when handling login attempts:\nuser.setPasswordSalt(salt);\nuserDAO.create(user);\n\n\n\n# 六、配置\n\n\n# 过滤链\n\n运行 Web 应用程序时，Shiro 将创建一些有用的默认 Filter 实例。\n\nFILTER NAME         CLASS\nanon                org.apache.shiro.web.filter.authc.AnonymousFilter\nauthc               org.apache.shiro.web.filter.authc.FormAuthenticationFilter\nauthcBasic          org.apache.shiro.web.filter.authc.BasicHttpAuthenticationFilter\nlogout              org.apache.shiro.web.filter.authc.LogoutFilter\nnoSessionCreation   org.apache.shiro.web.filter.session.NoSessionCreationFilter\nperms               org.apache.shiro.web.filter.authz.PermissionsAuthorizationFilter\nport                org.apache.shiro.web.filter.authz.PortFilter\nrest                org.apache.shiro.web.filter.authz.HttpMethodPermissionFilter\nroles               org.apache.shiro.web.filter.authz.RolesAuthorizationFilter\nssl                 org.apache.shiro.web.filter.authz.SslFilter\nuser                org.apache.shiro.web.filter.authc.UserFilter\n\n\n# RememberMe\n\nUsernamePasswordToken token = new UsernamePasswordToken(username, password);\ntoken.setRememberMe(true);\nSecurityUtils.getSubject().login(token);\n\n\n\n# 参考资料\n\n * Shiro 官方文档\n * 跟我学 Shiro\n * The New RBAC: Resource-Based Access Control',normalizedContent:'# shiro 快速入门\n\n> shiro 是一个安全框架，具有认证、授权、加密、会话管理功能。\n\n\n# 一、shiro 简介\n\n\n# shiro 特性\n\n\n\n核心功能：\n\n * authentication - 认证。验证用户是不是拥有相应的身份。\n * authorization - 授权。验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限。\n * session manager - 会话管理。即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中。会话可以是普通 javase 环境的，也可以是如 web 环境的。\n * cryptography - 加密。保护数据的安全性，如密码加密存储到数据库，而不是明文存储。\n\n辅助功能：\n\n * web support - web 支持。可以非常容易的集成到 web 环境；\n * caching - 缓存。比如用户登录后，其用户信息、拥有的角色 / 权限不必每次去查，这样可以提高效率；\n * concurrency - 并发。shiro 支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去；\n * testing - 测试。提供测试支持；\n * run as - 运行方式。允许一个用户假装为另一个用户（如果他们允许）的身份进行访问；\n * remember me - 记住我。即一次登录后，下次再访问免登录。\n\n> 🔔 注意：shiro 不会去维护用户、维护权限；这些需要我们自己去提供；然后通过相应的接口注入给 shiro 即可。\n\n\n# shiro 架构概述\n\n\n\n * subject - 主题。它代表当前用户，subject 可以是一个人，但也可以是第三方服务、守护进程帐户、时钟守护任务或者其它——当前和软件交互的任何事件。subject 是 shiro 的入口。\n   \n   * principals 是 subject 的“识别属性”。principals 可以是任何可以识别 subject 的东西，例如名字（姓氏），姓氏（姓氏或姓氏），用户名，社会保险号等。当然，principals 在应用程序中最好是惟一的。\n   * credentials 通常是仅由 subject 知道的秘密值，用作他们实际上“拥有”所主张身份的佐证 凭据的一些常见示例是密码，生物特征数据（例如指纹和视网膜扫描）以及 x.509 证书。\n\n * securitymanager - 安全管理。它是 shiro 的核心，所有与安全有关的操作（认证、授权、及会话、缓存的管理）都与 securitymanager 交互，且它管理着所有 subject。\n\n * realm - 域。用于访问安全相关数据，可以视为应用自身的数据源，需要开发者自己实现。shiro 会通过 realm 获取安全数据（如用户、角色、权限），就是说 securitymanager 要验证用户身份，那么它需要从 realm 获取相应的用户进行比较以确定用户身份是否合法；也需要从 realm 得到用户相应的角色/权限进行验证用户是否能进行操作；可以把 realm 看成 datasource，即安全数据源。\n\n\n# securitymanager\n\nsecuritymanager 是 shiro 框架核心中的核心，它相当于 shiro 的总指挥，负责调度所有行为，包括：认证、授权、获取安全数据（调用 realm）、会话管理等。\n\n\n\nsecuritymanager 聚合了以下组件：\n\n * authenticator - 认证器，负责认证。如果用户需要定制认证策略，可以实现此接口。\n * authorizer - 授权器，负责权限控制。用来决定主体是否有权限进行相应的操作；即控制着用户能访问应用中的哪些功能；\n * sessionmanager - 会话管理器。shiro 抽象了一个自己的 session 来管理主体与应用之间交互的数据。\n * sessiondao - 会话 dao 用于存储会话，需要用户自己实现。\n * cachemanager - 缓存控制器。用于管理如用户、角色、权限等信息的缓存。\n * cryptography - 密码器。用于对数据加密、解密。\n\n\n# 二、shiro 认证\n\n\n# 认证 subject\n\n验证 subject 的过程可以有效地分为三个不同的步骤：\n\n（1）收集 subject 提交的 principals 和 credentials\n\n//example using most common scenario of username/password pair:\nusernamepasswordtoken token = new usernamepasswordtoken(username, password);\n\n//"remember me" built-in:\ntoken.setrememberme(true);\n\n\n（2）提交 principals 和 credentials 以进行身份验证。\n\nsubject currentuser = securityutils.getsubject();\n\ncurrentuser.login(token);\n\n\n（3）如果提交成功，则允许访问，否则重试身份验证或阻止访问。\n\ntry {\n    currentuser.login(token);\n} catch ( unknownaccountexception uae ) { ...\n} catch ( incorrectcredentialsexception ice ) { ...\n} catch ( lockedaccountexception lae ) { ...\n} catch ( excessiveattemptsexception eae ) { ...\n} ... catch your own ...\n} catch ( authenticationexception ae ) {\n    //unexpected error?\n}\n\n\n\n# remembered 和 authenticated\n\n * remembered - 记住我。被记住的 subject 不是匿名的，并且具有已知的身份（即 subject.getprincipals() 是非空的）。 但是，在先前的会话期间，通过先前的身份验证会记住此身份。 如果 subject.isremembered() 返回 true，则认为该主题已被记住。\n * authenticated - 已认证。已认证的 subject 是在当前会话期间已成功认证的 subject。 如果 subject.isauthenticated() 返回 true，则认为该 subject 已通过身份验证。\n\n\n# 登出\n\n当 subject 与应用程序完成交互后，可以调用 subject.logout() 登出，即放弃所有标识信息。\n\ncurrentuser.logout();\n\n\n\n# 认证流程\n\n\n\n 1. 应用程序代码调用 subject.login 方法，传入构造的 authenticationtoken 实例，该实例代表最终用户的 principals 和 credentials。\n\n 2. subject 实例（通常是 delegatingsubject（或子类））通过调用 securitymanager.login（token）委托应用程序的 securitymanager，在此处开始实际的身份验证工作。\n\n 3. securitymanager 接收令牌，并通过调用 authenticator.authenticate（token）来简单地委派给其内部 authenticator 实例。这几乎总是一个 modularrealmauthenticator 实例，它支持在身份验证期间协调一个或多个 realm 实例。\n\n 4. 如果为该应用程序配置了多个 realm，则 modularrealmauthenticator 实例将利用其配置的 authenticationstrategy 发起多域验证尝试。在调用领域进行身份验证之前，期间和之后，将调用 authenticationstrategy 以使其对每个领域的结果做出反应。\n\n 5. 请咨询每个已配置的 realm，以查看其是否支持提交的 authenticationtoken。 如果是这样，将使用提交的令牌调用支持 realm 的 getauthenticationinfo 方法。 getauthenticationinfo 方法有效地表示对该特定 realm 的单个身份验证尝试。\n\n\n# 认证策略\n\n当为一个应用程序配置两个或多个领域时，modularrealmauthenticator 依赖于内部 authenticationstrategy 组件来确定认证尝试成功或失败的条件。\n\n例如，如果只有一个 realm 成功地对 authenticationtoken 进行身份验证，而所有其他 realm 都失败了，那么该身份验证尝试是否被视为成功？还是必须所有领域都成功进行身份验证才能将整体尝试视为成功？或者，如果某个领域成功通过身份验证，是否有必要进一步咨询其他领域？ authenticationstrategy 根据应用程序的需求做出适当的决定。\n\nauthenticationstrategy 是无状态组件，在尝试进行身份验证时会被查询 4 次（这 4 种交互所需的任何必要状态都将作为方法参数给出）：\n\n * 在任何领域被调用之前\n * 在调用单个 realm 的 getauthenticationinfo 方法之前\n * 在调用单个 realm 的 getauthenticationinfo 方法之后\n * 在所有领域都被调用之后\n\nauthenticationstrategy 还负责汇总每个成功 realm 的结果，并将它们“捆绑”成单个 authenticationinfo 表示形式。最终的聚合 authenticationinfo 实例是 authenticator 实例返回的结果，也是 shiro 用来表示主体的最终身份（也称为委托人）的东西。\n\nauthenticationstrategy         描述\natleastonesuccessfulstrategy   只要有一个 realm 成功认证，则整个尝试都被视为成功。\nfirstsuccessfulstrategy        仅使用从第一个成功通过身份验证的 realm 返回的信息，所有其他 realm 将被忽略。\nallsuccessfulstrategy          只有所有 realm 成功认证，则整个尝试才被视为成功。\n\n> 🔗 更多认证细节可以参考：apache shiro authentication\n\n\n# 三、shiro 授权\n\n授权，也称为访问控制，是管理对资源的访问的过程。 换句话说，控制谁有权访问应用程序中的内容。\n\n\n# 授权元素\n\n授权有三个核心要素：权限、角色和用户。\n\n# 权限\n\n权限示例：\n\n * 打开一个文件\n * 查看 /user/list web 页面\n * 查询记录\n * 删除一条记录\n * ...\n\n大多数资源都支持一般的 crud 操作。除此以外，对于一些特定的资源，任何有意义的行为都是可以的。基本的设计思路是：权限控制，至少是基于资源和行为。\n\n# 角色\n\n角色是一个命名实体，通常代表一组行为或职责。这些行为会转化为：谁可以在应用程序中执行哪些行为？谁不可以在程序中执行哪些行为？\n\n角色通常是分配给用户帐户的，因此通过关联，用户可以获得自身角色所赋予的权限。\n\n# 用户\n\n用户本质上是应用程序的“用户”。\n\n用户（即 shiro 的 subject）通过与角色或直接权限的关联在应用程序中执行某些行为。\n\n\n# 基于角色的授权\n\n如果授权是基于角色赋予权限的数据模型，编程模式如下：\n\n【示例一】\n\nsubject currentuser = securityutils.getsubject();\n\nif (currentuser.hasrole("administrator")) {\n    //show the admin button\n} else {\n    //don\'t show the button?  grey it out?\n}\n\n\n【示例二】\n\nsubject currentuser = securityutils.getsubject();\n\n// 检查当前 subject 是否有某种权限\n// 如果有，直接跳过；如果没有，shiro 会抛出 authorizationexception\ncurrentuser.checkrole("bankteller");\nopenbankaccount();\n\n\n> 提示：方式二相比方式一，代码更简洁\n\n\n# 基于权限的授权\n\n更好的授权策略通常是基于权限的授权。基于权限的授权，由于它和应用程序的原始功能（针对具体资源上的行为）紧密相关，所以基于权限的授权源代码会在功能更改时同步更改（而不是在安全策略发生更改时）。 这意味着与类似的基于角色的授权代码相比，修改代码的影响面要小得多。\n\n【示例】基于对象的权限检查\n\npermission printpermission = new printerpermission("laserjet4400n", "print");\n\nsubject currentuser = securityutils.getsubject();\n\nif (currentuser.ispermitted(printpermission)) {\n    //show the print button\n} else {\n    //don\'t show the button?  grey it out?\n}\n\n\n在对象中存储权限控制信息，但这种方式较为繁重\n\n【示例】字符串定义权限控制信息\n\nsubject currentuser = securityutils.getsubject();\n\nif (currentuser.ispermitted("printer:print:laserjet4400n")) {\n    //show the print button\n} else {\n    //don\'t show the button?  grey it out?\n}\n\n\n使用 : 分隔，表示资源类型、行为、资源 id，shiro 提供了默认实现： org.apache.shiro.authz.permission.wildcardpermission。\n\n这种权限控制方式的好处在于：轻量、灵活。\n\n\n# 基于注解的授权\n\nshiro 提供了一些用于授权的注解，来进一步简化授权代码。\n\n# @requiresauthentication\n\n@requiresauthentication 注解要求当前 subject 必须是已认证用户才可以访问被修饰的方法。\n\n【示例】\n\n@requiresauthentication\npublic void updateaccount(account useraccount) {\n    //this method will only be invoked by a\n    //subject that is guaranteed authenticated\n    ...\n}\n\n\n# @requiresguest\n\n@requiresguest 注解要求当前 subject 的角色是 guest 才可以访问被修饰的方法。\n\n\n# 授权流程\n\n\n\n 1. 应用程序或框架代码调用任何 subject 的 hasrole*，checkrole*，ispermitted* 或 checkpermission* 方法，并传入所需的权限或角色。\n\n 2. subject 实例，通常是 delegatingsubject（或子类），通过调用 securitymanager 几乎相同的各自 hasrole*，checkrole*，ispermitted* 或 checkpermission* 方法来委托 securitymanager （实现了 org.apache.shiro.authz.authorizer 接口）处理授权。\n\n 3. securitymanager 通过调用授权者各自的 hasrole*，checkrole*，ispermitted* 或 checkpermission* 方法来中继/委托其内部的 org.apache.shiro.authz.authorizer 实例。默认情况下，authorizer 实例是 modularrealmauthorizer 实例，该实例支持在任何授权操作期间协调一个或多个 realm 实例。\n\n 4. 检查每个已配置的 realm，以查看其是否实现相同的 authorizer 接口。如果是这样，则将调用 realm 各自的 hasrole*，checkrole*，ispermitted* 或 checkpermission* 方法。\n\n> 🔗 更多授权细节可以参考：apache shiro authorization\n\n\n# 四、shiro 会话管理\n\nshiro 提供了一套独特的会话管理方案：其 session 可以使用 java se 程序，也可以使用于 java web 程序。\n\n在 shiro 中，sessionmanager 负责管理应用所有 subject 的会话，如：创建、删除、失效、验证等。\n\n【示例】会话使用示例\n\nsubject currentuser = securityutils.getsubject();\n\nsession session = currentuser.getsession();\nsession.setattribute( "somekey", somevalue);\n\n\n\n# 会话超时\n\n默认情况下，shiro 中的会话有效期为 30 分钟，超时后，该会话将被 shiro 视为无效。\n\n可以通过 globalsessiontimeout 方法设置 shiro 会话超时时间。\n\n\n# 会话监听\n\nshiro 提供了 sessionlistener 接口（或 sessionlisteneradapter 接口），用于监听重要的会话事件，并允许使用者在事件触发时做定制化处理。\n\n【示例】\n\npublic class shirosessionlistener implements sessionlistener {\n\n    private final logger log = loggerfactory.getlogger(this.getclass());\n\n    private final atomicinteger sessioncount = new atomicinteger(0);\n\n    @override\n    public void onstart(session session) {\n        sessioncount.incrementandget();\n    }\n\n    @override\n    public void onstop(session session) {\n        sessioncount.decrementandget();\n    }\n\n    @override\n    public void onexpiration(session session) {\n        sessioncount.decrementandget();\n    }\n}\n\n\n\n# 会话存储\n\n大多数情况下，应用需要保存会话信息，以便在稍后可以使用它。\n\nshiro 提供了 sessionmanager 接口，负责将针对会话的 crud 操作委派给内部组件 sessiondao，该组件反映了数据访问对象（dao）设计模式。\n\n> 🔔 注意：由于会话通常具有时效性，所以一般会话天然适合存储于缓存中。存储于 redis 中是一个不错的选择。\n\n\n# 五、realm\n\nrealm 是 shiro 访问程序安全相关数据（如：用户、角色、权限）的接口。\n\nrealm 是有开发者自己实现的，开发者可以通过实现 realm 接口，接入应用的数据源，如：jdbc、文件、nosql 等等。\n\n\n# 认证令牌\n\nshiro 支持身份验证令牌。在咨询 realm 进行认证尝试之前，将调用其支持方法。 如果返回值为 true，则仅会调用其 getauthenticationinfo(token) 方法。通常，realm 会检查所提交令牌的类型（接口或类），以查看其是否可以处理它。\n\n令牌认证处理流程如下：\n\n 1. 检查用于标识 principal 的令牌（帐户标识信息）。\n 2. 根据 principal，在数据源中查找相应的帐户数据。\n 3. 确保令牌提供的凭证与数据存储中存储的凭证匹配。\n 4. 如果 credentials 匹配，则返回 authenticationinfo 实例。\n 5. 如果 credentials 不匹配，则抛出 authenticationexception 异常。\n\n\n# 加密\n\n通过前文，可以了解：shiro 需要通过一对 principal 和 credentials 来确认身份是否匹配（即认证）。\n\n一般来说，成熟软件是不允许存储账户、密码这些敏感数据时，使用明文存储。所以，通常要将密码加密后存储。\n\nshiro 提供了一些加密器，其思想就是用 md5、sha 这种数字签名算法，加 salt，然后转为 base64 字符串。为了避免被暴力破解，shiro 使用多次加密的方式获得最终的 credentials 字符串。\n\n【示例】shiro 加密密码示例\n\nimport org.apache.shiro.crypto.hash.sha256hash;\nimport org.apache.shiro.crypto.randomnumbergenerator;\nimport org.apache.shiro.crypto.securerandomnumbergenerator;\n...\n\n//we\'ll use a random number generator to generate salts.  this\n//is much more secure than using a username as a salt or not\n//having a salt at all.  shiro makes this easy.\n//\n//note that a normal app would reference an attribute rather\n//than create a new rng every time:\nrandomnumbergenerator rng = new securerandomnumbergenerator();\nobject salt = rng.nextbytes();\n\n//now hash the plain-text password with the random salt and multiple\n//iterations and then base64-encode the value (requires less space than hex):\nstring hashedpasswordbase64 = new sha256hash(plaintextpassword, salt, 1024).tobase64();\n\nuser user = new user(username, hashedpasswordbase64);\n//save the salt with the new account.  the hashedcredentialsmatcher\n//will need it later when handling login attempts:\nuser.setpasswordsalt(salt);\nuserdao.create(user);\n\n\n\n# 六、配置\n\n\n# 过滤链\n\n运行 web 应用程序时，shiro 将创建一些有用的默认 filter 实例。\n\nfilter name         class\nanon                org.apache.shiro.web.filter.authc.anonymousfilter\nauthc               org.apache.shiro.web.filter.authc.formauthenticationfilter\nauthcbasic          org.apache.shiro.web.filter.authc.basichttpauthenticationfilter\nlogout              org.apache.shiro.web.filter.authc.logoutfilter\nnosessioncreation   org.apache.shiro.web.filter.session.nosessioncreationfilter\nperms               org.apache.shiro.web.filter.authz.permissionsauthorizationfilter\nport                org.apache.shiro.web.filter.authz.portfilter\nrest                org.apache.shiro.web.filter.authz.httpmethodpermissionfilter\nroles               org.apache.shiro.web.filter.authz.rolesauthorizationfilter\nssl                 org.apache.shiro.web.filter.authz.sslfilter\nuser                org.apache.shiro.web.filter.authc.userfilter\n\n\n# rememberme\n\nusernamepasswordtoken token = new usernamepasswordtoken(username, password);\ntoken.setrememberme(true);\nsecurityutils.getsubject().login(token);\n\n\n\n# 参考资料\n\n * shiro 官方文档\n * 跟我学 shiro\n * the new rbac: resource-based access control',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Spring Security 快速入门",frontmatter:{title:"Spring Security 快速入门",categories:["编程","Java","框架","安全"],tags:["Java","框架","安全","SpringSecurity"],abbrlink:"a750524a",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/a6cc5f/"},regularPath:"/13.%E6%A1%86%E6%9E%B6/12.%E5%AE%89%E5%85%A8/02.SpringSecurity.html",relativePath:"13.框架/12.安全/02.SpringSecurity.md",key:"v-1fe197ae",path:"/pages/a6cc5f/",headers:[{level:2,title:"快速开始",slug:"快速开始",normalizedTitle:"快速开始",charIndex:27},{level:2,title:"核心 API",slug:"核心-api",normalizedTitle:"核心 api",charIndex:67},{level:2,title:"设计原理",slug:"设计原理",normalizedTitle:"设计原理",charIndex:78},{level:2,title:"认证",slug:"认证",normalizedTitle:"认证",charIndex:1374},{level:3,title:"数据模型",slug:"数据模型",normalizedTitle:"数据模型",charIndex:1381},{level:3,title:"认证基本流程",slug:"认证基本流程",normalizedTitle:"认证基本流程",charIndex:1968},{level:3,title:"用户名/密码认证",slug:"用户名-密码认证",normalizedTitle:"用户名/密码认证",charIndex:2894},{level:4,title:"表单认证",slug:"表单认证",normalizedTitle:"表单认证",charIndex:2994},{level:4,title:"基本认证",slug:"基本认证",normalizedTitle:"基本认证",charIndex:2927},{level:4,title:"内存认证",slug:"内存认证",normalizedTitle:"内存认证",charIndex:3231},{level:4,title:"JDBC 认证",slug:"jdbc-认证",normalizedTitle:"jdbc 认证",charIndex:3823},{level:4,title:"UserDetailsService",slug:"userdetailsservice",normalizedTitle:"userdetailsservice",charIndex:2964},{level:4,title:"PasswordEncoder",slug:"passwordencoder",normalizedTitle:"passwordencoder",charIndex:3480},{level:3,title:"Remember-Me",slug:"remember-me",normalizedTitle:"remember-me",charIndex:5442},{level:2,title:"Spring Boot 集成",slug:"spring-boot-集成",normalizedTitle:"spring boot 集成",charIndex:5458},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:5759}],headersStr:"快速开始 核心 API 设计原理 认证 数据模型 认证基本流程 用户名/密码认证 表单认证 基本认证 内存认证 JDBC 认证 UserDetailsService PasswordEncoder Remember-Me Spring Boot 集成 参考资料",content:'# Spring Security 快速入门\n\n\n# 快速开始\n\n参考：Securing a Web Application\n\n\n# 核心 API\n\n\n# 设计原理\n\nSpring Security 对于 Servlet 的支持基于过滤链（FilterChain）实现。\n\nSpring 提供了一个名为 DelegatingFilterProxy 的 Filter 实现，该实现允许在 Servlet 容器的生命周期和 Spring 的 ApplicationContext 之间进行桥接。 Servlet 容器允许使用其自己的标准注册 Filters，但它不了解 Spring 定义的 Bean。 DelegatingFilterProxy 可以通过标准的 Servlet 容器机制进行注册，但是可以将所有工作委托给实现 Filter 的 Spring Bean。\n\npublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) {\n    // Lazily get Filter that was registered as a Spring Bean\n    // For the example in DelegatingFilterProxy delegate is an instance of Bean Filter0\n    Filter delegate = getFilterBean(someBeanName);\n    // delegate work to the Spring Bean\n    delegate.doFilter(request, response);\n}\n\n\nFilterChainProxy 使用 SecurityFilterChain 确定应对此请求调用哪些 Spring Security 过滤器。\n\nSecurityFilterChain 中的安全过滤器通常是 Bean，但它们是使用 FilterChainProxy 而不是 DelegatingFilterProxy 注册的。\n\n实际上，FilterChainProxy 可用于确定应使用哪个 SecurityFilterChain。如果您的应用程序可以为不同的模块提供完全独立的配置。\n\n\n\nExceptionTranslationFilter 可以将 AccessDeniedException 和 AuthenticationException 转换为 HTTP 响应。\n\n\n\n核心源码：\n\ntry {\n    filterChain.doFilter(request, response);\n} catch (AccessDeniedException | AuthenticationException e) {\n    if (!authenticated || e instanceof AuthenticationException) {\n        startAuthentication();\n    } else {\n        accessDenied();\n    }\n}\n\n\n\n# 认证\n\n\n# 数据模型\n\nSpring Security 框架中的认证数据模型如下：\n\n\n\n * Authentication - 认证信息实体。\n   * principal - 用户标识。如：用户名、账户名等。通常是 UserDetails 的实例（后面详细讲解）。\n   * credentials - 认证凭证。如：密码等。\n   * authorities - 授权信息。如：用户的角色、权限等信息。\n * SecurityContext - 安全上下文。包含一个 Authentication 对象。\n * SecurityContextHolder - 安全上下文持有者。用于存储认证信息。\n\n【示例】注册认证信息\n\nSecurityContext context = SecurityContextHolder.createEmptyContext();\nAuthentication authentication =\n    new TestingAuthenticationToken("username", "password", "ROLE_USER");\ncontext.setAuthentication(authentication);\nSecurityContextHolder.setContext(context);\n\n\n【示例】访问认证信息\n\n\n# 认证基本流程\n\nAbstractAuthenticationProcessingFilter 用作验证用户凭据的基本过滤器。 在对凭证进行身份验证之前，Spring Security 通常使用 AuthenticationEntryPoint 请求凭证。\n\n\n\n * （1）当用户提交其凭据时，AbstractAuthenticationProcessingFilter 从要验证的 HttpServletRequest 创建一个 Authentication。创建的身份验证类型取决于 AbstractAuthenticationProcessingFilter 的子类。例如，UsernamePasswordAuthenticationFilter 根据在 HttpServletRequest 中提交的用户名和密码来创建 UsernamePasswordAuthenticationToken。\n * （2）接下来，将身份验证传递到 AuthenticationManager 进行身份验证。\n * （3）如果身份验证失败，则认证失败\n   * 清除 SecurityContextHolder。\n   * 调用 RememberMeServices.loginFail。如果没有配置 remember me，则为空。\n   * 调用 AuthenticationFailureHandler。\n * （4）如果身份验证成功，则认证成功。\n   * 如果是新的登录，则通知 SessionAuthenticationStrategy。\n   * 身份验证是在 SecurityContextHolder 上设置的。之后，SecurityContextPersistenceFilter 将 SecurityContext 保存到 HttpSession 中。\n   * 调用 RememberMeServices.loginSuccess。如果没有配置 remember me，则为空。\n   * ApplicationEventPublisher 发布一个 InteractiveAuthenticationSuccessEvent。\n\n\n# 用户名/密码认证\n\n读取用户名和密码的方式：\n\n * 表单\n * 基本认证\n * 数字认证\n\n存储机制\n\n * 内存\n * JDBC\n * UserDetailsService\n * LDAP\n\n# 表单认证\n\nspring security 支持通过从 html 表单获取登录时提交的用户名、密码。\n\n\n\n一旦，登录信息被提交，UsernamePasswordAuthenticationFilter 就会验证用户名和密码。\n\n\n\n# 基本认证\n\nprotected void configure(HttpSecurity http) {\n    http\n        // ...\n        .httpBasic(withDefaults());\n}\n\n\n# 内存认证\n\nInMemoryUserDetailsManager 实现了 UserDetailsService ，提供了基本的用户名、密码认证，其认证数据存储在内存中。\n\n@Bean\npublic UserDetailsService users() {\n    // The builder will ensure the passwords are encoded before saving in memory\n    UserBuilder users = User.withDefaultPasswordEncoder();\n    UserDetails user = users\n        .username("user")\n        .password("password")\n        .roles("USER")\n        .build();\n    UserDetails user = users\n        .username("admin")\n        .password("password")\n        .roles("USER", "ADMIN")\n        .build();\n    return new InMemoryUserDetailsManager(user, admin);\n}\n\n\n# JDBC 认证\n\nJdbcUserDetailsManager 实现了 UserDetailsService ，提供了基本的用户名、密码认证，其认证数据存储在关系型数据库中，通过 JDBC 方式访问。\n\n@Bean\nUserDetailsManager users(DataSource dataSource) {\n    UserDetails user = User.builder()\n        .username("user")\n        .password("{bcrypt}$2a$10$GRLdNijSQMUvl/au9ofL.eDwmoohzzS7.rmNSJZ.0FxO/BTk76klW")\n        .roles("USER")\n        .build();\n    UserDetails admin = User.builder()\n        .username("admin")\n        .password("{bcrypt}$2a$10$GRLdNijSQMUvl/au9ofL.eDwmoohzzS7.rmNSJZ.0FxO/BTk76klW")\n        .roles("USER", "ADMIN")\n        .build();\n    JdbcUserDetailsManager users = new JdbcUserDetailsManager(dataSource);\n    users.createUser()\n}\n\n\n基本的 scheam：\n\ncreate table users(\n    username varchar_ignorecase(50) not null primary key,\n    password varchar_ignorecase(50) not null,\n    enabled boolean not null\n);\n\ncreate table authorities (\n    username varchar_ignorecase(50) not null,\n    authority varchar_ignorecase(50) not null,\n    constraint fk_authorities_users foreign key(username) references users(username)\n);\ncreate unique index ix_auth_username on authorities (username,authority);\n\n\n# UserDetailsService\n\nUserDetails 由 UserDetailsService 返回。 DaoAuthenticationProvider 验证 UserDetails，然后返回身份验证，该身份验证的主体是已配置的 UserDetailsService 返回的 UserDetails。\n\nDaoAuthenticationProvider 使用 UserDetailsService 检索用户名，密码和其他用于使用用户名和密码进行身份验证的属性。 Spring Security 提供 UserDetailsService 的内存中和 JDBC 实现。\n\n您可以通过将自定义 UserDetailsService 公开为 bean 来定义自定义身份验证。\n\n# PasswordEncoder\n\nSpring Security 的 servlet 支持通过与 PasswordEncoder 集成来安全地存储密码。 可以通过公开一个 PasswordEncoder Bean 来定制 Spring Security 使用的 PasswordEncoder 实现。\n\n\n\n\n# Remember-Me\n\n\n# Spring Boot 集成\n\n@EnableWebSecurity 和 @Configuration 注解一起使用, 注解 WebSecurityConfigurer 类型的类。\n\n或者利用@EnableWebSecurity注解继承 WebSecurityConfigurerAdapter 的类，这样就构成了 Spring Security 的配置。\n\n * configure(WebSecurity)：通过重载该方法，可配置 Spring Security 的 Filter 链。\n * configure(HttpSecurity)：通过重载该方法，可配置如何通过拦截器保护请求。\n\n\n# 参考资料\n\n * Spring Security Architecture\n * Securing a Web Application',normalizedContent:'# spring security 快速入门\n\n\n# 快速开始\n\n参考：securing a web application\n\n\n# 核心 api\n\n\n# 设计原理\n\nspring security 对于 servlet 的支持基于过滤链（filterchain）实现。\n\nspring 提供了一个名为 delegatingfilterproxy 的 filter 实现，该实现允许在 servlet 容器的生命周期和 spring 的 applicationcontext 之间进行桥接。 servlet 容器允许使用其自己的标准注册 filters，但它不了解 spring 定义的 bean。 delegatingfilterproxy 可以通过标准的 servlet 容器机制进行注册，但是可以将所有工作委托给实现 filter 的 spring bean。\n\npublic void dofilter(servletrequest request, servletresponse response, filterchain chain) {\n    // lazily get filter that was registered as a spring bean\n    // for the example in delegatingfilterproxy delegate is an instance of bean filter0\n    filter delegate = getfilterbean(somebeanname);\n    // delegate work to the spring bean\n    delegate.dofilter(request, response);\n}\n\n\nfilterchainproxy 使用 securityfilterchain 确定应对此请求调用哪些 spring security 过滤器。\n\nsecurityfilterchain 中的安全过滤器通常是 bean，但它们是使用 filterchainproxy 而不是 delegatingfilterproxy 注册的。\n\n实际上，filterchainproxy 可用于确定应使用哪个 securityfilterchain。如果您的应用程序可以为不同的模块提供完全独立的配置。\n\n\n\nexceptiontranslationfilter 可以将 accessdeniedexception 和 authenticationexception 转换为 http 响应。\n\n\n\n核心源码：\n\ntry {\n    filterchain.dofilter(request, response);\n} catch (accessdeniedexception | authenticationexception e) {\n    if (!authenticated || e instanceof authenticationexception) {\n        startauthentication();\n    } else {\n        accessdenied();\n    }\n}\n\n\n\n# 认证\n\n\n# 数据模型\n\nspring security 框架中的认证数据模型如下：\n\n\n\n * authentication - 认证信息实体。\n   * principal - 用户标识。如：用户名、账户名等。通常是 userdetails 的实例（后面详细讲解）。\n   * credentials - 认证凭证。如：密码等。\n   * authorities - 授权信息。如：用户的角色、权限等信息。\n * securitycontext - 安全上下文。包含一个 authentication 对象。\n * securitycontextholder - 安全上下文持有者。用于存储认证信息。\n\n【示例】注册认证信息\n\nsecuritycontext context = securitycontextholder.createemptycontext();\nauthentication authentication =\n    new testingauthenticationtoken("username", "password", "role_user");\ncontext.setauthentication(authentication);\nsecuritycontextholder.setcontext(context);\n\n\n【示例】访问认证信息\n\n\n# 认证基本流程\n\nabstractauthenticationprocessingfilter 用作验证用户凭据的基本过滤器。 在对凭证进行身份验证之前，spring security 通常使用 authenticationentrypoint 请求凭证。\n\n\n\n * （1）当用户提交其凭据时，abstractauthenticationprocessingfilter 从要验证的 httpservletrequest 创建一个 authentication。创建的身份验证类型取决于 abstractauthenticationprocessingfilter 的子类。例如，usernamepasswordauthenticationfilter 根据在 httpservletrequest 中提交的用户名和密码来创建 usernamepasswordauthenticationtoken。\n * （2）接下来，将身份验证传递到 authenticationmanager 进行身份验证。\n * （3）如果身份验证失败，则认证失败\n   * 清除 securitycontextholder。\n   * 调用 remembermeservices.loginfail。如果没有配置 remember me，则为空。\n   * 调用 authenticationfailurehandler。\n * （4）如果身份验证成功，则认证成功。\n   * 如果是新的登录，则通知 sessionauthenticationstrategy。\n   * 身份验证是在 securitycontextholder 上设置的。之后，securitycontextpersistencefilter 将 securitycontext 保存到 httpsession 中。\n   * 调用 remembermeservices.loginsuccess。如果没有配置 remember me，则为空。\n   * applicationeventpublisher 发布一个 interactiveauthenticationsuccessevent。\n\n\n# 用户名/密码认证\n\n读取用户名和密码的方式：\n\n * 表单\n * 基本认证\n * 数字认证\n\n存储机制\n\n * 内存\n * jdbc\n * userdetailsservice\n * ldap\n\n# 表单认证\n\nspring security 支持通过从 html 表单获取登录时提交的用户名、密码。\n\n\n\n一旦，登录信息被提交，usernamepasswordauthenticationfilter 就会验证用户名和密码。\n\n\n\n# 基本认证\n\nprotected void configure(httpsecurity http) {\n    http\n        // ...\n        .httpbasic(withdefaults());\n}\n\n\n# 内存认证\n\ninmemoryuserdetailsmanager 实现了 userdetailsservice ，提供了基本的用户名、密码认证，其认证数据存储在内存中。\n\n@bean\npublic userdetailsservice users() {\n    // the builder will ensure the passwords are encoded before saving in memory\n    userbuilder users = user.withdefaultpasswordencoder();\n    userdetails user = users\n        .username("user")\n        .password("password")\n        .roles("user")\n        .build();\n    userdetails user = users\n        .username("admin")\n        .password("password")\n        .roles("user", "admin")\n        .build();\n    return new inmemoryuserdetailsmanager(user, admin);\n}\n\n\n# jdbc 认证\n\njdbcuserdetailsmanager 实现了 userdetailsservice ，提供了基本的用户名、密码认证，其认证数据存储在关系型数据库中，通过 jdbc 方式访问。\n\n@bean\nuserdetailsmanager users(datasource datasource) {\n    userdetails user = user.builder()\n        .username("user")\n        .password("{bcrypt}$2a$10$grldnijsqmuvl/au9ofl.edwmoohzzs7.rmnsjz.0fxo/btk76klw")\n        .roles("user")\n        .build();\n    userdetails admin = user.builder()\n        .username("admin")\n        .password("{bcrypt}$2a$10$grldnijsqmuvl/au9ofl.edwmoohzzs7.rmnsjz.0fxo/btk76klw")\n        .roles("user", "admin")\n        .build();\n    jdbcuserdetailsmanager users = new jdbcuserdetailsmanager(datasource);\n    users.createuser()\n}\n\n\n基本的 scheam：\n\ncreate table users(\n    username varchar_ignorecase(50) not null primary key,\n    password varchar_ignorecase(50) not null,\n    enabled boolean not null\n);\n\ncreate table authorities (\n    username varchar_ignorecase(50) not null,\n    authority varchar_ignorecase(50) not null,\n    constraint fk_authorities_users foreign key(username) references users(username)\n);\ncreate unique index ix_auth_username on authorities (username,authority);\n\n\n# userdetailsservice\n\nuserdetails 由 userdetailsservice 返回。 daoauthenticationprovider 验证 userdetails，然后返回身份验证，该身份验证的主体是已配置的 userdetailsservice 返回的 userdetails。\n\ndaoauthenticationprovider 使用 userdetailsservice 检索用户名，密码和其他用于使用用户名和密码进行身份验证的属性。 spring security 提供 userdetailsservice 的内存中和 jdbc 实现。\n\n您可以通过将自定义 userdetailsservice 公开为 bean 来定义自定义身份验证。\n\n# passwordencoder\n\nspring security 的 servlet 支持通过与 passwordencoder 集成来安全地存储密码。 可以通过公开一个 passwordencoder bean 来定制 spring security 使用的 passwordencoder 实现。\n\n\n\n\n# remember-me\n\n\n# spring boot 集成\n\n@enablewebsecurity 和 @configuration 注解一起使用, 注解 websecurityconfigurer 类型的类。\n\n或者利用@enablewebsecurity注解继承 websecurityconfigureradapter 的类，这样就构成了 spring security 的配置。\n\n * configure(websecurity)：通过重载该方法，可配置 spring security 的 filter 链。\n * configure(httpsecurity)：通过重载该方法，可配置如何通过拦截器保护请求。\n\n\n# 参考资料\n\n * spring security architecture\n * securing a web application',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Netty 快速入门",frontmatter:{title:"Netty 快速入门",categories:["编程","Java","框架","IO"],tags:["Java","IO","Netty"],abbrlink:"ddaa8ce6",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/520c52/"},regularPath:"/13.%E6%A1%86%E6%9E%B6/13.IO/01.Netty.html",relativePath:"13.框架/13.IO/01.Netty.md",key:"v-31a4aa1d",path:"/pages/520c52/",headers:[{level:2,title:"Netty 简介",slug:"netty-简介",normalizedTitle:"netty 简介",charIndex:17},{level:3,title:"Netty 的特性",slug:"netty-的特性",normalizedTitle:"netty 的特性",charIndex:83},{level:2,title:"核心组件",slug:"核心组件",normalizedTitle:"核心组件",charIndex:290},{level:2,title:"高性能",slug:"高性能",normalizedTitle:"高性能",charIndex:921},{level:2,title:"零拷贝",slug:"零拷贝",normalizedTitle:"零拷贝",charIndex:213},{level:3,title:"传统意义的拷贝",slug:"传统意义的拷贝",normalizedTitle:"传统意义的拷贝",charIndex:1132},{level:3,title:"零拷贝的概念",slug:"零拷贝的概念",normalizedTitle:"零拷贝的概念",charIndex:1353},{level:3,title:"Netty 中的零拷贝",slug:"netty-中的零拷贝",normalizedTitle:"netty 中的零拷贝",charIndex:1572},{level:2,title:"Netty 流程",slug:"netty-流程",normalizedTitle:"netty 流程",charIndex:2117},{level:2,title:"应用",slug:"应用",normalizedTitle:"应用",charIndex:2130},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:3672}],headersStr:"Netty 简介 Netty 的特性 核心组件 高性能 零拷贝 传统意义的拷贝 零拷贝的概念 Netty 中的零拷贝 Netty 流程 应用 参考资料",content:'# Netty 快速入门\n\n\n# Netty 简介\n\n> Netty 是一款基于 NIO（Nonblocking I/O，非阻塞 IO）开发的网络通信框架。\n\n\n# Netty 的特性\n\n * 高并发：Netty 是一款基于 NIO（Nonblocking IO，非阻塞 IO）开发的网络通信框架，对比于 BIO（Blocking I/O，阻塞 IO），他的并发性能得到了很大提高。\n * 传输快：Netty 的传输依赖于内存零拷贝特性，尽量减少不必要的内存拷贝，实现了更高效率的传输。\n * 封装好：Netty 封装了 NIO 操作的很多细节，提供了易于使用调用接口。\n\n\n# 核心组件\n\n * Channel：Netty 网络操作抽象类，它除了包括基本的 I/O 操作，如 bind、connect、read、write 等。\n * EventLoop：主要是配合 Channel 处理 I/O 操作，用来处理连接的生命周期中所发生的事情。\n * ChannelFuture：Netty 框架中所有的 I/O 操作都为异步的，因此我们需要 ChannelFuture 的 addListener()注册一个 ChannelFutureListener 监听事件，当操作执行成功或者失败时，监听就会自动触发返回结果。\n * ChannelHandler：充当了所有处理入站和出站数据的逻辑容器。ChannelHandler 主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。\n * ChannelPipeline：为 ChannelHandler 链提供了容器，当 channel 创建时，就会被自动分配到它专属的 ChannelPipeline，这个关联是永久性的。\n\nNetty 有两种发送消息的方式：\n\n * 直接写入 Channel 中，消息从 ChannelPipeline 当中尾部开始移动；\n * 写入和 ChannelHandler 绑定的 ChannelHandlerContext 中，消息从 ChannelPipeline 中的下一个 ChannelHandler 中移动。\n\n\n# 高性能\n\nNetty 高性能表现在哪些方面：\n\n * NIO 线程模型：同步非阻塞，用最少的资源做更多的事。\n * 内存零拷贝：尽量减少不必要的内存拷贝，实现了更高效率的传输。\n * 内存池设计：申请的内存可以重用，主要指直接内存。内部实现是用一颗二叉查找树管理内存分配情况。\n * 串形化处理读写：避免使用锁带来的性能开销。\n * 高性能序列化协议：支持 protobuf 等高性能序列化协议。\n\n\n# 零拷贝\n\n\n# 传统意义的拷贝\n\n是在发送数据的时候，传统的实现方式是：\n\nFile.read(bytes)\n\nSocket.send(bytes)\n\n这种方式需要四次数据拷贝和四次上下文切换：\n\n 1. 数据从磁盘读取到内核的 read buffer\n\n 2. 数据从内核缓冲区拷贝到用户缓冲区\n\n 3. 数据从用户缓冲区拷贝到内核的 socket buffer\n\n 4. 数据从内核的 socket buffer 拷贝到网卡接口（硬件）的缓冲区\n\n\n# 零拷贝的概念\n\n明显上面的第二步和第三步是非必要的，通过 java 的 FileChannel.transferTo 方法，可以避免上面两次多余的拷贝（当然这需要底层操作系统支持）\n\n * 调用 transferTo，数据从文件由 DMA 引擎拷贝到内核 read buffer\n * 接着 DMA 从内核 read buffer 将数据拷贝到网卡接口 buffer\n\n上面的两次操作都不需要 CPU 参与，所以就达到了零拷贝。\n\n\n# Netty 中的零拷贝\n\n主要体现在三个方面：\n\nbytebuffer\n\nNetty 发送和接收消息主要使用 bytebuffer，bytebuffer 使用对外内存（DirectMemory）直接进行 Socket 读写。\n\n原因：如果使用传统的堆内存进行 Socket 读写，JVM 会将堆内存 buffer 拷贝一份到直接内存中然后再写入 socket，多了一次缓冲区的内存拷贝。DirectMemory 中可以直接通过 DMA 发送到网卡接口\n\nComposite Buffers\n\n传统的 ByteBuffer，如果需要将两个 ByteBuffer 中的数据组合到一起，我们需要首先创建一个 size=size1+size2 大小的新的数组，然后将两个数组中的数据拷贝到新的数组中。但是使用 Netty 提供的组合 ByteBuf，就可以避免这样的操作，因为 CompositeByteBuf 并没有真正将多个 Buffer 组合起来，而是保存了它们的引用，从而避免了数据的拷贝，实现了零拷贝。\n\n对于 FileChannel.transferTo 的使用\n\nNetty 中使用了 FileChannel 的 transferTo 方法，该方法依赖于操作系统实现零拷贝。\n\n\n# Netty 流程\n\n\n# 应用\n\n> Netty 是一个广泛使用的 Java 网络编程框架。很多著名软件都使用了它，如：Dubbo、Cassandra、Elasticsearch、Vert.x 等。\n\n有了 Netty，你可以实现自己的 HTTP 服务器，FTP 服务器，UDP 服务器，RPC 服务器，WebSocket 服务器，Redis 的 Proxy 服务器，MySQL 的 Proxy 服务器等等。\n\npublic class NettyOioServer {\n\n    public void server(int port) throws Exception {\n        final ByteBuf buf = Unpooled.unreleasableBuffer(\n                Unpooled.copiedBuffer("Hi!\\r\\n", Charset.forName("UTF-8")));\n        EventLoopGroup group = new OioEventLoopGroup();\n        try {\n            ServerBootstrap b = new ServerBootstrap();        //1\n\n            b.group(group)                                    //2\n             .channel(OioServerSocketChannel.class)\n             .localAddress(new InetSocketAddress(port))\n             .childHandler(new ChannelInitializer<SocketChannel>() {//3\n                 @Override\n                 public void initChannel(SocketChannel ch)\n                     throws Exception {\n                     ch.pipeline().addLast(new ChannelInboundHandlerAdapter() {            //4\n                         @Override\n                         public void channelActive(ChannelHandlerContext ctx) throws Exception {\n                             ctx.writeAndFlush(buf.duplicate()).addListener(ChannelFutureListener.CLOSE);//5\n                         }\n                     });\n                 }\n             });\n            ChannelFuture f = b.bind().sync();  //6\n            f.channel().closeFuture().sync();\n        } finally {\n            group.shutdownGracefully().sync();        //7\n        }\n    }\n}\n\n\n\n# 参考资料\n\n * 官方\n   * Netty 官网\n   * Netty Github\n * 文章\n   * Netty 入门教程——认识 Netty\n   * 彻底理解 Netty，这一篇文章就够了\n   * Java 200+ 面试题补充 ② Netty 模块',normalizedContent:'# netty 快速入门\n\n\n# netty 简介\n\n> netty 是一款基于 nio（nonblocking i/o，非阻塞 io）开发的网络通信框架。\n\n\n# netty 的特性\n\n * 高并发：netty 是一款基于 nio（nonblocking io，非阻塞 io）开发的网络通信框架，对比于 bio（blocking i/o，阻塞 io），他的并发性能得到了很大提高。\n * 传输快：netty 的传输依赖于内存零拷贝特性，尽量减少不必要的内存拷贝，实现了更高效率的传输。\n * 封装好：netty 封装了 nio 操作的很多细节，提供了易于使用调用接口。\n\n\n# 核心组件\n\n * channel：netty 网络操作抽象类，它除了包括基本的 i/o 操作，如 bind、connect、read、write 等。\n * eventloop：主要是配合 channel 处理 i/o 操作，用来处理连接的生命周期中所发生的事情。\n * channelfuture：netty 框架中所有的 i/o 操作都为异步的，因此我们需要 channelfuture 的 addlistener()注册一个 channelfuturelistener 监听事件，当操作执行成功或者失败时，监听就会自动触发返回结果。\n * channelhandler：充当了所有处理入站和出站数据的逻辑容器。channelhandler 主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。\n * channelpipeline：为 channelhandler 链提供了容器，当 channel 创建时，就会被自动分配到它专属的 channelpipeline，这个关联是永久性的。\n\nnetty 有两种发送消息的方式：\n\n * 直接写入 channel 中，消息从 channelpipeline 当中尾部开始移动；\n * 写入和 channelhandler 绑定的 channelhandlercontext 中，消息从 channelpipeline 中的下一个 channelhandler 中移动。\n\n\n# 高性能\n\nnetty 高性能表现在哪些方面：\n\n * nio 线程模型：同步非阻塞，用最少的资源做更多的事。\n * 内存零拷贝：尽量减少不必要的内存拷贝，实现了更高效率的传输。\n * 内存池设计：申请的内存可以重用，主要指直接内存。内部实现是用一颗二叉查找树管理内存分配情况。\n * 串形化处理读写：避免使用锁带来的性能开销。\n * 高性能序列化协议：支持 protobuf 等高性能序列化协议。\n\n\n# 零拷贝\n\n\n# 传统意义的拷贝\n\n是在发送数据的时候，传统的实现方式是：\n\nfile.read(bytes)\n\nsocket.send(bytes)\n\n这种方式需要四次数据拷贝和四次上下文切换：\n\n 1. 数据从磁盘读取到内核的 read buffer\n\n 2. 数据从内核缓冲区拷贝到用户缓冲区\n\n 3. 数据从用户缓冲区拷贝到内核的 socket buffer\n\n 4. 数据从内核的 socket buffer 拷贝到网卡接口（硬件）的缓冲区\n\n\n# 零拷贝的概念\n\n明显上面的第二步和第三步是非必要的，通过 java 的 filechannel.transferto 方法，可以避免上面两次多余的拷贝（当然这需要底层操作系统支持）\n\n * 调用 transferto，数据从文件由 dma 引擎拷贝到内核 read buffer\n * 接着 dma 从内核 read buffer 将数据拷贝到网卡接口 buffer\n\n上面的两次操作都不需要 cpu 参与，所以就达到了零拷贝。\n\n\n# netty 中的零拷贝\n\n主要体现在三个方面：\n\nbytebuffer\n\nnetty 发送和接收消息主要使用 bytebuffer，bytebuffer 使用对外内存（directmemory）直接进行 socket 读写。\n\n原因：如果使用传统的堆内存进行 socket 读写，jvm 会将堆内存 buffer 拷贝一份到直接内存中然后再写入 socket，多了一次缓冲区的内存拷贝。directmemory 中可以直接通过 dma 发送到网卡接口\n\ncomposite buffers\n\n传统的 bytebuffer，如果需要将两个 bytebuffer 中的数据组合到一起，我们需要首先创建一个 size=size1+size2 大小的新的数组，然后将两个数组中的数据拷贝到新的数组中。但是使用 netty 提供的组合 bytebuf，就可以避免这样的操作，因为 compositebytebuf 并没有真正将多个 buffer 组合起来，而是保存了它们的引用，从而避免了数据的拷贝，实现了零拷贝。\n\n对于 filechannel.transferto 的使用\n\nnetty 中使用了 filechannel 的 transferto 方法，该方法依赖于操作系统实现零拷贝。\n\n\n# netty 流程\n\n\n# 应用\n\n> netty 是一个广泛使用的 java 网络编程框架。很多著名软件都使用了它，如：dubbo、cassandra、elasticsearch、vert.x 等。\n\n有了 netty，你可以实现自己的 http 服务器，ftp 服务器，udp 服务器，rpc 服务器，websocket 服务器，redis 的 proxy 服务器，mysql 的 proxy 服务器等等。\n\npublic class nettyoioserver {\n\n    public void server(int port) throws exception {\n        final bytebuf buf = unpooled.unreleasablebuffer(\n                unpooled.copiedbuffer("hi!\\r\\n", charset.forname("utf-8")));\n        eventloopgroup group = new oioeventloopgroup();\n        try {\n            serverbootstrap b = new serverbootstrap();        //1\n\n            b.group(group)                                    //2\n             .channel(oioserversocketchannel.class)\n             .localaddress(new inetsocketaddress(port))\n             .childhandler(new channelinitializer<socketchannel>() {//3\n                 @override\n                 public void initchannel(socketchannel ch)\n                     throws exception {\n                     ch.pipeline().addlast(new channelinboundhandleradapter() {            //4\n                         @override\n                         public void channelactive(channelhandlercontext ctx) throws exception {\n                             ctx.writeandflush(buf.duplicate()).addlistener(channelfuturelistener.close);//5\n                         }\n                     });\n                 }\n             });\n            channelfuture f = b.bind().sync();  //6\n            f.channel().closefuture().sync();\n        } finally {\n            group.shutdowngracefully().sync();        //7\n        }\n    }\n}\n\n\n\n# 参考资料\n\n * 官方\n   * netty 官网\n   * netty github\n * 文章\n   * netty 入门教程——认识 netty\n   * 彻底理解 netty，这一篇文章就够了\n   * java 200+ 面试题补充 ② netty 模块',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Dubbo 快速入门",frontmatter:{title:"Dubbo 快速入门",categories:["编程","Java","框架","微服务"],tags:["Java","框架","微服务","Dubbo"],abbrlink:"37e41c9c",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/e79b77/"},regularPath:"/13.%E6%A1%86%E6%9E%B6/14.%E5%BE%AE%E6%9C%8D%E5%8A%A1/01.Dubbo.html",relativePath:"13.框架/14.微服务/01.Dubbo.md",key:"v-03cb9ec2",path:"/pages/e79b77/",headers:[{level:2,title:"一、Dubbo 简介",slug:"一、dubbo-简介",normalizedTitle:"一、dubbo 简介",charIndex:105},{level:3,title:"RPC 原理简介",slug:"rpc-原理简介",normalizedTitle:"rpc 原理简介",charIndex:221},{level:4,title:"什么是 RPC",slug:"什么是-rpc",normalizedTitle:"什么是 rpc",charIndex:233},{level:4,title:"RPC 工作流程",slug:"rpc-工作流程",normalizedTitle:"rpc 工作流程",charIndex:430},{level:3,title:"为什么需要 Dubbo",slug:"为什么需要-dubbo",normalizedTitle:"为什么需要 dubbo",charIndex:731},{level:2,title:"二、QuickStart",slug:"二、quickstart",normalizedTitle:"二、quickstart",charIndex:1169},{level:2,title:"三、Dubbo 配置",slug:"三、dubbo-配置",normalizedTitle:"三、dubbo 配置",charIndex:4295},{level:3,title:"配置方式",slug:"配置方式",normalizedTitle:"配置方式",charIndex:4536},{level:4,title:"xml 配置",slug:"xml-配置",normalizedTitle:"xml 配置",charIndex:4562},{level:4,title:"properties 配置",slug:"properties-配置",normalizedTitle:"properties 配置",charIndex:4572},{level:3,title:"配置项",slug:"配置项",normalizedTitle:"配置项",charIndex:4370},{level:4,title:"配置之间的关系",slug:"配置之间的关系",normalizedTitle:"配置之间的关系",charIndex:7091},{level:4,title:"配置覆盖关系",slug:"配置覆盖关系",normalizedTitle:"配置覆盖关系",charIndex:7104},{level:2,title:"四、Dubbo 架构",slug:"四、dubbo-架构",normalizedTitle:"四、dubbo 架构",charIndex:7634},{level:3,title:"Dubbo 核心组件",slug:"dubbo-核心组件",normalizedTitle:"dubbo 核心组件",charIndex:7649},{level:3,title:"Dubbo 架构层次",slug:"dubbo-架构层次",normalizedTitle:"dubbo 架构层次",charIndex:8513},{level:4,title:"各层说明",slug:"各层说明",normalizedTitle:"各层说明",charIndex:8818},{level:4,title:"各层关系说明",slug:"各层关系说明",normalizedTitle:"各层关系说明",charIndex:9786},{level:2,title:"五、服务发现",slug:"五、服务发现",normalizedTitle:"五、服务发现",charIndex:10646},{level:3,title:"启动时检查",slug:"启动时检查",normalizedTitle:"启动时检查",charIndex:11375},{level:2,title:"六、Dubbo 协议",slug:"六、dubbo-协议",normalizedTitle:"六、dubbo 协议",charIndex:11507},{level:3,title:"dubbo 协议",slug:"dubbo-协议",normalizedTitle:"dubbo 协议",charIndex:5458},{level:3,title:"rmi 协议",slug:"rmi-协议",normalizedTitle:"rmi 协议",charIndex:11857},{level:3,title:"hessian 协议",slug:"hessian-协议",normalizedTitle:"hessian 协议",charIndex:11996},{level:3,title:"thrift 协议",slug:"thrift-协议",normalizedTitle:"thrift 协议",charIndex:12250},{level:3,title:"http 协议",slug:"http-协议",normalizedTitle:"http 协议",charIndex:12439},{level:3,title:"webservice 协议",slug:"webservice-协议",normalizedTitle:"webservice 协议",charIndex:12521},{level:3,title:"rest 协议",slug:"rest-协议",normalizedTitle:"rest 协议",charIndex:12778},{level:3,title:"memcached 协议",slug:"memcached-协议",normalizedTitle:"memcached 协议",charIndex:12875},{level:3,title:"redis 协议",slug:"redis-协议",normalizedTitle:"redis 协议",charIndex:12918},{level:2,title:"七、集群容错",slug:"七、集群容错",normalizedTitle:"七、集群容错",charIndex:13149},{level:2,title:"八、负载均衡",slug:"八、负载均衡",normalizedTitle:"八、负载均衡",charIndex:13679},{level:4,title:"Random",slug:"random",normalizedTitle:"random",charIndex:13722},{level:4,title:"RoundRobin",slug:"roundrobin",normalizedTitle:"roundrobin",charIndex:14296},{level:4,title:"LeastActive",slug:"leastactive",normalizedTitle:"leastactive",charIndex:14399},{level:4,title:"ConsistentHash",slug:"consistenthash",normalizedTitle:"consistenthash",charIndex:14485},{level:2,title:"九、Dubbo 服务治理",slug:"九、dubbo-服务治理",normalizedTitle:"九、dubbo 服务治理",charIndex:14799},{level:3,title:"服务治理简介",slug:"服务治理简介",normalizedTitle:"服务治理简介",charIndex:14816},{level:4,title:"调用链路",slug:"调用链路",normalizedTitle:"调用链路",charIndex:879},{level:4,title:"服务访问压力以及时长统计",slug:"服务访问压力以及时长统计",normalizedTitle:"服务访问压力以及时长统计",charIndex:984},{level:4,title:"其他",slug:"其他",normalizedTitle:"其他",charIndex:15417},{level:3,title:"路由规则",slug:"路由规则",normalizedTitle:"路由规则",charIndex:15922},{level:3,title:"服务降级",slug:"服务降级",normalizedTitle:"服务降级",charIndex:17010},{level:3,title:"访问控制",slug:"访问控制",normalizedTitle:"访问控制",charIndex:19757},{level:4,title:"直连",slug:"直连",normalizedTitle:"直连",charIndex:8352},{level:4,title:"只订阅",slug:"只订阅",normalizedTitle:"只订阅",charIndex:20427},{level:4,title:"只注册",slug:"只注册",normalizedTitle:"只注册",charIndex:20706},{level:4,title:"静态服务",slug:"静态服务",normalizedTitle:"静态服务",charIndex:21132},{level:3,title:"动态配置",slug:"动态配置",normalizedTitle:"动态配置",charIndex:7262},{level:2,title:"十、多版本",slug:"十、多版本",normalizedTitle:"十、多版本",charIndex:22741},{level:2,title:"十一、Dubbo SPI",slug:"十一、dubbo-spi",normalizedTitle:"十一、dubbo spi",charIndex:23343},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:23776}],headersStr:"一、Dubbo 简介 RPC 原理简介 什么是 RPC RPC 工作流程 为什么需要 Dubbo 二、QuickStart 三、Dubbo 配置 配置方式 xml 配置 properties 配置 配置项 配置之间的关系 配置覆盖关系 四、Dubbo 架构 Dubbo 核心组件 Dubbo 架构层次 各层说明 各层关系说明 五、服务发现 启动时检查 六、Dubbo 协议 dubbo 协议 rmi 协议 hessian 协议 thrift 协议 http 协议 webservice 协议 rest 协议 memcached 协议 redis 协议 七、集群容错 八、负载均衡 Random RoundRobin LeastActive ConsistentHash 九、Dubbo 服务治理 服务治理简介 调用链路 服务访问压力以及时长统计 其他 路由规则 服务降级 访问控制 直连 只订阅 只注册 静态服务 动态配置 十、多版本 十一、Dubbo SPI 参考资料",content:'# Dubbo 快速入门\n\n> Apache Dubbo 是一款高性能、轻量级的开源 Java RPC 框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。\n\n\n# 一、Dubbo 简介\n\nApache Dubbo 是一款高性能、轻量级的开源 Java RPC 框架。\n\nDubbo 提供了三大核心能力：\n\n * 面向接口的远程方法调用\n * 智能容错和负载均衡\n * 服务自动注册和发现\n\n\n# RPC 原理简介\n\n# 什么是 RPC\n\nRPC（Remote Procedure Call），即远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。比如两个不同的服务 A、B 部署在两台不同的机器上，那么服务 A 如果想要调用服务 B 中的某个方法该怎么办呢？使用 HTTP 请求 当然可以，但是可能会比较慢而且一些优化做的并不好。 RPC 的出现就是为了解决这个问题。\n\n# RPC 工作流程\n\n\n\n 1. 服务消费方（client）调用以本地调用方式调用服务；\n 2. client stub 接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；\n 3. client stub 找到服务地址，并将消息发送到服务端；\n 4. server stub 收到消息后进行解码；\n 5. server stub 根据解码结果调用本地的服务；\n 6. 本地服务执行并将结果返回给 server stub；\n 7. server stub 将返回结果打包成消息并发送至消费方；\n 8. client stub 接收到消息，并进行解码；\n 9. 服务消费方得到最终结果。\n\n\n# 为什么需要 Dubbo\n\n如果你要开发分布式程序，你也可以直接基于 HTTP 接口进行通信，但是为什么要用 Dubbo 呢？\n\n我觉得主要可以从 Dubbo 提供的下面四点特性来说为什么要用 Dubbo：\n\n 1. 负载均衡——同一个服务部署在不同的机器时该调用那一台机器上的服务。\n 2. 服务调用链路——随着系统的发展，服务越来越多，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。Dubbo 可以为我们解决服务之间互相是如何调用的。\n 3. 服务访问压力以及时长统计、资源调度和治理——基于访问压力实时管理集群容量，提高集群利用率。\n 4. 服务治理——某个服务挂掉之后调用备用服务。\n\n另外，Dubbo 除了能够应用在分布式系统中，也可以应用在现在比较火的微服务系统中。不过，由于 Spring Cloud 在微服务中应用更加广泛，所以，我觉得一般我们提 Dubbo 的话，大部分是分布式系统的情况。\n\n\n# 二、QuickStart\n\n（1）添加 maven 依赖\n\n<dependency>\n    <groupId>com.alibaba</groupId>\n    <artifactId>dubbo</artifactId>\n    <version>${dubbo.version}</version>\n</dependency>\n\n\n（2）定义 Provider\n\npackage com.alibaba.dubbo.demo;\n\npublic interface DemoService {\n    String sayHello(String name);\n}\n\n\n（3）实现 Provider\n\npackage com.alibaba.dubbo.demo.provider;\nimport com.alibaba.dubbo.demo.DemoService;\n\npublic class DemoServiceImpl implements DemoService {\n    public String sayHello(String name) {\n        return "Hello " + name;\n    }\n}\n\n\n（4）配置 Provider\n\n<?xml version="1.0" encoding="UTF-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n       xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"\n       xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd">\n    <dubbo:application name="demo-provider"/>\n    <dubbo:registry address="multicast://224.5.6.7:1234"/>\n    <dubbo:protocol name="dubbo" port="20880"/>\n    <dubbo:service interface="com.alibaba.dubbo.demo.DemoService" ref="demoService"/>\n    <bean id="demoService" class="com.alibaba.dubbo.demo.provider.DemoServiceImpl"/>\n</beans>\n\n\n（5）启动 Provider\n\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class Provider {\n    public static void main(String[] args) throws Exception {\n        ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\n                new String[] {"META-INF/spring/dubbo-demo-provider.xml"});\n        context.start();\n        // press any key to exit\n        System.in.read();\n    }\n}\n\n\n（6）配置 Consumer\n\n<?xml version="1.0" encoding="UTF-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n       xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"\n       xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd">\n    <dubbo:application name="demo-consumer"/>\n    <dubbo:registry address="multicast://224.5.6.7:1234"/>\n    <dubbo:reference id="demoService" interface="com.alibaba.dubbo.demo.DemoService"/>\n</beans>\n\n\n（7）启动 Consumer\n\nimport com.alibaba.dubbo.demo.DemoService;\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class Consumer {\n    public static void main(String[] args) throws Exception {\n        ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\n                new String[]{"META-INF/spring/dubbo-demo-consumer.xml"});\n        context.start();\n        // obtain proxy object for remote invocation\n        DemoService demoService = (DemoService) context.getBean("demoService");\n        // execute remote invocation\n        String hello = demoService.sayHello("world");\n        // show the result\n        System.out.println(hello);\n    }\n}\n\n\n\n# 三、Dubbo 配置\n\nDubbo 所有配置最终都将转换为 URL 表示，并由服务提供方生成，经注册中心传递给消费方，各属性对应 URL 的参数，参见配置项一览表中的 "对应 URL 参数" 列。\n\n只有 group，interface，version 是服务的匹配条件，三者决定是不是同一个服务，其它配置项均为调优和治理参数。\n\nURL 格式：protocol://username:password@host:port/path?key=value&key=value\n\n\n# 配置方式\n\nDubbo 支持多种配置方式：\n\n * xml 配置\n * properties 配置\n * API 配置\n * 注解配置\n\n如果同时存在多种配置方式，遵循以下覆盖策略：\n\n * JVM 启动 -D 参数优先，这样可以使用户在部署和启动时进行参数重写，比如在启动时需改变协议的端口。\n * XML 次之，如果在 XML 中有配置，则 dubbo.properties 中的相应配置项无效。\n * Properties 最后，相当于缺省值，只有 XML 没有配置时，dubbo.properties 的相应配置项才会生效，通常用于共享公共配置，比如应用名。\n\n\n\n# xml 配置\n\n示例：\n\n<?xml version="1.0" encoding="UTF-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n    xmlns:dubbo="http://dubbo.apache.org/schema/dubbo"\n    xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd">\n    \x3c!-- 提供方应用信息，用于计算依赖关系 --\x3e\n    <dubbo:application name="hello-world-app"  />\n    \x3c!-- 使用 multicast 广播注册中心暴露服务地址 --\x3e\n    <dubbo:registry address="multicast://224.5.6.7:1234" />\n    \x3c!-- 用 dubbo 协议在 20880 端口暴露服务 --\x3e\n    <dubbo:protocol name="dubbo" port="20880" />\n    \x3c!-- 声明需要暴露的服务接口 --\x3e\n    <dubbo:service interface="com.alibaba.dubbo.demo.DemoService" ref="demoServiceLocal" />\n    \x3c!-- 和本地 bean 一样实现服务 --\x3e\n    <bean id="demoService" class="com.alibaba.dubbo.demo.provider.DemoServiceImpl" />\n\n    \x3c!-- 生成远程服务代理，可以和本地 bean 一样使用 demoService --\x3e\n    <dubbo:reference id="demoServiceRemote" interface="com.alibaba.dubbo.demo.DemoService" />\n</beans>\n\n\nDubbo 会把以上配置项解析成下面的 URL 格式：\n\ndubbo://host-ip:20880/com.alibaba.dubbo.demo.DemoService\n\n\n然后基于扩展点自适应机制，通过 URL 的 dubbo:// 协议头识别，就会调用 DubboProtocol 的 export() 方法，打开服务端口 20880，就可以把服务 demoService 暴露到 20880 端口了。\n\n# properties 配置\n\n示例：\n\ndubbo.application.name=foo\ndubbo.application.owner=bar\ndubbo.registry.address=10.20.153.10:9090\n\n\n\n# 配置项\n\n所有配置项分为三大类：\n\n * 服务发现：表示该配置项用于服务的注册与发现，目的是让消费方找到提供方。\n * 服务治理：表示该配置项用于治理服务间的关系，或为开发测试提供便利条件。\n * 性能调优：表示该配置项用于调优性能，不同的选项对性能会产生影响。\n\n配置项清单：\n\n标签                  用途       解释\ndubbo:service       服务配置     用于暴露一个服务，定义服务的元信息，一个服务可以用多个协议暴露，一个服务也可以注册到多个注册中心\ndubbo:reference     引用配置     用于创建一个远程服务代理，一个引用可以指向多个注册中心\ndubbo:protocol      协议配置     用于配置提供服务的协议信息，协议由提供方指定，消费方被动接受\ndubbo:application   应用配置     用于配置当前应用信息，不管该应用是提供者还是消费者\ndubbo:module        模块配置     用于配置当前模块信息，可选\ndubbo:registry      注册中心配置   用于配置连接注册中心相关信息\ndubbo:monitor       监控中心配置   用于配置连接监控中心相关信息，可选\ndubbo:provider      提供方配置    当 ProtocolConfig 和 ServiceConfig 某属性没有配置时，采用此缺省值，可选\ndubbo:consumer      消费方配置    当 ReferenceConfig 某属性没有配置时，采用此缺省值，可选\ndubbo:method        方法配置     用于 ServiceConfig 和 ReferenceConfig 指定方法级的配置信息\ndubbo:argument      参数配置     用于指定方法参数配置\n\n> 详细配置说明请参考：官方配置\n\n# 配置之间的关系\n\n\n\n# 配置覆盖关系\n\n以 timeout 为例，显示了配置的查找顺序，其它 retries, loadbalance, actives 等类似：\n\n * 方法级优先，接口级次之，全局配置再次之。\n * 如果级别一样，则消费方优先，提供方次之。\n\n其中，服务提供方配置，通过 URL 经由注册中心传递给消费方。\n\n\n### 动态配置中心\n\n配置中心（v2.7.0）在 Dubbo 中承担两个职责：\n\n 1. 外部化配置。启动配置的集中式存储 （简单理解为 dubbo.properties 的外部化存储）。\n 2. 服务治理。服务治理规则的存储与通知。\n\n启用动态配置：\n\n<dubbo:config-center address="zookeeper://127.0.0.1:2181"/>\n\n\n或者\n\ndubbo.config-center.address=zookeeper://127.0.0.1:2181\n\n\n或者\n\nConfigCenterConfig configCenter = new ConfigCenterConfig();\nconfigCenter.setAddress("zookeeper://127.0.0.1:2181");\n\n\n\n# 四、Dubbo 架构\n\n\n# Dubbo 核心组件\n\n\n\n节点角色：\n\n节点          角色说明\nProvider    暴露服务的服务提供方\nConsumer    调用远程服务的服务消费方\nRegistry    服务注册与发现的注册中心\nMonitor     统计服务的调用次数和调用时间的监控中心\nContainer   服务运行容器\n\n调用关系：\n\n 1. 服务容器负责启动，加载，运行服务提供者。\n 2. 服务提供者在启动时，向注册中心注册自己提供的服务。\n 3. 服务消费者在启动时，向注册中心订阅自己所需的服务。\n 4. 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。\n 5. 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。\n 6. 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。\n\n重要知识点总结：\n\n * 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小\n * 监控中心负责统计各服务调用次数，调用时间等，统计先在内存汇总后每分钟一次发送到监控中心服务器，并以报表展示\n * 注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外\n * 注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者\n * 注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表\n * 注册中心和监控中心都是可选的，服务消费者可以直连服务提供者\n * 服务提供者无状态，任意一台宕掉后，不影响使用\n * 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复\n\n> 问：注册中心挂了可以继续通信吗？\n> \n> 答：可以，因为刚开始初始化的时候，消费者会将提供者的地址等信息拉取到本地缓存，所以注册中心挂了可以继续通信。\n\n\n# Dubbo 架构层次\n\n\n\n图例说明：\n\n * 图中左边淡蓝背景的为服务消费方使用的接口，右边淡绿色背景的为服务提供方使用的接口，位于中轴线上的为双方都用到的接口。\n * 图中从下至上分为十层，各层均为单向依赖，右边的黑色箭头代表层之间的依赖关系，每一层都可以剥离上层被复用，其中，Service 和 Config 层为 API，其它各层均为 SPI。\n * 图中绿色小块的为扩展接口，蓝色小块为实现类，图中只显示用于关联各层的实现类。\n * 图中蓝色虚线为初始化过程，即启动时组装链，红色实线为方法调用过程，即运行时调时链，紫色三角箭头为继承，可以把子类看作父类的同一个节点，线上的文字为调用的方法。\n\n# 各层说明\n\n * config 配置层：对外配置接口，以 ServiceConfig, ReferenceConfig 为中心，可以直接初始化配置类，也可以通过 spring 解析配置生成配置类\n * proxy 服务代理层：服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton, 以 ServiceProxy 为中心，扩展接口为 ProxyFactory\n * registry 注册中心层：封装服务地址的注册与发现，以服务 URL 为中心，扩展接口为 RegistryFactory, Registry, RegistryService\n * cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance\n * monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory, Monitor, MonitorService\n * protocol 远程调用层：封装 RPC 调用，以 Invocation, Result 为中心，扩展接口为 Protocol, Invoker, Exporter\n * exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer\n * transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec\n * serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool\n * serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool\n\n# 各层关系说明\n\n * 在 RPC 中，Protocol 是核心层，也就是只要有 Protocol + Invoker + Exporter 就可以完成非透明的 RPC 调用，然后在 Invoker 的主过程上 Filter 拦截点。\n * 图中的 Consumer 和 Provider 是抽象概念，只是想让看图者更直观的了解哪些类分属于客户端与服务器端，不用 Client 和 Server 的原因是 Dubbo 在很多场景下都使用 Provider, Consumer, Registry, Monitor 划分逻辑拓普节点，保持统一概念。\n * 而 Cluster 是外围概念，所以 Cluster 的目的是将多个 Invoker 伪装成一个 Invoker，这样其它人只要关注 Protocol 层 Invoker 即可，加上 Cluster 或者去掉 Cluster 对其它层都不会造成影响，因为只有一个提供者时，是不需要 Cluster 的。\n * Proxy 层封装了所有接口的透明化代理，而在其它层都以 Invoker 为中心，只有到了暴露给用户使用时，才用 Proxy 将 Invoker 转成接口，或将接口实现转成 Invoker，也就是去掉 Proxy 层 RPC 是可以 Run 的，只是不那么透明，不那么看起来像调本地服务一样调远程服务。\n * 而 Remoting 实现是 Dubbo 协议的实现，如果你选择 RMI 协议，整个 Remoting 都不会用上，Remoting 内部再划为 Transport 传输层和 Exchange 信息交换层，Transport 层只负责单向消息传输，是对 Mina, Netty, Grizzly 的抽象，它也可以扩展 UDP 传输，而 Exchange 层是在传输层之上封装了 Request-Response 语义。\n * Registry 和 Monitor 实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在一起。\n\n\n# 五、服务发现\n\n服务提供者注册服务的过程：\n\nDubbo 配置项 dubbo://registry 声明了注册中心的地址，Dubbo 会把以上配置项解析成类似下面的 URL 格式：\n\nregistry://multicast://224.5.6.7:1234/com.alibaba.dubbo.registry.RegistryService?export=URL.encode("dubbo://host-ip:20880/com.alibaba.dubbo.demo.DemoService")\n\n\n然后基于扩展点自适应机制，通过 URL 的“registry://”协议头识别，就会调用 RegistryProtocol 的 export() 方法，将 export 参数中的提供者 URL，注册到注册中心。\n\n服务消费者发现服务的过程：\n\nDubbo 配置项 dubbo://registry 声明了注册中心的地址，跟服务注册的原理类似，Dubbo 也会把以上配置项解析成下面的 URL 格式：\n\nregistry://multicast://224.5.6.7:1234/com.alibaba.dubbo.registry.RegistryService?refer=URL.encode("consummer://host-ip/com.alibaba.dubbo.demo.DemoService")\n\n\n然后基于扩展点自适应机制，通过 URL 的“registry://”协议头识别，就会调用 RegistryProtocol 的 refer() 方法，基于 refer 参数中的条件，查询服务 demoService 的地址。\n\n\n# 启动时检查\n\nDubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，以便上线时，能及早发现问题，默认 check="true"。\n\n可以通过 xml、properties、-D 参数三种方式设置。启动时检查\n\n\n# 六、Dubbo 协议\n\nDubbo 支持多种通信协议，不同的协议针对不同的序列化方式。\n\n\n# dubbo 协议\n\ndubbo 协议是 Dubbo 的默认通信协议，采用单一长连接和 NIO 异步通信，基于 hessian 作为序列化协议。\n\ndubbo 协议适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。反之，Dubbo 缺省协议不适合传送大数据量的服务，比如传文件，传视频等，除非请求量很低。\n\n为了要支持高并发场景，一般是服务提供者就几台机器，但是服务消费者有上百台，可能每天调用量达到上亿次！此时用长连接是最合适的，就是跟每个服务消费者维持一个长连接就可以，可能总共就 100 个连接。然后后面直接基于长连接 NIO 异步通信，可以支撑高并发请求。\n\n\n# rmi 协议\n\nrmi - 采用 JDK 标准的 java.rmi.* 实现，采用阻塞式短连接和 JDK 标准序列化方式。\n\n注意：如果正在使用 RMI 提供服务给外部访问，同时应用里依赖了老的 common-collections 包的情况下，存在反序列化安全风险。\n\n\n# hessian 协议\n\nhessian 协议用于集成 Hessian 的服务，Hessian 底层采用 Http 通讯，采用 Servlet 暴露服务，Dubbo 缺省内嵌 Jetty 作为服务器实现。\n\nDubbo 的 Hessian 协议可以和原生 Hessian 服务互操作，即：\n\n * 提供者用 Dubbo 的 Hessian 协议暴露服务，消费者直接用标准 Hessian 接口调用\n * 或者提供方用标准 Hessian 暴露服务，消费方用 Dubbo 的 Hessian 协议调用。\n\n\n# thrift 协议\n\n当前 dubbo 支持的 thrift 协议是对 thrift 原生协议的扩展，在原生协议的基础上添加了一些额外的头信息，比如 service name，magic number 等。\n\n使用 dubbo thrift 协议同样需要使用 thrift 的 idl compiler 编译生成相应的 java 代码，后续版本中会在这方面做一些增强。\n\n\n# http 协议\n\nhttp 协议基于 HTTP 表单的远程调用协议，采用 Spring 的 HttpInvoker 实现。\n\n使用 JSON 序列化方式。\n\n\n# webservice 协议\n\n基于 WebService 的远程调用协议，基于 Apache CXF 的 frontend-simple 和 transports-http 实现。\n\n使用 SOAP 序列化方式。\n\n可以和原生 WebService 服务互操作，即：\n\n * 提供者用 Dubbo 的 WebService 协议暴露服务，消费者直接用标准 WebService 接口调用，\n * 或者提供方用标准 WebService 暴露服务，消费方用 Dubbo 的 WebService 协议调用。\n\n\n# rest 协议\n\n基于标准的 Java REST API——JAX-RS 2.0（Java API for RESTful Web Services 的简写）实现的 REST 调用支持\n\n\n# memcached 协议\n\n基于 memcached 实现的 RPC 协议。\n\n\n# redis 协议\n\n基于 redis 实现的 RPC 协议。\n\n> 在现实世界中，序列化有多种方式。\n> \n> JDK 自身提供的序列化方式，效率不高，但是 Java 程序使用最多。\n> \n> 如果想要较好的可读性，可以使用 JSON （常见库有：jackson、gson、fastjson）或 SOAP （即 xml 形式）\n> \n> 如果想要更好的性能，可以使用 thrift、protobuf、hessian\n> \n> 想深入了解可以参考：序列化\n\n\n# 七、集群容错\n\n在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。\n\n\n * Failover - 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries="2" 来设置重试次数(不含第一次)。\n * Failfast - 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。\n * Failsafe - 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。\n * Failback - 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。\n * Forking - 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks="2" 来设置最大并行数。\n * Broadcast - 广播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。\n\n集群容错配置示例：\n\n<dubbo:service cluster="failsafe" />\n<dubbo:reference cluster="failsafe" />\n\n\n\n# 八、负载均衡\n\nDubbo 提供了多种负载均衡（LoadBalance）策略，缺省为 Random 随机调用。\n\nDubbo 的负载均衡配置可以细粒度到服务、方法级别，且 dubbo:service 和 dubbo:reference 均可配置。\n\n\x3c!-- 服务端服务级别 --\x3e\n<dubbo:service interface="..." loadbalance="roundrobin" />\n\x3c!-- 客户端服务级别 --\x3e\n<dubbo:reference interface="..." loadbalance="roundrobin" />\n\x3c!-- 服务端方法级别 --\x3e\n<dubbo:service interface="...">\n    <dubbo:method name="..." loadbalance="roundrobin"/>\n</dubbo:service>\n\x3c!-- 客户端方法级别 --\x3e\n<dubbo:reference interface="...">\n    <dubbo:method name="..." loadbalance="roundrobin"/>\n</dubbo:reference>\n\n\n# Random\n\n * 随机，按权重设置随机概率。\n * 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。\n\n# RoundRobin\n\n * 轮询，按公约后的权重设置轮询比率。\n * 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。\n\n# LeastActive\n\n * 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。\n * 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。\n\n# ConsistentHash\n\n * 一致性 Hash，相同参数的请求总是发到同一提供者。\n * 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。\n * 算法参见：http://en.wikipedia.org/wiki/Consistent_hashing\n * 缺省只对第一个参数 Hash，如果要修改，请配置 <dubbo:parameter key="hash.arguments" value="0,1" />\n * 缺省用 160 份虚拟节点，如果要修改，请配置 <dubbo:parameter key="hash.nodes" value="320" />\n\n\n# 九、Dubbo 服务治理\n\n\n# 服务治理简介\n\n * 当服务越来越多时，服务 URL 配置管理变得非常困难，F5 硬件负载均衡器的单点压力也越来越大。\n * 当进一步发展，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。\n * 接着，服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？\n\n以上问题可以归纳为服务治理问题，这也是 Dubbo 的核心功能。\n\n# 调用链路\n\n一个微服务架构，往往由大量分布式服务组成。那么这些服务之间互相是如何调用的？调用链路是啥？说实话，几乎到后面没人搞的清楚了，因为服务实在太多了，可能几百个甚至几千个服务。\n\n那就需要基于 dubbo 做的分布式系统中，对各个服务之间的调用自动记录下来，然后自动将各个服务之间的依赖关系和调用链路生成出来，做成一张图，显示出来，大家才可以看到对吧。\n\n# 服务访问压力以及时长统计\n\n需要自动统计各个接口和服务之间的调用次数以及访问延时，而且要分成两个级别。\n\n * 一个级别是接口粒度，就是每个服务的每个接口每天被调用多少次，TP50/TP90/TP99，三个档次的请求延时分别是多少；\n * 第二个级别是从源头入口开始，一个完整的请求链路经过几十个服务之后，完成一次请求，每天全链路走多少次，全链路请求延时的 TP50/TP90/TP99，分别是多少。\n\n# 其他\n\n * 服务分层（避免循环依赖）\n * 调用链路失败监控和报警\n * 服务鉴权\n * 每个服务的可用性的监控（接口调用成功率？几个 9？99.99%，99.9%，99%）\n\n所谓失败重试，就是 consumer 调用 provider 要是失败了，比如抛异常了，此时应该是可以重试的，或者调用超时了也可以重试。配置如下：\n\n<dubbo:reference id="xxxx" interface="xx" check="true" async="false" retries="3" timeout="2000"/>\n\n\n举个栗子。\n\n某个服务的接口，要耗费 5s，你这边不能干等着，你这边配置了 timeout 之后，我等待 2s，还没返回，我直接就撤了，不能干等你。\n\n可以结合你们公司具体的场景来说说你是怎么设置这些参数的：\n\n * timeout：一般设置为 200ms，我们认为不能超过 200ms 还没返回。\n * retries：设置 retries，一般是在读请求的时候，比如你要查询个数据，你可以设置个 retries，如果第一次没读到，报错，重试指定的次数，尝试再次读取。\n\n\n# 路由规则\n\n路由规则决定一次 dubbo 服务调用的目标服务器，分为条件路由规则和脚本路由规则，并且支持可扩展。\n\n向注册中心写入路由规则的操作通常由监控中心或治理中心的页面完成。\n\nRegistryFactory registryFactory = ExtensionLoader.getExtensionLoader(RegistryFactory.class).getAdaptiveExtension();\nRegistry registry = registryFactory.getRegistry(URL.valueOf("zookeeper://10.20.153.10:2181"));\nregistry.register(URL.valueOf("condition://0.0.0.0/com.foo.BarService?category=routers&dynamic=false&rule=" + URL.encode("host = 10.20.153.10 => host = 10.20.153.11") + "));\n\n\n * condition:// - 表示路由规则的类型，支持条件路由规则和脚本路由规则，可扩展，必填。\n * 0.0.0.0 - 表示对所有 IP 地址生效，如果只想对某个 IP 的生效，请填入具体 IP，必填。\n * com.foo.BarService - 表示只对指定服务生效，必填。\n * category=routers - 表示该数据为动态配置类型，必填。\n * dynamic=false - 表示该数据为持久数据，当注册方退出时，数据依然保存在注册中心，必填。\n * enabled=true - 覆盖规则是否生效，可不填，缺省生效。\n * force=false - 当路由结果为空时，是否强制执行，如果不强制执行，路由结果为空的路由规则将自动失效，可不填，缺省为 flase。\n * runtime=false - 是否在每次调用时执行路由规则，否则只在提供者地址列表变更时预先执行并缓存结果，调用时直接从缓存中获取路由结果。如果用了参数路由，必须设为 true，需要注意设置会影响调用的性能，可不填，缺省为 flase。\n * priority=1 - 路由规则的优先级，用于排序，优先级越大越靠前执行，可不填，缺省为 0。\n * rule=URL.encode("host = 10.20.153.10 => host = 10.20.153.11") - 表示路由规则的内容，必填。\n\n\n# 服务降级\n\n可以通过服务降级功能临时屏蔽某个出错的非关键服务，并定义降级后的返回策略。\n\n向注册中心写入动态配置覆盖规则：\n\nRegistryFactory registryFactory = ExtensionLoader.getExtensionLoader(RegistryFactory.class).getAdaptiveExtension();\nRegistry registry = registryFactory.getRegistry(URL.valueOf("zookeeper://10.20.153.10:2181"));\nregistry.register(URL.valueOf("override://0.0.0.0/com.foo.BarService?category=configurators&dynamic=false&application=foo&mock=force:return+null"));\n\n\n其中：\n\nmock=force:return+null 表示消费方对该服务的方法调用都直接返回 null 值，不发起远程调用。用来屏蔽不重要服务不可用时对调用方的影响。 还可以改为 mock=fail:return+null 表示消费方对该服务的方法调用在失败后，再返回 null 值，不抛异常。用来容忍不重要服务不稳定时对调用方的影响。\n\n比如说服务 A 调用服务 B，结果服务 B 挂掉了，服务 A 重试几次调用服务 B，还是不行，那么直接降级，走一个备用的逻辑，给用户返回响应。\n\n举个例子，我们有接口 HelloService。HelloServiceImpl 有该接口的具体实现。\n\npublic interface HelloService {\n   void sayHello();\n}\n\npublic class HelloServiceImpl implements HelloService {\n    public void sayHello() {\n        System.out.println("hello world......");\n    }\n}\n\n\nDubbo 配置：\n\n\x3c!-- provider 配置 --\x3e\n<?xml version="1.0" encoding="UTF-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"\n    xsi:schemaLocation="http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd">\n\n    <dubbo:application name="dubbo-provider" />\n    <dubbo:registry address="zookeeper://127.0.0.1:2181" />\n    <dubbo:protocol name="dubbo" port="20880" />\n    <dubbo:service interface="com.zhss.service.HelloService" ref="helloServiceImpl" timeout="10000" />\n    <bean id="helloServiceImpl" class="com.zhss.service.HelloServiceImpl" />\n\n</beans>\n\n\x3c!-- consumer 配置 --\x3e\n<?xml version="1.0" encoding="UTF-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n    xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"\n    xsi:schemaLocation="http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd">\n\n    <dubbo:application name="dubbo-consumer"  />\n\n    <dubbo:registry address="zookeeper://127.0.0.1:2181" />\n\n    <dubbo:reference id="fooService" interface="com.test.service.FooService"  timeout="10000" check="false" mock="return null">\n    </dubbo:reference>\n\n</beans>\n\n\n我们调用接口失败的时候，可以通过 mock 统一返回 null。\n\nmock 的值也可以修改为 true，然后再跟接口同一个路径下实现一个 Mock 类，命名规则是 “接口名称+Mock” 后缀。然后在 Mock 类里实现自己的降级逻辑。\n\npublic class HelloServiceMock implements HelloService {\n    public void sayHello() {\n        // 降级逻辑\n    }\n}\n\n\n\n# 访问控制\n\n# 直连\n\n在开发及测试环境下，经常需要绕过注册中心，只测试指定服务提供者，这时候可能需要点对点直连，点对点直联方式，将以服务接口为单位，忽略注册中心的提供者列表，A 接口配置点对点，不影响 B 接口从注册中心获取列表。\n\n\n\n配置方式：\n\n（1）通过 XML 配置\n\n如果是线上需求需要点对点，可在 dubbo:reference 中配置 url 指向提供者，将绕过注册中心，多个地址用分号隔开，配置如下：\n\n<dubbo:reference id="xxxService" interface="com.alibaba.xxx.XxxService" url="dubbo://localhost:20890" />\n\n\n（2）通过 -D 参数指定\n\n在 JVM 启动参数中加入-D 参数映射服务地址：\n\njava -Dcom.alibaba.xxx.XxxService=dubbo://localhost:20890\n\n\n（3）通过文件映射 如果服务比较多，也可以用文件映射，用 -Ddubbo.resolve.file 指定映射文件路径，此配置优先级高于 dubbo:reference 中的配置：\n\njava -Ddubbo.resolve.file=xxx.properties\n\n\n然后在映射文件 xxx.properties 中加入配置，其中 key 为服务名，value 为服务提供者 URL：\n\ncom.alibaba.xxx.XxxService=dubbo://localhost:20890\n\n\n# 只订阅\n\n为方便开发测试，经常会在线下共用一个所有服务可用的注册中心，这时，如果一个正在开发中的服务提供者注册，可能会影响消费者不能正常运行。\n\n可以让服务提供者开发方，只订阅服务(开发的服务可能依赖其它服务)，而不注册正在开发的服务，通过直连测试正在开发的服务。\n\n禁用注册配置：\n\n<dubbo:registry address="10.20.153.10:9090" register="false" />\n\n\n或者\n\n<dubbo:registry address="10.20.153.10:9090?register=false" />\n\n\n# 只注册\n\n如果有两个镜像环境，两个注册中心，有一个服务只在其中一个注册中心有部署，另一个注册中心还没来得及部署，而两个注册中心的其它应用都需要依赖此服务。这个时候，可以让服务提供者方只注册服务到另一注册中心，而不从另一注册中心订阅服务。\n\n禁用订阅配置\n\n<dubbo:registry id="hzRegistry" address="10.20.153.10:9090" />\n<dubbo:registry id="qdRegistry" address="10.20.141.150:9090" subscribe="false" />\n\n\n或者\n\n<dubbo:registry id="hzRegistry" address="10.20.153.10:9090" />\n<dubbo:registry id="qdRegistry" address="10.20.141.150:9090?subscribe=false" />\n\n\n# 静态服务\n\n有时候希望人工管理服务提供者的上线和下线，此时需将注册中心标识为非动态管理模式。\n\n<dubbo:registry address="10.20.141.150:9090" dynamic="false" />\n\n\n或者\n\n<dubbo:registry address="10.20.141.150:9090?dynamic=false" />\n\n\n服务提供者初次注册时为禁用状态，需人工启用。断线时，将不会被自动删除，需人工禁用。\n\n\n# 动态配置\n\n向注册中心写入动态配置覆盖规则。该功能通常由监控中心或治理中心的页面完成。\n\nRegistryFactory registryFactory = ExtensionLoader.getExtensionLoader(RegistryFactory.class).getAdaptiveExtension();\nRegistry registry = registryFactory.getRegistry(URL.valueOf("zookeeper://10.20.153.10:2181"));\nregistry.register(URL.valueOf("override://0.0.0.0/com.foo.BarService?category=configurators&dynamic=false&application=foo&timeout=1000"));\n\n\n其中：\n\n * override:// - 表示数据采用覆盖方式，支持 override 和 absent，可扩展，必填。\n * 0.0.0.0 - 表示对所有 IP 地址生效，如果只想覆盖某个 IP 的数据，请填入具体 IP，必填。\n * com.foo.BarService - 表示只对指定服务生效，必填。\n * category=configurators - 表示该数据为动态配置类型，必填。\n * dynamic=false - 表示该数据为持久数据，当注册方退出时，数据依然保存在注册中心，必填。\n * enabled=true - 覆盖规则是否生效，可不填，缺省生效。\n * application=foo - 表示只对指定应用生效，可不填，表示对所有应用生效。\n * timeout=1000 - 表示将满足以上条件的 timeout 参数的值覆盖为 1000。如果想覆盖其它参数，直接加在 override 的 URL 参数上。\n\n示例：\n\n * 禁用提供者：(通常用于临时踢除某台提供者机器，相似的，禁止消费者访问请使用路由规则)\n\noverride://10.20.153.10/com.foo.BarService?category=configurators&dynamic=false&disbaled=true\n\n\n * 调整权重：(通常用于容量评估，缺省权重为 100)\n\noverride://10.20.153.10/com.foo.BarService?category=configurators&dynamic=false&weight=200\n\n\n * 调整负载均衡策略：(缺省负载均衡策略为 random)\n\noverride://10.20.153.10/com.foo.BarService?category=configurators&dynamic=false&loadbalance=leastactive\n\n\n * 服务降级：(通常用于临时屏蔽某个出错的非关键服务)\n\noverride://0.0.0.0/com.foo.BarService?category=configurators&dynamic=false&application=foo&mock=force:return+null\n\n\n\n# 十、多版本\n\n当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。\n\n可以按照以下的步骤进行版本迁移：\n\n 1. 在低压力时间段，先升级一半提供者为新版本\n 2. 再将所有消费者升级为新版本\n 3. 然后将剩下的一半提供者升级为新版本\n\n老版本服务提供者配置：\n\n<dubbo:service interface="com.foo.BarService" version="1.0.0" />\n\n\n新版本服务提供者配置：\n\n<dubbo:service interface="com.foo.BarService" version="2.0.0" />\n\n\n老版本服务消费者配置：\n\n<dubbo:reference id="barService" interface="com.foo.BarService" version="1.0.0" />\n\n\n新版本服务消费者配置：\n\n<dubbo:reference id="barService" interface="com.foo.BarService" version="2.0.0" />\n\n\n如果不需要区分版本，可以按照以下的方式配置 [1]：\n\n<dubbo:reference id="barService" interface="com.foo.BarService" version="*" />\n\n\n\n# 十一、Dubbo SPI\n\nSPI 全称为 Service Provider Interface，是一种服务发现机制。SPI 的本质是将接口实现类的全限定名配置在文件中，并由服务加载器读取配置文件，加载实现类。这样可以在运行时，动态为接口替换实现类。正因此特性，我们可以很容易的通过 SPI 机制为我们的程序提供拓展功能。SPI 机制在第三方框架中也有所应用，比如 Dubbo 就是通过 SPI 机制加载所有的组件。不过，Dubbo 并未使用 Java 原生的 SPI 机制，而是对其进行了增强，使其能够更好的满足需求。在 Dubbo 中，SPI 是一个非常重要的模块。基于 SPI，我们可以很容易的对 Dubbo 进行拓展。\n\nDubbo SPI 的相关逻辑被封装在了 ExtensionLoader 类中，通过 ExtensionLoader，我们可以加载指定的实现类。Dubbo SPI 所需的配置文件需放置在 META-INF/dubbo 路径下。\n\n\n# 参考资料\n\n * 官方\n   * Dubbo Github\n   * Dubbo 官方文档\n   * 管理员手册\n * 文章\n   * 如何基于 Dubbo 进行服务治理、服务降级、失败重试以及超时重试？',normalizedContent:'# dubbo 快速入门\n\n> apache dubbo 是一款高性能、轻量级的开源 java rpc 框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。\n\n\n# 一、dubbo 简介\n\napache dubbo 是一款高性能、轻量级的开源 java rpc 框架。\n\ndubbo 提供了三大核心能力：\n\n * 面向接口的远程方法调用\n * 智能容错和负载均衡\n * 服务自动注册和发现\n\n\n# rpc 原理简介\n\n# 什么是 rpc\n\nrpc（remote procedure call），即远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。比如两个不同的服务 a、b 部署在两台不同的机器上，那么服务 a 如果想要调用服务 b 中的某个方法该怎么办呢？使用 http 请求 当然可以，但是可能会比较慢而且一些优化做的并不好。 rpc 的出现就是为了解决这个问题。\n\n# rpc 工作流程\n\n\n\n 1. 服务消费方（client）调用以本地调用方式调用服务；\n 2. client stub 接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；\n 3. client stub 找到服务地址，并将消息发送到服务端；\n 4. server stub 收到消息后进行解码；\n 5. server stub 根据解码结果调用本地的服务；\n 6. 本地服务执行并将结果返回给 server stub；\n 7. server stub 将返回结果打包成消息并发送至消费方；\n 8. client stub 接收到消息，并进行解码；\n 9. 服务消费方得到最终结果。\n\n\n# 为什么需要 dubbo\n\n如果你要开发分布式程序，你也可以直接基于 http 接口进行通信，但是为什么要用 dubbo 呢？\n\n我觉得主要可以从 dubbo 提供的下面四点特性来说为什么要用 dubbo：\n\n 1. 负载均衡——同一个服务部署在不同的机器时该调用那一台机器上的服务。\n 2. 服务调用链路——随着系统的发展，服务越来越多，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。dubbo 可以为我们解决服务之间互相是如何调用的。\n 3. 服务访问压力以及时长统计、资源调度和治理——基于访问压力实时管理集群容量，提高集群利用率。\n 4. 服务治理——某个服务挂掉之后调用备用服务。\n\n另外，dubbo 除了能够应用在分布式系统中，也可以应用在现在比较火的微服务系统中。不过，由于 spring cloud 在微服务中应用更加广泛，所以，我觉得一般我们提 dubbo 的话，大部分是分布式系统的情况。\n\n\n# 二、quickstart\n\n（1）添加 maven 依赖\n\n<dependency>\n    <groupid>com.alibaba</groupid>\n    <artifactid>dubbo</artifactid>\n    <version>${dubbo.version}</version>\n</dependency>\n\n\n（2）定义 provider\n\npackage com.alibaba.dubbo.demo;\n\npublic interface demoservice {\n    string sayhello(string name);\n}\n\n\n（3）实现 provider\n\npackage com.alibaba.dubbo.demo.provider;\nimport com.alibaba.dubbo.demo.demoservice;\n\npublic class demoserviceimpl implements demoservice {\n    public string sayhello(string name) {\n        return "hello " + name;\n    }\n}\n\n\n（4）配置 provider\n\n<?xml version="1.0" encoding="utf-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n       xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n       xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"\n       xsi:schemalocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd">\n    <dubbo:application name="demo-provider"/>\n    <dubbo:registry address="multicast://224.5.6.7:1234"/>\n    <dubbo:protocol name="dubbo" port="20880"/>\n    <dubbo:service interface="com.alibaba.dubbo.demo.demoservice" ref="demoservice"/>\n    <bean id="demoservice" class="com.alibaba.dubbo.demo.provider.demoserviceimpl"/>\n</beans>\n\n\n（5）启动 provider\n\nimport org.springframework.context.support.classpathxmlapplicationcontext;\n\npublic class provider {\n    public static void main(string[] args) throws exception {\n        classpathxmlapplicationcontext context = new classpathxmlapplicationcontext(\n                new string[] {"meta-inf/spring/dubbo-demo-provider.xml"});\n        context.start();\n        // press any key to exit\n        system.in.read();\n    }\n}\n\n\n（6）配置 consumer\n\n<?xml version="1.0" encoding="utf-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n       xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n       xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"\n       xsi:schemalocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd">\n    <dubbo:application name="demo-consumer"/>\n    <dubbo:registry address="multicast://224.5.6.7:1234"/>\n    <dubbo:reference id="demoservice" interface="com.alibaba.dubbo.demo.demoservice"/>\n</beans>\n\n\n（7）启动 consumer\n\nimport com.alibaba.dubbo.demo.demoservice;\nimport org.springframework.context.support.classpathxmlapplicationcontext;\n\npublic class consumer {\n    public static void main(string[] args) throws exception {\n        classpathxmlapplicationcontext context = new classpathxmlapplicationcontext(\n                new string[]{"meta-inf/spring/dubbo-demo-consumer.xml"});\n        context.start();\n        // obtain proxy object for remote invocation\n        demoservice demoservice = (demoservice) context.getbean("demoservice");\n        // execute remote invocation\n        string hello = demoservice.sayhello("world");\n        // show the result\n        system.out.println(hello);\n    }\n}\n\n\n\n# 三、dubbo 配置\n\ndubbo 所有配置最终都将转换为 url 表示，并由服务提供方生成，经注册中心传递给消费方，各属性对应 url 的参数，参见配置项一览表中的 "对应 url 参数" 列。\n\n只有 group，interface，version 是服务的匹配条件，三者决定是不是同一个服务，其它配置项均为调优和治理参数。\n\nurl 格式：protocol://username:password@host:port/path?key=value&key=value\n\n\n# 配置方式\n\ndubbo 支持多种配置方式：\n\n * xml 配置\n * properties 配置\n * api 配置\n * 注解配置\n\n如果同时存在多种配置方式，遵循以下覆盖策略：\n\n * jvm 启动 -d 参数优先，这样可以使用户在部署和启动时进行参数重写，比如在启动时需改变协议的端口。\n * xml 次之，如果在 xml 中有配置，则 dubbo.properties 中的相应配置项无效。\n * properties 最后，相当于缺省值，只有 xml 没有配置时，dubbo.properties 的相应配置项才会生效，通常用于共享公共配置，比如应用名。\n\n\n\n# xml 配置\n\n示例：\n\n<?xml version="1.0" encoding="utf-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n    xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n    xmlns:dubbo="http://dubbo.apache.org/schema/dubbo"\n    xsi:schemalocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd">\n    \x3c!-- 提供方应用信息，用于计算依赖关系 --\x3e\n    <dubbo:application name="hello-world-app"  />\n    \x3c!-- 使用 multicast 广播注册中心暴露服务地址 --\x3e\n    <dubbo:registry address="multicast://224.5.6.7:1234" />\n    \x3c!-- 用 dubbo 协议在 20880 端口暴露服务 --\x3e\n    <dubbo:protocol name="dubbo" port="20880" />\n    \x3c!-- 声明需要暴露的服务接口 --\x3e\n    <dubbo:service interface="com.alibaba.dubbo.demo.demoservice" ref="demoservicelocal" />\n    \x3c!-- 和本地 bean 一样实现服务 --\x3e\n    <bean id="demoservice" class="com.alibaba.dubbo.demo.provider.demoserviceimpl" />\n\n    \x3c!-- 生成远程服务代理，可以和本地 bean 一样使用 demoservice --\x3e\n    <dubbo:reference id="demoserviceremote" interface="com.alibaba.dubbo.demo.demoservice" />\n</beans>\n\n\ndubbo 会把以上配置项解析成下面的 url 格式：\n\ndubbo://host-ip:20880/com.alibaba.dubbo.demo.demoservice\n\n\n然后基于扩展点自适应机制，通过 url 的 dubbo:// 协议头识别，就会调用 dubboprotocol 的 export() 方法，打开服务端口 20880，就可以把服务 demoservice 暴露到 20880 端口了。\n\n# properties 配置\n\n示例：\n\ndubbo.application.name=foo\ndubbo.application.owner=bar\ndubbo.registry.address=10.20.153.10:9090\n\n\n\n# 配置项\n\n所有配置项分为三大类：\n\n * 服务发现：表示该配置项用于服务的注册与发现，目的是让消费方找到提供方。\n * 服务治理：表示该配置项用于治理服务间的关系，或为开发测试提供便利条件。\n * 性能调优：表示该配置项用于调优性能，不同的选项对性能会产生影响。\n\n配置项清单：\n\n标签                  用途       解释\ndubbo:service       服务配置     用于暴露一个服务，定义服务的元信息，一个服务可以用多个协议暴露，一个服务也可以注册到多个注册中心\ndubbo:reference     引用配置     用于创建一个远程服务代理，一个引用可以指向多个注册中心\ndubbo:protocol      协议配置     用于配置提供服务的协议信息，协议由提供方指定，消费方被动接受\ndubbo:application   应用配置     用于配置当前应用信息，不管该应用是提供者还是消费者\ndubbo:module        模块配置     用于配置当前模块信息，可选\ndubbo:registry      注册中心配置   用于配置连接注册中心相关信息\ndubbo:monitor       监控中心配置   用于配置连接监控中心相关信息，可选\ndubbo:provider      提供方配置    当 protocolconfig 和 serviceconfig 某属性没有配置时，采用此缺省值，可选\ndubbo:consumer      消费方配置    当 referenceconfig 某属性没有配置时，采用此缺省值，可选\ndubbo:method        方法配置     用于 serviceconfig 和 referenceconfig 指定方法级的配置信息\ndubbo:argument      参数配置     用于指定方法参数配置\n\n> 详细配置说明请参考：官方配置\n\n# 配置之间的关系\n\n\n\n# 配置覆盖关系\n\n以 timeout 为例，显示了配置的查找顺序，其它 retries, loadbalance, actives 等类似：\n\n * 方法级优先，接口级次之，全局配置再次之。\n * 如果级别一样，则消费方优先，提供方次之。\n\n其中，服务提供方配置，通过 url 经由注册中心传递给消费方。\n\n\n### 动态配置中心\n\n配置中心（v2.7.0）在 dubbo 中承担两个职责：\n\n 1. 外部化配置。启动配置的集中式存储 （简单理解为 dubbo.properties 的外部化存储）。\n 2. 服务治理。服务治理规则的存储与通知。\n\n启用动态配置：\n\n<dubbo:config-center address="zookeeper://127.0.0.1:2181"/>\n\n\n或者\n\ndubbo.config-center.address=zookeeper://127.0.0.1:2181\n\n\n或者\n\nconfigcenterconfig configcenter = new configcenterconfig();\nconfigcenter.setaddress("zookeeper://127.0.0.1:2181");\n\n\n\n# 四、dubbo 架构\n\n\n# dubbo 核心组件\n\n\n\n节点角色：\n\n节点          角色说明\nprovider    暴露服务的服务提供方\nconsumer    调用远程服务的服务消费方\nregistry    服务注册与发现的注册中心\nmonitor     统计服务的调用次数和调用时间的监控中心\ncontainer   服务运行容器\n\n调用关系：\n\n 1. 服务容器负责启动，加载，运行服务提供者。\n 2. 服务提供者在启动时，向注册中心注册自己提供的服务。\n 3. 服务消费者在启动时，向注册中心订阅自己所需的服务。\n 4. 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。\n 5. 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。\n 6. 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。\n\n重要知识点总结：\n\n * 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小\n * 监控中心负责统计各服务调用次数，调用时间等，统计先在内存汇总后每分钟一次发送到监控中心服务器，并以报表展示\n * 注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外\n * 注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者\n * 注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表\n * 注册中心和监控中心都是可选的，服务消费者可以直连服务提供者\n * 服务提供者无状态，任意一台宕掉后，不影响使用\n * 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复\n\n> 问：注册中心挂了可以继续通信吗？\n> \n> 答：可以，因为刚开始初始化的时候，消费者会将提供者的地址等信息拉取到本地缓存，所以注册中心挂了可以继续通信。\n\n\n# dubbo 架构层次\n\n\n\n图例说明：\n\n * 图中左边淡蓝背景的为服务消费方使用的接口，右边淡绿色背景的为服务提供方使用的接口，位于中轴线上的为双方都用到的接口。\n * 图中从下至上分为十层，各层均为单向依赖，右边的黑色箭头代表层之间的依赖关系，每一层都可以剥离上层被复用，其中，service 和 config 层为 api，其它各层均为 spi。\n * 图中绿色小块的为扩展接口，蓝色小块为实现类，图中只显示用于关联各层的实现类。\n * 图中蓝色虚线为初始化过程，即启动时组装链，红色实线为方法调用过程，即运行时调时链，紫色三角箭头为继承，可以把子类看作父类的同一个节点，线上的文字为调用的方法。\n\n# 各层说明\n\n * config 配置层：对外配置接口，以 serviceconfig, referenceconfig 为中心，可以直接初始化配置类，也可以通过 spring 解析配置生成配置类\n * proxy 服务代理层：服务接口透明代理，生成服务的客户端 stub 和服务器端 skeleton, 以 serviceproxy 为中心，扩展接口为 proxyfactory\n * registry 注册中心层：封装服务地址的注册与发现，以服务 url 为中心，扩展接口为 registryfactory, registry, registryservice\n * cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 invoker 为中心，扩展接口为 cluster, directory, router, loadbalance\n * monitor 监控层：rpc 调用次数和调用时间监控，以 statistics 为中心，扩展接口为 monitorfactory, monitor, monitorservice\n * protocol 远程调用层：封装 rpc 调用，以 invocation, result 为中心，扩展接口为 protocol, invoker, exporter\n * exchange 信息交换层：封装请求响应模式，同步转异步，以 request, response 为中心，扩展接口为 exchanger, exchangechannel, exchangeclient, exchangeserver\n * transport 网络传输层：抽象 mina 和 netty 为统一接口，以 message 为中心，扩展接口为 channel, transporter, client, server, codec\n * serialize 数据序列化层：可复用的一些工具，扩展接口为 serialization, objectinput, objectoutput, threadpool\n * serialize 数据序列化层：可复用的一些工具，扩展接口为 serialization, objectinput, objectoutput, threadpool\n\n# 各层关系说明\n\n * 在 rpc 中，protocol 是核心层，也就是只要有 protocol + invoker + exporter 就可以完成非透明的 rpc 调用，然后在 invoker 的主过程上 filter 拦截点。\n * 图中的 consumer 和 provider 是抽象概念，只是想让看图者更直观的了解哪些类分属于客户端与服务器端，不用 client 和 server 的原因是 dubbo 在很多场景下都使用 provider, consumer, registry, monitor 划分逻辑拓普节点，保持统一概念。\n * 而 cluster 是外围概念，所以 cluster 的目的是将多个 invoker 伪装成一个 invoker，这样其它人只要关注 protocol 层 invoker 即可，加上 cluster 或者去掉 cluster 对其它层都不会造成影响，因为只有一个提供者时，是不需要 cluster 的。\n * proxy 层封装了所有接口的透明化代理，而在其它层都以 invoker 为中心，只有到了暴露给用户使用时，才用 proxy 将 invoker 转成接口，或将接口实现转成 invoker，也就是去掉 proxy 层 rpc 是可以 run 的，只是不那么透明，不那么看起来像调本地服务一样调远程服务。\n * 而 remoting 实现是 dubbo 协议的实现，如果你选择 rmi 协议，整个 remoting 都不会用上，remoting 内部再划为 transport 传输层和 exchange 信息交换层，transport 层只负责单向消息传输，是对 mina, netty, grizzly 的抽象，它也可以扩展 udp 传输，而 exchange 层是在传输层之上封装了 request-response 语义。\n * registry 和 monitor 实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在一起。\n\n\n# 五、服务发现\n\n服务提供者注册服务的过程：\n\ndubbo 配置项 dubbo://registry 声明了注册中心的地址，dubbo 会把以上配置项解析成类似下面的 url 格式：\n\nregistry://multicast://224.5.6.7:1234/com.alibaba.dubbo.registry.registryservice?export=url.encode("dubbo://host-ip:20880/com.alibaba.dubbo.demo.demoservice")\n\n\n然后基于扩展点自适应机制，通过 url 的“registry://”协议头识别，就会调用 registryprotocol 的 export() 方法，将 export 参数中的提供者 url，注册到注册中心。\n\n服务消费者发现服务的过程：\n\ndubbo 配置项 dubbo://registry 声明了注册中心的地址，跟服务注册的原理类似，dubbo 也会把以上配置项解析成下面的 url 格式：\n\nregistry://multicast://224.5.6.7:1234/com.alibaba.dubbo.registry.registryservice?refer=url.encode("consummer://host-ip/com.alibaba.dubbo.demo.demoservice")\n\n\n然后基于扩展点自适应机制，通过 url 的“registry://”协议头识别，就会调用 registryprotocol 的 refer() 方法，基于 refer 参数中的条件，查询服务 demoservice 的地址。\n\n\n# 启动时检查\n\ndubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 spring 初始化完成，以便上线时，能及早发现问题，默认 check="true"。\n\n可以通过 xml、properties、-d 参数三种方式设置。启动时检查\n\n\n# 六、dubbo 协议\n\ndubbo 支持多种通信协议，不同的协议针对不同的序列化方式。\n\n\n# dubbo 协议\n\ndubbo 协议是 dubbo 的默认通信协议，采用单一长连接和 nio 异步通信，基于 hessian 作为序列化协议。\n\ndubbo 协议适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。反之，dubbo 缺省协议不适合传送大数据量的服务，比如传文件，传视频等，除非请求量很低。\n\n为了要支持高并发场景，一般是服务提供者就几台机器，但是服务消费者有上百台，可能每天调用量达到上亿次！此时用长连接是最合适的，就是跟每个服务消费者维持一个长连接就可以，可能总共就 100 个连接。然后后面直接基于长连接 nio 异步通信，可以支撑高并发请求。\n\n\n# rmi 协议\n\nrmi - 采用 jdk 标准的 java.rmi.* 实现，采用阻塞式短连接和 jdk 标准序列化方式。\n\n注意：如果正在使用 rmi 提供服务给外部访问，同时应用里依赖了老的 common-collections 包的情况下，存在反序列化安全风险。\n\n\n# hessian 协议\n\nhessian 协议用于集成 hessian 的服务，hessian 底层采用 http 通讯，采用 servlet 暴露服务，dubbo 缺省内嵌 jetty 作为服务器实现。\n\ndubbo 的 hessian 协议可以和原生 hessian 服务互操作，即：\n\n * 提供者用 dubbo 的 hessian 协议暴露服务，消费者直接用标准 hessian 接口调用\n * 或者提供方用标准 hessian 暴露服务，消费方用 dubbo 的 hessian 协议调用。\n\n\n# thrift 协议\n\n当前 dubbo 支持的 thrift 协议是对 thrift 原生协议的扩展，在原生协议的基础上添加了一些额外的头信息，比如 service name，magic number 等。\n\n使用 dubbo thrift 协议同样需要使用 thrift 的 idl compiler 编译生成相应的 java 代码，后续版本中会在这方面做一些增强。\n\n\n# http 协议\n\nhttp 协议基于 http 表单的远程调用协议，采用 spring 的 httpinvoker 实现。\n\n使用 json 序列化方式。\n\n\n# webservice 协议\n\n基于 webservice 的远程调用协议，基于 apache cxf 的 frontend-simple 和 transports-http 实现。\n\n使用 soap 序列化方式。\n\n可以和原生 webservice 服务互操作，即：\n\n * 提供者用 dubbo 的 webservice 协议暴露服务，消费者直接用标准 webservice 接口调用，\n * 或者提供方用标准 webservice 暴露服务，消费方用 dubbo 的 webservice 协议调用。\n\n\n# rest 协议\n\n基于标准的 java rest api——jax-rs 2.0（java api for restful web services 的简写）实现的 rest 调用支持\n\n\n# memcached 协议\n\n基于 memcached 实现的 rpc 协议。\n\n\n# redis 协议\n\n基于 redis 实现的 rpc 协议。\n\n> 在现实世界中，序列化有多种方式。\n> \n> jdk 自身提供的序列化方式，效率不高，但是 java 程序使用最多。\n> \n> 如果想要较好的可读性，可以使用 json （常见库有：jackson、gson、fastjson）或 soap （即 xml 形式）\n> \n> 如果想要更好的性能，可以使用 thrift、protobuf、hessian\n> \n> 想深入了解可以参考：序列化\n\n\n# 七、集群容错\n\n在集群调用失败时，dubbo 提供了多种容错方案，缺省为 failover 重试。\n\n\n * failover - 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries="2" 来设置重试次数(不含第一次)。\n * failfast - 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。\n * failsafe - 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。\n * failback - 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。\n * forking - 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks="2" 来设置最大并行数。\n * broadcast - 广播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。\n\n集群容错配置示例：\n\n<dubbo:service cluster="failsafe" />\n<dubbo:reference cluster="failsafe" />\n\n\n\n# 八、负载均衡\n\ndubbo 提供了多种负载均衡（loadbalance）策略，缺省为 random 随机调用。\n\ndubbo 的负载均衡配置可以细粒度到服务、方法级别，且 dubbo:service 和 dubbo:reference 均可配置。\n\n\x3c!-- 服务端服务级别 --\x3e\n<dubbo:service interface="..." loadbalance="roundrobin" />\n\x3c!-- 客户端服务级别 --\x3e\n<dubbo:reference interface="..." loadbalance="roundrobin" />\n\x3c!-- 服务端方法级别 --\x3e\n<dubbo:service interface="...">\n    <dubbo:method name="..." loadbalance="roundrobin"/>\n</dubbo:service>\n\x3c!-- 客户端方法级别 --\x3e\n<dubbo:reference interface="...">\n    <dubbo:method name="..." loadbalance="roundrobin"/>\n</dubbo:reference>\n\n\n# random\n\n * 随机，按权重设置随机概率。\n * 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。\n\n# roundrobin\n\n * 轮询，按公约后的权重设置轮询比率。\n * 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。\n\n# leastactive\n\n * 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。\n * 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。\n\n# consistenthash\n\n * 一致性 hash，相同参数的请求总是发到同一提供者。\n * 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。\n * 算法参见：http://en.wikipedia.org/wiki/consistent_hashing\n * 缺省只对第一个参数 hash，如果要修改，请配置 <dubbo:parameter key="hash.arguments" value="0,1" />\n * 缺省用 160 份虚拟节点，如果要修改，请配置 <dubbo:parameter key="hash.nodes" value="320" />\n\n\n# 九、dubbo 服务治理\n\n\n# 服务治理简介\n\n * 当服务越来越多时，服务 url 配置管理变得非常困难，f5 硬件负载均衡器的单点压力也越来越大。\n * 当进一步发展，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。\n * 接着，服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？\n\n以上问题可以归纳为服务治理问题，这也是 dubbo 的核心功能。\n\n# 调用链路\n\n一个微服务架构，往往由大量分布式服务组成。那么这些服务之间互相是如何调用的？调用链路是啥？说实话，几乎到后面没人搞的清楚了，因为服务实在太多了，可能几百个甚至几千个服务。\n\n那就需要基于 dubbo 做的分布式系统中，对各个服务之间的调用自动记录下来，然后自动将各个服务之间的依赖关系和调用链路生成出来，做成一张图，显示出来，大家才可以看到对吧。\n\n# 服务访问压力以及时长统计\n\n需要自动统计各个接口和服务之间的调用次数以及访问延时，而且要分成两个级别。\n\n * 一个级别是接口粒度，就是每个服务的每个接口每天被调用多少次，tp50/tp90/tp99，三个档次的请求延时分别是多少；\n * 第二个级别是从源头入口开始，一个完整的请求链路经过几十个服务之后，完成一次请求，每天全链路走多少次，全链路请求延时的 tp50/tp90/tp99，分别是多少。\n\n# 其他\n\n * 服务分层（避免循环依赖）\n * 调用链路失败监控和报警\n * 服务鉴权\n * 每个服务的可用性的监控（接口调用成功率？几个 9？99.99%，99.9%，99%）\n\n所谓失败重试，就是 consumer 调用 provider 要是失败了，比如抛异常了，此时应该是可以重试的，或者调用超时了也可以重试。配置如下：\n\n<dubbo:reference id="xxxx" interface="xx" check="true" async="false" retries="3" timeout="2000"/>\n\n\n举个栗子。\n\n某个服务的接口，要耗费 5s，你这边不能干等着，你这边配置了 timeout 之后，我等待 2s，还没返回，我直接就撤了，不能干等你。\n\n可以结合你们公司具体的场景来说说你是怎么设置这些参数的：\n\n * timeout：一般设置为 200ms，我们认为不能超过 200ms 还没返回。\n * retries：设置 retries，一般是在读请求的时候，比如你要查询个数据，你可以设置个 retries，如果第一次没读到，报错，重试指定的次数，尝试再次读取。\n\n\n# 路由规则\n\n路由规则决定一次 dubbo 服务调用的目标服务器，分为条件路由规则和脚本路由规则，并且支持可扩展。\n\n向注册中心写入路由规则的操作通常由监控中心或治理中心的页面完成。\n\nregistryfactory registryfactory = extensionloader.getextensionloader(registryfactory.class).getadaptiveextension();\nregistry registry = registryfactory.getregistry(url.valueof("zookeeper://10.20.153.10:2181"));\nregistry.register(url.valueof("condition://0.0.0.0/com.foo.barservice?category=routers&dynamic=false&rule=" + url.encode("host = 10.20.153.10 => host = 10.20.153.11") + "));\n\n\n * condition:// - 表示路由规则的类型，支持条件路由规则和脚本路由规则，可扩展，必填。\n * 0.0.0.0 - 表示对所有 ip 地址生效，如果只想对某个 ip 的生效，请填入具体 ip，必填。\n * com.foo.barservice - 表示只对指定服务生效，必填。\n * category=routers - 表示该数据为动态配置类型，必填。\n * dynamic=false - 表示该数据为持久数据，当注册方退出时，数据依然保存在注册中心，必填。\n * enabled=true - 覆盖规则是否生效，可不填，缺省生效。\n * force=false - 当路由结果为空时，是否强制执行，如果不强制执行，路由结果为空的路由规则将自动失效，可不填，缺省为 flase。\n * runtime=false - 是否在每次调用时执行路由规则，否则只在提供者地址列表变更时预先执行并缓存结果，调用时直接从缓存中获取路由结果。如果用了参数路由，必须设为 true，需要注意设置会影响调用的性能，可不填，缺省为 flase。\n * priority=1 - 路由规则的优先级，用于排序，优先级越大越靠前执行，可不填，缺省为 0。\n * rule=url.encode("host = 10.20.153.10 => host = 10.20.153.11") - 表示路由规则的内容，必填。\n\n\n# 服务降级\n\n可以通过服务降级功能临时屏蔽某个出错的非关键服务，并定义降级后的返回策略。\n\n向注册中心写入动态配置覆盖规则：\n\nregistryfactory registryfactory = extensionloader.getextensionloader(registryfactory.class).getadaptiveextension();\nregistry registry = registryfactory.getregistry(url.valueof("zookeeper://10.20.153.10:2181"));\nregistry.register(url.valueof("override://0.0.0.0/com.foo.barservice?category=configurators&dynamic=false&application=foo&mock=force:return+null"));\n\n\n其中：\n\nmock=force:return+null 表示消费方对该服务的方法调用都直接返回 null 值，不发起远程调用。用来屏蔽不重要服务不可用时对调用方的影响。 还可以改为 mock=fail:return+null 表示消费方对该服务的方法调用在失败后，再返回 null 值，不抛异常。用来容忍不重要服务不稳定时对调用方的影响。\n\n比如说服务 a 调用服务 b，结果服务 b 挂掉了，服务 a 重试几次调用服务 b，还是不行，那么直接降级，走一个备用的逻辑，给用户返回响应。\n\n举个例子，我们有接口 helloservice。helloserviceimpl 有该接口的具体实现。\n\npublic interface helloservice {\n   void sayhello();\n}\n\npublic class helloserviceimpl implements helloservice {\n    public void sayhello() {\n        system.out.println("hello world......");\n    }\n}\n\n\ndubbo 配置：\n\n\x3c!-- provider 配置 --\x3e\n<?xml version="1.0" encoding="utf-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n    xmlns:xsi="http://www.w3.org/2001/xmlschema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"\n    xsi:schemalocation="http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd">\n\n    <dubbo:application name="dubbo-provider" />\n    <dubbo:registry address="zookeeper://127.0.0.1:2181" />\n    <dubbo:protocol name="dubbo" port="20880" />\n    <dubbo:service interface="com.zhss.service.helloservice" ref="helloserviceimpl" timeout="10000" />\n    <bean id="helloserviceimpl" class="com.zhss.service.helloserviceimpl" />\n\n</beans>\n\n\x3c!-- consumer 配置 --\x3e\n<?xml version="1.0" encoding="utf-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n    xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n    xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"\n    xsi:schemalocation="http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd">\n\n    <dubbo:application name="dubbo-consumer"  />\n\n    <dubbo:registry address="zookeeper://127.0.0.1:2181" />\n\n    <dubbo:reference id="fooservice" interface="com.test.service.fooservice"  timeout="10000" check="false" mock="return null">\n    </dubbo:reference>\n\n</beans>\n\n\n我们调用接口失败的时候，可以通过 mock 统一返回 null。\n\nmock 的值也可以修改为 true，然后再跟接口同一个路径下实现一个 mock 类，命名规则是 “接口名称+mock” 后缀。然后在 mock 类里实现自己的降级逻辑。\n\npublic class helloservicemock implements helloservice {\n    public void sayhello() {\n        // 降级逻辑\n    }\n}\n\n\n\n# 访问控制\n\n# 直连\n\n在开发及测试环境下，经常需要绕过注册中心，只测试指定服务提供者，这时候可能需要点对点直连，点对点直联方式，将以服务接口为单位，忽略注册中心的提供者列表，a 接口配置点对点，不影响 b 接口从注册中心获取列表。\n\n\n\n配置方式：\n\n（1）通过 xml 配置\n\n如果是线上需求需要点对点，可在 dubbo:reference 中配置 url 指向提供者，将绕过注册中心，多个地址用分号隔开，配置如下：\n\n<dubbo:reference id="xxxservice" interface="com.alibaba.xxx.xxxservice" url="dubbo://localhost:20890" />\n\n\n（2）通过 -d 参数指定\n\n在 jvm 启动参数中加入-d 参数映射服务地址：\n\njava -dcom.alibaba.xxx.xxxservice=dubbo://localhost:20890\n\n\n（3）通过文件映射 如果服务比较多，也可以用文件映射，用 -ddubbo.resolve.file 指定映射文件路径，此配置优先级高于 dubbo:reference 中的配置：\n\njava -ddubbo.resolve.file=xxx.properties\n\n\n然后在映射文件 xxx.properties 中加入配置，其中 key 为服务名，value 为服务提供者 url：\n\ncom.alibaba.xxx.xxxservice=dubbo://localhost:20890\n\n\n# 只订阅\n\n为方便开发测试，经常会在线下共用一个所有服务可用的注册中心，这时，如果一个正在开发中的服务提供者注册，可能会影响消费者不能正常运行。\n\n可以让服务提供者开发方，只订阅服务(开发的服务可能依赖其它服务)，而不注册正在开发的服务，通过直连测试正在开发的服务。\n\n禁用注册配置：\n\n<dubbo:registry address="10.20.153.10:9090" register="false" />\n\n\n或者\n\n<dubbo:registry address="10.20.153.10:9090?register=false" />\n\n\n# 只注册\n\n如果有两个镜像环境，两个注册中心，有一个服务只在其中一个注册中心有部署，另一个注册中心还没来得及部署，而两个注册中心的其它应用都需要依赖此服务。这个时候，可以让服务提供者方只注册服务到另一注册中心，而不从另一注册中心订阅服务。\n\n禁用订阅配置\n\n<dubbo:registry id="hzregistry" address="10.20.153.10:9090" />\n<dubbo:registry id="qdregistry" address="10.20.141.150:9090" subscribe="false" />\n\n\n或者\n\n<dubbo:registry id="hzregistry" address="10.20.153.10:9090" />\n<dubbo:registry id="qdregistry" address="10.20.141.150:9090?subscribe=false" />\n\n\n# 静态服务\n\n有时候希望人工管理服务提供者的上线和下线，此时需将注册中心标识为非动态管理模式。\n\n<dubbo:registry address="10.20.141.150:9090" dynamic="false" />\n\n\n或者\n\n<dubbo:registry address="10.20.141.150:9090?dynamic=false" />\n\n\n服务提供者初次注册时为禁用状态，需人工启用。断线时，将不会被自动删除，需人工禁用。\n\n\n# 动态配置\n\n向注册中心写入动态配置覆盖规则。该功能通常由监控中心或治理中心的页面完成。\n\nregistryfactory registryfactory = extensionloader.getextensionloader(registryfactory.class).getadaptiveextension();\nregistry registry = registryfactory.getregistry(url.valueof("zookeeper://10.20.153.10:2181"));\nregistry.register(url.valueof("override://0.0.0.0/com.foo.barservice?category=configurators&dynamic=false&application=foo&timeout=1000"));\n\n\n其中：\n\n * override:// - 表示数据采用覆盖方式，支持 override 和 absent，可扩展，必填。\n * 0.0.0.0 - 表示对所有 ip 地址生效，如果只想覆盖某个 ip 的数据，请填入具体 ip，必填。\n * com.foo.barservice - 表示只对指定服务生效，必填。\n * category=configurators - 表示该数据为动态配置类型，必填。\n * dynamic=false - 表示该数据为持久数据，当注册方退出时，数据依然保存在注册中心，必填。\n * enabled=true - 覆盖规则是否生效，可不填，缺省生效。\n * application=foo - 表示只对指定应用生效，可不填，表示对所有应用生效。\n * timeout=1000 - 表示将满足以上条件的 timeout 参数的值覆盖为 1000。如果想覆盖其它参数，直接加在 override 的 url 参数上。\n\n示例：\n\n * 禁用提供者：(通常用于临时踢除某台提供者机器，相似的，禁止消费者访问请使用路由规则)\n\noverride://10.20.153.10/com.foo.barservice?category=configurators&dynamic=false&disbaled=true\n\n\n * 调整权重：(通常用于容量评估，缺省权重为 100)\n\noverride://10.20.153.10/com.foo.barservice?category=configurators&dynamic=false&weight=200\n\n\n * 调整负载均衡策略：(缺省负载均衡策略为 random)\n\noverride://10.20.153.10/com.foo.barservice?category=configurators&dynamic=false&loadbalance=leastactive\n\n\n * 服务降级：(通常用于临时屏蔽某个出错的非关键服务)\n\noverride://0.0.0.0/com.foo.barservice?category=configurators&dynamic=false&application=foo&mock=force:return+null\n\n\n\n# 十、多版本\n\n当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。\n\n可以按照以下的步骤进行版本迁移：\n\n 1. 在低压力时间段，先升级一半提供者为新版本\n 2. 再将所有消费者升级为新版本\n 3. 然后将剩下的一半提供者升级为新版本\n\n老版本服务提供者配置：\n\n<dubbo:service interface="com.foo.barservice" version="1.0.0" />\n\n\n新版本服务提供者配置：\n\n<dubbo:service interface="com.foo.barservice" version="2.0.0" />\n\n\n老版本服务消费者配置：\n\n<dubbo:reference id="barservice" interface="com.foo.barservice" version="1.0.0" />\n\n\n新版本服务消费者配置：\n\n<dubbo:reference id="barservice" interface="com.foo.barservice" version="2.0.0" />\n\n\n如果不需要区分版本，可以按照以下的方式配置 [1]：\n\n<dubbo:reference id="barservice" interface="com.foo.barservice" version="*" />\n\n\n\n# 十一、dubbo spi\n\nspi 全称为 service provider interface，是一种服务发现机制。spi 的本质是将接口实现类的全限定名配置在文件中，并由服务加载器读取配置文件，加载实现类。这样可以在运行时，动态为接口替换实现类。正因此特性，我们可以很容易的通过 spi 机制为我们的程序提供拓展功能。spi 机制在第三方框架中也有所应用，比如 dubbo 就是通过 spi 机制加载所有的组件。不过，dubbo 并未使用 java 原生的 spi 机制，而是对其进行了增强，使其能够更好的满足需求。在 dubbo 中，spi 是一个非常重要的模块。基于 spi，我们可以很容易的对 dubbo 进行拓展。\n\ndubbo spi 的相关逻辑被封装在了 extensionloader 类中，通过 extensionloader，我们可以加载指定的实现类。dubbo spi 所需的配置文件需放置在 meta-inf/dubbo 路径下。\n\n\n# 参考资料\n\n * 官方\n   * dubbo github\n   * dubbo 官方文档\n   * 管理员手册\n * 文章\n   * 如何基于 dubbo 进行服务治理、服务降级、失败重试以及超时重试？',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 框架",frontmatter:{title:"Java 框架",categories:["编程","Java","框架"],tags:["Java","框架"],abbrlink:"b3f7d0e8",date:"2022-02-18T08:53:11.000Z",hidden:!0,permalink:"/pages/fd4995/"},regularPath:"/13.%E6%A1%86%E6%9E%B6/",relativePath:"13.框架/README.md",key:"v-448a2646",path:"/pages/fd4995/",headers:[{level:2,title:"📖 内容",slug:"📖-内容",normalizedTitle:"📖 内容",charIndex:14},{level:3,title:"Spring",slug:"spring",normalizedTitle:"spring",charIndex:24},{level:3,title:"Spring Boot",slug:"spring-boot",normalizedTitle:"spring boot",charIndex:72},{level:3,title:"ORM",slug:"orm",normalizedTitle:"orm",charIndex:129},{level:3,title:"安全",slug:"安全",normalizedTitle:"安全",charIndex:168},{level:3,title:"IO",slug:"io",normalizedTitle:"io",charIndex:404},{level:3,title:"微服务",slug:"微服务",normalizedTitle:"微服务",charIndex:421},{level:2,title:"📚 资料",slug:"📚-资料",normalizedTitle:"📚 资料",charIndex:439},{level:2,title:"🚪 传送",slug:"🚪-传送",normalizedTitle:"🚪 传送",charIndex:737}],headersStr:"📖 内容 Spring Spring Boot ORM 安全 IO 微服务 📚 资料 🚪 传送",content:"# Java 框架\n\n\n# 📖 内容\n\n\n# Spring\n\n📚 spring-tutorial 是一个 Spring 实战教程。\n\n\n# Spring Boot\n\n📚 Spring Boot 教程 是一个 Spring Boot 实战教程。\n\n\n# ORM\n\n * Mybatis 快速入门\n * Mybatis 原理\n\n\n# 安全\n\n> Java 领域比较流行的安全框架就是 shiro 和 spring-security。\n> \n> shiro 更为简单、轻便，容易理解，能满足大多数基本安全场景下的需要。\n> \n> spring-security 功能更丰富，也比 shiro 更复杂。值得一提的是由于 spring-security 是 spring 团队开发，所以集成 spring 和 spring-boot 框架更容易。\n\n * Shiro\n * SpringSecurity\n\n\n# IO\n\n * Netty\n\n\n# 微服务\n\n * Dubbo\n\n\n# 📚 资料\n\n * Mybatis\n   * Mybatis Github\n   * Mybatis 官网\n   * MyBatis 官方代码生成（mybatis-generator）\n   * MyBatis 官方集成 Spring（mybatis-spring）\n   * Mybatis 官方集成 Spring Boot（mybatis-spring-boot）\n   * MyBatis-Plus - CRUD 扩展插件、代码生成器、分页器等多功能\n   * Mapper - CRUD 扩展插件\n   * Mybatis-PageHelper - Mybatis 通用分页插件\n\n\n# 🚪 传送\n\n◾ 🏠 JAVA-TUTORIAL 首页 ◾ 🎯 我的博客 ◾",normalizedContent:"# java 框架\n\n\n# 📖 内容\n\n\n# spring\n\n📚 spring-tutorial 是一个 spring 实战教程。\n\n\n# spring boot\n\n📚 spring boot 教程 是一个 spring boot 实战教程。\n\n\n# orm\n\n * mybatis 快速入门\n * mybatis 原理\n\n\n# 安全\n\n> java 领域比较流行的安全框架就是 shiro 和 spring-security。\n> \n> shiro 更为简单、轻便，容易理解，能满足大多数基本安全场景下的需要。\n> \n> spring-security 功能更丰富，也比 shiro 更复杂。值得一提的是由于 spring-security 是 spring 团队开发，所以集成 spring 和 spring-boot 框架更容易。\n\n * shiro\n * springsecurity\n\n\n# io\n\n * netty\n\n\n# 微服务\n\n * dubbo\n\n\n# 📚 资料\n\n * mybatis\n   * mybatis github\n   * mybatis 官网\n   * mybatis 官方代码生成（mybatis-generator）\n   * mybatis 官方集成 spring（mybatis-spring）\n   * mybatis 官方集成 spring boot（mybatis-spring-boot）\n   * mybatis-plus - crud 扩展插件、代码生成器、分页器等多功能\n   * mapper - crud 扩展插件\n   * mybatis-pagehelper - mybatis 通用分页插件\n\n\n# 🚪 传送\n\n◾ 🏠 java-tutorial 首页 ◾ 🎯 我的博客 ◾",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"消息队列面试",frontmatter:{title:"消息队列面试",categories:["编程","Java","中间件","MQ"],tags:["Java","中间件","MQ","面试"],abbrlink:"82d4fac9",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/5a6cf3/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/01.MQ/01.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%9D%A2%E8%AF%95.html",relativePath:"14.中间件/01.MQ/01.消息队列面试.md",key:"v-6aa69b5a",path:"/pages/5a6cf3/",headers:[{level:2,title:"为什么使用消息队列？",slug:"为什么使用消息队列",normalizedTitle:"为什么使用消息队列？",charIndex:18},{level:3,title:"解耦",slug:"解耦",normalizedTitle:"解耦",charIndex:33},{level:3,title:"异步",slug:"异步",normalizedTitle:"异步",charIndex:565},{level:3,title:"削峰",slug:"削峰",normalizedTitle:"削峰",charIndex:1017},{level:2,title:"消息队列有什么优缺点",slug:"消息队列有什么优缺点",normalizedTitle:"消息队列有什么优缺点",charIndex:1652},{level:2,title:"Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？",slug:"kafka、activemq、rabbitmq、rocketmq-有什么优缺点",normalizedTitle:"kafka、activemq、rabbitmq、rocketmq 有什么优缺点？",charIndex:2149},{level:2,title:"如何保证消息队列的高可用？",slug:"如何保证消息队列的高可用",normalizedTitle:"如何保证消息队列的高可用？",charIndex:3976},{level:3,title:"RabbitMQ 的高可用性",slug:"rabbitmq-的高可用性",normalizedTitle:"rabbitmq 的高可用性",charIndex:3994},{level:4,title:"单机模式",slug:"单机模式",normalizedTitle:"单机模式",charIndex:4101},{level:4,title:"普通集群模式（无高可用性）",slug:"普通集群模式-无高可用性",normalizedTitle:"普通集群模式（无高可用性）",charIndex:4179},{level:4,title:"镜像集群模式（高可用性）",slug:"镜像集群模式-高可用性",normalizedTitle:"镜像集群模式（高可用性）",charIndex:4689},{level:3,title:"Kafka 的高可用性",slug:"kafka-的高可用性",normalizedTitle:"kafka 的高可用性",charIndex:5307},{level:2,title:"如何保证消息不被重复消费？（如何保证消息消费的幂等性）",slug:"如何保证消息不被重复消费-如何保证消息消费的幂等性",normalizedTitle:"如何保证消息不被重复消费？（如何保证消息消费的幂等性）",charIndex:6781},{level:2,title:"如何保证消息的可靠性传输？（如何处理消息丢失的问题）",slug:"如何保证消息的可靠性传输-如何处理消息丢失的问题",normalizedTitle:"如何保证消息的可靠性传输？（如何处理消息丢失的问题）",charIndex:8332},{level:3,title:"RabbitMQ",slug:"rabbitmq",normalizedTitle:"rabbitmq",charIndex:2164},{level:4,title:"生产者弄丢了数据",slug:"生产者弄丢了数据",normalizedTitle:"生产者弄丢了数据",charIndex:8434},{level:4,title:"RabbitMQ 弄丢了数据",slug:"rabbitmq-弄丢了数据",normalizedTitle:"rabbitmq 弄丢了数据",charIndex:9297},{level:4,title:"消费端弄丢了数据",slug:"消费端弄丢了数据",normalizedTitle:"消费端弄丢了数据",charIndex:9933},{level:3,title:"Kafka",slug:"kafka",normalizedTitle:"kafka",charIndex:2149},{level:4,title:"消费端弄丢了数据",slug:"消费端弄丢了数据-2",normalizedTitle:"消费端弄丢了数据",charIndex:9933},{level:4,title:"Kafka 弄丢了数据",slug:"kafka-弄丢了数据",normalizedTitle:"kafka 弄丢了数据",charIndex:10672},{level:4,title:"生产者会不会弄丢数据？",slug:"生产者会不会弄丢数据",normalizedTitle:"生产者会不会弄丢数据？",charIndex:11391},{level:2,title:"如何保证消息的顺序性？",slug:"如何保证消息的顺序性",normalizedTitle:"如何保证消息的顺序性？",charIndex:11518},{level:3,title:"解决方案",slug:"解决方案",normalizedTitle:"解决方案",charIndex:12413},{level:4,title:"RabbitMQ",slug:"rabbitmq-2",normalizedTitle:"rabbitmq",charIndex:2164},{level:4,title:"Kafka",slug:"kafka-2",normalizedTitle:"kafka",charIndex:2149},{level:2,title:"如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？",slug:"如何解决消息队列的延时以及过期失效问题-消息队列满了以后该怎么处理-有几百万消息持续积压几小时-说说怎么解决",normalizedTitle:"如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？",charIndex:12598},{level:3,title:"面试题剖析",slug:"面试题剖析",normalizedTitle:"面试题剖析",charIndex:12932},{level:3,title:"大量消息在 mq 里积压了几个小时了还没解决",slug:"大量消息在-mq-里积压了几个小时了还没解决",normalizedTitle:"大量消息在 mq 里积压了几个小时了还没解决",charIndex:13007},{level:3,title:"mq 中的消息过期失效了",slug:"mq-中的消息过期失效了",normalizedTitle:"mq 中的消息过期失效了",charIndex:13663},{level:3,title:"mq 都快写满了",slug:"mq-都快写满了",normalizedTitle:"mq 都快写满了",charIndex:14121},{level:2,title:"如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路。",slug:"如果让你写一个消息队列-该如何进行架构设计啊-说一下你的思路。",normalizedTitle:"如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路。",charIndex:14265},{level:3,title:"面试官心理分析",slug:"面试官心理分析",normalizedTitle:"面试官心理分析",charIndex:14301},{level:3,title:"面试题剖析",slug:"面试题剖析-2",normalizedTitle:"面试题剖析",charIndex:12932}],headersStr:"为什么使用消息队列？ 解耦 异步 削峰 消息队列有什么优缺点 Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？ 如何保证消息队列的高可用？ RabbitMQ 的高可用性 单机模式 普通集群模式（无高可用性） 镜像集群模式（高可用性） Kafka 的高可用性 如何保证消息不被重复消费？（如何保证消息消费的幂等性） 如何保证消息的可靠性传输？（如何处理消息丢失的问题） RabbitMQ 生产者弄丢了数据 RabbitMQ 弄丢了数据 消费端弄丢了数据 Kafka 消费端弄丢了数据 Kafka 弄丢了数据 生产者会不会弄丢数据？ 如何保证消息的顺序性？ 解决方案 RabbitMQ Kafka 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？ 面试题剖析 大量消息在 mq 里积压了几个小时了还没解决 mq 中的消息过期失效了 mq 都快写满了 如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路。 面试官心理分析 面试题剖析",content:"# 消息队列面试夺命连环问\n\n\n# 为什么使用消息队列？\n\n\n# 解耦\n\n看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃......\n\n\n\n在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！\n\n如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。\n\n\n\n总结：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。\n\n面试技巧：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个 MQ 去进行系统的解耦。在简历中体现出来这块东西，用 MQ 作解耦。\n\n\n# 异步\n\n再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。\n\n\n\n一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。\n\n如果使用 MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！\n\n\n\n\n# 削峰\n\n每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。\n\n一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。\n\n但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。\n\n\n\n如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。\n\n\n\n这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉。\n\n\n# 消息队列有什么优缺点\n\n优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。\n\n缺点有以下几个：\n\n * 系统可用性降低 系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用，可以点击这里查看。\n * 系统复杂度提高 硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。\n * 一致性问题 A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。\n\n所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。\n\n\n# Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？\n\n特性                ACTIVEMQ                     RABBITMQ                        ROCKETMQ                                      KAFKA\n单机吞吐量             万级，比 RocketMQ、Kafka 低一个数量级   同 ActiveMQ                      10 万级，支撑高吞吐                                   10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景\ntopic 数量对吞吐量的影响                                                                topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ   topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic\n                                                                               的一大优势，在同等机器下，可以支撑大量的 topic                    数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源\n时效性               ms 级                         微秒级，这是 RabbitMQ 的一大特点，延迟最低      ms 级                                          延迟在 ms 级以内\n可用性               高，基于主从架构实现高可用                同 ActiveMQ                      非常高，分布式架构                                     非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用\n消息可靠性             有较低的概率丢失数据                   基本不丢                            经过参数优化配置，可以做到 0 丢失                            同 RocketMQ\n功能支持              MQ 领域的功能极其完备                 基于 erlang 开发，并发能力很强，性能极好，延时很低   MQ 功能较为完善，还是分布式的，扩展性好                         功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用\n\n综上，各种对比之后，有如下建议：\n\n * 一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；\n * 后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；\n * 不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。\n * 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。\n * 如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。\n\n\n# 如何保证消息队列的高可用？\n\n\n# RabbitMQ 的高可用性\n\nRabbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。\n\nRabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。\n\n# 单机模式\n\n单机模式，就是 Demo 级别的，一般就是你本地启动了玩玩儿的 😄，没人生产用单机模式。\n\n# 普通集群模式（无高可用性）\n\n普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。\n\n\n\n这种方式确实很麻烦，也不怎么好，没做到所谓的分布式，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。\n\n而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让 RabbitMQ 落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。\n\n所以这个事儿就比较尴尬了，这就没有什么所谓的高可用性，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。\n\n# 镜像集群模式（高可用性）\n\n这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。\n\n\n\n那么如何开启这个镜像集群模式呢？其实很简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。\n\n这样的话，好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！第二，这么玩儿，不是分布式的，就没有扩展性可言了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并没有办法线性扩展你的 queue。你想，如果这个 queue 的数据量很大，大到这个机器上的容量无法容纳了，此时该怎么办呢？\n\n\n# Kafka 的高可用性\n\nKafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。\n\n这就是天然的分布式消息队列，就是说一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。\n\n实际上 RabbmitMQ 之类的，并不是分布式消息队列，它就是传统的消息队列，只不过提供了一些集群、HA(High Availability, 高可用性) 的机制而已，因为无论怎么玩儿，RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。\n\nKafka 0.8 以前，是没有 HA 机制的，就是任何一个 broker 宕机了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言。\n\n比如说，我们假设创建了一个 topic，指定其 partition 数量是 3 个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 的 1/3 的数据就丢了，因此这个是做不到高可用的。\n\n\n\nKafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader？很简单，要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题，系统复杂度太高，很容易出问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。\n\n\n\n这么搞，就有所谓的高可用性了，因为如果某个 broker 宕机了，没事儿，那个 broker 上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中重新选举一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。\n\n写数据的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）\n\n消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。\n\n看到这里，相信你大致明白了 Kafka 是如何保证高可用机制的了，对吧？不至于一无所知，现场还能给面试官画画图。要是遇上面试官确实是 Kafka 高手，深挖了问，那你只能说不好意思，太深入的你没研究过。\n\n\n# 如何保证消息不被重复消费？（如何保证消息消费的幂等性）\n\n首先，比如 RabbitMQ、RocketMQ、Kafka，都有可能会出现消息重复消费的问题，正常。因为这问题通常不是 MQ 自己保证的，是由我们开发来保证的。挑一个 Kafka 来举个例子，说说怎么重复消费吧。\n\nKafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。\n\n但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接 kill 进程了，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset，尴尬了。重启之后，少数消息会再次消费一次。\n\n举个栗子。\n\n有这么个场景。数据 1/2/3 依次进入 kafka，kafka 会给这三条数据每条分配一个 offset，代表这条数据的序号，我们就假设分配的 offset 依次是 152/153/154。消费者从 kafka 去消费的时候，也是按照这个顺序去消费。假如当消费者消费了 offset=153 的这条数据，刚准备去提交 offset 到 zookeeper，此时消费者进程被重启了。那么此时消费过的数据 1/2 的 offset 并没有提交，kafka 也就不知道你已经消费了 offset=153 这条数据。那么重启之后，消费者会找 kafka 说，嘿，哥儿们，你给我接着把上次我消费到的那个地方后面的数据继续给我传递过来。由于之前的 offset 没有提交成功，那么数据 1/2 会再次传过来，如果此时消费者没有去重的话，那么就会导致重复消费。\n\n\n\n如果消费者干的事儿是拿一条数据就往数据库里写一条，会导致说，你可能就把数据 1/2 在数据库里插入了 2 次，那么数据就错啦。\n\n其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性。\n\n举个例子吧。假设你有个系统，消费一条消息就往数据库里插入一条数据，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数据，从而保证了数据的正确性。\n\n一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性。\n\n幂等性，通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。\n\n所以第二个问题来了，怎么保证消息队列消费的幂等性？\n\n其实还是得结合业务来思考，我这里给几个思路：\n\n * 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。\n * 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。\n * 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。\n * 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。\n\n\n\n当然，如何保证 MQ 的消费是幂等性的，需要结合具体的业务来看。\n\n\n# 如何保证消息的可靠性传输？（如何处理消息丢失的问题）\n\n数据的丢失问题，可能出现在生产者、MQ、消费者中，咱们从 RabbitMQ 和 Kafka 分别来分析一下吧。\n\n\n# RabbitMQ\n\n\n\n# 生产者弄丢了数据\n\n生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢了，因为网络问题啥的，都有可能。\n\n此时可以选择用 RabbitMQ 提供的事务功能，就是生产者发送数据之前开启 RabbitMQ 事务channel.txSelect，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txCommit。\n\n// 开启事务\nchannel.txSelect\ntry {\n    // 这里发送消息\n} catch (Exception e) {\n    channel.txRollback\n\n    // 这里再次重发这条消息\n}\n\n// 提交事务\nchannel.txCommit\n\n\n但是问题是，RabbitMQ 事务机制（同步）一搞，基本上吞吐量会下来，因为太耗性能。\n\n所以一般来说，如果你要确保说写 RabbitMQ 的消息别丢，可以开启 confirm 模式，在生产者那里设置开启 confirm模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 nack 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。\n\n事务机制和 confirm 机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是 confirm 机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。\n\n所以一般在生产者这块避免数据丢失，都是用 confirm 机制的。\n\n# RabbitMQ 弄丢了数据\n\n就是 RabbitMQ 自己弄丢了数据，这个你必须开启 RabbitMQ 的持久化，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率较小。\n\n设置持久化有两个步骤：\n\n * 创建 queue 的时候将其设置为持久化 这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。\n * 第二个是发送消息的时候将消息的 deliveryMode 设置为 2 就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。\n\n必须要同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。\n\n注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。\n\n所以，持久化可以跟生产者那边的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 ack，你也是可以自己重发的。\n\n# 消费端弄丢了数据\n\nRabbitMQ 如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。\n\n这个时候得用 RabbitMQ 提供的 ack 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 ack，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 ack 一把。这样的话，如果你还没处理完，不就没有 ack 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。\n\n\n\n\n# Kafka\n\n# 消费端弄丢了数据\n\n唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边自动提交了 offset，让 Kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。\n\n这不是跟 RabbitMQ 差不多吗，大家都知道 Kafka 会自动提交 offset，那么只要关闭自动提交 offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是可能会有重复消费，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。\n\n生产环境碰到的一个问题，就是说我们的 Kafka 消费者消费到了数据之后是写到一个内存的 queue 里先缓冲一下，结果有的时候，你刚把消息写入内存 queue，然后消费者会自动提交 offset。然后此时我们重启了系统，就会导致内存 queue 里还没来得及处理的数据就丢失了。\n\n# Kafka 弄丢了数据\n\n这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。\n\n生产环境也遇到过，我们也是，之前 Kafka 的 leader 机器宕机了，将 follower 切换为 leader 之后，就会发现说这个数据就丢了。\n\n所以此时一般是要求起码设置如下 4 个参数：\n\n * 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。\n * 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。\n * 在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。\n * 在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。\n\n我们生产环境就是按照上述要求配置的，这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。\n\n# 生产者会不会弄丢数据？\n\n如果按照上述的思路设置了 acks=all，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。\n\n\n# 如何保证消息的顺序性？\n\n我举个例子，我们以前做过一个 mysql binlog 同步的系统，压力还是非常大的，日同步数据要达到上亿，就是说数据从一个 mysql 库原封不动地同步到另一个 mysql 库里面去（mysql -> mysql）。常见的一点在于说比如大数据 team，就需要同步一个 mysql 库过来，对公司的业务系统的数据做各种复杂的操作。\n\n你在 mysql 里增删改一条数据，对应出来了增删改 3 条 binlog 日志，接着这三条 binlog 发送到 MQ 里面，再消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。\n\n本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。\n\n先看看顺序会错乱的俩场景：\n\n * RabbitMQ：一个 queue，多个 consumer。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者 2 先执行完操作，把 data2 存入数据库，然后是 data1/data3。这不明显乱了。\n\n\n\n * Kafka：比如说我们建了一个 topic，有三个 partition。生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。 消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞多个线程来并发处理消息。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十 ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而多个线程并发跑的话，顺序可能就乱掉了。\n\n\n\n\n# 解决方案\n\n# RabbitMQ\n\n\n\n# Kafka\n\n * 一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。\n * 写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。\n\n\n\n\n# 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？\n\n你看这问法，其实本质针对的场景，都是说，可能你的消费端出了问题，不消费了；或者消费的速度极其慢。接着就坑爹了，可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是这整个就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如 RabbitMQ 设置了消息过期时间后就没了怎么办？\n\n所以就这事儿，其实线上挺常见的，一般不出，一出就是大 case。一般常见于，举个例子，消费端每次消费之后要写 mysql，结果 mysql 挂了，消费端 hang 那儿了，不动了；或者是消费端出了个什么岔子，导致消费速度极其慢。\n\n\n# 面试题剖析\n\n关于这个事儿，我们一个一个来梳理吧，先假设一个场景，我们现在消费端出故障了，然后大量消息在 mq 里积压，现在出事故了，慌了。\n\n\n# 大量消息在 mq 里积压了几个小时了还没解决\n\n几千万条数据在 MQ 里积压了七八个小时，从下午 4 点多，积压到了晚上 11 点多。这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复 consumer 的问题，让它恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。\n\n一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟就是 18 万条。所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来。\n\n一般这个时候，只能临时紧急扩容了，具体操作步骤和思路如下：\n\n * 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。\n * 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。\n * 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。\n * 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。\n * 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。\n\n\n# mq 中的消息过期失效了\n\n假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。\n\n这个情况下，就不是说要增加 consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上 12 点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。\n\n假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。\n\n\n# mq 都快写满了\n\n如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。\n\n\n# 如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路。\n\n\n# 面试官心理分析\n\n其实聊到这个问题，一般面试官要考察两块：\n\n * 你有没有对某一个消息队列做过较为深入的原理的了解，或者从整体了解把握住一个消息队列的架构原理。\n * 看看你的设计能力，给你一个常见的系统，就是消息队列系统，看看你能不能从全局把握一下整体架构设计，给出一些关键点出来。\n\n说实话，问类似问题的时候，大部分人基本都会蒙，因为平时从来没有思考过类似的问题，大多数人就是平时埋头用，从来不去思考背后的一些东西。类似的问题，比如，如果让你来设计一个 Spring 框架你会怎么做？如果让你来设计一个 Dubbo 框架你会怎么做？如果让你来设计一个 MyBatis 框架你会怎么做？\n\n\n# 面试题剖析\n\n其实回答这类问题，说白了，不求你看过那技术的源码，起码你要大概知道那个技术的基本原理、核心组成部分、基本架构构成，然后参照一些开源的技术把一个系统设计出来的思路说一下就好。\n\n比如说这个消息队列系统，我们从以下几个角度来考虑一下：\n\n * 首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？\n * 其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。\n * 其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。\n * 能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。\n\nmq 肯定是很复杂的，面试官问你这个问题，其实是个开放题，他就是看看你有没有从架构角度整体构思和设计的思维以及能力。确实这个问题可以刷掉一大批人，因为大部分人平时不思考这些东西。",normalizedContent:"# 消息队列面试夺命连环问\n\n\n# 为什么使用消息队列？\n\n\n# 解耦\n\n看这么个场景。a 系统发送数据到 bcd 三个系统，通过接口调用发送。如果 e 系统也要这个数据呢？那如果 c 系统现在不需要了呢？a 系统负责人几乎崩溃......\n\n\n\n在这个场景中，a 系统跟其它各种乱七八糟的系统严重耦合，a 系统产生一条比较关键的数据，很多系统都需要 a 系统将这个数据发送过来。a 系统要时时刻刻考虑 bcde 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！\n\n如果使用 mq，a 系统产生一条数据，发送到 mq 里面去，哪个系统需要数据自己去 mq 里面消费。如果新系统需要数据，直接从 mq 里消费即可；如果某个系统不需要这条数据了，就取消对 mq 消息的消费即可。这样下来，a 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。\n\n\n\n总结：通过一个 mq，pub/sub 发布订阅消息这么一个模型，a 系统就跟其它系统彻底解耦了。\n\n面试技巧：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 mq 给它异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个 mq 去进行系统的解耦。在简历中体现出来这块东西，用 mq 作解耦。\n\n\n# 异步\n\n再来看一个场景，a 系统接收一个请求，需要在自己本地写库，还需要在 bcd 三个系统写库，自己本地写库要 3ms，bcd 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。\n\n\n\n一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。\n\n如果使用 mq，那么 a 系统连续发送 3 条消息到 mq 队列中，假如耗时 5ms，a 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！\n\n\n\n\n# 削峰\n\n每天 0:00 到 12:00，a 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 mysql 的，大量的请求涌入 mysql，每秒钟对 mysql 执行约 5k 条 sql。\n\n一般的 mysql，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 mysql 给打死了，导致系统崩溃，用户也就没法再使用系统了。\n\n但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。\n\n\n\n如果使用 mq，每秒 5k 个请求写入 mq，a 系统每秒钟最多处理 2k 个请求，因为 mysql 每秒钟最多处理 2k 个。a 系统从 mq 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，a 系统也绝对不会挂掉。而 mq 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 mq 中。\n\n\n\n这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 mq，但是 a 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，a 系统就会快速将积压的消息给解决掉。\n\n\n# 消息队列有什么优缺点\n\n优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。\n\n缺点有以下几个：\n\n * 系统可用性降低 系统引入的外部依赖越多，越容易挂掉。本来你就是 a 系统调用 bcd 三个系统的接口就好了，人 abcd 四个系统好好的，没啥问题，你偏加个 mq 进来，万一 mq 挂了咋整，mq 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用，可以点击这里查看。\n * 系统复杂度提高 硬生生加个 mq 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。\n * 一致性问题 a 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 bcd 三个系统那里，bd 两个系统写库成功了，结果 c 系统写库失败了，咋整？你这数据就不一致了。\n\n所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。\n\n\n# kafka、activemq、rabbitmq、rocketmq 有什么优缺点？\n\n特性                activemq                     rabbitmq                        rocketmq                                      kafka\n单机吞吐量             万级，比 rocketmq、kafka 低一个数量级   同 activemq                      10 万级，支撑高吞吐                                   10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景\ntopic 数量对吞吐量的影响                                                                topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 rocketmq   topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，kafka 尽量保证 topic\n                                                                               的一大优势，在同等机器下，可以支撑大量的 topic                    数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源\n时效性               ms 级                         微秒级，这是 rabbitmq 的一大特点，延迟最低      ms 级                                          延迟在 ms 级以内\n可用性               高，基于主从架构实现高可用                同 activemq                      非常高，分布式架构                                     非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用\n消息可靠性             有较低的概率丢失数据                   基本不丢                            经过参数优化配置，可以做到 0 丢失                            同 rocketmq\n功能支持              mq 领域的功能极其完备                 基于 erlang 开发，并发能力很强，性能极好，延时很低   mq 功能较为完善，还是分布式的，扩展性好                         功能较为简单，主要支持简单的 mq 功能，在大数据领域的实时计算以及日志采集被大规模使用\n\n综上，各种对比之后，有如下建议：\n\n * 一般的业务系统要引入 mq，最早大家都用 activemq，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；\n * 后来大家开始用 rabbitmq，但是确实 erlang 语言阻止了大量的 java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；\n * 不过现在确实越来越多的公司会去用 rocketmq，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 rocketmq 已捐给 apache，但 github 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 rocketmq，否则回去老老实实用 rabbitmq 吧，人家有活跃的开源社区，绝对不会黄。\n * 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 rabbitmq 是不错的选择；大型公司，基础架构研发实力较强，用 rocketmq 是很好的选择。\n * 如果是大数据领域的实时计算、日志采集等场景，用 kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。\n\n\n# 如何保证消息队列的高可用？\n\n\n# rabbitmq 的高可用性\n\nrabbitmq 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，我们就以 rabbitmq 为例子讲解第一种 mq 的高可用性怎么实现。\n\nrabbitmq 有三种模式：单机模式、普通集群模式、镜像集群模式。\n\n# 单机模式\n\n单机模式，就是 demo 级别的，一般就是你本地启动了玩玩儿的 😄，没人生产用单机模式。\n\n# 普通集群模式（无高可用性）\n\n普通集群模式，意思就是在多台机器上启动多个 rabbitmq 实例，每个机器启动一个。你创建的 queue，只会放在一个 rabbitmq 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。\n\n\n\n这种方式确实很麻烦，也不怎么好，没做到所谓的分布式，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。\n\n而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让 rabbitmq 落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。\n\n所以这个事儿就比较尴尬了，这就没有什么所谓的高可用性，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。\n\n# 镜像集群模式（高可用性）\n\n这种模式，才是所谓的 rabbitmq 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 rabbitmq 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。\n\n\n\n那么如何开启这个镜像集群模式呢？其实很简单，rabbitmq 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。\n\n这样的话，好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！第二，这么玩儿，不是分布式的，就没有扩展性可言了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并没有办法线性扩展你的 queue。你想，如果这个 queue 的数据量很大，大到这个机器上的容量无法容纳了，此时该怎么办呢？\n\n\n# kafka 的高可用性\n\nkafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。\n\n这就是天然的分布式消息队列，就是说一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。\n\n实际上 rabbmitmq 之类的，并不是分布式消息队列，它就是传统的消息队列，只不过提供了一些集群、ha(high availability, 高可用性) 的机制而已，因为无论怎么玩儿，rabbitmq 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。\n\nkafka 0.8 以前，是没有 ha 机制的，就是任何一个 broker 宕机了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言。\n\n比如说，我们假设创建了一个 topic，指定其 partition 数量是 3 个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 的 1/3 的数据就丢了，因此这个是做不到高可用的。\n\n\n\nkafka 0.8 以后，提供了 ha 机制，就是 replica（复制品） 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader？很简单，要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题，系统复杂度太高，很容易出问题。kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。\n\n\n\n这么搞，就有所谓的高可用性了，因为如果某个 broker 宕机了，没事儿，那个 broker 上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中重新选举一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。\n\n写数据的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）\n\n消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。\n\n看到这里，相信你大致明白了 kafka 是如何保证高可用机制的了，对吧？不至于一无所知，现场还能给面试官画画图。要是遇上面试官确实是 kafka 高手，深挖了问，那你只能说不好意思，太深入的你没研究过。\n\n\n# 如何保证消息不被重复消费？（如何保证消息消费的幂等性）\n\n首先，比如 rabbitmq、rocketmq、kafka，都有可能会出现消息重复消费的问题，正常。因为这问题通常不是 mq 自己保证的，是由我们开发来保证的。挑一个 kafka 来举个例子，说说怎么重复消费吧。\n\nkafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。\n\n但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接 kill 进程了，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset，尴尬了。重启之后，少数消息会再次消费一次。\n\n举个栗子。\n\n有这么个场景。数据 1/2/3 依次进入 kafka，kafka 会给这三条数据每条分配一个 offset，代表这条数据的序号，我们就假设分配的 offset 依次是 152/153/154。消费者从 kafka 去消费的时候，也是按照这个顺序去消费。假如当消费者消费了 offset=153 的这条数据，刚准备去提交 offset 到 zookeeper，此时消费者进程被重启了。那么此时消费过的数据 1/2 的 offset 并没有提交，kafka 也就不知道你已经消费了 offset=153 这条数据。那么重启之后，消费者会找 kafka 说，嘿，哥儿们，你给我接着把上次我消费到的那个地方后面的数据继续给我传递过来。由于之前的 offset 没有提交成功，那么数据 1/2 会再次传过来，如果此时消费者没有去重的话，那么就会导致重复消费。\n\n\n\n如果消费者干的事儿是拿一条数据就往数据库里写一条，会导致说，你可能就把数据 1/2 在数据库里插入了 2 次，那么数据就错啦。\n\n其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性。\n\n举个例子吧。假设你有个系统，消费一条消息就往数据库里插入一条数据，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数据，从而保证了数据的正确性。\n\n一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性。\n\n幂等性，通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。\n\n所以第二个问题来了，怎么保证消息队列消费的幂等性？\n\n其实还是得结合业务来思考，我这里给几个思路：\n\n * 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。\n * 比如你是写 redis，那没问题了，反正每次都是 set，天然幂等性。\n * 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。\n * 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。\n\n\n\n当然，如何保证 mq 的消费是幂等性的，需要结合具体的业务来看。\n\n\n# 如何保证消息的可靠性传输？（如何处理消息丢失的问题）\n\n数据的丢失问题，可能出现在生产者、mq、消费者中，咱们从 rabbitmq 和 kafka 分别来分析一下吧。\n\n\n# rabbitmq\n\n\n\n# 生产者弄丢了数据\n\n生产者将数据发送到 rabbitmq 的时候，可能数据就在半路给搞丢了，因为网络问题啥的，都有可能。\n\n此时可以选择用 rabbitmq 提供的事务功能，就是生产者发送数据之前开启 rabbitmq 事务channel.txselect，然后发送消息，如果消息没有成功被 rabbitmq 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txrollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txcommit。\n\n// 开启事务\nchannel.txselect\ntry {\n    // 这里发送消息\n} catch (exception e) {\n    channel.txrollback\n\n    // 这里再次重发这条消息\n}\n\n// 提交事务\nchannel.txcommit\n\n\n但是问题是，rabbitmq 事务机制（同步）一搞，基本上吞吐量会下来，因为太耗性能。\n\n所以一般来说，如果你要确保说写 rabbitmq 的消息别丢，可以开启 confirm 模式，在生产者那里设置开启 confirm模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 rabbitmq 中，rabbitmq 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。如果 rabbitmq 没能处理这个消息，会回调你的一个 nack 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。\n\n事务机制和 confirm 机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是 confirm 机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息 rabbitmq 接收了之后会异步回调你的一个接口通知你这个消息接收到了。\n\n所以一般在生产者这块避免数据丢失，都是用 confirm 机制的。\n\n# rabbitmq 弄丢了数据\n\n就是 rabbitmq 自己弄丢了数据，这个你必须开启 rabbitmq 的持久化，就是消息写入之后会持久化到磁盘，哪怕是 rabbitmq 自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，rabbitmq 还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率较小。\n\n设置持久化有两个步骤：\n\n * 创建 queue 的时候将其设置为持久化 这样就可以保证 rabbitmq 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。\n * 第二个是发送消息的时候将消息的 deliverymode 设置为 2 就是将消息设置为持久化的，此时 rabbitmq 就会将消息持久化到磁盘上去。\n\n必须要同时设置这两个持久化才行，rabbitmq 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。\n\n注意，哪怕是你给 rabbitmq 开启了持久化机制，也有一种可能，就是这个消息写到了 rabbitmq 中，但是还没来得及持久化到磁盘上，结果不巧，此时 rabbitmq 挂了，就会导致内存里的一点点数据丢失。\n\n所以，持久化可以跟生产者那边的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack 了，所以哪怕是在持久化到磁盘之前，rabbitmq 挂了，数据丢了，生产者收不到 ack，你也是可以自己重发的。\n\n# 消费端弄丢了数据\n\nrabbitmq 如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，rabbitmq 认为你都消费了，这数据就丢了。\n\n这个时候得用 rabbitmq 提供的 ack 机制，简单来说，就是你必须关闭 rabbitmq 的自动 ack，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 ack 一把。这样的话，如果你还没处理完，不就没有 ack 了？那 rabbitmq 就认为你还没处理完，这个时候 rabbitmq 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。\n\n\n\n\n# kafka\n\n# 消费端弄丢了数据\n\n唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边自动提交了 offset，让 kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。\n\n这不是跟 rabbitmq 差不多吗，大家都知道 kafka 会自动提交 offset，那么只要关闭自动提交 offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是可能会有重复消费，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。\n\n生产环境碰到的一个问题，就是说我们的 kafka 消费者消费到了数据之后是写到一个内存的 queue 里先缓冲一下，结果有的时候，你刚把消息写入内存 queue，然后消费者会自动提交 offset。然后此时我们重启了系统，就会导致内存 queue 里还没来得及处理的数据就丢失了。\n\n# kafka 弄丢了数据\n\n这块比较常见的一个场景，就是 kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。\n\n生产环境也遇到过，我们也是，之前 kafka 的 leader 机器宕机了，将 follower 切换为 leader 之后，就会发现说这个数据就丢了。\n\n所以此时一般是要求起码设置如下 4 个参数：\n\n * 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。\n * 在 kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。\n * 在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。\n * 在 producer 端设置 retries=max（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。\n\n我们生产环境就是按照上述要求配置的，这样配置之后，至少在 kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。\n\n# 生产者会不会弄丢数据？\n\n如果按照上述的思路设置了 acks=all，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。\n\n\n# 如何保证消息的顺序性？\n\n我举个例子，我们以前做过一个 mysql binlog 同步的系统，压力还是非常大的，日同步数据要达到上亿，就是说数据从一个 mysql 库原封不动地同步到另一个 mysql 库里面去（mysql -> mysql）。常见的一点在于说比如大数据 team，就需要同步一个 mysql 库过来，对公司的业务系统的数据做各种复杂的操作。\n\n你在 mysql 里增删改一条数据，对应出来了增删改 3 条 binlog 日志，接着这三条 binlog 发送到 mq 里面，再消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。\n\n本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。\n\n先看看顺序会错乱的俩场景：\n\n * rabbitmq：一个 queue，多个 consumer。比如，生产者向 rabbitmq 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 rabbitmq 的一个内存队列。有三个消费者分别从 mq 中消费这三条数据中的一条，结果消费者 2 先执行完操作，把 data2 存入数据库，然后是 data1/data3。这不明显乱了。\n\n\n\n * kafka：比如说我们建了一个 topic，有三个 partition。生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。 消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞多个线程来并发处理消息。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十 ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而多个线程并发跑的话，顺序可能就乱掉了。\n\n\n\n\n# 解决方案\n\n# rabbitmq\n\n\n\n# kafka\n\n * 一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。\n * 写 n 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 n 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。\n\n\n\n\n# 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？\n\n你看这问法，其实本质针对的场景，都是说，可能你的消费端出了问题，不消费了；或者消费的速度极其慢。接着就坑爹了，可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是这整个就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如 rabbitmq 设置了消息过期时间后就没了怎么办？\n\n所以就这事儿，其实线上挺常见的，一般不出，一出就是大 case。一般常见于，举个例子，消费端每次消费之后要写 mysql，结果 mysql 挂了，消费端 hang 那儿了，不动了；或者是消费端出了个什么岔子，导致消费速度极其慢。\n\n\n# 面试题剖析\n\n关于这个事儿，我们一个一个来梳理吧，先假设一个场景，我们现在消费端出故障了，然后大量消息在 mq 里积压，现在出事故了，慌了。\n\n\n# 大量消息在 mq 里积压了几个小时了还没解决\n\n几千万条数据在 mq 里积压了七八个小时，从下午 4 点多，积压到了晚上 11 点多。这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复 consumer 的问题，让它恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。\n\n一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟就是 18 万条。所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来。\n\n一般这个时候，只能临时紧急扩容了，具体操作步骤和思路如下：\n\n * 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。\n * 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。\n * 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。\n * 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。\n * 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。\n\n\n# mq 中的消息过期失效了\n\n假设你用的是 rabbitmq，rabbtimq 是可以设置过期时间的，也就是 ttl。如果消息在 queue 中积压超过一定的时间就会被 rabbitmq 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。\n\n这个情况下，就不是说要增加 consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上 12 点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。\n\n假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。\n\n\n# mq 都快写满了\n\n如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。\n\n\n# 如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路。\n\n\n# 面试官心理分析\n\n其实聊到这个问题，一般面试官要考察两块：\n\n * 你有没有对某一个消息队列做过较为深入的原理的了解，或者从整体了解把握住一个消息队列的架构原理。\n * 看看你的设计能力，给你一个常见的系统，就是消息队列系统，看看你能不能从全局把握一下整体架构设计，给出一些关键点出来。\n\n说实话，问类似问题的时候，大部分人基本都会蒙，因为平时从来没有思考过类似的问题，大多数人就是平时埋头用，从来不去思考背后的一些东西。类似的问题，比如，如果让你来设计一个 spring 框架你会怎么做？如果让你来设计一个 dubbo 框架你会怎么做？如果让你来设计一个 mybatis 框架你会怎么做？\n\n\n# 面试题剖析\n\n其实回答这类问题，说白了，不求你看过那技术的源码，起码你要大概知道那个技术的基本原理、核心组成部分、基本架构构成，然后参照一些开源的技术把一个系统设计出来的思路说一下就好。\n\n比如说这个消息队列系统，我们从以下几个角度来考虑一下：\n\n * 首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？\n * 其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。\n * 其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。\n * 能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。\n\nmq 肯定是很复杂的，面试官问你这个问题，其实是个开放题，他就是看看你有没有从架构角度整体构思和设计的思维以及能力。确实这个问题可以刷掉一大批人，因为大部分人平时不思考这些东西。",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"消息队列基本原理",frontmatter:{title:"消息队列基本原理",categories:["编程","Java","中间件","MQ"],tags:["Java","中间件","MQ"],abbrlink:"2d0902c8",date:"2019-07-05T15:11:00.000Z",permalink:"/pages/055069/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/01.MQ/02.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86.html",relativePath:"14.中间件/01.MQ/02.消息队列基本原理.md",key:"v-6140a136",path:"/pages/055069/",headers:[{level:2,title:"MQ 的简介",slug:"mq-的简介",normalizedTitle:"mq 的简介",charIndex:259},{level:3,title:"什么是 MQ",slug:"什么是-mq",normalizedTitle:"什么是 mq",charIndex:270},{level:3,title:"MQ 通信模型",slug:"mq-通信模型",normalizedTitle:"mq 通信模型",charIndex:718},{level:2,title:"MQ 的应用",slug:"mq-的应用",normalizedTitle:"mq 的应用",charIndex:1482},{level:3,title:"异步处理",slug:"异步处理",normalizedTitle:"异步处理",charIndex:69},{level:3,title:"系统解耦",slug:"系统解耦",normalizedTitle:"系统解耦",charIndex:1924},{level:3,title:"流量削峰",slug:"流量削峰",normalizedTitle:"流量削峰",charIndex:2250},{level:3,title:"传输缓冲",slug:"传输缓冲",normalizedTitle:"传输缓冲",charIndex:2802},{level:3,title:"最终一致性",slug:"最终一致性",normalizedTitle:"最终一致性",charIndex:102},{level:3,title:"系统间通信",slug:"系统间通信",normalizedTitle:"系统间通信",charIndex:3381},{level:2,title:"MQ 的问题",slug:"mq-的问题",normalizedTitle:"mq 的问题",charIndex:3518},{level:3,title:"重复消费",slug:"重复消费",normalizedTitle:"重复消费",charIndex:3702},{level:4,title:"重复消费问题原因",slug:"重复消费问题原因",normalizedTitle:"重复消费问题原因",charIndex:3949},{level:4,title:"重复消费解决方案",slug:"重复消费解决方案",normalizedTitle:"重复消费解决方案",charIndex:4299},{level:3,title:"消息丢失",slug:"消息丢失",normalizedTitle:"消息丢失",charIndex:3718},{level:4,title:"消费方丢失数据",slug:"消费方丢失数据",normalizedTitle:"消费方丢失数据",charIndex:4706},{level:4,title:"Kafka Server 丢失数据",slug:"kafka-server-丢失数据",normalizedTitle:"kafka server 丢失数据",charIndex:4941},{level:4,title:"生产方丢失数据",slug:"生产方丢失数据",normalizedTitle:"生产方丢失数据",charIndex:4717},{level:3,title:"消息的顺序性",slug:"消息的顺序性",normalizedTitle:"消息的顺序性",charIndex:3740},{level:3,title:"消息积压",slug:"消息积压",normalizedTitle:"消息积压",charIndex:3760},{level:2,title:"MQ 的高可用",slug:"mq-的高可用",normalizedTitle:"mq 的高可用",charIndex:3651},{level:3,title:"Kafka 的高可用",slug:"kafka-的高可用",normalizedTitle:"kafka 的高可用",charIndex:6598},{level:4,title:"Kafka 的核心概念",slug:"kafka-的核心概念",normalizedTitle:"kafka 的核心概念",charIndex:6612},{level:4,title:"Kafka 的副本机制",slug:"kafka-的副本机制",normalizedTitle:"kafka 的副本机制",charIndex:7089},{level:4,title:"Kafka 选举 Leader",slug:"kafka-选举-leader",normalizedTitle:"kafka 选举 leader",charIndex:7750},{level:2,title:"主流 MQ",slug:"主流-mq",normalizedTitle:"主流 mq",charIndex:7880},{level:3,title:"ActiveMQ",slug:"activemq",normalizedTitle:"activemq",charIndex:168},{level:4,title:"(a) 主要特性",slug:"a-主要特性",normalizedTitle:"(a) 主要特性",charIndex:8035},{level:4,title:"(b) 部署环境",slug:"b-部署环境",normalizedTitle:"(b) 部署环境",charIndex:8678},{level:4,title:"(c) 优点",slug:"c-优点",normalizedTitle:"(c) 优点",charIndex:8767},{level:4,title:"(d) 缺点",slug:"d-缺点",normalizedTitle:"(d) 缺点",charIndex:9157},{level:3,title:"RabbitMQ",slug:"rabbitmq",normalizedTitle:"rabbitmq",charIndex:150},{level:4,title:"(a) 主要特性",slug:"a-主要特性-2",normalizedTitle:"(a) 主要特性",charIndex:8035},{level:4,title:"(b) 部署环境",slug:"b-部署环境-2",normalizedTitle:"(b) 部署环境",charIndex:8678},{level:4,title:"(c) 优点",slug:"c-优点-2",normalizedTitle:"(c) 优点",charIndex:8767},{level:4,title:"(d) 缺点",slug:"d-缺点-2",normalizedTitle:"(d) 缺点",charIndex:9157},{level:3,title:"RocketMQ",slug:"rocketmq",normalizedTitle:"rocketmq",charIndex:159},{level:4,title:"(a) 主要特性",slug:"a-主要特性-3",normalizedTitle:"(a) 主要特性",charIndex:8035},{level:4,title:"(b) 部署环境",slug:"b-部署环境-3",normalizedTitle:"(b) 部署环境",charIndex:8678},{level:4,title:"(c) 优点",slug:"c-优点-3",normalizedTitle:"(c) 优点",charIndex:8767},{level:4,title:"(d) 缺点",slug:"d-缺点-3",normalizedTitle:"(d) 缺点",charIndex:9157},{level:3,title:"Kafka",slug:"kafka",normalizedTitle:"kafka",charIndex:144},{level:4,title:"(a) 主要特性",slug:"a-主要特性-4",normalizedTitle:"(a) 主要特性",charIndex:8035},{level:4,title:"(b) 部署环境",slug:"b-部署环境-4",normalizedTitle:"(b) 部署环境",charIndex:8678},{level:4,title:"(c) 优点",slug:"c-优点-4",normalizedTitle:"(c) 优点",charIndex:8767},{level:4,title:"(d) 缺点",slug:"d-缺点-4",normalizedTitle:"(d) 缺点",charIndex:9157},{level:3,title:"MQ 的技术选型",slug:"mq-的技术选型",normalizedTitle:"mq 的技术选型",charIndex:12543},{level:2,title:"JMS",slug:"jms",normalizedTitle:"jms",charIndex:7938},{level:3,title:"消息模型",slug:"消息模型",normalizedTitle:"消息模型",charIndex:14568},{level:4,title:"P2P 模式",slug:"p2p-模式",normalizedTitle:"p2p 模式",charIndex:14650},{level:4,title:"Pub/sub 模式",slug:"pub-sub-模式",normalizedTitle:"pub/sub 模式",charIndex:14940},{level:3,title:"消息消费",slug:"消息消费",normalizedTitle:"消息消费",charIndex:3905},{level:3,title:"JMS 编程模型",slug:"jms-编程模型",normalizedTitle:"jms 编程模型",charIndex:15621},{level:4,title:"ConnectionFactory",slug:"connectionfactory",normalizedTitle:"connectionfactory",charIndex:15633},{level:4,title:"Destination",slug:"destination",normalizedTitle:"destination",charIndex:879},{level:4,title:"Connection",slug:"connection",normalizedTitle:"connection",charIndex:15633},{level:4,title:"Session",slug:"session",normalizedTitle:"session",charIndex:16089},{level:4,title:"消息的生产者",slug:"消息的生产者",normalizedTitle:"消息的生产者",charIndex:16329},{level:4,title:"消息消费者",slug:"消息消费者",normalizedTitle:"消息消费者",charIndex:15827},{level:4,title:"MessageListener",slug:"messagelistener",normalizedTitle:"messagelistener",charIndex:16670},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:16791}],headersStr:"MQ 的简介 什么是 MQ MQ 通信模型 MQ 的应用 异步处理 系统解耦 流量削峰 传输缓冲 最终一致性 系统间通信 MQ 的问题 重复消费 重复消费问题原因 重复消费解决方案 消息丢失 消费方丢失数据 Kafka Server 丢失数据 生产方丢失数据 消息的顺序性 消息积压 MQ 的高可用 Kafka 的高可用 Kafka 的核心概念 Kafka 的副本机制 Kafka 选举 Leader 主流 MQ ActiveMQ (a) 主要特性 (b) 部署环境 (c) 优点 (d) 缺点 RabbitMQ (a) 主要特性 (b) 部署环境 (c) 优点 (d) 缺点 RocketMQ (a) 主要特性 (b) 部署环境 (c) 优点 (d) 缺点 Kafka (a) 主要特性 (b) 部署环境 (c) 优点 (d) 缺点 MQ 的技术选型 JMS 消息模型 P2P 模式 Pub/sub 模式 消息消费 JMS 编程模型 ConnectionFactory Destination Connection Session 消息的生产者 消息消费者 MessageListener 参考资料",content:'# 消息队列基本原理\n\n> 消息队列（Message Queue，简称 MQ）技术是应用间交换信息的一种技术。\n> \n> 消息队列主要解决异步处理、应用间耦合，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。\n> \n> 目前主流的 MQ 有：Kafka、RabbitMQ、RocketMQ、ActiveMQ，而部分数据库如 Redis、MySQL 以及 phxsql 也可实现消息队列的功能。\n> \n> 注意：为了简便，下文中除了文章标题，一律使用 MQ 简称。\n\n\n# MQ 的简介\n\n\n# 什么是 MQ\n\n消息队列（Message Queue，简称 MQ）技术是应用间交换信息的一种技术。\n\n消息队列主要解决应用耦合，异步消息，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。\n\nMQ 是消费-生产者模型的一个典型的代表，一端往消息队列中不断写入消息，而另一端则可以读取队列中的消息。消息发布者只管把消息发布到 MQ 中而不用管谁来取，消息使用者只管从 MQ 中取消息而不管是谁发布的。这样发布者和使用者都不用知道对方的存在。\n\nMQ 的数据可驻留在内存或磁盘上，直到它们被应用程序读取。通过 MQ，应用程序可独立地执行，它们不需要知道彼此的位置，不需要等待接收程序接收此消息。在分布式计算环境中，为了集成分布式应用，开发者需要对异构网络环境下的分布式应用提供有效的通信手段。为了管理需要共享的信息，对应用提供公共的信息交换机制是重要的。\n\n目前主流的 MQ 有：Kafka、RabbitMQ、RocketMQ、ActiveMQ。\n\n\n# MQ 通信模型\n\nMQ 通信模型大致有以下类型：\n\n * 点对点 - 点对点方式是最为传统和常见的通讯方式，它支持一对一、一对多、多对多、多对一等多种配置方式，支持树状、网状等多种拓扑结构。\n * 多点广播 - MQ 适用于不同类型的应用。其中重要的，也是正在发展中的是"多点广播"应用，即能够将消息发送到多个目标站点 (Destination List)。可以使用一条 MQ 指令将单一消息发送到多个目标站点，并确保为每一站点可靠地提供信息。MQ 不仅提供了多点广播的功能，而且还拥有智能消息分发功能，在将一条消息发送到同一系统上的多个用户时，MQ 将消息的一个复制版本和该系统上接收者的名单发送到目标 MQ 系统。目标 MQ 系统在本地复制这些消息，并将它们发送到名单上的队列，从而尽可能减少网络的传输量。\n * 发布/订阅 (Publish/Subscribe) - 发布/订阅模式使消息的分发可以突破目的队列地理位置的限制，使消息按照特定的主题甚至内容进行分发，用户或应用程序可以根据主题或内容接收到所需要的消息。发布/订阅模式使得发送者和接收者之间的耦合关系变得更为松散，发送者不必关心接收者的目的地址，而接收者也不必关心消息的发送地址，而只是根据消息的主题进行消息的收发。\n * 集群 (Cluster) - 为了简化点对点通讯模式中的系统配置，MQ 提供 Cluster(集群) 的解决方案。集群类似于一个域 (Domain)，集群内部的队列管理器之间通讯时，不需要两两之间建立消息通道，而是采用集群 (Cluster) 通道与其它成员通讯，从而大大简化了系统配置。此外，集群中的队列管理器之间能够自动进行负载均衡，当某一队列管理器出现故障时，其它队列管理器可以接管它的工作，从而大大提高系统的高可靠性。\n\n\n# MQ 的应用\n\n\n# 异步处理\n\n> MQ 可以将系统间的处理流程异步化，减少等待响应的时间，从而提高整体并发吞吐量。\n> \n> 一般，MQ 异步处理应用于非核心流程，例如：短信/邮件通知、数据推送、上报数据到监控中心/日志中心等。\n\n假设这样一个场景，用户向系统 A 发起请求，系统 A 处理计算只需要 10 ms，然后通知系统 BCD 写库，系统 BCD 写库耗时分别为：100ms、200ms、300ms。最终总耗时为： 10+100ms+200ms+300ms=610ms。此外，加上请求和响应的网络传输时间，从用户角度看，可能要等待将近 1s 才能得到结果。\n\n\n\n如果使用 MQ，系统 A 接到请求后，耗时 10ms 处理计算，然后向系统 BCD 连续发送消息，假设耗时 5ms。那么 这一过程的总耗时为 3ms + 5ms = 8ms，这相比于 610 ms，大大缩短了响应时间。至于系统 BCD 的写库操作，只要自行消费 MQ 后处理即可，用户无需关注。\n\n\n\n\n# 系统解耦\n\n> 通过 MQ，可以消除系统间的强耦合。它的好处在于：\n> \n>  * 消息的消费者系统可以随意增加，无需修改生产者系统的代码。\n>  * 生产者系统、消费者系统彼此不会影响对方的流程。\n>    * 如果生产者系统宕机，消费者系统收不到消息，就不会有下一步的动作。\n>    * 如果消费者系统宕机，生产者系统让然可以正常发送消息，不影响流程。\n\n不同系统如果要建立通信，传统的做法是：调用接口。\n\n如果需要和新的系统建立通信或删除已建立的通信，都需要修改代码，这种方案显然耦合度很高。\n\n\n\n如果使用 MQ，系统间的通信只需要通过发布/订阅（Pub/Sub）模型即可，彼此没有直接联系，也就不需要相互感知，从而达到 解耦。\n\n\n\n\n# 流量削峰\n\n> 当 上下游系统 处理能力存在差距的时候，利用 MQ 做一个 “漏斗” 模型，进行 流控。把 MQ 当成可靠的 消息暂存地，进行一定程度的 消息堆积；在下游有能力处理的时候，再发送消息。\n> \n> MQ 的流量削峰常用于高并发场景（例如：秒杀、团抢等业务场景），它是缓解瞬时暴增流量的核心手段之一。\n> \n> 如果没有 MQ，两个系统之间通过 协商、滑动窗口、限流/降级/熔断 等复杂的方案也能实现 流控。但 系统复杂性 指数级增长，势必在上游或者下游做存储，并且要处理 定时、拥塞 等一系列问题。而且每当有 处理能力有差距 的时候，都需要 单独 开发一套逻辑来维护这套逻辑。\n\n假设某个系统读写数据库的稳定性能为每秒处理 1000 条数据。平常情况下，远远达不到这么大的处理量。假设，因为因为做活动，系统的瞬时请求量剧增，达到每秒 10000 个并发请求，数据库根本承受不了，可能直接就把数据库给整崩溃了，这样系统服务就不可用了。\n\n\n\n如果使用 MQ，每秒写入 10000 条请求，但是系统 A 每秒只从 MQ 中消费 1000 条请求，然后写入数据库。这样，就不会超过数据库的承受能力，而是把请求积压在 MQ 中。只要高峰期一过，系统 A 就会很快把积压的消息给处理掉。\n\n\n\n\n# 传输缓冲\n\n（1）MQ 常被用于做海量数据的传输缓冲。\n\n例如，Kafka 常被用于做为各种日志数据、采集数据的数据中转。然后，Kafka 将数据转发给 Logstash、Elasticsearch 中，然后基于 Elasticsearch 来做日志中心，提供检索、聚合、分析日志的能力。开发者可以通过 Kibana 集成 Elasticsearch 数据进行可视化展示，或自行进行定制化开发。\n\n\n\n（2）MQ 也可以被用于流式处理。\n\n例如，Kafka 几乎已经是流计算的数据采集端的标准组件。而流计算通过实时数据处理能力，提供了更为快捷的聚合计算能力，被大量应用于链路监控、实时监控、实时数仓、实时大屏、风控、推荐等应用领域。\n\n\n# 最终一致性\n\n最终一致性 不是 消息队列 的必备特性，但确实可以依靠 消息队列 来做 最终一致性 的事情。\n\n * 先写消息再操作，确保操作完成后再修改消息状态。定时任务补偿机制 实现消息 可靠发送接收、业务操作的可靠执行，要注意 消息重复 与 幂等设计。\n * 所有不保证 100% 不丢消息 的消息队列，理论上无法实现 最终一致性。\n\n> 像 Kafka 一类的设计，在设计层面上就有 丢消息 的可能（比如 定时刷盘，如果掉电就会丢消息）。哪怕只丢千分之一的消息，业务也必须用其他的手段来保证结果正确。\n\n\n# 系统间通信\n\n消息队列一般都内置了 高效的通信机制，因此也可以用于单纯的 消息通讯，比如实现 点对点消息队列 或者 聊天室 等。\n\n生产者/消费者 模式，只需要关心消息是否 送达队列，至于谁希望订阅和需要消费，是 下游 的事情，无疑极大地减少了开发和联调的工作量。\n\n\n# MQ 的问题\n\n任何技术都会有利有弊，MQ 给整体系统架构带来很多好处，但也会付出一定的代价。\n\nMQ 主要引入了以下问题：\n\n * 系统可用性降低：引入了 MQ 后，通信需要基于 MQ 完成，如果 MQ 宕机，则服务不可用。因此，MQ 要保证是高可用的，详情参考：MQ 的高可用\n * 系统复杂度提高：使用 MQ，需要关注一些新的问题：\n   * 如何保证消息没有 重复消费？\n   * 如何处理 消息丢失 的问题？\n   * 如何保证传递 消息的顺序性？\n   * 如何处理大量 消息积压 的问题？\n * 一致性问题：假设系统 A 处理完直接返回成功的结果给用户，用户认为请求成功。但如果此时，系统 BCD 中只要有任意一个写库失败，那么数据就不一致了。这种情况如何处理？\n\n下面，我们针对以上问题来一一分析。\n\n\n# 重复消费\n\n如何保证消息不被重复消费 和 如何保证消息消费的幂等性 是同一个问题。\n\n必须先明确产生重复消费的原因，才能对症下药。\n\n# 重复消费问题原因\n\n重复消费问题通常不是 MQ 来处理，而是由开发来处理的。\n\n以 Kafka 举例，Kafka 每个 Partition 都是一个有序的、不可变的记录序列，不断追加到结构化的提交日志中。Partition 中为每条记录分配一个连续的 id 号，称为偏移量（Offset），用于唯一标识 Partition 内的记录。\n\nKafka 的客户端和 Broker 都会保存 Offset。客户端消费消息后，每隔一段时间，就把已消费的 Offset 提交给 Kafka Broker，表示已消费。\n\n\n\n在这个过程中，如果客户端应用消费消息后，因为宕机、重启等情况而没有提交已消费的 Offset 。当系统恢复后，会继续消费消息，由于 Offset 未提交，就会出现重复消费的问题。\n\n# 重复消费解决方案\n\n应对重复消费问题，需要在业务层面，通过 幂等性设计 来解决。\n\nMQ 重复消费不可怕，可怕的是没有应对机制，可以借鉴的思路有：\n\n * 如果是写关系型数据库，可以先根据主键查询，判断数据是否已存在，存在则更新，不存在则插入；\n * 如果是写 Redis，由于 set 操作天然具有幂等性，所以什么都不用做；\n * 如果是根据消息做较复杂的逻辑处理，可以在消息中加入全局唯一 ID，例如：订单 ID 等。在客户端存储中（Mysql、Redis 等）保存已消费消息的 ID。一旦接受到新消息，先判断消息中的 ID 是否在已消费消息 ID 表中存在，存在则不再处理，不存在则处理。\n\n在实际开发中，可以参考上面的例子，结合现实场景，设计合理的幂等性方案。\n\n\n# 消息丢失\n\n如何处理消息丢失的问题 和 如何保证消息不被重复消费 是同一个问题。关注点有：\n\n * MQ Server 丢失数据\n * 消费方丢失数据\n * 生产方丢失数据\n\n# 消费方丢失数据\n\n唯一可能导致消费方丢失数据的情况是：消费方设置了自动提交 Offset。一旦设置了自动提交 Offset，接受到消息后就会自动提交 Offset 给 Kafka ，Kafka 就认为消息已被消费。如果此时，消费方尚未来得及处理消息就挂了，那么消息就丢了。\n\n解决方法就是：消费方关闭自动提交 Offset，处理完消息后手动提交 Offset。但这种情况下可能会出现重复消费的情形，需要自行保证幂等性。\n\n# Kafka Server 丢失数据\n\n当 Kafka 某个 Broker 宕机，需要重新选举 Partition 的 Leader。若此时其他的 Follower 尚未同步 Leader 的数据，那么新选某个 Follower 为 Leader 后，就丢失了部分数据。\n\n为此，一般要求至少设置 4 个参数：\n\n * 给 Topic 设置 replication.factor 参数 - 这个值必须大于 1，要求每个 Partition 必须有至少 2 个副本。\n * 在 Kafka 服务端设置 min.insync.replicas 参数 - 这个值必须大于 1，这是要求一个 Leader 需要和至少一个 Follower 保持通信，这样才能确保 Leader 挂了还有替补。\n * 在 Producer 端设置 acks=all - 这意味着：要求每条数据，必须是写入所有 replica 之后，才能认为写入成功了。\n * 在 Producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思） - 这意味着要求一旦写入失败，就无限重试，卡在这里了。\n\n# 生产方丢失数据\n\n如果按照上述的思路设置了 acks=all，生产方一定不会丢数据。\n\n要求是，你的 Leader 接收到消息，所有的 Follower 都同步到了消息之后，才认为本生产消息成功了。如果未满足这个条件，生产者会自动不断的重试，重试无限次。\n\n\n# 消息的顺序性\n\n要保证 MQ 的顺序性，势必要付出一定的代价，所以实施方案前，要先明确业务场景是不是有必要保证消息的顺序性。只有那些明确对消息处理顺序有要求的业务场景才值得去保证消息顺序性。\n\n方案一\n\n一个 Topic，一个 Partition，一个 Consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。\n\n方案二\n\n * 写入数据到 Partition 时指定一个全局唯一的 ID，例如订单 ID。发送方保证相同 ID 的消息有序的发送到同一个 Partition。\n * 基于上一点，消费方从 Kafka Partition 中消费消息时，此刻一定是顺序的。但如果消费方式以并发方式消费消息，顺序就可能会被打乱。为此，还有做到以下几点：\n   * 消费方维护 N 个缓存队列，具有相同 ID 的数据都写入同一个队列中；\n   * 创建 N 个线程，每个线程只负责从指定的一个队列中取数据。\n\n\n\n\n# 消息积压\n\n假设一个 MQ 消费者可以一秒处理 1000 条消息，三个 MQ 消费者可以一秒处理 3000 条消息，那么一分钟的处理量是 18 万条。如果 MQ 中积压了几百万到上千万的数据，即使消费者恢复了，也需要大概很长的时间才能恢复过来。\n\n对于产线环境来说，漫长的等待是不可接受的，所以面临这种窘境时，只能临时紧急扩容以应对了，具体操作步骤和思路如下：\n\n * 先修复 Consumer 的问题，确保其恢复消费速度，然后将现有 Consumer 都停掉。\n * 新建一个 Topic，Partition 是原来的 10 倍，临时建立好原先 10 倍的 Queue 数量。\n * 然后写一个临时的分发数据的 Consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 Queue。\n * 接着临时征用 10 倍的机器来部署 Consumer ，每一批 Consumer 消费一个临时 Queue 的数据。这种做法相当于是临时将 Queue 资源和 Consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。\n * 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。\n\n\n# MQ 的高可用\n\n不同 MQ 实现高可用的原理各不相同。因为 Kafka 比较具有代表性，所以这里以 Kafka 为例。\n\n\n# Kafka 的高可用\n\n# Kafka 的核心概念\n\n了解 Kafka，必须先了解 Kafka 的核心概念：\n\n * Broker - Kafka 集群包含一个或多个节点，这种节点被称为 Broker。\n\n * Topic - 每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic。（不同 Topic 的消息是物理隔离的；同一个 Topic 的消息保存在一个或多个 Broker 上，但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处）。对于每一个 Topic， Kafka 集群都会维持一个分区日志。\n\n * Partition - 了提高 Kafka 的吞吐率，每个 Topic 包含一个或多个 Partition，每个 Partition 在物理上对应一个文件夹，该文件夹下存储这个 Partition 的所有消息和索引文件。\n   \n   * Kafka 日志的分区（Partition）分布在 Kafka 集群的节点上。每个节点在处理数据和请求时，共享这些分区。每一个分区都会在已配置的节点上进行备份，确保容错性。\n\n\n\n# Kafka 的副本机制\n\nKafka 是如何实现高可用的呢？\n\nKafka 在 0.8 以前的版本中，如果一个 Broker 宕机了，其上面的 Partition 都不能用了，这自然不是高可用的。\n\n为了实现高可用，Kafka 引入了复制功能。\n\n简单来说，就是副本机制（ Replicate ）。\n\n每个 Partition 都有一个 Leader，零个或多个 Follower。Leader 和 Follower 都是 Broker，每个 Broker 都会成为某些分区的 Leader 和某些分区的 Follower，因此集群的负载是平衡的。\n\n * Leader 处理一切对 Partition （分区）的读写请求；\n * 而 Follower 只需被动的同步 Leader 上的数据。\n\n同一个 Topic 的不同 Partition 会分布在多个 Broker 上，而且一个 Partition 还会在其他的 Broker 上面进行备份，Producer 在发布消息到某个 Partition 时，先找到该 Partition 的 Leader，然后向这个 Leader 推送消息；每个 Follower 都从 Leader 拉取消息，拉取消息成功之后，向 Leader 发送一个 ACK 确认。\n\n\n\n> FAQ\n> \n> 问：为什么让 Leader 处理一切对对 Partition （分区）的读写请求？\n> \n> 答：因为如果允许所有 Broker 都可以处理读写请求，就可能产生数据一致性问题。\n\n# Kafka 选举 Leader\n\n由上文可知，Partition 在多个 Broker 上存在副本。\n\n如果某个 Follower 宕机，啥事儿没有，正常工作。\n\n如果 Leader 宕机了，会从 Follower 中重新选举一个新的 Leader。\n\n\n# 主流 MQ\n\n\n# ActiveMQ\n\nActiveMQ 是由 Apache 出品，ActiveMQ 是一个完全支持JMS1.1 和 J2EE 1.4 规范的 JMS Provider 实现。它非常快速，支持 多种语言的客户端 和 协议，而且可以非常容易的嵌入到企业的应用环境中，并有许多高级功能。\n\n\n\n# (a) 主要特性\n\n 1. 服从 JMS 规范：JMS 规范提供了良好的标准和保证，包括：同步 或 异步 的消息分发，一次和仅一次的消息分发，消息接收 和 订阅 等等。遵从 JMS 规范的好处在于，不论使用什么 JMS 实现提供者，这些基础特性都是可用的；\n 2. 连接灵活性：ActiveMQ 提供了广泛的 连接协议，支持的协议有：HTTP/S，IP 多播，SSL，TCP，UDP 等等。对众多协议的支持让 ActiveMQ 拥有了很好的灵活性；\n 3. 支持的协议种类多：OpenWire、STOMP、REST、XMPP、AMQP；\n 4. 持久化插件和安全插件：ActiveMQ 提供了 多种持久化 选择。而且，ActiveMQ 的安全性也可以完全依据用户需求进行 自定义鉴权 和 授权；\n 5. 支持的客户端语言种类多：除了 Java 之外，还有：C/C++，.NET，Perl，PHP，Python，Ruby；\n 6. 代理集群：多个 ActiveMQ 代理 可以组成一个 集群 来提供服务；\n 7. 异常简单的管理：ActiveMQ 是以开发者思维被设计的。所以，它并不需要专门的管理员，因为它提供了简单又使用的管理特性。有很多中方法可以 监控 ActiveMQ 不同层面的数据，包括使用在 JConsole 或者在 ActiveMQ 的 Web Console 中使用 JMX。通过处理 JMX 的告警消息，通过使用 命令行脚本，甚至可以通过监控各种类型的 日志。\n\n# (b) 部署环境\n\nActiveMQ 可以运行在 Java 语言所支持的平台之上。使用 ActiveMQ 需要：\n\n * Java JDK\n * ActiveMQ 安装包\n\n# (c) 优点\n\n 1. 跨平台 (JAVA 编写与平台无关，ActiveMQ 几乎可以运行在任何的 JVM 上)；\n 2. 可以用 JDBC：可以将 数据持久化 到数据库。虽然使用 JDBC 会降低 ActiveMQ 的性能，但是数据库一直都是开发人员最熟悉的存储介质；\n 3. 支持 JMS 规范：支持 JMS 规范提供的 统一接口;\n 4. 支持 自动重连 和 错误重试机制；\n 5. 有安全机制：支持基于 shiro，jaas 等多种 安全配置机制，可以对 Queue/Topic 进行 认证和授权；\n 6. 监控完善：拥有完善的 监控，包括 Web Console，JMX，Shell 命令行，Jolokia 的 RESTful API；\n 7. 界面友善：提供的 Web Console 可以满足大部分情况，还有很多 第三方的组件 可以使用，比如 hawtio；\n\n# (d) 缺点\n\n 1. 社区活跃度不及 RabbitMQ 高；\n 2. 根据其他用户反馈，会出莫名其妙的问题，会 丢失消息；\n 3. 目前重心放到 activemq 6.0 产品 Apollo，对 5.x 的维护较少；\n 4. 不适合用于 上千个队列 的应用场景；\n\n\n# RabbitMQ\n\nRabbitMQ 于 2007 年发布，是一个在 AMQP (高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。\n\n\n\n# (a) 主要特性\n\n 1. 可靠性：提供了多种技术可以让你在 性能 和 可靠性 之间进行 权衡。这些技术包括 持久性机制、投递确认、发布者证实 和 高可用性机制；\n 2. 灵活的路由：消息在到达队列前是通过 交换机 进行 路由 的。RabbitMQ 为典型的路由逻辑提供了 多种内置交换机 类型。如果你有更复杂的路由需求，可以将这些交换机组合起来使用，你甚至可以实现自己的交换机类型，并且当做 RabbitMQ 的 插件 来使用；\n 3. 消息集群：在相同局域网中的多个 RabbitMQ 服务器可以 聚合 在一起，作为一个独立的逻辑代理来使用；\n 4. 队列高可用：队列可以在集群中的机器上 进行镜像，以确保在硬件问题下还保证 消息安全；\n 5. 支持多种协议：支持 多种消息队列协议；\n 6. 支持多种语言：用 Erlang 语言编写，支持只要是你能想到的 所有编程语言；\n 7. 管理界面： RabbitMQ 有一个易用的 用户界面，使得用户可以 监控 和 管理 消息 Broker 的许多方面；\n 8. 跟踪机制：如果 消息异常，RabbitMQ 提供消息跟踪机制，使用者可以找出发生了什么；\n 9. 插件机制：提供了许多 插件，来从多方面进行扩展，也可以编写自己的插件。\n\n# (b) 部署环境\n\nRabbitMQ 可以运行在 Erlang 语言所支持的平台之上，包括 Solaris，BSD，Linux，MacOSX，TRU64，Windows 等。使用 RabbitMQ 需要：\n\n * ErLang 语言包\n * RabbitMQ 安装包\n\n# (c) 优点\n\n 1. 由于 Erlang 语言的特性，消息队列性能较好，支持 高并发；\n 2. 健壮、稳定、易用、跨平台、支持 多种语言、文档齐全；\n 3. 有消息 确认机制 和 持久化机制，可靠性高；\n 4. 高度可定制的 路由；\n 5. 管理界面 较丰富，在互联网公司也有较大规模的应用，社区活跃度高。\n\n# (d) 缺点\n\n 1. 尽管结合 Erlang 语言本身的并发优势，性能较好，但是不利于做 二次开发和维护；\n 2. 实现了 代理架构，意味着消息在发送到客户端之前可以在 中央节点 上排队。此特性使得 RabbitMQ 易于使用和部署，但是使得其 运行速度较慢，因为中央节点 增加了延迟，消息封装后 也比较大；\n 3. 需要学习 比较复杂 的 接口和协议，学习和维护成本较高。\n\n\n# RocketMQ\n\nRocketMQ 出自 阿里 的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一些改进，消息可靠性上 比 Kafka 更好。RocketMQ 在阿里内部 \b 被广泛应用在 订单，交易，充值，流计算，消息推送，日志流式处理，binglog 分发 等场景。\n\n# (a) 主要特性\n\n![img](data:image/svg+xml;utf8,)\n\n 1. 基于 队列模型：具有 高性能、高可靠、高实时、分布式 等特点；\n 2. Producer、Consumer、队列 都支持 分布式；\n 3. Producer 向一些队列轮流发送消息，队列集合 称为 Topic。Consumer 如果做 广播消费，则一个 Consumer 实例消费这个 Topic 对应的 所有队列；如果做 集群消费，则 多个 Consumer 实例 平均消费 这个 Topic 对应的队列集合；\n 4. 能够保证 严格的消息顺序；\n 5. 提供丰富的 消息拉取模式；\n 6. 高效的订阅者 水平扩展能力；\n 7. 实时 的 消息订阅机制；\n 8. 亿级 消息堆积 能力；\n 9. 较少的外部依赖。\n\n# (b) 部署环境\n\nRocketMQ 可以运行在 Java 语言所支持的平台之上。使用 RocketMQ 需要：\n\n * Java JDK\n * 安装 git、Maven\n * RocketMQ 安装包\n\n# (c) 优点\n\n 1. 单机 支持 1 万以上 持久化队列；\n 2. RocketMQ 的所有消息都是 持久化的，先写入系统 PAGECACHE，然后 刷盘，可以保证 内存 与 磁盘 都有一份数据，而 访问 时，直接 从内存读取。\n 3. 模型简单，接口易用（JMS 的接口很多场合并不太实用）；\n 4. 性能非常好，可以允许 大量堆积消息 在 Broker 中；\n 5. 支持 多种消费模式，包括 集群消费、广播消费等；\n 6. 各个环节 分布式扩展设计，支持 主从 和 高可用；\n 7. 开发度较活跃，版本更新很快。\n\n# (d) 缺点\n\n 1. 支持的 客户端语言 不多，目前是 Java 及 C++，其中 C++ 还不成熟；\n 2. RocketMQ 社区关注度及成熟度也不及前两者；\n 3. 没有 Web 管理界面，提供了一个 CLI (命令行界面) 管理工具带来 查询、管理 和 诊断各种问题；\n 4. 没有在 MQ 核心里实现 JMS 等接口；\n\n\n# Kafka\n\nApache Kafka 是一个 分布式消息发布订阅 系统。它最初由 LinkedIn 公司基于独特的设计实现为一个 分布式的日志提交系统 (a distributed commit log)，之后成为 Apache 项目的一部分。Kafka 性能高效、可扩展良好 并且 可持久化。它的 分区特性，可复制 和 可容错 都是其不错的特性。\n\n![img](data:image/svg+xml;utf8,)\n\n# (a) 主要特性\n\n 1. 快速持久化：可以在 O(1) 的系统开销下进行 消息持久化；\n 2. 高吞吐：在一台普通的服务器上既可以达到 10W/s 的 吞吐速率；\n 3. 完全的分布式系统：Broker、Producer 和 Consumer 都原生自动支持 分布式，自动实现 负载均衡；\n 4. 支持 同步 和 异步 复制两种 高可用机制；\n 5. 支持 数据批量发送 和 拉取；\n 6. 零拷贝技术(zero-copy)：减少 IO 操作步骤，提高 系统吞吐量；\n 7. 数据迁移、扩容 对用户透明；\n 8. 无需停机 即可扩展机器；\n 9. 其他特性：丰富的 消息拉取模型、高效 订阅者水平扩展、实时的 消息订阅、亿级的 消息堆积能力、定期删除机制；\n\n# (b) 部署环境\n\n使用 Kafka 需要：\n\n * Java JDK\n * Kafka 安装包\n\n# (c) 优点\n\n 1. 客户端语言丰富：支持 Java、.Net、PHP、Ruby、Python、Go 等多种语言；\n 2. 高性能：单机写入 TPS 约在 100 万条/秒，消息大小 10 个字节；\n 3. 提供 完全分布式架构，并有 replica 机制，拥有较高的 可用性 和 可靠性，理论上支持 消息无限堆积；\n 4. 支持批量操作；\n 5. 消费者 采用 Pull 方式获取消息。消息有序，通过控制 能够保证所有消息被消费且仅被消费 一次；\n 6. 有优秀的第三方 Kafka Web 管理界面 Kafka-Manager；\n 7. 在 日志领域 比较成熟，被多家公司和多个开源项目使用。\n\n# (d) 缺点\n\n 1. Kafka 单机超过 64 个 队列/分区 时，Load 时会发生明显的飙高现象。队列 越多，负载 越高，发送消息 响应时间变长；\n 2. 使用 短轮询方式，实时性 取决于 轮询间隔时间；\n 3. 消费失败 不支持重试；\n 4. 支持 消息顺序，但是 一台代理宕机 后，就会产生 消息乱序；\n 5. 社区更新较慢。\n\n\n# MQ 的技术选型\n\nMQ 的技术选型一般要考虑以下几点：\n\n * 是否开源：这决定了能否商用，所以最为重要。\n * 社区活跃度越高越好：高社区活跃度，一般保证了低 Bug 率，因为大部分 Bug，已经有人遇到并解决了。\n * 技术生态适配性：客户端对各种编程语言的支持。比如：如果使用 MQ 的都是 Java 应用，那么 ActiveMQ、RabbitMQ、RocketMQ、Kafka 都可以。如果需要支持其他语言，那么 RMQ 比较合适，因为它支持的编程语言比较丰富。如果 MQ 是应用于大数据或流式计算，那么 Kafka 几乎是标配。如果是应用于在线业务系统，那么 Kafka 就不合适了，可以考虑 RabbitMQ、 RocketMQ 很合适。\n * 高可用性：应用于线上的准入标准。\n * 性能：具备足够好的性能，能满足绝大多数场景的性能要求。\n\n特性                ACTIVEMQ                     RABBITMQ                        ROCKETMQ                                      KAFKA\n单机吞吐量             万级，比 RocketMQ、Kafka 低一个数量级   同 ActiveMQ                      10 万级，支撑高吞吐                                   10 万级，高吞吐，一般配合大数据类的系统来进行流式计算、日志采集等场景\ntopic 数量对吞吐量的影响                                                                topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ   topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic\n                                                                               的一大优势，在同等机器下，可以支撑大量的 topic                    数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源\n时效性               ms 级                         微秒级，这是 RabbitMQ 的一大特点，延迟最低      ms 级                                          延迟在 ms 级以内\n可用性               高，基于主从架构实现高可用                同 ActiveMQ                      非常高，分布式架构                                     非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用\n消息可靠性             有较低的概率丢失数据                   基本不丢                            经过参数优化配置，可以做到 0 丢失                            同 RocketMQ\n功能支持              MQ 领域的功能极其完备                 基于 erlang 开发，并发能力很强，性能极好，延时很低   MQ 功能较为完善，还是分布式的，扩展性好                         功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用\n\n综上，各种对比之后，有如下建议：\n\n * 业务系统场景，建议使用 RocketMQ、RabbitMQ。如果所有应用都是 Java，优选 RocketMQ，因为 RocketMQ 本身就是 Java 开发的，所以最适配。如果业务中有多种编程语言的应用，建议选择 RabbitMQ。\n * 大数据和流式计算领域，或是作为日志缓冲，强烈建议选择 Kafka，业界标准，久经考验。\n\n\n# JMS\n\n提到 MQ，就顺便提一下 JMS 。\n\nJMS（JAVA Message Service，java 消息服务）API 是一个消息服务的标准/规范，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。\n\n在 EJB 架构中，有消息 bean 可以无缝的与 JMS 消息服务集成。在 J2EE 架构模式中，有消息服务者模式，用于实现消息与应用直接的解耦。\n\n\n# 消息模型\n\n在 JMS 标准中，有两种消息模型：\n\n * P2P(Point to Point)\n * Pub/Sub(Publish/Subscribe)\n\n# P2P 模式\n\n\nP2P 模式包含三个角色：MQ（Queue），发送者(Sender)，接收者(Receiver)。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。\n\nP2P 的特点\n\n * 每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在 MQ 中)\n * 发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列\n * 接收者在成功接收消息之后需向队列应答成功\n\n如果希望发送的每个消息都会被成功处理的话，那么需要 P2P 模式。\n\n# Pub/sub 模式\n\n\n包含三个角色主题（Topic），发布者（Publisher），订阅者（Subscriber） 。多个发布者将消息发送到 Topic,系统将这些消息传递给多个订阅者。\n\nPub/Sub 的特点\n\n * 每个消息可以有多个消费者\n * 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。\n * 为了消费消息，订阅者必须保持运行的状态。\n\n为了缓和这样严格的时间相关性，JMS 允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。\n\n如果希望发送的消息可以不被做任何处理、或者只被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用 Pub/Sub 模型。\n\n\n# 消息消费\n\n在 JMS 中，消息的产生和消费都是异步的。对于消费来说，JMS 的消息者可以通过两种方式来消费消息。\n\n * 同步 - 订阅者或接收者通过 receive 方法来接收消息，receive 方法在接收到消息之前（或超时之前）将一直阻塞；\n * 异步 - 订阅者或接收者可以注册为一个消息监听器。当消息到达之后，系统自动调用监听器的 onMessage 方法。\n\nJNDI - Java 命名和目录接口,是一种标准的 Java 命名系统接口。可以在网络上查找和访问服务。通过指定一个资源名称，该名称对应于数据库或命名服务中的一个记录，同时返回资源连接建立所必须的信息。\n\nJNDI 在 JMS 中起到查找和访问发送目标或消息来源的作用。\n\n\n# JMS 编程模型\n\n# ConnectionFactory\n\n创建 Connection 对象的工厂，针对两种不同的 jms 消息模型，分别有 QueueConnectionFactory 和 TopicConnectionFactory 两种。可以通过 JNDI 来查找 ConnectionFactory 对象。\n\n# Destination\n\nDestination 的意思是消息生产者的消息发送目标或者说消息消费者的消息来源。对于消息生产者来说，它的 Destination 是某个队列（Queue）或某个主题（Topic）;对于消息消费者来说，它的 Destination 也是某个队列或主题（即消息来源）。\n\n所以，Destination 实际上就是两种类型的对象：Queue、Topic。可以通过 JNDI 来查找 Destination。\n\n# Connection\n\nConnection 表示在客户端和 JMS 系统之间建立的链接（对 TCP/IP socket 的包装）。Connection 可以产生一个或多个 Session。跟 ConnectionFactory 一样，Connection 也有两种类型：QueueConnection 和 TopicConnection。\n\n# Session\n\nSession 是操作消息的接口。可以通过 session 创建生产者、消费者、消息等。Session 提供了事务的功能。当需要使用 session 发送/接收多个消息时，可以将这些发送/接收动作放到一个事务中。同样，也分 QueueSession 和 TopicSession。\n\n# 消息的生产者\n\n消息生产者由 Session 创建，并用于将消息发送到 Destination。同样，消息生产者分两种类型：QueueSender 和 TopicPublisher。可以调用消息生产者的方法（send 或 publish 方法）发送消息。\n\n# 消息消费者\n\n消息消费者由 Session 创建，用于接收被发送到 Destination 的消息。两种类型：QueueReceiver 和 TopicSubscriber。可分别通过 session 的 createReceiver(Queue)或 createSubscriber(Topic)来创建。当然，也可以 session 的 creatDurableSubscriber 方法来创建持久化的订阅者。\n\n# MessageListener\n\n消息监听器。如果注册了消息监听器，一旦消息到达，将自动调用监听器的 onMessage 方法。EJB 中的 MDB（Message-Driven Bean）就是一种 MessageListener。\n\n\n# 参考资料\n\n * 大型网站架构系列：分布式 MQ（一）\n * 大型网站架构系列：MQ（二）\n * 分布式开放 MQ(RocketMQ)的原理与实践\n * 阿里 RocketMQ 优势对比\n * advanced-java 之 MQ\n * 浅谈消息队列及常见的消息中间件',normalizedContent:'# 消息队列基本原理\n\n> 消息队列（message queue，简称 mq）技术是应用间交换信息的一种技术。\n> \n> 消息队列主要解决异步处理、应用间耦合，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。\n> \n> 目前主流的 mq 有：kafka、rabbitmq、rocketmq、activemq，而部分数据库如 redis、mysql 以及 phxsql 也可实现消息队列的功能。\n> \n> 注意：为了简便，下文中除了文章标题，一律使用 mq 简称。\n\n\n# mq 的简介\n\n\n# 什么是 mq\n\n消息队列（message queue，简称 mq）技术是应用间交换信息的一种技术。\n\n消息队列主要解决应用耦合，异步消息，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。\n\nmq 是消费-生产者模型的一个典型的代表，一端往消息队列中不断写入消息，而另一端则可以读取队列中的消息。消息发布者只管把消息发布到 mq 中而不用管谁来取，消息使用者只管从 mq 中取消息而不管是谁发布的。这样发布者和使用者都不用知道对方的存在。\n\nmq 的数据可驻留在内存或磁盘上，直到它们被应用程序读取。通过 mq，应用程序可独立地执行，它们不需要知道彼此的位置，不需要等待接收程序接收此消息。在分布式计算环境中，为了集成分布式应用，开发者需要对异构网络环境下的分布式应用提供有效的通信手段。为了管理需要共享的信息，对应用提供公共的信息交换机制是重要的。\n\n目前主流的 mq 有：kafka、rabbitmq、rocketmq、activemq。\n\n\n# mq 通信模型\n\nmq 通信模型大致有以下类型：\n\n * 点对点 - 点对点方式是最为传统和常见的通讯方式，它支持一对一、一对多、多对多、多对一等多种配置方式，支持树状、网状等多种拓扑结构。\n * 多点广播 - mq 适用于不同类型的应用。其中重要的，也是正在发展中的是"多点广播"应用，即能够将消息发送到多个目标站点 (destination list)。可以使用一条 mq 指令将单一消息发送到多个目标站点，并确保为每一站点可靠地提供信息。mq 不仅提供了多点广播的功能，而且还拥有智能消息分发功能，在将一条消息发送到同一系统上的多个用户时，mq 将消息的一个复制版本和该系统上接收者的名单发送到目标 mq 系统。目标 mq 系统在本地复制这些消息，并将它们发送到名单上的队列，从而尽可能减少网络的传输量。\n * 发布/订阅 (publish/subscribe) - 发布/订阅模式使消息的分发可以突破目的队列地理位置的限制，使消息按照特定的主题甚至内容进行分发，用户或应用程序可以根据主题或内容接收到所需要的消息。发布/订阅模式使得发送者和接收者之间的耦合关系变得更为松散，发送者不必关心接收者的目的地址，而接收者也不必关心消息的发送地址，而只是根据消息的主题进行消息的收发。\n * 集群 (cluster) - 为了简化点对点通讯模式中的系统配置，mq 提供 cluster(集群) 的解决方案。集群类似于一个域 (domain)，集群内部的队列管理器之间通讯时，不需要两两之间建立消息通道，而是采用集群 (cluster) 通道与其它成员通讯，从而大大简化了系统配置。此外，集群中的队列管理器之间能够自动进行负载均衡，当某一队列管理器出现故障时，其它队列管理器可以接管它的工作，从而大大提高系统的高可靠性。\n\n\n# mq 的应用\n\n\n# 异步处理\n\n> mq 可以将系统间的处理流程异步化，减少等待响应的时间，从而提高整体并发吞吐量。\n> \n> 一般，mq 异步处理应用于非核心流程，例如：短信/邮件通知、数据推送、上报数据到监控中心/日志中心等。\n\n假设这样一个场景，用户向系统 a 发起请求，系统 a 处理计算只需要 10 ms，然后通知系统 bcd 写库，系统 bcd 写库耗时分别为：100ms、200ms、300ms。最终总耗时为： 10+100ms+200ms+300ms=610ms。此外，加上请求和响应的网络传输时间，从用户角度看，可能要等待将近 1s 才能得到结果。\n\n\n\n如果使用 mq，系统 a 接到请求后，耗时 10ms 处理计算，然后向系统 bcd 连续发送消息，假设耗时 5ms。那么 这一过程的总耗时为 3ms + 5ms = 8ms，这相比于 610 ms，大大缩短了响应时间。至于系统 bcd 的写库操作，只要自行消费 mq 后处理即可，用户无需关注。\n\n\n\n\n# 系统解耦\n\n> 通过 mq，可以消除系统间的强耦合。它的好处在于：\n> \n>  * 消息的消费者系统可以随意增加，无需修改生产者系统的代码。\n>  * 生产者系统、消费者系统彼此不会影响对方的流程。\n>    * 如果生产者系统宕机，消费者系统收不到消息，就不会有下一步的动作。\n>    * 如果消费者系统宕机，生产者系统让然可以正常发送消息，不影响流程。\n\n不同系统如果要建立通信，传统的做法是：调用接口。\n\n如果需要和新的系统建立通信或删除已建立的通信，都需要修改代码，这种方案显然耦合度很高。\n\n\n\n如果使用 mq，系统间的通信只需要通过发布/订阅（pub/sub）模型即可，彼此没有直接联系，也就不需要相互感知，从而达到 解耦。\n\n\n\n\n# 流量削峰\n\n> 当 上下游系统 处理能力存在差距的时候，利用 mq 做一个 “漏斗” 模型，进行 流控。把 mq 当成可靠的 消息暂存地，进行一定程度的 消息堆积；在下游有能力处理的时候，再发送消息。\n> \n> mq 的流量削峰常用于高并发场景（例如：秒杀、团抢等业务场景），它是缓解瞬时暴增流量的核心手段之一。\n> \n> 如果没有 mq，两个系统之间通过 协商、滑动窗口、限流/降级/熔断 等复杂的方案也能实现 流控。但 系统复杂性 指数级增长，势必在上游或者下游做存储，并且要处理 定时、拥塞 等一系列问题。而且每当有 处理能力有差距 的时候，都需要 单独 开发一套逻辑来维护这套逻辑。\n\n假设某个系统读写数据库的稳定性能为每秒处理 1000 条数据。平常情况下，远远达不到这么大的处理量。假设，因为因为做活动，系统的瞬时请求量剧增，达到每秒 10000 个并发请求，数据库根本承受不了，可能直接就把数据库给整崩溃了，这样系统服务就不可用了。\n\n\n\n如果使用 mq，每秒写入 10000 条请求，但是系统 a 每秒只从 mq 中消费 1000 条请求，然后写入数据库。这样，就不会超过数据库的承受能力，而是把请求积压在 mq 中。只要高峰期一过，系统 a 就会很快把积压的消息给处理掉。\n\n\n\n\n# 传输缓冲\n\n（1）mq 常被用于做海量数据的传输缓冲。\n\n例如，kafka 常被用于做为各种日志数据、采集数据的数据中转。然后，kafka 将数据转发给 logstash、elasticsearch 中，然后基于 elasticsearch 来做日志中心，提供检索、聚合、分析日志的能力。开发者可以通过 kibana 集成 elasticsearch 数据进行可视化展示，或自行进行定制化开发。\n\n\n\n（2）mq 也可以被用于流式处理。\n\n例如，kafka 几乎已经是流计算的数据采集端的标准组件。而流计算通过实时数据处理能力，提供了更为快捷的聚合计算能力，被大量应用于链路监控、实时监控、实时数仓、实时大屏、风控、推荐等应用领域。\n\n\n# 最终一致性\n\n最终一致性 不是 消息队列 的必备特性，但确实可以依靠 消息队列 来做 最终一致性 的事情。\n\n * 先写消息再操作，确保操作完成后再修改消息状态。定时任务补偿机制 实现消息 可靠发送接收、业务操作的可靠执行，要注意 消息重复 与 幂等设计。\n * 所有不保证 100% 不丢消息 的消息队列，理论上无法实现 最终一致性。\n\n> 像 kafka 一类的设计，在设计层面上就有 丢消息 的可能（比如 定时刷盘，如果掉电就会丢消息）。哪怕只丢千分之一的消息，业务也必须用其他的手段来保证结果正确。\n\n\n# 系统间通信\n\n消息队列一般都内置了 高效的通信机制，因此也可以用于单纯的 消息通讯，比如实现 点对点消息队列 或者 聊天室 等。\n\n生产者/消费者 模式，只需要关心消息是否 送达队列，至于谁希望订阅和需要消费，是 下游 的事情，无疑极大地减少了开发和联调的工作量。\n\n\n# mq 的问题\n\n任何技术都会有利有弊，mq 给整体系统架构带来很多好处，但也会付出一定的代价。\n\nmq 主要引入了以下问题：\n\n * 系统可用性降低：引入了 mq 后，通信需要基于 mq 完成，如果 mq 宕机，则服务不可用。因此，mq 要保证是高可用的，详情参考：mq 的高可用\n * 系统复杂度提高：使用 mq，需要关注一些新的问题：\n   * 如何保证消息没有 重复消费？\n   * 如何处理 消息丢失 的问题？\n   * 如何保证传递 消息的顺序性？\n   * 如何处理大量 消息积压 的问题？\n * 一致性问题：假设系统 a 处理完直接返回成功的结果给用户，用户认为请求成功。但如果此时，系统 bcd 中只要有任意一个写库失败，那么数据就不一致了。这种情况如何处理？\n\n下面，我们针对以上问题来一一分析。\n\n\n# 重复消费\n\n如何保证消息不被重复消费 和 如何保证消息消费的幂等性 是同一个问题。\n\n必须先明确产生重复消费的原因，才能对症下药。\n\n# 重复消费问题原因\n\n重复消费问题通常不是 mq 来处理，而是由开发来处理的。\n\n以 kafka 举例，kafka 每个 partition 都是一个有序的、不可变的记录序列，不断追加到结构化的提交日志中。partition 中为每条记录分配一个连续的 id 号，称为偏移量（offset），用于唯一标识 partition 内的记录。\n\nkafka 的客户端和 broker 都会保存 offset。客户端消费消息后，每隔一段时间，就把已消费的 offset 提交给 kafka broker，表示已消费。\n\n\n\n在这个过程中，如果客户端应用消费消息后，因为宕机、重启等情况而没有提交已消费的 offset 。当系统恢复后，会继续消费消息，由于 offset 未提交，就会出现重复消费的问题。\n\n# 重复消费解决方案\n\n应对重复消费问题，需要在业务层面，通过 幂等性设计 来解决。\n\nmq 重复消费不可怕，可怕的是没有应对机制，可以借鉴的思路有：\n\n * 如果是写关系型数据库，可以先根据主键查询，判断数据是否已存在，存在则更新，不存在则插入；\n * 如果是写 redis，由于 set 操作天然具有幂等性，所以什么都不用做；\n * 如果是根据消息做较复杂的逻辑处理，可以在消息中加入全局唯一 id，例如：订单 id 等。在客户端存储中（mysql、redis 等）保存已消费消息的 id。一旦接受到新消息，先判断消息中的 id 是否在已消费消息 id 表中存在，存在则不再处理，不存在则处理。\n\n在实际开发中，可以参考上面的例子，结合现实场景，设计合理的幂等性方案。\n\n\n# 消息丢失\n\n如何处理消息丢失的问题 和 如何保证消息不被重复消费 是同一个问题。关注点有：\n\n * mq server 丢失数据\n * 消费方丢失数据\n * 生产方丢失数据\n\n# 消费方丢失数据\n\n唯一可能导致消费方丢失数据的情况是：消费方设置了自动提交 offset。一旦设置了自动提交 offset，接受到消息后就会自动提交 offset 给 kafka ，kafka 就认为消息已被消费。如果此时，消费方尚未来得及处理消息就挂了，那么消息就丢了。\n\n解决方法就是：消费方关闭自动提交 offset，处理完消息后手动提交 offset。但这种情况下可能会出现重复消费的情形，需要自行保证幂等性。\n\n# kafka server 丢失数据\n\n当 kafka 某个 broker 宕机，需要重新选举 partition 的 leader。若此时其他的 follower 尚未同步 leader 的数据，那么新选某个 follower 为 leader 后，就丢失了部分数据。\n\n为此，一般要求至少设置 4 个参数：\n\n * 给 topic 设置 replication.factor 参数 - 这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。\n * 在 kafka 服务端设置 min.insync.replicas 参数 - 这个值必须大于 1，这是要求一个 leader 需要和至少一个 follower 保持通信，这样才能确保 leader 挂了还有替补。\n * 在 producer 端设置 acks=all - 这意味着：要求每条数据，必须是写入所有 replica 之后，才能认为写入成功了。\n * 在 producer 端设置 retries=max（很大很大很大的一个值，无限次重试的意思） - 这意味着要求一旦写入失败，就无限重试，卡在这里了。\n\n# 生产方丢失数据\n\n如果按照上述的思路设置了 acks=all，生产方一定不会丢数据。\n\n要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本生产消息成功了。如果未满足这个条件，生产者会自动不断的重试，重试无限次。\n\n\n# 消息的顺序性\n\n要保证 mq 的顺序性，势必要付出一定的代价，所以实施方案前，要先明确业务场景是不是有必要保证消息的顺序性。只有那些明确对消息处理顺序有要求的业务场景才值得去保证消息顺序性。\n\n方案一\n\n一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。\n\n方案二\n\n * 写入数据到 partition 时指定一个全局唯一的 id，例如订单 id。发送方保证相同 id 的消息有序的发送到同一个 partition。\n * 基于上一点，消费方从 kafka partition 中消费消息时，此刻一定是顺序的。但如果消费方式以并发方式消费消息，顺序就可能会被打乱。为此，还有做到以下几点：\n   * 消费方维护 n 个缓存队列，具有相同 id 的数据都写入同一个队列中；\n   * 创建 n 个线程，每个线程只负责从指定的一个队列中取数据。\n\n\n\n\n# 消息积压\n\n假设一个 mq 消费者可以一秒处理 1000 条消息，三个 mq 消费者可以一秒处理 3000 条消息，那么一分钟的处理量是 18 万条。如果 mq 中积压了几百万到上千万的数据，即使消费者恢复了，也需要大概很长的时间才能恢复过来。\n\n对于产线环境来说，漫长的等待是不可接受的，所以面临这种窘境时，只能临时紧急扩容以应对了，具体操作步骤和思路如下：\n\n * 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。\n * 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。\n * 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。\n * 接着临时征用 10 倍的机器来部署 consumer ，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。\n * 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。\n\n\n# mq 的高可用\n\n不同 mq 实现高可用的原理各不相同。因为 kafka 比较具有代表性，所以这里以 kafka 为例。\n\n\n# kafka 的高可用\n\n# kafka 的核心概念\n\n了解 kafka，必须先了解 kafka 的核心概念：\n\n * broker - kafka 集群包含一个或多个节点，这种节点被称为 broker。\n\n * topic - 每条发布到 kafka 集群的消息都有一个类别，这个类别被称为 topic。（不同 topic 的消息是物理隔离的；同一个 topic 的消息保存在一个或多个 broker 上，但用户只需指定消息的 topic 即可生产或消费数据而不必关心数据存于何处）。对于每一个 topic， kafka 集群都会维持一个分区日志。\n\n * partition - 了提高 kafka 的吞吐率，每个 topic 包含一个或多个 partition，每个 partition 在物理上对应一个文件夹，该文件夹下存储这个 partition 的所有消息和索引文件。\n   \n   * kafka 日志的分区（partition）分布在 kafka 集群的节点上。每个节点在处理数据和请求时，共享这些分区。每一个分区都会在已配置的节点上进行备份，确保容错性。\n\n\n\n# kafka 的副本机制\n\nkafka 是如何实现高可用的呢？\n\nkafka 在 0.8 以前的版本中，如果一个 broker 宕机了，其上面的 partition 都不能用了，这自然不是高可用的。\n\n为了实现高可用，kafka 引入了复制功能。\n\n简单来说，就是副本机制（ replicate ）。\n\n每个 partition 都有一个 leader，零个或多个 follower。leader 和 follower 都是 broker，每个 broker 都会成为某些分区的 leader 和某些分区的 follower，因此集群的负载是平衡的。\n\n * leader 处理一切对 partition （分区）的读写请求；\n * 而 follower 只需被动的同步 leader 上的数据。\n\n同一个 topic 的不同 partition 会分布在多个 broker 上，而且一个 partition 还会在其他的 broker 上面进行备份，producer 在发布消息到某个 partition 时，先找到该 partition 的 leader，然后向这个 leader 推送消息；每个 follower 都从 leader 拉取消息，拉取消息成功之后，向 leader 发送一个 ack 确认。\n\n\n\n> faq\n> \n> 问：为什么让 leader 处理一切对对 partition （分区）的读写请求？\n> \n> 答：因为如果允许所有 broker 都可以处理读写请求，就可能产生数据一致性问题。\n\n# kafka 选举 leader\n\n由上文可知，partition 在多个 broker 上存在副本。\n\n如果某个 follower 宕机，啥事儿没有，正常工作。\n\n如果 leader 宕机了，会从 follower 中重新选举一个新的 leader。\n\n\n# 主流 mq\n\n\n# activemq\n\nactivemq 是由 apache 出品，activemq 是一个完全支持jms1.1 和 j2ee 1.4 规范的 jms provider 实现。它非常快速，支持 多种语言的客户端 和 协议，而且可以非常容易的嵌入到企业的应用环境中，并有许多高级功能。\n\n\n\n# (a) 主要特性\n\n 1. 服从 jms 规范：jms 规范提供了良好的标准和保证，包括：同步 或 异步 的消息分发，一次和仅一次的消息分发，消息接收 和 订阅 等等。遵从 jms 规范的好处在于，不论使用什么 jms 实现提供者，这些基础特性都是可用的；\n 2. 连接灵活性：activemq 提供了广泛的 连接协议，支持的协议有：http/s，ip 多播，ssl，tcp，udp 等等。对众多协议的支持让 activemq 拥有了很好的灵活性；\n 3. 支持的协议种类多：openwire、stomp、rest、xmpp、amqp；\n 4. 持久化插件和安全插件：activemq 提供了 多种持久化 选择。而且，activemq 的安全性也可以完全依据用户需求进行 自定义鉴权 和 授权；\n 5. 支持的客户端语言种类多：除了 java 之外，还有：c/c++，.net，perl，php，python，ruby；\n 6. 代理集群：多个 activemq 代理 可以组成一个 集群 来提供服务；\n 7. 异常简单的管理：activemq 是以开发者思维被设计的。所以，它并不需要专门的管理员，因为它提供了简单又使用的管理特性。有很多中方法可以 监控 activemq 不同层面的数据，包括使用在 jconsole 或者在 activemq 的 web console 中使用 jmx。通过处理 jmx 的告警消息，通过使用 命令行脚本，甚至可以通过监控各种类型的 日志。\n\n# (b) 部署环境\n\nactivemq 可以运行在 java 语言所支持的平台之上。使用 activemq 需要：\n\n * java jdk\n * activemq 安装包\n\n# (c) 优点\n\n 1. 跨平台 (java 编写与平台无关，activemq 几乎可以运行在任何的 jvm 上)；\n 2. 可以用 jdbc：可以将 数据持久化 到数据库。虽然使用 jdbc 会降低 activemq 的性能，但是数据库一直都是开发人员最熟悉的存储介质；\n 3. 支持 jms 规范：支持 jms 规范提供的 统一接口;\n 4. 支持 自动重连 和 错误重试机制；\n 5. 有安全机制：支持基于 shiro，jaas 等多种 安全配置机制，可以对 queue/topic 进行 认证和授权；\n 6. 监控完善：拥有完善的 监控，包括 web console，jmx，shell 命令行，jolokia 的 restful api；\n 7. 界面友善：提供的 web console 可以满足大部分情况，还有很多 第三方的组件 可以使用，比如 hawtio；\n\n# (d) 缺点\n\n 1. 社区活跃度不及 rabbitmq 高；\n 2. 根据其他用户反馈，会出莫名其妙的问题，会 丢失消息；\n 3. 目前重心放到 activemq 6.0 产品 apollo，对 5.x 的维护较少；\n 4. 不适合用于 上千个队列 的应用场景；\n\n\n# rabbitmq\n\nrabbitmq 于 2007 年发布，是一个在 amqp (高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。\n\n\n\n# (a) 主要特性\n\n 1. 可靠性：提供了多种技术可以让你在 性能 和 可靠性 之间进行 权衡。这些技术包括 持久性机制、投递确认、发布者证实 和 高可用性机制；\n 2. 灵活的路由：消息在到达队列前是通过 交换机 进行 路由 的。rabbitmq 为典型的路由逻辑提供了 多种内置交换机 类型。如果你有更复杂的路由需求，可以将这些交换机组合起来使用，你甚至可以实现自己的交换机类型，并且当做 rabbitmq 的 插件 来使用；\n 3. 消息集群：在相同局域网中的多个 rabbitmq 服务器可以 聚合 在一起，作为一个独立的逻辑代理来使用；\n 4. 队列高可用：队列可以在集群中的机器上 进行镜像，以确保在硬件问题下还保证 消息安全；\n 5. 支持多种协议：支持 多种消息队列协议；\n 6. 支持多种语言：用 erlang 语言编写，支持只要是你能想到的 所有编程语言；\n 7. 管理界面： rabbitmq 有一个易用的 用户界面，使得用户可以 监控 和 管理 消息 broker 的许多方面；\n 8. 跟踪机制：如果 消息异常，rabbitmq 提供消息跟踪机制，使用者可以找出发生了什么；\n 9. 插件机制：提供了许多 插件，来从多方面进行扩展，也可以编写自己的插件。\n\n# (b) 部署环境\n\nrabbitmq 可以运行在 erlang 语言所支持的平台之上，包括 solaris，bsd，linux，macosx，tru64，windows 等。使用 rabbitmq 需要：\n\n * erlang 语言包\n * rabbitmq 安装包\n\n# (c) 优点\n\n 1. 由于 erlang 语言的特性，消息队列性能较好，支持 高并发；\n 2. 健壮、稳定、易用、跨平台、支持 多种语言、文档齐全；\n 3. 有消息 确认机制 和 持久化机制，可靠性高；\n 4. 高度可定制的 路由；\n 5. 管理界面 较丰富，在互联网公司也有较大规模的应用，社区活跃度高。\n\n# (d) 缺点\n\n 1. 尽管结合 erlang 语言本身的并发优势，性能较好，但是不利于做 二次开发和维护；\n 2. 实现了 代理架构，意味着消息在发送到客户端之前可以在 中央节点 上排队。此特性使得 rabbitmq 易于使用和部署，但是使得其 运行速度较慢，因为中央节点 增加了延迟，消息封装后 也比较大；\n 3. 需要学习 比较复杂 的 接口和协议，学习和维护成本较高。\n\n\n# rocketmq\n\nrocketmq 出自 阿里 的开源产品，用 java 语言实现，在设计时参考了 kafka，并做出了自己的一些改进，消息可靠性上 比 kafka 更好。rocketmq 在阿里内部 \b 被广泛应用在 订单，交易，充值，流计算，消息推送，日志流式处理，binglog 分发 等场景。\n\n# (a) 主要特性\n\n![img](data:image/svg+xml;utf8,)\n\n 1. 基于 队列模型：具有 高性能、高可靠、高实时、分布式 等特点；\n 2. producer、consumer、队列 都支持 分布式；\n 3. producer 向一些队列轮流发送消息，队列集合 称为 topic。consumer 如果做 广播消费，则一个 consumer 实例消费这个 topic 对应的 所有队列；如果做 集群消费，则 多个 consumer 实例 平均消费 这个 topic 对应的队列集合；\n 4. 能够保证 严格的消息顺序；\n 5. 提供丰富的 消息拉取模式；\n 6. 高效的订阅者 水平扩展能力；\n 7. 实时 的 消息订阅机制；\n 8. 亿级 消息堆积 能力；\n 9. 较少的外部依赖。\n\n# (b) 部署环境\n\nrocketmq 可以运行在 java 语言所支持的平台之上。使用 rocketmq 需要：\n\n * java jdk\n * 安装 git、maven\n * rocketmq 安装包\n\n# (c) 优点\n\n 1. 单机 支持 1 万以上 持久化队列；\n 2. rocketmq 的所有消息都是 持久化的，先写入系统 pagecache，然后 刷盘，可以保证 内存 与 磁盘 都有一份数据，而 访问 时，直接 从内存读取。\n 3. 模型简单，接口易用（jms 的接口很多场合并不太实用）；\n 4. 性能非常好，可以允许 大量堆积消息 在 broker 中；\n 5. 支持 多种消费模式，包括 集群消费、广播消费等；\n 6. 各个环节 分布式扩展设计，支持 主从 和 高可用；\n 7. 开发度较活跃，版本更新很快。\n\n# (d) 缺点\n\n 1. 支持的 客户端语言 不多，目前是 java 及 c++，其中 c++ 还不成熟；\n 2. rocketmq 社区关注度及成熟度也不及前两者；\n 3. 没有 web 管理界面，提供了一个 cli (命令行界面) 管理工具带来 查询、管理 和 诊断各种问题；\n 4. 没有在 mq 核心里实现 jms 等接口；\n\n\n# kafka\n\napache kafka 是一个 分布式消息发布订阅 系统。它最初由 linkedin 公司基于独特的设计实现为一个 分布式的日志提交系统 (a distributed commit log)，之后成为 apache 项目的一部分。kafka 性能高效、可扩展良好 并且 可持久化。它的 分区特性，可复制 和 可容错 都是其不错的特性。\n\n![img](data:image/svg+xml;utf8,)\n\n# (a) 主要特性\n\n 1. 快速持久化：可以在 o(1) 的系统开销下进行 消息持久化；\n 2. 高吞吐：在一台普通的服务器上既可以达到 10w/s 的 吞吐速率；\n 3. 完全的分布式系统：broker、producer 和 consumer 都原生自动支持 分布式，自动实现 负载均衡；\n 4. 支持 同步 和 异步 复制两种 高可用机制；\n 5. 支持 数据批量发送 和 拉取；\n 6. 零拷贝技术(zero-copy)：减少 io 操作步骤，提高 系统吞吐量；\n 7. 数据迁移、扩容 对用户透明；\n 8. 无需停机 即可扩展机器；\n 9. 其他特性：丰富的 消息拉取模型、高效 订阅者水平扩展、实时的 消息订阅、亿级的 消息堆积能力、定期删除机制；\n\n# (b) 部署环境\n\n使用 kafka 需要：\n\n * java jdk\n * kafka 安装包\n\n# (c) 优点\n\n 1. 客户端语言丰富：支持 java、.net、php、ruby、python、go 等多种语言；\n 2. 高性能：单机写入 tps 约在 100 万条/秒，消息大小 10 个字节；\n 3. 提供 完全分布式架构，并有 replica 机制，拥有较高的 可用性 和 可靠性，理论上支持 消息无限堆积；\n 4. 支持批量操作；\n 5. 消费者 采用 pull 方式获取消息。消息有序，通过控制 能够保证所有消息被消费且仅被消费 一次；\n 6. 有优秀的第三方 kafka web 管理界面 kafka-manager；\n 7. 在 日志领域 比较成熟，被多家公司和多个开源项目使用。\n\n# (d) 缺点\n\n 1. kafka 单机超过 64 个 队列/分区 时，load 时会发生明显的飙高现象。队列 越多，负载 越高，发送消息 响应时间变长；\n 2. 使用 短轮询方式，实时性 取决于 轮询间隔时间；\n 3. 消费失败 不支持重试；\n 4. 支持 消息顺序，但是 一台代理宕机 后，就会产生 消息乱序；\n 5. 社区更新较慢。\n\n\n# mq 的技术选型\n\nmq 的技术选型一般要考虑以下几点：\n\n * 是否开源：这决定了能否商用，所以最为重要。\n * 社区活跃度越高越好：高社区活跃度，一般保证了低 bug 率，因为大部分 bug，已经有人遇到并解决了。\n * 技术生态适配性：客户端对各种编程语言的支持。比如：如果使用 mq 的都是 java 应用，那么 activemq、rabbitmq、rocketmq、kafka 都可以。如果需要支持其他语言，那么 rmq 比较合适，因为它支持的编程语言比较丰富。如果 mq 是应用于大数据或流式计算，那么 kafka 几乎是标配。如果是应用于在线业务系统，那么 kafka 就不合适了，可以考虑 rabbitmq、 rocketmq 很合适。\n * 高可用性：应用于线上的准入标准。\n * 性能：具备足够好的性能，能满足绝大多数场景的性能要求。\n\n特性                activemq                     rabbitmq                        rocketmq                                      kafka\n单机吞吐量             万级，比 rocketmq、kafka 低一个数量级   同 activemq                      10 万级，支撑高吞吐                                   10 万级，高吞吐，一般配合大数据类的系统来进行流式计算、日志采集等场景\ntopic 数量对吞吐量的影响                                                                topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 rocketmq   topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，kafka 尽量保证 topic\n                                                                               的一大优势，在同等机器下，可以支撑大量的 topic                    数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源\n时效性               ms 级                         微秒级，这是 rabbitmq 的一大特点，延迟最低      ms 级                                          延迟在 ms 级以内\n可用性               高，基于主从架构实现高可用                同 activemq                      非常高，分布式架构                                     非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用\n消息可靠性             有较低的概率丢失数据                   基本不丢                            经过参数优化配置，可以做到 0 丢失                            同 rocketmq\n功能支持              mq 领域的功能极其完备                 基于 erlang 开发，并发能力很强，性能极好，延时很低   mq 功能较为完善，还是分布式的，扩展性好                         功能较为简单，主要支持简单的 mq 功能，在大数据领域的实时计算以及日志采集被大规模使用\n\n综上，各种对比之后，有如下建议：\n\n * 业务系统场景，建议使用 rocketmq、rabbitmq。如果所有应用都是 java，优选 rocketmq，因为 rocketmq 本身就是 java 开发的，所以最适配。如果业务中有多种编程语言的应用，建议选择 rabbitmq。\n * 大数据和流式计算领域，或是作为日志缓冲，强烈建议选择 kafka，业界标准，久经考验。\n\n\n# jms\n\n提到 mq，就顺便提一下 jms 。\n\njms（java message service，java 消息服务）api 是一个消息服务的标准/规范，允许应用程序组件基于 javaee 平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。\n\n在 ejb 架构中，有消息 bean 可以无缝的与 jms 消息服务集成。在 j2ee 架构模式中，有消息服务者模式，用于实现消息与应用直接的解耦。\n\n\n# 消息模型\n\n在 jms 标准中，有两种消息模型：\n\n * p2p(point to point)\n * pub/sub(publish/subscribe)\n\n# p2p 模式\n\n\np2p 模式包含三个角色：mq（queue），发送者(sender)，接收者(receiver)。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。\n\np2p 的特点\n\n * 每个消息只有一个消费者（consumer）(即一旦被消费，消息就不再在 mq 中)\n * 发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列\n * 接收者在成功接收消息之后需向队列应答成功\n\n如果希望发送的每个消息都会被成功处理的话，那么需要 p2p 模式。\n\n# pub/sub 模式\n\n\n包含三个角色主题（topic），发布者（publisher），订阅者（subscriber） 。多个发布者将消息发送到 topic,系统将这些消息传递给多个订阅者。\n\npub/sub 的特点\n\n * 每个消息可以有多个消费者\n * 发布者和订阅者之间有时间上的依赖性。针对某个主题（topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。\n * 为了消费消息，订阅者必须保持运行的状态。\n\n为了缓和这样严格的时间相关性，jms 允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。\n\n如果希望发送的消息可以不被做任何处理、或者只被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用 pub/sub 模型。\n\n\n# 消息消费\n\n在 jms 中，消息的产生和消费都是异步的。对于消费来说，jms 的消息者可以通过两种方式来消费消息。\n\n * 同步 - 订阅者或接收者通过 receive 方法来接收消息，receive 方法在接收到消息之前（或超时之前）将一直阻塞；\n * 异步 - 订阅者或接收者可以注册为一个消息监听器。当消息到达之后，系统自动调用监听器的 onmessage 方法。\n\njndi - java 命名和目录接口,是一种标准的 java 命名系统接口。可以在网络上查找和访问服务。通过指定一个资源名称，该名称对应于数据库或命名服务中的一个记录，同时返回资源连接建立所必须的信息。\n\njndi 在 jms 中起到查找和访问发送目标或消息来源的作用。\n\n\n# jms 编程模型\n\n# connectionfactory\n\n创建 connection 对象的工厂，针对两种不同的 jms 消息模型，分别有 queueconnectionfactory 和 topicconnectionfactory 两种。可以通过 jndi 来查找 connectionfactory 对象。\n\n# destination\n\ndestination 的意思是消息生产者的消息发送目标或者说消息消费者的消息来源。对于消息生产者来说，它的 destination 是某个队列（queue）或某个主题（topic）;对于消息消费者来说，它的 destination 也是某个队列或主题（即消息来源）。\n\n所以，destination 实际上就是两种类型的对象：queue、topic。可以通过 jndi 来查找 destination。\n\n# connection\n\nconnection 表示在客户端和 jms 系统之间建立的链接（对 tcp/ip socket 的包装）。connection 可以产生一个或多个 session。跟 connectionfactory 一样，connection 也有两种类型：queueconnection 和 topicconnection。\n\n# session\n\nsession 是操作消息的接口。可以通过 session 创建生产者、消费者、消息等。session 提供了事务的功能。当需要使用 session 发送/接收多个消息时，可以将这些发送/接收动作放到一个事务中。同样，也分 queuesession 和 topicsession。\n\n# 消息的生产者\n\n消息生产者由 session 创建，并用于将消息发送到 destination。同样，消息生产者分两种类型：queuesender 和 topicpublisher。可以调用消息生产者的方法（send 或 publish 方法）发送消息。\n\n# 消息消费者\n\n消息消费者由 session 创建，用于接收被发送到 destination 的消息。两种类型：queuereceiver 和 topicsubscriber。可分别通过 session 的 createreceiver(queue)或 createsubscriber(topic)来创建。当然，也可以 session 的 creatdurablesubscriber 方法来创建持久化的订阅者。\n\n# messagelistener\n\n消息监听器。如果注册了消息监听器，一旦消息到达，将自动调用监听器的 onmessage 方法。ejb 中的 mdb（message-driven bean）就是一种 messagelistener。\n\n\n# 参考资料\n\n * 大型网站架构系列：分布式 mq（一）\n * 大型网站架构系列：mq（二）\n * 分布式开放 mq(rocketmq)的原理与实践\n * 阿里 rocketmq 优势对比\n * advanced-java 之 mq\n * 浅谈消息队列及常见的消息中间件',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"RocketMQ 快速入门",frontmatter:{title:"RocketMQ 快速入门",categories:["编程","Java","中间件","MQ"],tags:["Java","中间件","MQ","RocketMQ"],abbrlink:"3e7adddd",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/f56a96/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/01.MQ/03.RocketMQ.html",relativePath:"14.中间件/01.MQ/03.RocketMQ.md",key:"v-5df11448",path:"/pages/f56a96/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:20},{level:2,title:"安装",slug:"安装",normalizedTitle:"安装",charIndex:1266},{level:3,title:"环境要求",slug:"环境要求",normalizedTitle:"环境要求",charIndex:1273},{level:3,title:"下载解压",slug:"下载解压",normalizedTitle:"下载解压",charIndex:1353},{level:3,title:"启动 Name Server",slug:"启动-name-server",normalizedTitle:"启动 name server",charIndex:1526},{level:3,title:"启动 Broker",slug:"启动-broker",normalizedTitle:"启动 broker",charIndex:1648},{level:3,title:"收发消息",slug:"收发消息",normalizedTitle:"收发消息",charIndex:1821},{level:3,title:"关闭服务器",slug:"关闭服务器",normalizedTitle:"关闭服务器",charIndex:2196},{level:2,title:"API",slug:"api",normalizedTitle:"api",charIndex:2422},{level:3,title:"Producer",slug:"producer",normalizedTitle:"producer",charIndex:150},{level:4,title:"可靠的同步发送",slug:"可靠的同步发送",normalizedTitle:"可靠的同步发送",charIndex:2660},{level:4,title:"可靠的异步发送",slug:"可靠的异步发送",normalizedTitle:"可靠的异步发送",charIndex:2671},{level:4,title:"单向传输",slug:"单向传输",normalizedTitle:"单向传输",charIndex:5083},{level:3,title:"Consumer",slug:"consumer",normalizedTitle:"consumer",charIndex:392},{level:3,title:"FAQ",slug:"faq",normalizedTitle:"faq",charIndex:7656},{level:4,title:"connect to <172.17.0.1:10909> failed",slug:"connect-to-172-17-0-1-10909-failed",normalizedTitle:"connect to &lt;172.17.0.1:10909&gt; failed",charIndex:null},{level:2,title:"架构",slug:"架构",normalizedTitle:"架构",charIndex:9309},{level:3,title:"Producer",slug:"producer-2",normalizedTitle:"producer",charIndex:150},{level:3,title:"Consumer",slug:"consumer-2",normalizedTitle:"consumer",charIndex:392},{level:3,title:"NameServer",slug:"nameserver",normalizedTitle:"nameserver",charIndex:9331},{level:3,title:"Broker",slug:"broker",normalizedTitle:"broker",charIndex:414},{level:2,title:"原理",slug:"原理",normalizedTitle:"原理",charIndex:10949},{level:3,title:"顺序消息",slug:"顺序消息",normalizedTitle:"顺序消息",charIndex:11050},{level:4,title:"第一种模型",slug:"第一种模型",normalizedTitle:"第一种模型",charIndex:11058},{level:4,title:"第二种模型",slug:"第二种模型",normalizedTitle:"第二种模型",charIndex:11361},{level:3,title:"消息重复",slug:"消息重复",normalizedTitle:"消息重复",charIndex:12040},{level:3,title:"事务消息",slug:"事务消息",normalizedTitle:"事务消息",charIndex:14058},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:14316}],headersStr:"简介 安装 环境要求 下载解压 启动 Name Server 启动 Broker 收发消息 关闭服务器 API Producer 可靠的同步发送 可靠的异步发送 单向传输 Consumer FAQ connect to <172.17.0.1:10909> failed 架构 Producer Consumer NameServer Broker 原理 顺序消息 第一种模型 第二种模型 消息重复 事务消息 参考资料",content:'# RocketMQ 快速入门\n\n\n# 简介\n\nRocketMQ 是一款开源的分布式消息队列，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。\n\nRocketMQ 被阿里巴巴捐赠给 Apache，成为 Apache 的孵化项目。\n\n\n\nRocketMQ 有以下核心概念：\n\n * Producer - 将业务应用程序系统生成的消息发送给代理。RocketMQ 提供多种发送范例：同步，异步和单向。\n   * Producer Group - 具有相同角色的 Producer 组合在一起。如果原始 Producer 在事务之后崩溃，则代理可以联系同一 Producer 组的不同 Producer 实例以提交或回滚事务。警告：考虑到提供的 Producer 在发送消息方面足够强大，每个 Producer 组只允许一个实例，以避免不必要的生成器实例初始化。\n * Consumer - Consumer 从 Broker 那里获取消息并将其提供给应用程序。从用户应用的角度来看，提供了两种类型的 Consumer：\n   * PullConsumer - PullConsumer 积极地从 Broker 那里获取消息。一旦提取了批量消息，用户应用程序就会启动消费过程。\n   * PushConsumer - PushConsumer 封装消息提取，消费进度并维护其他内部工作，为最终用户留下回调接口，这个借口会在消息到达时被执行。\n   * Consumer Group - 完全相同角色的 Consumer 被组合在一起并命名为 Consumer Group。Consumer Group 是一个很好的概念，在消息消费方面实现负载平衡和容错目标非常容易。警告：Consumer Group 中的 Consumer 实例必须具有完全相同的主题订阅。\n * Broker - Broker 是 RocketMQ 的主要组成部分。它接收从 Producer 发送的消息，存储它们并准备处理来自 Consumer 的消费请求。它还存储与消息相关的元数据，包括 Consumer Group，消耗进度偏移和主题/队列信息。\n * Name Server - 充当路由信息提供者。Producer/Consumer 客户查找主题以查找相应的 Broker 列表。\n * Topic - 是 Producer 传递消息和 Consumer 提取消息的类别。\n * Message - 是要传递的信息。消息必须有一个主题，可以将其解释为您要发送给的邮件地址。消息还可以具有可选 Tag 和额外的键值对。例如，您可以为消息设置业务密钥，并在代理服务器上查找消息以诊断开发期间的问题。\n   * Message Queue - 主题被划分为一个或多个子主题“消息队列”。\n   * Tag - 即子主题，为用户提供了额外的灵活性。对于 Tag，来自同一业务模块的具有不同目的的消息可以具有相同的主题和不同的 Tag。\n\n\n# 安装\n\n\n# 环境要求\n\n * 推荐 64 位操作系统：Linux/Unix/Mac\n * 64bit JDK 1.8+\n * Maven 3.2.x\n * Git\n\n\n# 下载解压\n\n进入官方下载地址：https://rocketmq.apache.org/dowloading/releases/，选择合适版本\n\n建议选择 binary 版本。\n\n解压到本地：\n\n> unzip rocketmq-all-4.2.0-source-release.zip\n> cd rocketmq-all-4.2.0/\n\n\n\n# 启动 Name Server\n\n> nohup sh bin/mqnamesrv &\n> tail -f ~/logs/rocketmqlogs/namesrv.log\nThe Name Server boot success...\n\n\n\n# 启动 Broker\n\n> nohup sh bin/mqbroker -n localhost:9876 -c conf/broker.conf &\n> tail -f ~/logs/rocketmqlogs/broker.log\nThe broker[%s, 172.30.30.233:10911] boot success...\n\n\n\n# 收发消息\n\n执行收发消息操作之前，不许告诉客户端命名服务器的位置。在 RocketMQ 中有多种方法来实现这个目的。这里，我们使用最简单的方法——设置环境变量 NAMESRV_ADDR ：\n\n> export NAMESRV_ADDR=localhost:9876\n> sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer\nSendResult [sendStatus=SEND_OK, msgId= ...\n\n> sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer\nConsumeMessageThread_%d Receive New Messages: [MessageExt...\n\n\n\n# 关闭服务器\n\n> sh bin/mqshutdown broker\nThe mqbroker(36695) is running...\nSend shutdown request to mqbroker(36695) OK\n\n> sh bin/mqshutdown namesrv\nThe mqnamesrv(36664) is running...\nSend shutdown request to mqnamesrv(36664) OK\n\n\n\n# API\n\n首先在项目中引入 maven 依赖：\n\n<dependency>\n    <groupId>org.apache.rocketmq</groupId>\n    <artifactId>rocketmq-client</artifactId>\n    <version>4.2.0</version>\n</dependency>\n\n\n\n# Producer\n\nProducer 在 RocketMQ 中负责发送消息。\n\nRocketMQ 有三种消息发送方式：\n\n * 可靠的同步发送\n * 可靠的异步发送\n * 单项发送\n\n# 可靠的同步发送\n\n可靠的同步传输用于广泛的场景，如重要的通知消息，短信通知，短信营销系统等。\n\npublic class SyncProducer {\n    public static void main(String[] args) throws Exception {\n        //Instantiate with a producer group name.\n        DefaultMQProducer producer = new\n            DefaultMQProducer("please_rename_unique_group_name");\n        //Launch the instance.\n        producer.start();\n        for (int i = 0; i < 100; i++) {\n            //Create a message instance, specifying topic, tag and message body.\n            Message msg = new Message("TopicTest" /* Topic */,\n                "TagA" /* Tag */,\n                ("Hello RocketMQ " +\n                    i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */\n            );\n            //Call send message to deliver message to one of brokers.\n            SendResult sendResult = producer.send(msg);\n            System.out.printf("%s%n", sendResult);\n        }\n        //Shut down once the producer instance is not longer in use.\n        producer.shutdown();\n    }\n}\n\n\n# 可靠的异步发送\n\n异步传输通常用于响应时间敏感的业务场景。\n\npublic class AsyncProducer {\n    public static void main(String[] args) throws Exception {\n        //Instantiate with a producer group name.\n        DefaultMQProducer producer = new DefaultMQProducer("ExampleProducerGroup");\n        //Launch the instance.\n        producer.start();\n        producer.setRetryTimesWhenSendAsyncFailed(0);\n        for (int i = 0; i < 100; i++) {\n                final int index = i;\n                //Create a message instance, specifying topic, tag and message body.\n                Message msg = new Message("TopicTest",\n                    "TagA",\n                    "OrderID188",\n                    "Hello world".getBytes(RemotingHelper.DEFAULT_CHARSET));\n                producer.send(msg, new SendCallback() {\n                    @Override\n                    public void onSuccess(SendResult sendResult) {\n                        System.out.printf("%-10d OK %s %n", index,\n                            sendResult.getMsgId());\n                    }\n                    @Override\n                    public void onException(Throwable e) {\n                        System.out.printf("%-10d Exception %s %n", index, e);\n                        e.printStackTrace();\n                    }\n                });\n        }\n        //Shut down once the producer instance is not longer in use.\n        producer.shutdown();\n    }\n}\n\n\n# 单向传输\n\n单向传输用于需要中等可靠性的情况，例如日志收集。\n\npublic class OnewayProducer {\n    public static void main(String[] args) throws Exception{\n        //Instantiate with a producer group name.\n        DefaultMQProducer producer = new DefaultMQProducer("ExampleProducerGroup");\n        //Launch the instance.\n        producer.start();\n        for (int i = 0; i < 100; i++) {\n            //Create a message instance, specifying topic, tag and message body.\n            Message msg = new Message("TopicTest" /* Topic */,\n                "TagA" /* Tag */,\n                ("Hello RocketMQ " +\n                    i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */\n            );\n            //Call send message to deliver message to one of brokers.\n            producer.sendOneway(msg);\n\n        }\n        //Shut down once the producer instance is not longer in use.\n        producer.shutdown();\n    }\n}\n\n\n\n# Consumer\n\nConsumer 在 RocketMQ 中负责接收消息。\n\npublic class OrderedConsumer {\n    public static void main(String[] args) throws Exception {\n        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("example_group_name");\n        consumer.setNamesrvAddr(RocketConfig.HOST);\n\n        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);\n\n        consumer.subscribe("TopicTest", "TagA || TagC || TagD");\n\n        consumer.registerMessageListener(new MessageListenerOrderly() {\n\n            AtomicLong consumeTimes = new AtomicLong(0);\n\n            @Override\n            public ConsumeOrderlyStatus consumeMessage(List<MessageExt> msgs,\n                ConsumeOrderlyContext context) {\n                context.setAutoCommit(false);\n                System.out.printf(Thread.currentThread().getName() + " Receive New Messages: " + msgs + "%n");\n                this.consumeTimes.incrementAndGet();\n                if ((this.consumeTimes.get() % 2) == 0) {\n                    return ConsumeOrderlyStatus.SUCCESS;\n                } else if ((this.consumeTimes.get() % 3) == 0) {\n                    return ConsumeOrderlyStatus.ROLLBACK;\n                } else if ((this.consumeTimes.get() % 4) == 0) {\n                    return ConsumeOrderlyStatus.COMMIT;\n                } else if ((this.consumeTimes.get() % 5) == 0) {\n                    context.setSuspendCurrentQueueTimeMillis(3000);\n                    return ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT;\n                }\n                return ConsumeOrderlyStatus.SUCCESS;\n\n            }\n        });\n\n        consumer.start();\n\n        System.out.printf("Consumer Started.%n");\n    }\n}\n\n\n\n# FAQ\n\n# connect to <172.17.0.1:10909> failed\n\n启动后，Producer 客户端连接 RocketMQ 时报错：\n\norg.apache.rocketmq.remoting.exception.RemotingConnectException: connect to <172.17.0.1:10909> failed\n    at org.apache.rocketmq.remoting.netty.NettyRemotingClient.invokeSync(NettyRemotingClient.java:357)\n    at org.apache.rocketmq.client.impl.MQClientAPIImpl.sendMessageSync(MQClientAPIImpl.java:343)\n    at org.apache.rocketmq.client.impl.MQClientAPIImpl.sendMessage(MQClientAPIImpl.java:327)\n    at org.apache.rocketmq.client.impl.MQClientAPIImpl.sendMessage(MQClientAPIImpl.java:290)\n    at org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendKernelImpl(DefaultMQProducerImpl.java:688)\n    at org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendSelectImpl(DefaultMQProducerImpl.java:901)\n    at org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:878)\n    at org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:873)\n    at org.apache.rocketmq.client.producer.DefaultMQProducer.send(DefaultMQProducer.java:369)\n    at com.emrubik.uc.mdm.sync.utils.MdmInit.sendMessage(MdmInit.java:62)\n    at com.emrubik.uc.mdm.sync.utils.MdmInit.main(MdmInit.java:2149)\n\n\n原因：RocketMQ 部署在虚拟机上，内网 ip 为 10.10.30.63，该虚拟机一个 docker0 网卡，ip 为 172.17.0.1。RocketMQ broker 启动时默认使用了 docker0 网卡，Producer 客户端无法连接 172.17.0.1，造成以上问题。\n\n解决方案\n\n（1）干掉 docker0 网卡或修改网卡名称\n\n（2）停掉 broker，修改 broker 配置文件，重启 broker。\n\n修改 conf/broker.conf，增加两行来指定启动 broker 的 IP：\n\nnamesrvAddr = 10.10.30.63:9876\nbrokerIP1 = 10.10.30.63\n\n\n启动时需要指定配置文件\n\nnohup sh bin/mqbroker -n localhost:9876 -c conf/broker.conf &\n\n\n\n# 架构\n\n\n\nRocketMQ 由四部分组成：NameServer、Broker、Producer、Consumer。其中任意一个组成都可以水平扩展为集群模式，以避免单点故障问题。\n\n\n# Producer\n\nProducers 支持分布式集群方式部署。Producer 通过 MQ 的负载均衡模块选择相应的 Broker 集群队列进行消息投递，投递的过程支持快速失败并且低延迟。\n\n\n# Consumer\n\nConsumer 支持分布式集群方式部署。支持以 push 推，pull 拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制，可以满足大多数用户的需求。\n\n\n# NameServer\n\nNameServer 是一个 Topic 路由注册中心，其角色类似 Dubbo 中的 zookeeper，支持 Broker 的动态注册与发现。主要包括两个功能：\n\n * Broker 管理，NameServer 接受 Broker 集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查 Broker 是否还存活；\n * 路由信息管理，每个 NameServer 将保存关于 Broker 集群的整个路由信息和用于客户端查询的队列信息。然后 Producer 和 Conumser 通过 NameServer 就可以知道整个 Broker 集群的路由信息，从而进行消息的投递和消费。\n\nNameServer 通常也是集群的方式部署，各实例间相互不进行信息通讯。Broker 是向每一台 NameServer 注册自己的路由信息，所以每一个 NameServer 实例上面都保存一份完整的路由信息。当某个 NameServer 因某种原因下线了，Broker 仍然可以向其它 NameServer 同步其路由信息，Producer、Consumer 仍然可以动态感知 Broker 的路由的信息。\n\nNameServer 是一个功能齐全的服务器，主要包括两个功能：\n\n 1. Broker 管理 - NameServer 接受来自 Broker 集群的注册，并提供心跳机制来检查 Broker 节点是否存活。\n 2. 路由管理 - 每个 NameServer 将保存有关 Broker 集群的完整路由信息和客户端查询的查询队列。\n\nRocketMQ 客户端（Producer/Consumer）将从 NameServer 查询队列路由信息。\n\n将 NameServer 地址列表提供给客户端有四种方法：\n\n 1. 编程方式 - 类似：producer.setNamesrvAddr("ip:port")\n 2. Java 选项 - 使用 rocketmq.namesrv.addr 参数\n 3. 环境变量 - 设置环境变量 NAMESRV_ADDR\n 4. HTTP 端点\n\n> 更详细信息可以参考官方文档：here\n\n\n# Broker\n\nBroker 主要负责消息的存储、投递和查询以及服务高可用保证，为了实现这些功能，Broker 包含了以下几个重要子模块。\n\nBroker 有几个重要的子模块：\n\n * Remoting Module：整个 Broker 的实体，负责处理来自 clients 端的请求。\n * Client Manager：负责管理客户端(Producer/Consumer)和维护 Consumer 的 Topic 订阅信息。\n * Store Service：提供方便简单的 API 接口处理消息存储到物理硬盘和查询功能。\n * HA Service：高可用服务，提供 Master Broker 和 Slave Broker 之间的数据同步功能。\n * Index Service：根据特定的 Message key 对投递到 Broker 的消息进行索引服务，以提供消息的快速查询。\n\n\n\n\n# 原理\n\n分布式消息系统作为实现分布式系统可扩展、可伸缩性的关键组件，需要具有高吞吐量、高可用等特点。而谈到消息系统的设计，就回避不了两个问题：\n\n 1. 消息的顺序问题\n 2. 消息的重复问题\n\n\n# 顺序消息\n\n# 第一种模型\n\n假如生产者产生了 2 条消息：M1、M2，要保证这两条消息的顺序，应该怎样做？你脑中想到的可能是这样：\n\n\n\n假定 M1 发送到 S1，M2 发送到 S2，如果要保证 M1 先于 M2 被消费，那么需要 M1 到达消费端被消费后，通知 S2，然后 S2 再将 M2 发送到消费端。\n\n这个模型存在的问题是，如果 M1 和 M2 分别发送到两台 Server 上，就不能保证 M1 先达到 MQ 集群，也不能保证 M1 被先消费。换个角度看，如果 M2 先于 M1 达到 MQ 集群，甚至 M2 被消费后，M1 才达到消费端，这时消息也就乱序了，说明以上模型是不能保证消息的顺序的。\n\n\n\n# 第二种模型\n\n如何才能在 MQ 集群保证消息的顺序？一种简单的方式就是将 M1、M2 发送到同一个 Server 上：\n\n这样可以保证 M1 先于 M2 到达 MQServer（生产者等待 M1 发送成功后再发送 M2），根据先达到先被消费的原则，M1 会先于 M2 被消费，这样就保证了消息的顺序。\n\n这个模型也仅仅是理论上可以保证消息的顺序，在实际场景中可能会遇到下面的问题：\n\n\n\n只要将消息从一台服务器发往另一台服务器，就会存在网络延迟问题。如上图所示，如果发送 M1 耗时大于发送 M2 的耗时，那么 M2 就仍将被先消费，仍然不能保证消息的顺序。即使 M1 和 M2 同时到达消费端，由于不清楚消费端 1 和消费端 2 的负载情况，仍然有可能出现 M2 先于 M1 被消费的情况。\n\n如何解决这个问题？将 M1 和 M2 发往同一个消费者，且发送 M1 后，需要消费端响应成功后才能发送 M2。\n\n这可能产生另外的问题：如果 M1 被发送到消费端后，消费端 1 没有响应，那是继续发送 M2 呢，还是重新发送 M1？一般为了保证消息一定被消费，肯定会选择重发 M1 到另外一个消费端 2，就如下图所示。\n\n\n\n这样的模型就严格保证消息的顺序，细心的你仍然会发现问题，消费端 1 没有响应 Server 时有两种情况，一种是 M1 确实没有到达(数据在网络传送中丢失)，另外一种消费端已经消费 M1 且已经发送响应消息，只是 MQ Server 端没有收到。如果是第二种情况，重发 M1，就会造成 M1 被重复消费。也就引入了我们要说的第二个问题，消息重复问题，这个后文会详细讲解。\n\n回过头来看消息顺序问题，严格的顺序消息非常容易理解，也可以通过文中所描述的方式来简单处理。总结起来，要实现严格的顺序消息，简单且可行的办法就是：\n\n保证生产者 - MQServer - 消费者是一对一对一的关系。\n\n这样的设计虽然简单易行，但也会存在一些很严重的问题，比如：\n\n 1. 并行度就会成为消息系统的瓶颈（吞吐量不够）\n 2. 更多的异常处理，比如：只要消费端出现问题，就会导致整个处理流程阻塞，我们不得不花费更多的精力来解决阻塞的问题。\n\nRocketMQ 的解决方案：通过合理的设计或者将问题分解来规避。如果硬要把时间花在解决问题本身，实际上不仅效率低下，而且也是一种浪费。从这个角度来看消息的顺序问题，我们可以得出两个结论：\n\n 1. 不关注乱序的应用实际大量存在\n 2. 队列无序并不意味着消息无序\n\n最后我们从源码角度分析 RocketMQ 怎么实现发送顺序消息。\n\nRocketMQ 通过轮询所有队列的方式来确定消息被发送到哪一个队列（负载均衡策略）。比如下面的示例中，订单号相同的消息会被先后发送到同一个队列中：\n\n// RocketMQ 通过 MessageQueueSelector 中实现的算法来确定消息发送到哪一个队列上\n// RocketMQ 默认提供了两种 MessageQueueSelector 实现：随机/Hash\n// 当然你可以根据业务实现自己的 MessageQueueSelector 来决定消息按照何种策略发送到消息队列中\nSendResult sendResult = producer.send(msg, new MessageQueueSelector() {\n    @Override\n    public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {\n        Integer id = (Integer) arg;\n        int index = id % mqs.size();\n        return mqs.get(index);\n    }\n}, orderId);\n\n\n在获取到路由信息以后，会根据 MessageQueueSelector 实现的算法来选择一个队列，同一个 OrderId 获取到的肯定是同一个队列。\n\nprivate SendResult send()  {\n    // 获取topic路由信息\n    TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic());\n    if (topicPublishInfo != null && topicPublishInfo.ok()) {\n        MessageQueue mq = null;\n        // 根据我们的算法，选择一个发送队列\n        // 这里的arg = orderId\n        mq = selector.select(topicPublishInfo.getMessageQueueList(), msg, arg);\n        if (mq != null) {\n            return this.sendKernelImpl(msg, mq, communicationMode, sendCallback, timeout);\n        }\n    }\n}\n\n\n\n# 消息重复\n\n造成消息重复的根本原因是：网络不可达。只要通过网络交换数据，就无法避免这个问题。所以解决这个问题的办法就是绕过这个问题。那么问题就变成了：如果消费端收到两条一样的消息，应该怎样处理？\n\n 1. 消费端处理消息的业务逻辑保持幂等性。\n 2. 保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现。\n\n第 1 条很好理解，只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。\n\n第 2 条原理就是利用一张日志表来记录已经处理成功的消息的 ID，如果新到的消息 ID 已经在日志表中，那么就不再处理这条消息。\n\n第 1 条解决方案，很明显应该在消费端实现，不属于消息系统要实现的功能。\n\n第 2 条可以消息系统实现，也可以业务端实现。正常情况下出现重复消息的概率其实很小，如果由消息系统来实现的话，肯定会对消息系统的吞吐量和高可用有影响，所以最好还是由业务端自己处理消息重复的问题，这也是 RocketMQ 不解决消息重复的问题的原因。\n\nRocketMQ 不保证消息不重复，如果你的业务需要保证严格的不重复消息，需要你自己在业务端去重。\n\n\n# 事务消息\n\nRocketMQ 除了支持普通消息，顺序消息，另外还支持事务消息。\n\n假设这样的场景：\n\n\n\n图中执行本地事务（Bob 账户扣款）和发送异步消息应该保证同时成功或者同时失败，也就是扣款成功了，发送消息一定要成功，如果扣款失败了，就不能再发送消息。那问题是：我们是先扣款还是先发送消息呢？\n\n\n\nRocketMQ 分布式事务步骤：\n\n发送 Prepared 消息 2222222222222222222，并拿到接受消息的地址。 执行本地事务 通过第 1 步骤拿到的地址去访问消息，并修改消息状态。\n\n\n# 参考资料\n\n * RocketMQ 官方文档\n * 分布式开放消息系统(RocketMQ)的原理与实践',normalizedContent:'# rocketmq 快速入门\n\n\n# 简介\n\nrocketmq 是一款开源的分布式消息队列，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。\n\nrocketmq 被阿里巴巴捐赠给 apache，成为 apache 的孵化项目。\n\n\n\nrocketmq 有以下核心概念：\n\n * producer - 将业务应用程序系统生成的消息发送给代理。rocketmq 提供多种发送范例：同步，异步和单向。\n   * producer group - 具有相同角色的 producer 组合在一起。如果原始 producer 在事务之后崩溃，则代理可以联系同一 producer 组的不同 producer 实例以提交或回滚事务。警告：考虑到提供的 producer 在发送消息方面足够强大，每个 producer 组只允许一个实例，以避免不必要的生成器实例初始化。\n * consumer - consumer 从 broker 那里获取消息并将其提供给应用程序。从用户应用的角度来看，提供了两种类型的 consumer：\n   * pullconsumer - pullconsumer 积极地从 broker 那里获取消息。一旦提取了批量消息，用户应用程序就会启动消费过程。\n   * pushconsumer - pushconsumer 封装消息提取，消费进度并维护其他内部工作，为最终用户留下回调接口，这个借口会在消息到达时被执行。\n   * consumer group - 完全相同角色的 consumer 被组合在一起并命名为 consumer group。consumer group 是一个很好的概念，在消息消费方面实现负载平衡和容错目标非常容易。警告：consumer group 中的 consumer 实例必须具有完全相同的主题订阅。\n * broker - broker 是 rocketmq 的主要组成部分。它接收从 producer 发送的消息，存储它们并准备处理来自 consumer 的消费请求。它还存储与消息相关的元数据，包括 consumer group，消耗进度偏移和主题/队列信息。\n * name server - 充当路由信息提供者。producer/consumer 客户查找主题以查找相应的 broker 列表。\n * topic - 是 producer 传递消息和 consumer 提取消息的类别。\n * message - 是要传递的信息。消息必须有一个主题，可以将其解释为您要发送给的邮件地址。消息还可以具有可选 tag 和额外的键值对。例如，您可以为消息设置业务密钥，并在代理服务器上查找消息以诊断开发期间的问题。\n   * message queue - 主题被划分为一个或多个子主题“消息队列”。\n   * tag - 即子主题，为用户提供了额外的灵活性。对于 tag，来自同一业务模块的具有不同目的的消息可以具有相同的主题和不同的 tag。\n\n\n# 安装\n\n\n# 环境要求\n\n * 推荐 64 位操作系统：linux/unix/mac\n * 64bit jdk 1.8+\n * maven 3.2.x\n * git\n\n\n# 下载解压\n\n进入官方下载地址：https://rocketmq.apache.org/dowloading/releases/，选择合适版本\n\n建议选择 binary 版本。\n\n解压到本地：\n\n> unzip rocketmq-all-4.2.0-source-release.zip\n> cd rocketmq-all-4.2.0/\n\n\n\n# 启动 name server\n\n> nohup sh bin/mqnamesrv &\n> tail -f ~/logs/rocketmqlogs/namesrv.log\nthe name server boot success...\n\n\n\n# 启动 broker\n\n> nohup sh bin/mqbroker -n localhost:9876 -c conf/broker.conf &\n> tail -f ~/logs/rocketmqlogs/broker.log\nthe broker[%s, 172.30.30.233:10911] boot success...\n\n\n\n# 收发消息\n\n执行收发消息操作之前，不许告诉客户端命名服务器的位置。在 rocketmq 中有多种方法来实现这个目的。这里，我们使用最简单的方法——设置环境变量 namesrv_addr ：\n\n> export namesrv_addr=localhost:9876\n> sh bin/tools.sh org.apache.rocketmq.example.quickstart.producer\nsendresult [sendstatus=send_ok, msgid= ...\n\n> sh bin/tools.sh org.apache.rocketmq.example.quickstart.consumer\nconsumemessagethread_%d receive new messages: [messageext...\n\n\n\n# 关闭服务器\n\n> sh bin/mqshutdown broker\nthe mqbroker(36695) is running...\nsend shutdown request to mqbroker(36695) ok\n\n> sh bin/mqshutdown namesrv\nthe mqnamesrv(36664) is running...\nsend shutdown request to mqnamesrv(36664) ok\n\n\n\n# api\n\n首先在项目中引入 maven 依赖：\n\n<dependency>\n    <groupid>org.apache.rocketmq</groupid>\n    <artifactid>rocketmq-client</artifactid>\n    <version>4.2.0</version>\n</dependency>\n\n\n\n# producer\n\nproducer 在 rocketmq 中负责发送消息。\n\nrocketmq 有三种消息发送方式：\n\n * 可靠的同步发送\n * 可靠的异步发送\n * 单项发送\n\n# 可靠的同步发送\n\n可靠的同步传输用于广泛的场景，如重要的通知消息，短信通知，短信营销系统等。\n\npublic class syncproducer {\n    public static void main(string[] args) throws exception {\n        //instantiate with a producer group name.\n        defaultmqproducer producer = new\n            defaultmqproducer("please_rename_unique_group_name");\n        //launch the instance.\n        producer.start();\n        for (int i = 0; i < 100; i++) {\n            //create a message instance, specifying topic, tag and message body.\n            message msg = new message("topictest" /* topic */,\n                "taga" /* tag */,\n                ("hello rocketmq " +\n                    i).getbytes(remotinghelper.default_charset) /* message body */\n            );\n            //call send message to deliver message to one of brokers.\n            sendresult sendresult = producer.send(msg);\n            system.out.printf("%s%n", sendresult);\n        }\n        //shut down once the producer instance is not longer in use.\n        producer.shutdown();\n    }\n}\n\n\n# 可靠的异步发送\n\n异步传输通常用于响应时间敏感的业务场景。\n\npublic class asyncproducer {\n    public static void main(string[] args) throws exception {\n        //instantiate with a producer group name.\n        defaultmqproducer producer = new defaultmqproducer("exampleproducergroup");\n        //launch the instance.\n        producer.start();\n        producer.setretrytimeswhensendasyncfailed(0);\n        for (int i = 0; i < 100; i++) {\n                final int index = i;\n                //create a message instance, specifying topic, tag and message body.\n                message msg = new message("topictest",\n                    "taga",\n                    "orderid188",\n                    "hello world".getbytes(remotinghelper.default_charset));\n                producer.send(msg, new sendcallback() {\n                    @override\n                    public void onsuccess(sendresult sendresult) {\n                        system.out.printf("%-10d ok %s %n", index,\n                            sendresult.getmsgid());\n                    }\n                    @override\n                    public void onexception(throwable e) {\n                        system.out.printf("%-10d exception %s %n", index, e);\n                        e.printstacktrace();\n                    }\n                });\n        }\n        //shut down once the producer instance is not longer in use.\n        producer.shutdown();\n    }\n}\n\n\n# 单向传输\n\n单向传输用于需要中等可靠性的情况，例如日志收集。\n\npublic class onewayproducer {\n    public static void main(string[] args) throws exception{\n        //instantiate with a producer group name.\n        defaultmqproducer producer = new defaultmqproducer("exampleproducergroup");\n        //launch the instance.\n        producer.start();\n        for (int i = 0; i < 100; i++) {\n            //create a message instance, specifying topic, tag and message body.\n            message msg = new message("topictest" /* topic */,\n                "taga" /* tag */,\n                ("hello rocketmq " +\n                    i).getbytes(remotinghelper.default_charset) /* message body */\n            );\n            //call send message to deliver message to one of brokers.\n            producer.sendoneway(msg);\n\n        }\n        //shut down once the producer instance is not longer in use.\n        producer.shutdown();\n    }\n}\n\n\n\n# consumer\n\nconsumer 在 rocketmq 中负责接收消息。\n\npublic class orderedconsumer {\n    public static void main(string[] args) throws exception {\n        defaultmqpushconsumer consumer = new defaultmqpushconsumer("example_group_name");\n        consumer.setnamesrvaddr(rocketconfig.host);\n\n        consumer.setconsumefromwhere(consumefromwhere.consume_from_first_offset);\n\n        consumer.subscribe("topictest", "taga || tagc || tagd");\n\n        consumer.registermessagelistener(new messagelistenerorderly() {\n\n            atomiclong consumetimes = new atomiclong(0);\n\n            @override\n            public consumeorderlystatus consumemessage(list<messageext> msgs,\n                consumeorderlycontext context) {\n                context.setautocommit(false);\n                system.out.printf(thread.currentthread().getname() + " receive new messages: " + msgs + "%n");\n                this.consumetimes.incrementandget();\n                if ((this.consumetimes.get() % 2) == 0) {\n                    return consumeorderlystatus.success;\n                } else if ((this.consumetimes.get() % 3) == 0) {\n                    return consumeorderlystatus.rollback;\n                } else if ((this.consumetimes.get() % 4) == 0) {\n                    return consumeorderlystatus.commit;\n                } else if ((this.consumetimes.get() % 5) == 0) {\n                    context.setsuspendcurrentqueuetimemillis(3000);\n                    return consumeorderlystatus.suspend_current_queue_a_moment;\n                }\n                return consumeorderlystatus.success;\n\n            }\n        });\n\n        consumer.start();\n\n        system.out.printf("consumer started.%n");\n    }\n}\n\n\n\n# faq\n\n# connect to <172.17.0.1:10909> failed\n\n启动后，producer 客户端连接 rocketmq 时报错：\n\norg.apache.rocketmq.remoting.exception.remotingconnectexception: connect to <172.17.0.1:10909> failed\n    at org.apache.rocketmq.remoting.netty.nettyremotingclient.invokesync(nettyremotingclient.java:357)\n    at org.apache.rocketmq.client.impl.mqclientapiimpl.sendmessagesync(mqclientapiimpl.java:343)\n    at org.apache.rocketmq.client.impl.mqclientapiimpl.sendmessage(mqclientapiimpl.java:327)\n    at org.apache.rocketmq.client.impl.mqclientapiimpl.sendmessage(mqclientapiimpl.java:290)\n    at org.apache.rocketmq.client.impl.producer.defaultmqproducerimpl.sendkernelimpl(defaultmqproducerimpl.java:688)\n    at org.apache.rocketmq.client.impl.producer.defaultmqproducerimpl.sendselectimpl(defaultmqproducerimpl.java:901)\n    at org.apache.rocketmq.client.impl.producer.defaultmqproducerimpl.send(defaultmqproducerimpl.java:878)\n    at org.apache.rocketmq.client.impl.producer.defaultmqproducerimpl.send(defaultmqproducerimpl.java:873)\n    at org.apache.rocketmq.client.producer.defaultmqproducer.send(defaultmqproducer.java:369)\n    at com.emrubik.uc.mdm.sync.utils.mdminit.sendmessage(mdminit.java:62)\n    at com.emrubik.uc.mdm.sync.utils.mdminit.main(mdminit.java:2149)\n\n\n原因：rocketmq 部署在虚拟机上，内网 ip 为 10.10.30.63，该虚拟机一个 docker0 网卡，ip 为 172.17.0.1。rocketmq broker 启动时默认使用了 docker0 网卡，producer 客户端无法连接 172.17.0.1，造成以上问题。\n\n解决方案\n\n（1）干掉 docker0 网卡或修改网卡名称\n\n（2）停掉 broker，修改 broker 配置文件，重启 broker。\n\n修改 conf/broker.conf，增加两行来指定启动 broker 的 ip：\n\nnamesrvaddr = 10.10.30.63:9876\nbrokerip1 = 10.10.30.63\n\n\n启动时需要指定配置文件\n\nnohup sh bin/mqbroker -n localhost:9876 -c conf/broker.conf &\n\n\n\n# 架构\n\n\n\nrocketmq 由四部分组成：nameserver、broker、producer、consumer。其中任意一个组成都可以水平扩展为集群模式，以避免单点故障问题。\n\n\n# producer\n\nproducers 支持分布式集群方式部署。producer 通过 mq 的负载均衡模块选择相应的 broker 集群队列进行消息投递，投递的过程支持快速失败并且低延迟。\n\n\n# consumer\n\nconsumer 支持分布式集群方式部署。支持以 push 推，pull 拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制，可以满足大多数用户的需求。\n\n\n# nameserver\n\nnameserver 是一个 topic 路由注册中心，其角色类似 dubbo 中的 zookeeper，支持 broker 的动态注册与发现。主要包括两个功能：\n\n * broker 管理，nameserver 接受 broker 集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查 broker 是否还存活；\n * 路由信息管理，每个 nameserver 将保存关于 broker 集群的整个路由信息和用于客户端查询的队列信息。然后 producer 和 conumser 通过 nameserver 就可以知道整个 broker 集群的路由信息，从而进行消息的投递和消费。\n\nnameserver 通常也是集群的方式部署，各实例间相互不进行信息通讯。broker 是向每一台 nameserver 注册自己的路由信息，所以每一个 nameserver 实例上面都保存一份完整的路由信息。当某个 nameserver 因某种原因下线了，broker 仍然可以向其它 nameserver 同步其路由信息，producer、consumer 仍然可以动态感知 broker 的路由的信息。\n\nnameserver 是一个功能齐全的服务器，主要包括两个功能：\n\n 1. broker 管理 - nameserver 接受来自 broker 集群的注册，并提供心跳机制来检查 broker 节点是否存活。\n 2. 路由管理 - 每个 nameserver 将保存有关 broker 集群的完整路由信息和客户端查询的查询队列。\n\nrocketmq 客户端（producer/consumer）将从 nameserver 查询队列路由信息。\n\n将 nameserver 地址列表提供给客户端有四种方法：\n\n 1. 编程方式 - 类似：producer.setnamesrvaddr("ip:port")\n 2. java 选项 - 使用 rocketmq.namesrv.addr 参数\n 3. 环境变量 - 设置环境变量 namesrv_addr\n 4. http 端点\n\n> 更详细信息可以参考官方文档：here\n\n\n# broker\n\nbroker 主要负责消息的存储、投递和查询以及服务高可用保证，为了实现这些功能，broker 包含了以下几个重要子模块。\n\nbroker 有几个重要的子模块：\n\n * remoting module：整个 broker 的实体，负责处理来自 clients 端的请求。\n * client manager：负责管理客户端(producer/consumer)和维护 consumer 的 topic 订阅信息。\n * store service：提供方便简单的 api 接口处理消息存储到物理硬盘和查询功能。\n * ha service：高可用服务，提供 master broker 和 slave broker 之间的数据同步功能。\n * index service：根据特定的 message key 对投递到 broker 的消息进行索引服务，以提供消息的快速查询。\n\n\n\n\n# 原理\n\n分布式消息系统作为实现分布式系统可扩展、可伸缩性的关键组件，需要具有高吞吐量、高可用等特点。而谈到消息系统的设计，就回避不了两个问题：\n\n 1. 消息的顺序问题\n 2. 消息的重复问题\n\n\n# 顺序消息\n\n# 第一种模型\n\n假如生产者产生了 2 条消息：m1、m2，要保证这两条消息的顺序，应该怎样做？你脑中想到的可能是这样：\n\n\n\n假定 m1 发送到 s1，m2 发送到 s2，如果要保证 m1 先于 m2 被消费，那么需要 m1 到达消费端被消费后，通知 s2，然后 s2 再将 m2 发送到消费端。\n\n这个模型存在的问题是，如果 m1 和 m2 分别发送到两台 server 上，就不能保证 m1 先达到 mq 集群，也不能保证 m1 被先消费。换个角度看，如果 m2 先于 m1 达到 mq 集群，甚至 m2 被消费后，m1 才达到消费端，这时消息也就乱序了，说明以上模型是不能保证消息的顺序的。\n\n\n\n# 第二种模型\n\n如何才能在 mq 集群保证消息的顺序？一种简单的方式就是将 m1、m2 发送到同一个 server 上：\n\n这样可以保证 m1 先于 m2 到达 mqserver（生产者等待 m1 发送成功后再发送 m2），根据先达到先被消费的原则，m1 会先于 m2 被消费，这样就保证了消息的顺序。\n\n这个模型也仅仅是理论上可以保证消息的顺序，在实际场景中可能会遇到下面的问题：\n\n\n\n只要将消息从一台服务器发往另一台服务器，就会存在网络延迟问题。如上图所示，如果发送 m1 耗时大于发送 m2 的耗时，那么 m2 就仍将被先消费，仍然不能保证消息的顺序。即使 m1 和 m2 同时到达消费端，由于不清楚消费端 1 和消费端 2 的负载情况，仍然有可能出现 m2 先于 m1 被消费的情况。\n\n如何解决这个问题？将 m1 和 m2 发往同一个消费者，且发送 m1 后，需要消费端响应成功后才能发送 m2。\n\n这可能产生另外的问题：如果 m1 被发送到消费端后，消费端 1 没有响应，那是继续发送 m2 呢，还是重新发送 m1？一般为了保证消息一定被消费，肯定会选择重发 m1 到另外一个消费端 2，就如下图所示。\n\n\n\n这样的模型就严格保证消息的顺序，细心的你仍然会发现问题，消费端 1 没有响应 server 时有两种情况，一种是 m1 确实没有到达(数据在网络传送中丢失)，另外一种消费端已经消费 m1 且已经发送响应消息，只是 mq server 端没有收到。如果是第二种情况，重发 m1，就会造成 m1 被重复消费。也就引入了我们要说的第二个问题，消息重复问题，这个后文会详细讲解。\n\n回过头来看消息顺序问题，严格的顺序消息非常容易理解，也可以通过文中所描述的方式来简单处理。总结起来，要实现严格的顺序消息，简单且可行的办法就是：\n\n保证生产者 - mqserver - 消费者是一对一对一的关系。\n\n这样的设计虽然简单易行，但也会存在一些很严重的问题，比如：\n\n 1. 并行度就会成为消息系统的瓶颈（吞吐量不够）\n 2. 更多的异常处理，比如：只要消费端出现问题，就会导致整个处理流程阻塞，我们不得不花费更多的精力来解决阻塞的问题。\n\nrocketmq 的解决方案：通过合理的设计或者将问题分解来规避。如果硬要把时间花在解决问题本身，实际上不仅效率低下，而且也是一种浪费。从这个角度来看消息的顺序问题，我们可以得出两个结论：\n\n 1. 不关注乱序的应用实际大量存在\n 2. 队列无序并不意味着消息无序\n\n最后我们从源码角度分析 rocketmq 怎么实现发送顺序消息。\n\nrocketmq 通过轮询所有队列的方式来确定消息被发送到哪一个队列（负载均衡策略）。比如下面的示例中，订单号相同的消息会被先后发送到同一个队列中：\n\n// rocketmq 通过 messagequeueselector 中实现的算法来确定消息发送到哪一个队列上\n// rocketmq 默认提供了两种 messagequeueselector 实现：随机/hash\n// 当然你可以根据业务实现自己的 messagequeueselector 来决定消息按照何种策略发送到消息队列中\nsendresult sendresult = producer.send(msg, new messagequeueselector() {\n    @override\n    public messagequeue select(list<messagequeue> mqs, message msg, object arg) {\n        integer id = (integer) arg;\n        int index = id % mqs.size();\n        return mqs.get(index);\n    }\n}, orderid);\n\n\n在获取到路由信息以后，会根据 messagequeueselector 实现的算法来选择一个队列，同一个 orderid 获取到的肯定是同一个队列。\n\nprivate sendresult send()  {\n    // 获取topic路由信息\n    topicpublishinfo topicpublishinfo = this.trytofindtopicpublishinfo(msg.gettopic());\n    if (topicpublishinfo != null && topicpublishinfo.ok()) {\n        messagequeue mq = null;\n        // 根据我们的算法，选择一个发送队列\n        // 这里的arg = orderid\n        mq = selector.select(topicpublishinfo.getmessagequeuelist(), msg, arg);\n        if (mq != null) {\n            return this.sendkernelimpl(msg, mq, communicationmode, sendcallback, timeout);\n        }\n    }\n}\n\n\n\n# 消息重复\n\n造成消息重复的根本原因是：网络不可达。只要通过网络交换数据，就无法避免这个问题。所以解决这个问题的办法就是绕过这个问题。那么问题就变成了：如果消费端收到两条一样的消息，应该怎样处理？\n\n 1. 消费端处理消息的业务逻辑保持幂等性。\n 2. 保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现。\n\n第 1 条很好理解，只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。\n\n第 2 条原理就是利用一张日志表来记录已经处理成功的消息的 id，如果新到的消息 id 已经在日志表中，那么就不再处理这条消息。\n\n第 1 条解决方案，很明显应该在消费端实现，不属于消息系统要实现的功能。\n\n第 2 条可以消息系统实现，也可以业务端实现。正常情况下出现重复消息的概率其实很小，如果由消息系统来实现的话，肯定会对消息系统的吞吐量和高可用有影响，所以最好还是由业务端自己处理消息重复的问题，这也是 rocketmq 不解决消息重复的问题的原因。\n\nrocketmq 不保证消息不重复，如果你的业务需要保证严格的不重复消息，需要你自己在业务端去重。\n\n\n# 事务消息\n\nrocketmq 除了支持普通消息，顺序消息，另外还支持事务消息。\n\n假设这样的场景：\n\n\n\n图中执行本地事务（bob 账户扣款）和发送异步消息应该保证同时成功或者同时失败，也就是扣款成功了，发送消息一定要成功，如果扣款失败了，就不能再发送消息。那问题是：我们是先扣款还是先发送消息呢？\n\n\n\nrocketmq 分布式事务步骤：\n\n发送 prepared 消息 2222222222222222222，并拿到接受消息的地址。 执行本地事务 通过第 1 步骤拿到的地址去访问消息，并修改消息状态。\n\n\n# 参考资料\n\n * rocketmq 官方文档\n * 分布式开放消息系统(rocketmq)的原理与实践',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"ActiveMQ 快速入门",frontmatter:{title:"ActiveMQ 快速入门",categories:["编程","Java","中间件","MQ"],tags:["Java","中间件","MQ","ActiveMQ"],abbrlink:"30b5d114",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/3f7c49/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/01.MQ/04.ActiveMQ.html",relativePath:"14.中间件/01.MQ/04.ActiveMQ.md",key:"v-f41b300c",path:"/pages/3f7c49/",headers:[{level:2,title:"JMS 基本概念",slug:"jms-基本概念",normalizedTitle:"jms 基本概念",charIndex:20},{level:3,title:"消息模型",slug:"消息模型",normalizedTitle:"消息模型",charIndex:184},{level:4,title:"P2P 的特点",slug:"p2p-的特点",normalizedTitle:"p2p 的特点",charIndex:260},{level:4,title:"Pub/Sub 的特点",slug:"pub-sub-的特点",normalizedTitle:"pub/sub 的特点",charIndex:501},{level:3,title:"JMS 编程模型",slug:"jms-编程模型",normalizedTitle:"jms 编程模型",charIndex:853},{level:4,title:"ConnectionFactory",slug:"connectionfactory",normalizedTitle:"connectionfactory",charIndex:867},{level:4,title:"Connection",slug:"connection",normalizedTitle:"connection",charIndex:867},{level:4,title:"Destination",slug:"destination",normalizedTitle:"destination",charIndex:1189},{level:4,title:"Session",slug:"session",normalizedTitle:"session",charIndex:1102},{level:4,title:"MessageConsumer",slug:"messageconsumer",normalizedTitle:"messageconsumer",charIndex:1599},{level:4,title:"MessageProducer",slug:"messageproducer",normalizedTitle:"messageproducer",charIndex:1757},{level:4,title:"Message",slug:"message",normalizedTitle:"message",charIndex:51},{level:2,title:"安装",slug:"安装",normalizedTitle:"安装",charIndex:2702},{level:2,title:"项目中的应用",slug:"项目中的应用",normalizedTitle:"项目中的应用",charIndex:3124},{level:2,title:"资源",slug:"资源",normalizedTitle:"资源",charIndex:7437}],headersStr:"JMS 基本概念 消息模型 P2P 的特点 Pub/Sub 的特点 JMS 编程模型 ConnectionFactory Connection Destination Session MessageConsumer MessageProducer Message 安装 项目中的应用 资源",content:'# ActiveMQ 快速入门\n\n\n# JMS 基本概念\n\nJMS 即 Java 消息服务（Java Message Service）API，是一个 Java 平台中关于面向消息中间件的 API。它用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。Java 消息服务是一个与具体平台无关的 API，绝大多数 MOM 提供商都对 JMS 提供支持。\n\n\n# 消息模型\n\nJMS 有两种消息模型：\n\n * Point-to-Point(P2P)\n * Publish/Subscribe(Pub/Sub)\n\n# P2P 的特点\n\n\n\n在点对点的消息系统中，消息分发给一个单独的使用者。点对点消息往往与队列 javax.jms.Queue 相关联。\n\n每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中)。\n\n发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列。\n\n接收者在成功接收消息之后需向队列应答成功。\n\n如果你希望发送的每个消息都应该被成功处理的话，那么你需要 P2P 模式。\n\n# Pub/Sub 的特点\n\n\n\n发布/订阅消息系统支持一个事件驱动模型，消息生产者和消费者都参与消息的传递。生产者发布事件，而使用者订阅感兴趣的事件，并使用事件。该类型消息一般与特定的主题 javax.jms.Topic 关联。\n\n每个消息可以有多个消费者。\n\n发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息，而且为了消费消息，订阅者必须保持运行的状态。\n\n为了缓和这样严格的时间相关性，JMS 允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。\n\n如果你希望发送的消息可以不被做任何处理、或者被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用 Pub/Sub 模型。\n\n\n# JMS 编程模型\n\n\n\n# ConnectionFactory\n\n创建 Connection 对象的工厂，针对两种不同的 jms 消息模型，分别有 QueueConnectionFactory 和TopicConnectionFactory 两种。可以通过 JNDI 来查找 ConnectionFactory 对象。\n\n# Connection\n\nConnection 表示在客户端和 JMS 系统之间建立的链接（对 TCP/IP socket 的包装）。Connection 可以产生一个或多个Session。跟 ConnectionFactory 一样，Connection 也有两种类型：QueueConnection 和 TopicConnection。\n\n# Destination\n\nDestination 是一个包装了消息目标标识符的被管对象。消息目标是指消息发布和接收的地点，或者是队列 Queue ，或者是主题 Topic 。JMS 管理员创建这些对象，然后用户通过 JNDI 发现它们。和连接工厂一样，管理员可以创建两种类型的目标，点对点模型的 Queue，以及发布者/订阅者模型的 Topic。\n\n# Session\n\nSession 表示一个单线程的上下文，用于发送和接收消息。由于会话是单线程的，所以消息是连续的，就是说消息是按照发送的顺序一个一个接收的。会话的好处是它支持事务。如果用户选择了事务支持，会话上下文将保存一组消息，直到事务被提交才发送这些消息。在提交事务之前，用户可以使用回滚操作取消这些消息。一个会话允许用户创建消息，生产者来发送消息，消费者来接收消息。同样，Session 也分 QueueSession 和 TopicSession。\n\n# MessageConsumer\n\nMessageConsumer 由 Session 创建，并用于将消息发送到 Destination。消费者可以同步地（阻塞模式），或（非阻塞）接收 Queue 和 Topic 类型的消息。同样，消息生产者分两种类型：QueueSender 和TopicPublisher。\n\n# MessageProducer\n\nMessageProducer 由 Session 创建，用于接收被发送到 Destination 的消息。MessageProducer 有两种类型：QueueReceiver 和 TopicSubscriber。可分别通过 session 的 createReceiver(Queue) 或 createSubscriber(Topic) 来创建。当然，也可以 session 的 creatDurableSubscriber 方法来创建持久化的订阅者。\n\n# Message\n\n是在消费者和生产者之间传送的对象，也就是说从一个应用程序传送到另一个应用程序。一个消息有三个主要部分：\n\n * 消息头（必须）：包含用于识别和为消息寻找路由的操作设置。\n * 一组消息属性（可选）：包含额外的属性，支持其他提供者和用户的兼容。可以创建定制的字段和过滤器（消息选择器）。\n * 一个消息体（可选）：允许用户创建五种类型的消息（文本消息，映射消息，字节消息，流消息和对象消息）。\n\n消息接口非常灵活，并提供了许多方式来定制消息的内容。\n\nCOMMON              POINT-TO-POINT                PUBLISH-SUBSCRIBE\nConnectionFactory   QueueConnectionFactory        TopicConnectionFactory\nConnection          QueueConnection               TopicConnection\nDestination         Queue                         Topic\nSession             QueueSession                  TopicSession\nMessageProducer     QueueSender                   TopicPublisher\nMessageSender       QueueReceiver, QueueBrowser   TopicSubscriber\n\n\n# 安装\n\n安装条件\n\nJDK1.7 及以上版本\n\n本地配置了 JAVA_HOME 环境变量。\n\n下载\n\n支持 Windows/Unix/Linux/Cygwin\n\nActiveMQ 官方下载地址\n\nWindows 下运行\n\n（1）解压压缩包到本地；\n\n（2）打开控制台，进入安装目录的 bin 目录下；\n\ncd [activemq_install_dir]\n\n\n（3）执行 activemq start 来启动 ActiveMQ\n\nbin\\activemq start\n\n\n测试安装是否成功\n\n（1）ActiveMQ 默认监听端口为 61616\n\nnetstat -an|find “61616”\n\n\n（2）访问 http://127.0.0.1:8161/admin/\n\n（3）输入用户名、密码\n\nLogin: admin\nPasswort: admin\n\n\n（4）点击导航栏的 Queues 菜单\n\n（5）添加一个队列（queue）\n\n\n# 项目中的应用\n\n引入依赖\n\n<dependency>\n  <groupId>org.apache.activemq</groupId>\n  <artifactId>activemq-all</artifactId>\n  <version>5.14.1</version>\n</dependency>\n\n\nSender.java\n\npublic class Sender {\n    private static final int SEND_NUMBER = 4;\n\n    public static void main(String[] args) {\n        // ConnectionFactory ：连接工厂，JMS 用它创建连接\n        ConnectionFactory connectionFactory;\n        // Connection ：JMS 客户端到JMS Provider 的连接\n        Connection connection = null;\n        // Session： 一个发送或接收消息的线程\n        Session session;\n        // Destination ：消息的目的地;消息发送给谁.\n        Destination destination;\n        // MessageProducer：消息发送者\n        MessageProducer producer;\n        // TextMessage message;\n        // 构造ConnectionFactory实例对象，此处采用ActiveMq的实现jar\n        connectionFactory = new ActiveMQConnectionFactory(\n                ActiveMQConnection.DEFAULT_USER,\n                ActiveMQConnection.DEFAULT_PASSWORD,\n                "tcp://localhost:61616");\n        try {\n            // 构造从工厂得到连接对象\n            connection = connectionFactory.createConnection();\n            // 启动\n            connection.start();\n            // 获取操作连接\n            session = connection.createSession(Boolean.TRUE,\n                    Session.AUTO_ACKNOWLEDGE);\n            // 获取session注意参数值xingbo.xu-queue是一个服务器的queue，须在在ActiveMq的console配置\n            destination = session.createQueue("FirstQueue");\n            // 得到消息生成者【发送者】\n            producer = session.createProducer(destination);\n            // 设置不持久化，此处学习，实际根据项目决定\n            producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT);\n            // 构造消息，此处写死，项目就是参数，或者方法获取\n            sendMessage(session, producer);\n            session.commit();\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            try {\n                if (null != connection)\n                    connection.close();\n            } catch (Throwable ignore) {\n            }\n        }\n    }\n\n    public static void sendMessage(Session session, MessageProducer producer)\n            throws Exception {\n        for (int i = 1; i <= SEND_NUMBER; i++) {\n            TextMessage message = session\n                    .createTextMessage("ActiveMq 发送的消息" + i);\n            // 发送消息到目的地方\n            System.out.println("发送消息：" + "ActiveMq 发送的消息" + i);\n            producer.send(message);\n        }\n    }\n}\n\n\nReceiver.java\n\npublic class Receiver {\n    public static void main(String[] args) {\n        // ConnectionFactory ：连接工厂，JMS 用它创建连接\n        ConnectionFactory connectionFactory;\n        // Connection ：JMS 客户端到JMS Provider 的连接\n        Connection connection = null;\n        // Session： 一个发送或接收消息的线程\n        Session session;\n        // Destination ：消息的目的地;消息发送给谁.\n        Destination destination;\n        // 消费者，消息接收者\n        MessageConsumer consumer;\n        connectionFactory = new ActiveMQConnectionFactory(\n                ActiveMQConnection.DEFAULT_USER,\n                ActiveMQConnection.DEFAULT_PASSWORD,\n                "tcp://localhost:61616");\n        try {\n            // 构造从工厂得到连接对象\n            connection = connectionFactory.createConnection();\n            // 启动\n            connection.start();\n            // 获取操作连接\n            session = connection.createSession(Boolean.FALSE,\n                    Session.AUTO_ACKNOWLEDGE);\n            // 获取session注意参数值xingbo.xu-queue是一个服务器的queue，须在在ActiveMq的console配置\n            destination = session.createQueue("FirstQueue");\n            consumer = session.createConsumer(destination);\n            while (true) {\n                //设置接收者接收消息的时间，为了便于测试，这里谁定为100s\n                TextMessage message = (TextMessage) consumer.receive(100000);\n                if (null != message) {\n                    System.out.println("收到消息" + message.getText());\n                } else {\n                    break;\n                }\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            try {\n                if (null != connection)\n                    connection.close();\n            } catch (Throwable ignore) {\n            }\n        }\n    }\n}\n\n\n运行\n\n先运行 Receiver.java 进行消息监听，再运行 Send.java 发送消息。\n\n输出\n\nSend 的输出内容\n\n发送消息：Activemq 发送消息0\n发送消息：Activemq 发送消息1\n发送消息：Activemq 发送消息2\n发送消息：Activemq 发送消息3\n\n\nReceiver 的输出内容\n\n收到消息ActiveMQ 发送消息0\n收到消息ActiveMQ 发送消息1\n收到消息ActiveMQ 发送消息2\n收到消息ActiveMQ 发送消息3\n\n\n\n# 资源\n\n * ActiveMQ 官网\n * oracle 官方的 jms 介绍',normalizedContent:'# activemq 快速入门\n\n\n# jms 基本概念\n\njms 即 java 消息服务（java message service）api，是一个 java 平台中关于面向消息中间件的 api。它用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。java 消息服务是一个与具体平台无关的 api，绝大多数 mom 提供商都对 jms 提供支持。\n\n\n# 消息模型\n\njms 有两种消息模型：\n\n * point-to-point(p2p)\n * publish/subscribe(pub/sub)\n\n# p2p 的特点\n\n\n\n在点对点的消息系统中，消息分发给一个单独的使用者。点对点消息往往与队列 javax.jms.queue 相关联。\n\n每个消息只有一个消费者（consumer）(即一旦被消费，消息就不再在消息队列中)。\n\n发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列。\n\n接收者在成功接收消息之后需向队列应答成功。\n\n如果你希望发送的每个消息都应该被成功处理的话，那么你需要 p2p 模式。\n\n# pub/sub 的特点\n\n\n\n发布/订阅消息系统支持一个事件驱动模型，消息生产者和消费者都参与消息的传递。生产者发布事件，而使用者订阅感兴趣的事件，并使用事件。该类型消息一般与特定的主题 javax.jms.topic 关联。\n\n每个消息可以有多个消费者。\n\n发布者和订阅者之间有时间上的依赖性。针对某个主题（topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息，而且为了消费消息，订阅者必须保持运行的状态。\n\n为了缓和这样严格的时间相关性，jms 允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。\n\n如果你希望发送的消息可以不被做任何处理、或者被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用 pub/sub 模型。\n\n\n# jms 编程模型\n\n\n\n# connectionfactory\n\n创建 connection 对象的工厂，针对两种不同的 jms 消息模型，分别有 queueconnectionfactory 和topicconnectionfactory 两种。可以通过 jndi 来查找 connectionfactory 对象。\n\n# connection\n\nconnection 表示在客户端和 jms 系统之间建立的链接（对 tcp/ip socket 的包装）。connection 可以产生一个或多个session。跟 connectionfactory 一样，connection 也有两种类型：queueconnection 和 topicconnection。\n\n# destination\n\ndestination 是一个包装了消息目标标识符的被管对象。消息目标是指消息发布和接收的地点，或者是队列 queue ，或者是主题 topic 。jms 管理员创建这些对象，然后用户通过 jndi 发现它们。和连接工厂一样，管理员可以创建两种类型的目标，点对点模型的 queue，以及发布者/订阅者模型的 topic。\n\n# session\n\nsession 表示一个单线程的上下文，用于发送和接收消息。由于会话是单线程的，所以消息是连续的，就是说消息是按照发送的顺序一个一个接收的。会话的好处是它支持事务。如果用户选择了事务支持，会话上下文将保存一组消息，直到事务被提交才发送这些消息。在提交事务之前，用户可以使用回滚操作取消这些消息。一个会话允许用户创建消息，生产者来发送消息，消费者来接收消息。同样，session 也分 queuesession 和 topicsession。\n\n# messageconsumer\n\nmessageconsumer 由 session 创建，并用于将消息发送到 destination。消费者可以同步地（阻塞模式），或（非阻塞）接收 queue 和 topic 类型的消息。同样，消息生产者分两种类型：queuesender 和topicpublisher。\n\n# messageproducer\n\nmessageproducer 由 session 创建，用于接收被发送到 destination 的消息。messageproducer 有两种类型：queuereceiver 和 topicsubscriber。可分别通过 session 的 createreceiver(queue) 或 createsubscriber(topic) 来创建。当然，也可以 session 的 creatdurablesubscriber 方法来创建持久化的订阅者。\n\n# message\n\n是在消费者和生产者之间传送的对象，也就是说从一个应用程序传送到另一个应用程序。一个消息有三个主要部分：\n\n * 消息头（必须）：包含用于识别和为消息寻找路由的操作设置。\n * 一组消息属性（可选）：包含额外的属性，支持其他提供者和用户的兼容。可以创建定制的字段和过滤器（消息选择器）。\n * 一个消息体（可选）：允许用户创建五种类型的消息（文本消息，映射消息，字节消息，流消息和对象消息）。\n\n消息接口非常灵活，并提供了许多方式来定制消息的内容。\n\ncommon              point-to-point                publish-subscribe\nconnectionfactory   queueconnectionfactory        topicconnectionfactory\nconnection          queueconnection               topicconnection\ndestination         queue                         topic\nsession             queuesession                  topicsession\nmessageproducer     queuesender                   topicpublisher\nmessagesender       queuereceiver, queuebrowser   topicsubscriber\n\n\n# 安装\n\n安装条件\n\njdk1.7 及以上版本\n\n本地配置了 java_home 环境变量。\n\n下载\n\n支持 windows/unix/linux/cygwin\n\nactivemq 官方下载地址\n\nwindows 下运行\n\n（1）解压压缩包到本地；\n\n（2）打开控制台，进入安装目录的 bin 目录下；\n\ncd [activemq_install_dir]\n\n\n（3）执行 activemq start 来启动 activemq\n\nbin\\activemq start\n\n\n测试安装是否成功\n\n（1）activemq 默认监听端口为 61616\n\nnetstat -an|find “61616”\n\n\n（2）访问 http://127.0.0.1:8161/admin/\n\n（3）输入用户名、密码\n\nlogin: admin\npasswort: admin\n\n\n（4）点击导航栏的 queues 菜单\n\n（5）添加一个队列（queue）\n\n\n# 项目中的应用\n\n引入依赖\n\n<dependency>\n  <groupid>org.apache.activemq</groupid>\n  <artifactid>activemq-all</artifactid>\n  <version>5.14.1</version>\n</dependency>\n\n\nsender.java\n\npublic class sender {\n    private static final int send_number = 4;\n\n    public static void main(string[] args) {\n        // connectionfactory ：连接工厂，jms 用它创建连接\n        connectionfactory connectionfactory;\n        // connection ：jms 客户端到jms provider 的连接\n        connection connection = null;\n        // session： 一个发送或接收消息的线程\n        session session;\n        // destination ：消息的目的地;消息发送给谁.\n        destination destination;\n        // messageproducer：消息发送者\n        messageproducer producer;\n        // textmessage message;\n        // 构造connectionfactory实例对象，此处采用activemq的实现jar\n        connectionfactory = new activemqconnectionfactory(\n                activemqconnection.default_user,\n                activemqconnection.default_password,\n                "tcp://localhost:61616");\n        try {\n            // 构造从工厂得到连接对象\n            connection = connectionfactory.createconnection();\n            // 启动\n            connection.start();\n            // 获取操作连接\n            session = connection.createsession(boolean.true,\n                    session.auto_acknowledge);\n            // 获取session注意参数值xingbo.xu-queue是一个服务器的queue，须在在activemq的console配置\n            destination = session.createqueue("firstqueue");\n            // 得到消息生成者【发送者】\n            producer = session.createproducer(destination);\n            // 设置不持久化，此处学习，实际根据项目决定\n            producer.setdeliverymode(deliverymode.non_persistent);\n            // 构造消息，此处写死，项目就是参数，或者方法获取\n            sendmessage(session, producer);\n            session.commit();\n        } catch (exception e) {\n            e.printstacktrace();\n        } finally {\n            try {\n                if (null != connection)\n                    connection.close();\n            } catch (throwable ignore) {\n            }\n        }\n    }\n\n    public static void sendmessage(session session, messageproducer producer)\n            throws exception {\n        for (int i = 1; i <= send_number; i++) {\n            textmessage message = session\n                    .createtextmessage("activemq 发送的消息" + i);\n            // 发送消息到目的地方\n            system.out.println("发送消息：" + "activemq 发送的消息" + i);\n            producer.send(message);\n        }\n    }\n}\n\n\nreceiver.java\n\npublic class receiver {\n    public static void main(string[] args) {\n        // connectionfactory ：连接工厂，jms 用它创建连接\n        connectionfactory connectionfactory;\n        // connection ：jms 客户端到jms provider 的连接\n        connection connection = null;\n        // session： 一个发送或接收消息的线程\n        session session;\n        // destination ：消息的目的地;消息发送给谁.\n        destination destination;\n        // 消费者，消息接收者\n        messageconsumer consumer;\n        connectionfactory = new activemqconnectionfactory(\n                activemqconnection.default_user,\n                activemqconnection.default_password,\n                "tcp://localhost:61616");\n        try {\n            // 构造从工厂得到连接对象\n            connection = connectionfactory.createconnection();\n            // 启动\n            connection.start();\n            // 获取操作连接\n            session = connection.createsession(boolean.false,\n                    session.auto_acknowledge);\n            // 获取session注意参数值xingbo.xu-queue是一个服务器的queue，须在在activemq的console配置\n            destination = session.createqueue("firstqueue");\n            consumer = session.createconsumer(destination);\n            while (true) {\n                //设置接收者接收消息的时间，为了便于测试，这里谁定为100s\n                textmessage message = (textmessage) consumer.receive(100000);\n                if (null != message) {\n                    system.out.println("收到消息" + message.gettext());\n                } else {\n                    break;\n                }\n            }\n        } catch (exception e) {\n            e.printstacktrace();\n        } finally {\n            try {\n                if (null != connection)\n                    connection.close();\n            } catch (throwable ignore) {\n            }\n        }\n    }\n}\n\n\n运行\n\n先运行 receiver.java 进行消息监听，再运行 send.java 发送消息。\n\n输出\n\nsend 的输出内容\n\n发送消息：activemq 发送消息0\n发送消息：activemq 发送消息1\n发送消息：activemq 发送消息2\n发送消息：activemq 发送消息3\n\n\nreceiver 的输出内容\n\n收到消息activemq 发送消息0\n收到消息activemq 发送消息1\n收到消息activemq 发送消息2\n收到消息activemq 发送消息3\n\n\n\n# 资源\n\n * activemq 官网\n * oracle 官方的 jms 介绍',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 和消息队列",frontmatter:{title:"Java 和消息队列",categories:["编程","Java","中间件","MQ"],tags:["Java","中间件","MQ"],abbrlink:"71639a39",date:"2022-02-17T22:34:30.000Z",hidden:!0,permalink:"/pages/fc0b29/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/01.MQ/",relativePath:"14.中间件/01.MQ/README.md",key:"v-2525a60d",path:"/pages/fc0b29/",headers:[{level:2,title:"内容",slug:"内容",normalizedTitle:"内容",charIndex:196},{level:2,title:"技术对比",slug:"技术对比",normalizedTitle:"技术对比",charIndex:265},{level:2,title:"📚 资料",slug:"📚-资料",normalizedTitle:"📚 资料",charIndex:2056},{level:2,title:"🚪 传送",slug:"🚪-传送",normalizedTitle:"🚪 传送",charIndex:2169}],headersStr:"内容 技术对比 📚 资料 🚪 传送",content:"# Java 和消息队列\n\n> 消息队列（Message Queue，简称 MQ）技术是分布式应用间交换信息的一种技术。\n> \n> 消息队列主要解决应用耦合，异步消息，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。\n> \n> 如果想深入学习各种消息队列产品，建议先了解一下 消息队列基本原理 ，有助于理解消息队列特性的实现和设计思路。\n\n\n# 内容\n\n * 消息队列面试\n * 消息队列基本原理\n * Kafka 教程 📚\n * RocketMQ\n * ActiveMQ\n\n\n# 技术对比\n\n特性                ACTIVEMQ                     RABBITMQ                        ROCKETMQ                                      KAFKA\n单机吞吐量             万级，比 RocketMQ、Kafka 低一个数量级   同 ActiveMQ                      10 万级，支撑高吞吐                                   10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景\ntopic 数量对吞吐量的影响                                                                topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ   topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic\n                                                                               的一大优势，在同等机器下，可以支撑大量的 topic                    数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源\n时效性               ms 级                         微秒级，这是 RabbitMQ 的一大特点，延迟最低      ms 级                                          延迟在 ms 级以内\n可用性               高，基于主从架构实现高可用                同 ActiveMQ                      非常高，分布式架构                                     非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用\n消息可靠性             有较低的概率丢失数据                   基本不丢                            经过参数优化配置，可以做到 0 丢失                            同 RocketMQ\n功能支持              MQ 领域的功能极其完备                 基于 erlang 开发，并发能力很强，性能极好，延时很低   MQ 功能较为完善，还是分布式的，扩展性好                         功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用\n\n综上，各种对比之后，有如下建议：\n\n * 一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；\n * 后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；\n * 不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。\n * 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。\n * 如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。\n\n\n# 📚 资料\n\n * Kafka\n   * Kafka Github\n   * Kafka 官网\n   * Kafka 官方文档\n   * Kafka 中文文档\n * ActiveMQ\n   * ActiveMQ 官网\n\n\n# 🚪 传送\n\n◾ 🏠 JAVA-TUTORIAL 首页 ◾ 🎯 我的博客 ◾",normalizedContent:"# java 和消息队列\n\n> 消息队列（message queue，简称 mq）技术是分布式应用间交换信息的一种技术。\n> \n> 消息队列主要解决应用耦合，异步消息，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。\n> \n> 如果想深入学习各种消息队列产品，建议先了解一下 消息队列基本原理 ，有助于理解消息队列特性的实现和设计思路。\n\n\n# 内容\n\n * 消息队列面试\n * 消息队列基本原理\n * kafka 教程 📚\n * rocketmq\n * activemq\n\n\n# 技术对比\n\n特性                activemq                     rabbitmq                        rocketmq                                      kafka\n单机吞吐量             万级，比 rocketmq、kafka 低一个数量级   同 activemq                      10 万级，支撑高吞吐                                   10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景\ntopic 数量对吞吐量的影响                                                                topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 rocketmq   topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，kafka 尽量保证 topic\n                                                                               的一大优势，在同等机器下，可以支撑大量的 topic                    数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源\n时效性               ms 级                         微秒级，这是 rabbitmq 的一大特点，延迟最低      ms 级                                          延迟在 ms 级以内\n可用性               高，基于主从架构实现高可用                同 activemq                      非常高，分布式架构                                     非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用\n消息可靠性             有较低的概率丢失数据                   基本不丢                            经过参数优化配置，可以做到 0 丢失                            同 rocketmq\n功能支持              mq 领域的功能极其完备                 基于 erlang 开发，并发能力很强，性能极好，延时很低   mq 功能较为完善，还是分布式的，扩展性好                         功能较为简单，主要支持简单的 mq 功能，在大数据领域的实时计算以及日志采集被大规模使用\n\n综上，各种对比之后，有如下建议：\n\n * 一般的业务系统要引入 mq，最早大家都用 activemq，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；\n * 后来大家开始用 rabbitmq，但是确实 erlang 语言阻止了大量的 java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；\n * 不过现在确实越来越多的公司会去用 rocketmq，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 rocketmq 已捐给 apache，但 github 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 rocketmq，否则回去老老实实用 rabbitmq 吧，人家有活跃的开源社区，绝对不会黄。\n * 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 rabbitmq 是不错的选择；大型公司，基础架构研发实力较强，用 rocketmq 是很好的选择。\n * 如果是大数据领域的实时计算、日志采集等场景，用 kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。\n\n\n# 📚 资料\n\n * kafka\n   * kafka github\n   * kafka 官网\n   * kafka 官方文档\n   * kafka 中文文档\n * activemq\n   * activemq 官网\n\n\n# 🚪 传送\n\n◾ 🏠 java-tutorial 首页 ◾ 🎯 我的博客 ◾",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"缓存夺命连环问",frontmatter:{title:"缓存夺命连环问",categories:["编程","Java","中间件","缓存"],tags:["Java","中间件","缓存","面试"],abbrlink:"ba1174c4",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/eb30d6/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/02.%E7%BC%93%E5%AD%98/01.%E7%BC%93%E5%AD%98%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"14.中间件/02.缓存/01.缓存面试题.md",key:"v-fa0cf7f8",path:"/pages/eb30d6/",headers:[{level:2,title:"为什么要用缓存？",slug:"为什么要用缓存",normalizedTitle:"为什么要用缓存？",charIndex:14},{level:3,title:"高性能",slug:"高性能",normalizedTitle:"高性能",charIndex:36},{level:3,title:"高并发",slug:"高并发",normalizedTitle:"高并发",charIndex:40},{level:2,title:"用了缓存之后会有什么不良后果？",slug:"用了缓存之后会有什么不良后果",normalizedTitle:"用了缓存之后会有什么不良后果？",charIndex:621},{level:2,title:"redis 和 memcached 有啥区别？",slug:"redis-和-memcached-有啥区别",normalizedTitle:"redis 和 memcached 有啥区别？",charIndex:705},{level:2,title:"为啥 redis 单线程模型也能效率这么高？",slug:"为啥-redis-单线程模型也能效率这么高",normalizedTitle:"为啥 redis 单线程模型也能效率这么高？",charIndex:1091},{level:3,title:"redis 的线程模型",slug:"redis-的线程模型",normalizedTitle:"redis 的线程模型",charIndex:1118},{level:3,title:"为啥 redis 单线程模型也能效率这么高?",slug:"为啥-redis-单线程模型也能效率这么高-2",normalizedTitle:"为啥 redis 单线程模型也能效率这么高?",charIndex:2392},{level:2,title:"Redis 有哪些数据类型",slug:"redis-有哪些数据类型",normalizedTitle:"redis 有哪些数据类型",charIndex:2542},{level:3,title:"string",slug:"string",normalizedTitle:"string",charIndex:2580},{level:3,title:"hash",slug:"hash",normalizedTitle:"hash",charIndex:2590},{level:3,title:"list",slug:"list",normalizedTitle:"list",charIndex:2598},{level:3,title:"set",slug:"set",normalizedTitle:"set",charIndex:1914},{level:3,title:"sorted set",slug:"sorted-set",normalizedTitle:"sorted set",charIndex:2613},{level:2,title:"如何保证 redis 的高并发和高可用？redis 的主从复制原理能介绍一下么？redis 的哨兵原理能介绍一下么？",slug:"如何保证-redis-的高并发和高可用-redis-的主从复制原理能介绍一下么-redis-的哨兵原理能介绍一下么",normalizedTitle:"如何保证 redis 的高并发和高可用？redis 的主从复制原理能介绍一下么？redis 的哨兵原理能介绍一下么？",charIndex:4165},{level:2,title:"redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？",slug:"redis-的过期策略都有哪些-内存淘汰机制都有哪些-手写一下-lru-代码实现",normalizedTitle:"redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 lru 代码实现？",charIndex:4606},{level:3,title:"redis 过期策略",slug:"redis-过期策略",normalizedTitle:"redis 过期策略",charIndex:4652},{level:3,title:"内存淘汰机制",slug:"内存淘汰机制",normalizedTitle:"内存淘汰机制",charIndex:4622},{level:3,title:"手写一个 LRU 算法",slug:"手写一个-lru-算法",normalizedTitle:"手写一个 lru 算法",charIndex:5659},{level:2,title:"redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？",slug:"redis-集群模式的工作原理能说一下么-在集群模式下-redis-的-key-是如何寻址的-分布式寻址都有哪些算法-了解一致性-hash-算法吗",normalizedTitle:"redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？",charIndex:6318},{level:3,title:"面试题剖析",slug:"面试题剖析",normalizedTitle:"面试题剖析",charIndex:7200},{level:3,title:"redis cluster 介绍",slug:"redis-cluster-介绍",normalizedTitle:"redis cluster 介绍",charIndex:7210},{level:3,title:"节点间的内部通信机制",slug:"节点间的内部通信机制",normalizedTitle:"节点间的内部通信机制",charIndex:7524},{level:4,title:"基本通信原理",slug:"基本通信原理",normalizedTitle:"基本通信原理",charIndex:7538},{level:4,title:"gossip 协议",slug:"gossip-协议",normalizedTitle:"gossip 协议",charIndex:7479},{level:4,title:"ping 消息深入",slug:"ping-消息深入",normalizedTitle:"ping 消息深入",charIndex:8605},{level:3,title:"分布式寻址算法",slug:"分布式寻址算法",normalizedTitle:"分布式寻址算法",charIndex:8963},{level:4,title:"hash 算法",slug:"hash-算法",normalizedTitle:"hash 算法",charIndex:6383},{level:4,title:"一致性 hash 算法",slug:"一致性-hash-算法",normalizedTitle:"一致性 hash 算法",charIndex:6379},{level:4,title:"redis cluster 的 hash slot 算法",slug:"redis-cluster-的-hash-slot-算法",normalizedTitle:"redis cluster 的 hash slot 算法",charIndex:9031},{level:3,title:"redis cluster 的高可用与主备切换原理",slug:"redis-cluster-的高可用与主备切换原理",normalizedTitle:"redis cluster 的高可用与主备切换原理",charIndex:10090},{level:4,title:"判断节点宕机",slug:"判断节点宕机",normalizedTitle:"判断节点宕机",charIndex:10153},{level:4,title:"从节点过滤",slug:"从节点过滤",normalizedTitle:"从节点过滤",charIndex:10399},{level:4,title:"从节点选举",slug:"从节点选举",normalizedTitle:"从节点选举",charIndex:10583},{level:4,title:"与哨兵比较",slug:"与哨兵比较",normalizedTitle:"与哨兵比较",charIndex:10809},{level:2,title:"如何保证缓存与数据库的双写一致性？",slug:"如何保证缓存与数据库的双写一致性",normalizedTitle:"如何保证缓存与数据库的双写一致性？",charIndex:10892},{level:3,title:"Cache Aside Pattern",slug:"cache-aside-pattern",normalizedTitle:"cache aside pattern",charIndex:11081},{level:3,title:"最初级的缓存不一致问题及解决方案",slug:"最初级的缓存不一致问题及解决方案",normalizedTitle:"最初级的缓存不一致问题及解决方案",charIndex:11879},{level:3,title:"比较复杂的数据不一致问题分析",slug:"比较复杂的数据不一致问题分析",normalizedTitle:"比较复杂的数据不一致问题分析",charIndex:12055},{level:2,title:"了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？",slug:"了解什么是-redis-的雪崩、穿透和击穿-redis-崩溃之后会怎么样-系统该如何应对这种情况-如何处理-redis-的穿透",normalizedTitle:"了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？",charIndex:14399},{level:3,title:"缓存雪崩",slug:"缓存雪崩",normalizedTitle:"缓存雪崩",charIndex:671},{level:3,title:"缓存穿透",slug:"缓存穿透",normalizedTitle:"缓存穿透",charIndex:676},{level:3,title:"缓存击穿",slug:"缓存击穿",normalizedTitle:"缓存击穿",charIndex:15542},{level:2,title:"redis 的并发竞争问题是什么？如何解决这个问题？了解 redis 事务的 CAS 方案吗？",slug:"redis-的并发竞争问题是什么-如何解决这个问题-了解-redis-事务的-cas-方案吗",normalizedTitle:"redis 的并发竞争问题是什么？如何解决这个问题？了解 redis 事务的 cas 方案吗？",charIndex:15743},{level:2,title:"生产环境中的 redis 是怎么部署的？",slug:"生产环境中的-redis-是怎么部署的",normalizedTitle:"生产环境中的 redis 是怎么部署的？",charIndex:16070}],headersStr:"为什么要用缓存？ 高性能 高并发 用了缓存之后会有什么不良后果？ redis 和 memcached 有啥区别？ 为啥 redis 单线程模型也能效率这么高？ redis 的线程模型 为啥 redis 单线程模型也能效率这么高? Redis 有哪些数据类型 string hash list set sorted set 如何保证 redis 的高并发和高可用？redis 的主从复制原理能介绍一下么？redis 的哨兵原理能介绍一下么？ redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？ redis 过期策略 内存淘汰机制 手写一个 LRU 算法 redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？ 面试题剖析 redis cluster 介绍 节点间的内部通信机制 基本通信原理 gossip 协议 ping 消息深入 分布式寻址算法 hash 算法 一致性 hash 算法 redis cluster 的 hash slot 算法 redis cluster 的高可用与主备切换原理 判断节点宕机 从节点过滤 从节点选举 与哨兵比较 如何保证缓存与数据库的双写一致性？ Cache Aside Pattern 最初级的缓存不一致问题及解决方案 比较复杂的数据不一致问题分析 了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？ 缓存雪崩 缓存穿透 缓存击穿 redis 的并发竞争问题是什么？如何解决这个问题？了解 redis 事务的 CAS 方案吗？ 生产环境中的 redis 是怎么部署的？",content:'# 缓存夺命连环问\n\n\n# 为什么要用缓存？\n\n用缓存，主要有两个用途：高性能、高并发。\n\n\n# 高性能\n\n假设这么个场景，你有个操作，一个请求过来，吭哧吭哧你各种乱七八糟操作 mysql，半天查出来一个结果，耗时 600ms。但是这个结果可能接下来几个小时都不会变了，或者变了也可以不用立即反馈给用户。那么此时咋办？\n\n缓存啊，折腾 600ms 查出来的结果，扔缓存里，一个 key 对应一个 value，下次再有人查，别走 mysql 折腾 600ms 了，直接从缓存里，通过一个 key 查出来一个 value，2ms 搞定。性能提升 300 倍。\n\n就是说对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直接将查询出来的结果放在缓存中，后面直接读缓存就好。\n\n\n# 高并发\n\nmysql 这么重的数据库，压根儿设计不是让你玩儿高并发的，虽然也可以玩儿，但是天然支持不好。mysql 单机支撑到 2000QPS 也开始容易报警了。\n\n所以要是你有个系统，高峰期一秒钟过来的请求有 1 万，那一个 mysql 单机绝对会死掉。你这个时候就只能上缓存，把很多数据放缓存，别放 mysql。缓存功能简单，说白了就是 key-value 式操作，单机支撑的并发量轻松一秒几万十几万，支撑高并发 so easy。单机承载并发量是 mysql 单机的几十倍。\n\n> 缓存是走内存的，内存天然就支撑高并发。\n\n\n# 用了缓存之后会有什么不良后果？\n\n常见的缓存问题有以下几个：\n\n * 缓存与数据库双写不一致\n * 缓存雪崩、缓存穿透\n * 缓存并发竞争\n\n后面再详细说明。\n\n\n# redis 和 memcached 有啥区别？\n\nredis 支持复杂的数据结构\n\nredis 相比 memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， redis 会是不错的选择。\n\nredis 原生支持集群模式\n\n在 redis3.x 版本中，便能支持 cluster 模式，而 memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。\n\n性能对比\n\n由于 redis 只使用单核，而 memcached 可以使用多核，所以平均每一个核上 redis 在存储小数据时比 memcached 性能更高。而在 100k 以上的数据中，memcached 性能要高于 redis。虽然 redis 最近也在存储大数据的性能上进行优化，但是比起 memcached，还是稍有逊色。\n\n\n# 为啥 redis 单线程模型也能效率这么高？\n\n\n# redis 的线程模型\n\nredis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。\n\n文件事件处理器的结构包含 4 个部分：\n\n * 多个 socket\n * IO 多路复用程序\n * 文件事件分派器\n * 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）\n\n多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。\n\n来看客户端与 redis 的一次通信过程：\n\n\n\n要明白，通信是通过 socket 来完成的，不懂的同学可以先去看一看 socket 网络编程。\n\n首先，redis 服务端进程初始化的时候，会将 server socket 的 AE_READABLE 事件与连接应答处理器关联。\n\n客户端 socket01 向 redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 AE_READABLE 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 AE_READABLE 事件与命令请求处理器关联。\n\n假设此时客户端发送了一个 set key value 请求，此时 redis 中的 socket01 会产生 AE_READABLE 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 AE_READABLE 事件，由于前面 socket01 的 AE_READABLE 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 key value 并在自己内存中完成 key value 的设置。操作完成后，它会将 socket01 的 AE_WRITABLE 事件与命令回复处理器关联。\n\n如果此时客户端准备好接收返回结果了，那么 redis 中的 socket01 会产生一个 AE_WRITABLE 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok，之后解除 socket01 的 AE_WRITABLE 事件与命令回复处理器的关联。\n\n这样便完成了一次通信。\n\n\n# 为啥 redis 单线程模型也能效率这么高?\n\n * 纯内存操作。\n * 核心是基于非阻塞的 IO 多路复用机制。\n * C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。\n * 单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。\n\n\n# Redis 有哪些数据类型\n\nredis 主要有以下几种数据类型：\n\n * string\n * hash\n * list\n * set\n * sorted set\n\n\n# string\n\n这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。\n\nset college szu\n\n\n\n# hash\n\n这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 redis 里，然后每次读写缓存的时候，可以就操作 hash 里的某个字段。\n\nhset person name bingo\nhset person age 20\nhset person id 1\nhget person name\nperson = {\n    "name": "bingo",\n    "age": 20,\n    "id": 1\n}\n\n\n\n# list\n\nlist 是有序列表，这个可以玩儿出很多花样。\n\n比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。\n\n比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。\n\n# 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。\nlrange mylist 0 -1\n\n\n比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。\n\nlpush mylist 1\nlpush mylist 2\nlpush mylist 3 4 5\n\n# 1\nrpop mylist\n\n\n\n# set\n\nset 是无序集合，自动去重。\n\n直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 redis 进行全局的 set 去重。\n\n可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。\n\n把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。\n\n#-------操作一个set-------\n# 添加元素\nsadd mySet 1\n\n# 查看全部元素\nsmembers mySet\n\n# 判断是否包含某个值\nsismember mySet 3\n\n# 删除某个/些元素\nsrem mySet 1\nsrem mySet 2 4\n\n# 查看元素个数\nscard mySet\n\n# 随机删除一个元素\nspop mySet\n\n#-------操作多个set-------\n# 将一个set的元素移动到另外一个set\nsmove yourSet mySet 2\n\n# 求两set的交集\nsinter yourSet mySet\n\n# 求两set的并集\nsunion yourSet mySet\n\n# 求在yourSet中而不在mySet中的元素\nsdiff yourSet mySet\n\n\n\n# sorted set\n\nsorted set 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。\n\nzadd board 85 zhangsan\nzadd board 72 lisi\nzadd board 96 wangwu\nzadd board 63 zhaoliu\n\n# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）\nzrevrange board 0 3\n\n# 获取某用户的排名\nzrank board zhaoliu\n\n\n\n# 如何保证 redis 的高并发和高可用？redis 的主从复制原理能介绍一下么？redis 的哨兵原理能介绍一下么？\n\n如果你用 redis 缓存技术的话，肯定要考虑如何用 redis 来加多台机器，保证 redis 是高并发的，还有就是如何让 redis 保证自己不是挂掉以后就直接死掉了，即 redis 高可用。\n\n由于此节内容较多，因此，会分为两个小节进行讲解。\n\n * redis 主从架构\n * redis 基于哨兵实现高可用\n\nredis 实现高并发主要依靠主从架构，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万 QPS，多从用来查询数据，多个从实例可以提供每秒 10w 的 QPS。\n\n如果想要在实现高并发的同时，容纳大量的数据，那么就需要 redis 集群，使用 redis 集群之后，可以提供每秒几十万的读写并发。\n\nredis 高可用，如果是做主从架构部署，那么加上哨兵就可以了，就可以实现，任何一个实例宕机，可以进行主备切换。\n\n\n# redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？\n\n\n# redis 过期策略\n\nredis 过期策略是：定期删除+惰性删除。\n\n所谓定期删除，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。\n\n假设 redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的灾难。实际上 redis 是每隔 100ms 随机抽取一些 key 来检查和删除的。\n\n但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。\n\n> 获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。\n\n但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了，咋整？\n\n答案是：走内存淘汰机制。\n\n\n# 内存淘汰机制\n\nredis 内存淘汰机制有以下几个：\n\n * noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。\n * allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。\n * allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。\n * volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 key（这个一般不太合适）。\n * volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key。\n * volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除。\n\n\n# 手写一个 LRU 算法\n\n你可以现场手写最原始的 LRU 算法，那个代码量太大了，似乎不太现实。\n\n不求自己纯手工从底层开始打造出自己的 LRU，但是起码要知道如何利用已有的 JDK 数据结构实现一个 Java 版的 LRU。\n\nclass LRUCache<K, V> extends LinkedHashMap<K, V> {\n    private final int CACHE_SIZE;\n\n    /**\n     * 传递进来最多能缓存多少数据\n     *\n     * @param cacheSize 缓存大小\n     */\n    public LRUCache(int cacheSize) {\n        // true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。\n        super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);\n        CACHE_SIZE = cacheSize;\n    }\n\n    @Override\n    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {\n        // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。\n        return size() > CACHE_SIZE;\n    }\n}\n\n\n\n# redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？\n\n在前几年，redis 如果要搞几个节点，每个节点存储一部分的数据，得借助一些中间件来实现，比如说有 codis，或者 twemproxy，都有。有一些 redis 中间件，你读写 redis 中间件，redis 中间件负责将你的数据分布式存储在多台机器上的 redis 实例中。\n\n这两年，redis 不断在发展，redis 也不断有新的版本，现在的 redis 集群模式，可以做到在多台机器上，部署多个 redis 实例，每个实例存储一部分的数据，同时每个 redis 主实例可以挂 redis 从实例，自动确保说，如果 redis 主实例挂了，会自动切换到 redis 从实例上来。\n\n现在 redis 的新版本，大家都是用 redis cluster 的，也就是 redis 原生支持的 redis 集群模式，那么面试官肯定会就 redis cluster 对你来个几连炮。要是你没用过 redis cluster，正常，以前很多人用 codis 之类的客户端来支持集群，但是起码你得研究一下 redis cluster 吧。\n\n如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个 G，单机就足够了，可以使用 replication，一个 master 多个 slaves，要几个 slave 跟你要求的读吞吐量有关，然后自己搭建一个 sentinel 集群去保证 redis 主从架构的高可用性。\n\nredis cluster，主要是针对海量数据+高并发+高可用的场景。redis cluster 支撑 N 个 redis master node，每个 master node 都可以挂载多个 slave node。这样整个 redis 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 master 节点，每个 master 节点就能存放更多的数据了。\n\n\n# 面试题剖析\n\n\n# redis cluster 介绍\n\n * 自动将数据进行分片，每个 master 上放一部分数据\n * 提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的\n\n在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加 1w 的端口号，比如 16379。\n\n16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，gossip 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。\n\n\n# 节点间的内部通信机制\n\n# 基本通信原理\n\n集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。\n\n集中式是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 storm。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。\n\n\n\nredis 维护集群元数据采用另一个方式， gossip 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。\n\n\n\n集中式的好处在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到；不好在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。\n\ngossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。\n\n * 10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如 7001，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另外几个节点发送 ping 消息，同时其它几个节点接收到 ping 之后返回 pong。\n * 交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。\n\n# gossip 协议\n\ngossip 协议包含多种消息，包含 ping,pong,meet,fail 等等。\n\n * meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。\n\nredis-trib.rb add-node\n\n\n其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群。\n\n * ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。\n * pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。\n * fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦。\n\n# ping 消息深入\n\nping 时要携带一些元数据，如果很频繁，可能会加重网络负担。\n\n每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了 cluster_node_timeout / 2，那么立即发送 ping，避免数据交换延时过长，落后的时间太长了。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 cluster_node_timeout 可以调节，如果调得比较大，那么会降低 ping 的频率。\n\n每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 3 个其它节点的信息，最多包含 总节点数减 2 个其它节点的信息。\n\n\n# 分布式寻址算法\n\n * hash 算法（大量缓存重建）\n * 一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）\n * redis cluster 的 hash slot 算法\n\n# hash 算法\n\n来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会导致大部分的请求过来，全部无法拿到有效的缓存，导致大量的流量涌入数据库。\n\n\n\n# 一致性 hash 算法\n\n一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。\n\n来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，遇到的第一个 master 节点就是 key 所在位置。\n\n在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。\n\n燃鹅，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成缓存热点的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。\n\n\n\n# redis cluster 的 hash slot 算法\n\nredis cluster 有固定的 16384 个 hash slot，对每个 key 计算 CRC16 值，然后对 16384 取模，可以获取 key 对应的 hash slot。\n\nredis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 hash tag 来实现。\n\n任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。\n\n\n\n\n# redis cluster 的高可用与主备切换原理\n\nredis cluster 的高可用的原理，几乎跟哨兵是类似的。\n\n# 判断节点宕机\n\n如果一个节点认为另外一个节点宕机，那么就是 pfail，主观宕机。如果多个节点都认为另外一个节点宕机了，那么就是 fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown。\n\n在 cluster-node-timeout 内，某个节点一直没有返回 pong，那么就被认为 pfail。\n\n如果一个节点认为某个节点 pfail 了，那么会在 gossip ping 消息中，ping 给其他节点，如果超过半数的节点都认为 pfail 了，那么就会变成 fail。\n\n# 从节点过滤\n\n对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。\n\n检查每个 slave node 与 master node 断开连接的时间，如果超过了 cluster-node-timeout * cluster-slave-validity-factor，那么就没有资格切换成 master。\n\n# 从节点选举\n\n每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。\n\n所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node（N/2 + 1）都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。\n\n从节点执行主备切换，从节点切换为主节点。\n\n# 与哨兵比较\n\n整个流程跟哨兵相比，非常类似，所以说，redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。\n\n\n# 如何保证缓存与数据库的双写一致性？\n\n一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统不是严格要求 “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：读请求和写请求串行化，串到一个内存队列里去。\n\n串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。\n\n\n# Cache Aside Pattern\n\n最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。\n\n * 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。\n * 更新的时候，先更新数据库，然后再删除缓存。\n\n为什么是删除缓存，而不是更新缓存？\n\n原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。\n\n比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。\n\n另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于比较复杂的缓存数据计算的场景，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，这个缓存到底会不会被频繁访问到？\n\n举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有大量的冷数据。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。用到缓存才去算缓存。\n\n其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。\n\n\n# 最初级的缓存不一致问题及解决方案\n\n问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。\n\n\n\n解决思路：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。\n\n\n# 比较复杂的数据不一致问题分析\n\n数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一样了...\n\n为什么上亿流量高并发场景下，缓存会出现这个问题？\n\n只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场景。但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就可能会出现上述的数据库+缓存不一致的情况。\n\n解决方案如下：\n\n更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个 jvm 内部队列中。\n\n一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。\n\n这里有一个优化点，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。\n\n待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。\n\n如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。\n\n高并发的场景下，该解决方案要注意的问题：\n\n * 读请求长时阻塞\n\n由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。\n\n该解决方案，最大的风险点在于说，可能数据更新很频繁，导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库。务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。\n\n另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要部署多个服务，每个服务分摊一些数据的更新操作。如果一个内存队列里居然会挤压 100 个商品的库存修改操作，每隔库存修改操作要耗费 10ms 去完成，那么最后一个商品的读请求，可能等待 10 * 100 = 1000ms = 1s 后，才能得到数据，这个时候就导致读请求的长时阻塞。\n\n一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 hang 多少时间，如果读请求在 200ms 返回，如果你计算过后，哪怕是最繁忙的时候，积压 10 个更新操作，最多等待 200ms，那还可以的。\n\n如果一个内存队列中可能积压的更新操作特别多，那么你就要加机器，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少。\n\n其实根据之前的项目经验，一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的。像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒的 QPS 能到几百就不错了。\n\n我们来实际粗略测算一下。\n\n如果一秒有 500 的写操作，如果分成 5 个时间片，每 200ms 就 100 个写操作，放到 20 个内存队列中，每个内存队列，可能就积压 5 个写操作。每个写操作性能测试后，一般是在 20ms 左右就完成，那么针对每个内存队列的数据的读请求，也就最多 hang 一会儿，200ms 以内肯定能返回了。\n\n经过刚才简单的测算，我们知道，单机支撑的写 QPS 在几百是没问题的，如果写 QPS 扩大了 10 倍，那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列。\n\n * 读请求并发量过高\n\n这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。\n\n但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。\n\n * 多服务实例部署的请求路由\n\n可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器路由到相同的服务实例上。\n\n比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。\n\n * 热点商品的路由问题，导致请求的倾斜\n\n万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些。\n\n\n# 了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？\n\n\n# 缓存雪崩\n\n对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。\n\n这就是缓存雪崩。\n\n\n\n大约在 3 年前，国内比较知名的一个互联网公司，曾因为缓存事故，导致雪崩，后台系统全部崩溃，事故从当天下午持续到晚上凌晨 3~4 点，公司损失了几千万。\n\n缓存雪崩的事前事中事后的解决方案如下。\n\n * 事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。\n * 事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死。\n * 事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。\n\n\n\n用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 redis。如果 ehcache 和 redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 redis 中。\n\n限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？走降级！可以返回一些默认的值，或者友情提示，或者空白的值。\n\n好处：\n\n * 数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。\n * 只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。\n * 只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来一次。\n\n\n# 缓存穿透\n\n对于系统 A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。\n\n黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。\n\n举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“视缓存于无物”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。\n\n\n\n解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 set -999 UNKNOWN。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。\n\n\n# 缓存击穿\n\n缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。\n\n解决方式也很简单，可以将热点数据设置为永远不过期；或者基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据。\n\n\n# redis 的并发竞争问题是什么？如何解决这个问题？了解 redis 事务的 CAS 方案吗？\n\n某个时刻，多个系统实例都去更新某个 key。可以基于 zookeeper 实现分布式锁。每个系统通过 zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 key，别人都不允许读和写。\n\n\n\n你要写入缓存的数据，都是从 mysql 里查出来的，都得写入 mysql 中，写入 mysql 中的时候必须保存一个时间戳，从 mysql 查出来的时候，时间戳也查出来。\n\n每次要写之前，先判断一下当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。\n\n\n# 生产环境中的 redis 是怎么部署的？\n\nredis cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰 qps 可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求/s。\n\n机器是什么配置？32G 内存+ 8 核 CPU + 1T 磁盘，但是分配给 redis 进程的是 10g 内存，一般线上生产环境，redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。\n\n5 台机器对外提供读写，一共有 50g 内存。\n\n因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。\n\n你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。\n\n其实大型的公司，会有基础架构的 team 负责缓存集群的运维。',normalizedContent:'# 缓存夺命连环问\n\n\n# 为什么要用缓存？\n\n用缓存，主要有两个用途：高性能、高并发。\n\n\n# 高性能\n\n假设这么个场景，你有个操作，一个请求过来，吭哧吭哧你各种乱七八糟操作 mysql，半天查出来一个结果，耗时 600ms。但是这个结果可能接下来几个小时都不会变了，或者变了也可以不用立即反馈给用户。那么此时咋办？\n\n缓存啊，折腾 600ms 查出来的结果，扔缓存里，一个 key 对应一个 value，下次再有人查，别走 mysql 折腾 600ms 了，直接从缓存里，通过一个 key 查出来一个 value，2ms 搞定。性能提升 300 倍。\n\n就是说对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直接将查询出来的结果放在缓存中，后面直接读缓存就好。\n\n\n# 高并发\n\nmysql 这么重的数据库，压根儿设计不是让你玩儿高并发的，虽然也可以玩儿，但是天然支持不好。mysql 单机支撑到 2000qps 也开始容易报警了。\n\n所以要是你有个系统，高峰期一秒钟过来的请求有 1 万，那一个 mysql 单机绝对会死掉。你这个时候就只能上缓存，把很多数据放缓存，别放 mysql。缓存功能简单，说白了就是 key-value 式操作，单机支撑的并发量轻松一秒几万十几万，支撑高并发 so easy。单机承载并发量是 mysql 单机的几十倍。\n\n> 缓存是走内存的，内存天然就支撑高并发。\n\n\n# 用了缓存之后会有什么不良后果？\n\n常见的缓存问题有以下几个：\n\n * 缓存与数据库双写不一致\n * 缓存雪崩、缓存穿透\n * 缓存并发竞争\n\n后面再详细说明。\n\n\n# redis 和 memcached 有啥区别？\n\nredis 支持复杂的数据结构\n\nredis 相比 memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， redis 会是不错的选择。\n\nredis 原生支持集群模式\n\n在 redis3.x 版本中，便能支持 cluster 模式，而 memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。\n\n性能对比\n\n由于 redis 只使用单核，而 memcached 可以使用多核，所以平均每一个核上 redis 在存储小数据时比 memcached 性能更高。而在 100k 以上的数据中，memcached 性能要高于 redis。虽然 redis 最近也在存储大数据的性能上进行优化，但是比起 memcached，还是稍有逊色。\n\n\n# 为啥 redis 单线程模型也能效率这么高？\n\n\n# redis 的线程模型\n\nredis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 io 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。\n\n文件事件处理器的结构包含 4 个部分：\n\n * 多个 socket\n * io 多路复用程序\n * 文件事件分派器\n * 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）\n\n多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 io 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。\n\n来看客户端与 redis 的一次通信过程：\n\n\n\n要明白，通信是通过 socket 来完成的，不懂的同学可以先去看一看 socket 网络编程。\n\n首先，redis 服务端进程初始化的时候，会将 server socket 的 ae_readable 事件与连接应答处理器关联。\n\n客户端 socket01 向 redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 ae_readable 事件，io 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 ae_readable 事件与命令请求处理器关联。\n\n假设此时客户端发送了一个 set key value 请求，此时 redis 中的 socket01 会产生 ae_readable 事件，io 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 ae_readable 事件，由于前面 socket01 的 ae_readable 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 key value 并在自己内存中完成 key value 的设置。操作完成后，它会将 socket01 的 ae_writable 事件与命令回复处理器关联。\n\n如果此时客户端准备好接收返回结果了，那么 redis 中的 socket01 会产生一个 ae_writable 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok，之后解除 socket01 的 ae_writable 事件与命令回复处理器的关联。\n\n这样便完成了一次通信。\n\n\n# 为啥 redis 单线程模型也能效率这么高?\n\n * 纯内存操作。\n * 核心是基于非阻塞的 io 多路复用机制。\n * c 语言实现，一般来说，c 语言实现的程序“距离”操作系统更近，执行速度相对会更快。\n * 单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。\n\n\n# redis 有哪些数据类型\n\nredis 主要有以下几种数据类型：\n\n * string\n * hash\n * list\n * set\n * sorted set\n\n\n# string\n\n这是最简单的类型，就是普通的 set 和 get，做简单的 kv 缓存。\n\nset college szu\n\n\n\n# hash\n\n这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 redis 里，然后每次读写缓存的时候，可以就操作 hash 里的某个字段。\n\nhset person name bingo\nhset person age 20\nhset person id 1\nhget person name\nperson = {\n    "name": "bingo",\n    "age": 20,\n    "id": 1\n}\n\n\n\n# list\n\nlist 是有序列表，这个可以玩儿出很多花样。\n\n比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。\n\n比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。\n\n# 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。\nlrange mylist 0 -1\n\n\n比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。\n\nlpush mylist 1\nlpush mylist 2\nlpush mylist 3 4 5\n\n# 1\nrpop mylist\n\n\n\n# set\n\nset 是无序集合，自动去重。\n\n直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 hashset 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 redis 进行全局的 set 去重。\n\n可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。\n\n把两个大 v 的粉丝都放在两个 set 中，对两个 set 做交集。\n\n#-------操作一个set-------\n# 添加元素\nsadd myset 1\n\n# 查看全部元素\nsmembers myset\n\n# 判断是否包含某个值\nsismember myset 3\n\n# 删除某个/些元素\nsrem myset 1\nsrem myset 2 4\n\n# 查看元素个数\nscard myset\n\n# 随机删除一个元素\nspop myset\n\n#-------操作多个set-------\n# 将一个set的元素移动到另外一个set\nsmove yourset myset 2\n\n# 求两set的交集\nsinter yourset myset\n\n# 求两set的并集\nsunion yourset myset\n\n# 求在yourset中而不在myset中的元素\nsdiff yourset myset\n\n\n\n# sorted set\n\nsorted set 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。\n\nzadd board 85 zhangsan\nzadd board 72 lisi\nzadd board 96 wangwu\nzadd board 63 zhaoliu\n\n# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）\nzrevrange board 0 3\n\n# 获取某用户的排名\nzrank board zhaoliu\n\n\n\n# 如何保证 redis 的高并发和高可用？redis 的主从复制原理能介绍一下么？redis 的哨兵原理能介绍一下么？\n\n如果你用 redis 缓存技术的话，肯定要考虑如何用 redis 来加多台机器，保证 redis 是高并发的，还有就是如何让 redis 保证自己不是挂掉以后就直接死掉了，即 redis 高可用。\n\n由于此节内容较多，因此，会分为两个小节进行讲解。\n\n * redis 主从架构\n * redis 基于哨兵实现高可用\n\nredis 实现高并发主要依靠主从架构，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万 qps，多从用来查询数据，多个从实例可以提供每秒 10w 的 qps。\n\n如果想要在实现高并发的同时，容纳大量的数据，那么就需要 redis 集群，使用 redis 集群之后，可以提供每秒几十万的读写并发。\n\nredis 高可用，如果是做主从架构部署，那么加上哨兵就可以了，就可以实现，任何一个实例宕机，可以进行主备切换。\n\n\n# redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 lru 代码实现？\n\n\n# redis 过期策略\n\nredis 过期策略是：定期删除+惰性删除。\n\n所谓定期删除，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。\n\n假设 redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的灾难。实际上 redis 是每隔 100ms 随机抽取一些 key 来检查和删除的。\n\n但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。\n\n> 获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。\n\n但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了，咋整？\n\n答案是：走内存淘汰机制。\n\n\n# 内存淘汰机制\n\nredis 内存淘汰机制有以下几个：\n\n * noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。\n * allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。\n * allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。\n * volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 key（这个一般不太合适）。\n * volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key。\n * volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除。\n\n\n# 手写一个 lru 算法\n\n你可以现场手写最原始的 lru 算法，那个代码量太大了，似乎不太现实。\n\n不求自己纯手工从底层开始打造出自己的 lru，但是起码要知道如何利用已有的 jdk 数据结构实现一个 java 版的 lru。\n\nclass lrucache<k, v> extends linkedhashmap<k, v> {\n    private final int cache_size;\n\n    /**\n     * 传递进来最多能缓存多少数据\n     *\n     * @param cachesize 缓存大小\n     */\n    public lrucache(int cachesize) {\n        // true 表示让 linkedhashmap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。\n        super((int) math.ceil(cachesize / 0.75) + 1, 0.75f, true);\n        cache_size = cachesize;\n    }\n\n    @override\n    protected boolean removeeldestentry(map.entry<k, v> eldest) {\n        // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。\n        return size() > cache_size;\n    }\n}\n\n\n\n# redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？\n\n在前几年，redis 如果要搞几个节点，每个节点存储一部分的数据，得借助一些中间件来实现，比如说有 codis，或者 twemproxy，都有。有一些 redis 中间件，你读写 redis 中间件，redis 中间件负责将你的数据分布式存储在多台机器上的 redis 实例中。\n\n这两年，redis 不断在发展，redis 也不断有新的版本，现在的 redis 集群模式，可以做到在多台机器上，部署多个 redis 实例，每个实例存储一部分的数据，同时每个 redis 主实例可以挂 redis 从实例，自动确保说，如果 redis 主实例挂了，会自动切换到 redis 从实例上来。\n\n现在 redis 的新版本，大家都是用 redis cluster 的，也就是 redis 原生支持的 redis 集群模式，那么面试官肯定会就 redis cluster 对你来个几连炮。要是你没用过 redis cluster，正常，以前很多人用 codis 之类的客户端来支持集群，但是起码你得研究一下 redis cluster 吧。\n\n如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个 g，单机就足够了，可以使用 replication，一个 master 多个 slaves，要几个 slave 跟你要求的读吞吐量有关，然后自己搭建一个 sentinel 集群去保证 redis 主从架构的高可用性。\n\nredis cluster，主要是针对海量数据+高并发+高可用的场景。redis cluster 支撑 n 个 redis master node，每个 master node 都可以挂载多个 slave node。这样整个 redis 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 master 节点，每个 master 节点就能存放更多的数据了。\n\n\n# 面试题剖析\n\n\n# redis cluster 介绍\n\n * 自动将数据进行分片，每个 master 上放一部分数据\n * 提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的\n\n在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加 1w 的端口号，比如 16379。\n\n16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，gossip 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。\n\n\n# 节点间的内部通信机制\n\n# 基本通信原理\n\n集群元数据的维护有两种方式：集中式、gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。\n\n集中式是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 storm。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。\n\n\n\nredis 维护集群元数据采用另一个方式， gossip 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。\n\n\n\n集中式的好处在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到；不好在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。\n\ngossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。\n\n * 10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如 7001，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另外几个节点发送 ping 消息，同时其它几个节点接收到 ping 之后返回 pong。\n * 交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。\n\n# gossip 协议\n\ngossip 协议包含多种消息，包含 ping,pong,meet,fail 等等。\n\n * meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。\n\nredis-trib.rb add-node\n\n\n其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群。\n\n * ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。\n * pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。\n * fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦。\n\n# ping 消息深入\n\nping 时要携带一些元数据，如果很频繁，可能会加重网络负担。\n\n每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了 cluster_node_timeout / 2，那么立即发送 ping，避免数据交换延时过长，落后的时间太长了。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 cluster_node_timeout 可以调节，如果调得比较大，那么会降低 ping 的频率。\n\n每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 3 个其它节点的信息，最多包含 总节点数减 2 个其它节点的信息。\n\n\n# 分布式寻址算法\n\n * hash 算法（大量缓存重建）\n * 一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）\n * redis cluster 的 hash slot 算法\n\n# hash 算法\n\n来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会导致大部分的请求过来，全部无法拿到有效的缓存，导致大量的流量涌入数据库。\n\n\n\n# 一致性 hash 算法\n\n一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。\n\n来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，遇到的第一个 master 节点就是 key 所在位置。\n\n在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。\n\n燃鹅，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成缓存热点的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。\n\n\n\n# redis cluster 的 hash slot 算法\n\nredis cluster 有固定的 16384 个 hash slot，对每个 key 计算 crc16 值，然后对 16384 取模，可以获取 key 对应的 hash slot。\n\nredis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 hash tag 来实现。\n\n任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。\n\n\n\n\n# redis cluster 的高可用与主备切换原理\n\nredis cluster 的高可用的原理，几乎跟哨兵是类似的。\n\n# 判断节点宕机\n\n如果一个节点认为另外一个节点宕机，那么就是 pfail，主观宕机。如果多个节点都认为另外一个节点宕机了，那么就是 fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown。\n\n在 cluster-node-timeout 内，某个节点一直没有返回 pong，那么就被认为 pfail。\n\n如果一个节点认为某个节点 pfail 了，那么会在 gossip ping 消息中，ping 给其他节点，如果超过半数的节点都认为 pfail 了，那么就会变成 fail。\n\n# 从节点过滤\n\n对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。\n\n检查每个 slave node 与 master node 断开连接的时间，如果超过了 cluster-node-timeout * cluster-slave-validity-factor，那么就没有资格切换成 master。\n\n# 从节点选举\n\n每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。\n\n所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node（n/2 + 1）都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。\n\n从节点执行主备切换，从节点切换为主节点。\n\n# 与哨兵比较\n\n整个流程跟哨兵相比，非常类似，所以说，redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。\n\n\n# 如何保证缓存与数据库的双写一致性？\n\n一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统不是严格要求 “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：读请求和写请求串行化，串到一个内存队列里去。\n\n串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。\n\n\n# cache aside pattern\n\n最经典的缓存+数据库读写的模式，就是 cache aside pattern。\n\n * 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。\n * 更新的时候，先更新数据库，然后再删除缓存。\n\n为什么是删除缓存，而不是更新缓存？\n\n原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。\n\n比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。\n\n另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于比较复杂的缓存数据计算的场景，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，这个缓存到底会不会被频繁访问到？\n\n举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有大量的冷数据。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。用到缓存才去算缓存。\n\n其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。\n\n\n# 最初级的缓存不一致问题及解决方案\n\n问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。\n\n\n\n解决思路：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。\n\n\n# 比较复杂的数据不一致问题分析\n\n数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一样了...\n\n为什么上亿流量高并发场景下，缓存会出现这个问题？\n\n只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场景。但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就可能会出现上述的数据库+缓存不一致的情况。\n\n解决方案如下：\n\n更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个 jvm 内部队列中。\n\n一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。\n\n这里有一个优化点，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。\n\n待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。\n\n如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。\n\n高并发的场景下，该解决方案要注意的问题：\n\n * 读请求长时阻塞\n\n由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。\n\n该解决方案，最大的风险点在于说，可能数据更新很频繁，导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库。务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。\n\n另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要部署多个服务，每个服务分摊一些数据的更新操作。如果一个内存队列里居然会挤压 100 个商品的库存修改操作，每隔库存修改操作要耗费 10ms 去完成，那么最后一个商品的读请求，可能等待 10 * 100 = 1000ms = 1s 后，才能得到数据，这个时候就导致读请求的长时阻塞。\n\n一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 hang 多少时间，如果读请求在 200ms 返回，如果你计算过后，哪怕是最繁忙的时候，积压 10 个更新操作，最多等待 200ms，那还可以的。\n\n如果一个内存队列中可能积压的更新操作特别多，那么你就要加机器，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少。\n\n其实根据之前的项目经验，一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的。像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒的 qps 能到几百就不错了。\n\n我们来实际粗略测算一下。\n\n如果一秒有 500 的写操作，如果分成 5 个时间片，每 200ms 就 100 个写操作，放到 20 个内存队列中，每个内存队列，可能就积压 5 个写操作。每个写操作性能测试后，一般是在 20ms 左右就完成，那么针对每个内存队列的数据的读请求，也就最多 hang 一会儿，200ms 以内肯定能返回了。\n\n经过刚才简单的测算，我们知道，单机支撑的写 qps 在几百是没问题的，如果写 qps 扩大了 10 倍，那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列。\n\n * 读请求并发量过高\n\n这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。\n\n但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。\n\n * 多服务实例部署的请求路由\n\n可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 nginx 服务器路由到相同的服务实例上。\n\n比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 nginx 的 hash 路由功能等等。\n\n * 热点商品的路由问题，导致请求的倾斜\n\n万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些。\n\n\n# 了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？\n\n\n# 缓存雪崩\n\n对于系统 a，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，dba 很着急，重启数据库，但是数据库立马又被新的流量给打死了。\n\n这就是缓存雪崩。\n\n\n\n大约在 3 年前，国内比较知名的一个互联网公司，曾因为缓存事故，导致雪崩，后台系统全部崩溃，事故从当天下午持续到晚上凌晨 3~4 点，公司损失了几千万。\n\n缓存雪崩的事前事中事后的解决方案如下。\n\n * 事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。\n * 事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 mysql 被打死。\n * 事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。\n\n\n\n用户发送一个请求，系统 a 收到请求后，先查本地 ehcache 缓存，如果没查到再查 redis。如果 ehcache 和 redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 redis 中。\n\n限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？走降级！可以返回一些默认的值，或者友情提示，或者空白的值。\n\n好处：\n\n * 数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。\n * 只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。\n * 只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来一次。\n\n\n# 缓存穿透\n\n对于系统 a，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。\n\n黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。\n\n举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“视缓存于无物”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。\n\n\n\n解决方式很简单，每次系统 a 从数据库中只要没查到，就写一个空值到缓存里去，比如 set -999 unknown。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。\n\n\n# 缓存击穿\n\n缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。\n\n解决方式也很简单，可以将热点数据设置为永远不过期；或者基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据。\n\n\n# redis 的并发竞争问题是什么？如何解决这个问题？了解 redis 事务的 cas 方案吗？\n\n某个时刻，多个系统实例都去更新某个 key。可以基于 zookeeper 实现分布式锁。每个系统通过 zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 key，别人都不允许读和写。\n\n\n\n你要写入缓存的数据，都是从 mysql 里查出来的，都得写入 mysql 中，写入 mysql 中的时候必须保存一个时间戳，从 mysql 查出来的时候，时间戳也查出来。\n\n每次要写之前，先判断一下当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。\n\n\n# 生产环境中的 redis 是怎么部署的？\n\nredis cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰 qps 可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求/s。\n\n机器是什么配置？32g 内存+ 8 核 cpu + 1t 磁盘，但是分配给 redis 进程的是 10g 内存，一般线上生产环境，redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。\n\n5 台机器对外提供读写，一共有 50g 内存。\n\n因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。\n\n你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。\n\n其实大型的公司，会有基础架构的 team 负责缓存集群的运维。',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 缓存中间件",frontmatter:{title:"Java 缓存中间件",categories:["编程","Java","中间件","缓存"],tags:["Java","中间件","缓存"],abbrlink:"e87a26e9",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/970fa6/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/02.%E7%BC%93%E5%AD%98/02.Java%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6.html",relativePath:"14.中间件/02.缓存/02.Java缓存中间件.md",key:"v-47099c49",path:"/pages/970fa6/",headers:[{level:2,title:"一 、JSR 107",slug:"一-、jsr-107",normalizedTitle:"一 、jsr 107",charIndex:54},{level:2,title:"二、Spring Cache",slug:"二、spring-cache",normalizedTitle:"二、spring cache",charIndex:608},{level:3,title:"开启缓存注解",slug:"开启缓存注解",normalizedTitle:"开启缓存注解",charIndex:936},{level:3,title:"spring 缓存注解 API",slug:"spring-缓存注解-api",normalizedTitle:"spring 缓存注解 api",charIndex:1180},{level:4,title:"@Cacheable",slug:"cacheable",normalizedTitle:"@cacheable",charIndex:1293},{level:4,title:"@CachePut",slug:"cacheput",normalizedTitle:"@cacheput",charIndex:1482},{level:4,title:"@CacheEvict",slug:"cacheevict",normalizedTitle:"@cacheevict",charIndex:1587},{level:4,title:"@Caching",slug:"caching",normalizedTitle:"@caching",charIndex:2483},{level:4,title:"@CacheConfig",slug:"cacheconfig",normalizedTitle:"@cacheconfig",charIndex:2737},{level:2,title:"三、Spring Boot Cache",slug:"三、spring-boot-cache",normalizedTitle:"三、spring boot cache",charIndex:2987},{level:3,title:"Spring Boot Cache 快速入门",slug:"spring-boot-cache-快速入门",normalizedTitle:"spring boot cache 快速入门",charIndex:3096},{level:2,title:"四、JetCache",slug:"四、jetcache",normalizedTitle:"四、jetcache",charIndex:3926},{level:3,title:"jetcache 快速入门",slug:"jetcache-快速入门",normalizedTitle:"jetcache 快速入门",charIndex:4221},{level:2,title:"五、j2cache",slug:"五、j2cache",normalizedTitle:"五、j2cache",charIndex:6371},{level:2,title:"六、总结",slug:"六、总结",normalizedTitle:"六、总结",charIndex:6385},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:6542}],headersStr:"一 、JSR 107 二、Spring Cache 开启缓存注解 spring 缓存注解 API @Cacheable @CachePut @CacheEvict @Caching @CacheConfig 三、Spring Boot Cache Spring Boot Cache 快速入门 四、JetCache jetcache 快速入门 五、j2cache 六、总结 参考资料",content:'# Java 缓存中间件\n\n> 关键词：Spring Cache、J2Cache、JetCache\n\n\n# 一 、JSR 107\n\nJSR107 中制订了 Java 缓存的规范。\n\n因此，在很多缓存框架、缓存库中，其 API 都参考了 JSR 107 规范。\n\n\n\nJava Caching 定义了 5 个核心接口\n\n * CachingProvider - 定义了创建、配置、获取、管理和控制多个 CacheManager。一个应用可以在运行期访问多个 CachingProvider。\n * CacheManager - 定义了创建、配置、获取、管理和控制多个唯一命名的 Cache，这些 Cache 存在于 CacheManager 的上下文中。一个 CacheManager 仅被一个 CachingProvider 所拥有。\n * Cache - 是一个类似 Map 的数据结构并临时存储以 Key 为索引的值。一个 Cache 仅被一个 CacheManager 所拥有。\n * Entry - 是一个存储在 Cache 中的 key-value 对。\n * Expiry - 每一个存储在 Cache 中的条目有一个定义的有效期，即 Expiry Duration。一旦超过这个时间，条目为过期的状态。一旦过期，条目将不可访问、更新和删除。缓存有效期可以通过 ExpiryPolicy 设置。\n\n\n# 二、Spring Cache\n\n> 详见：Spring Cache 官方文档\n\nSpring 作为 Java 开发最著名的框架，也提供了缓存功能的框架—— Spring Cache。\n\nSpring 支持基于注释（annotation）的缓存（cache）技术，它本质上不是一个具体的缓存实现方案（例如：EHCache 或 OSCache），而是一个对缓存使用的抽象，通过在既有代码中添加少量它定义的各种 annotation，即能够达到缓存方法的返回对象的效果。\n\nSpring Cache 的特点：\n\n * 通过缓存注解即可支持缓存功能\n * 支持 Spring EL 表达式\n * 支持 AspectJ\n * 支持自定义 key 和缓存管理\n\n\n# 开启缓存注解\n\nSpring 为缓存功能提供了注解功能，但是你必须启动注解。\n\n有两种方式：\n\n（一）使用标记注解 @EnableCaching\n\n这种方式对于 Spring 或 Spring Boot 项目都适用。\n\n@Configuration\n@EnableCaching\npublic class AppConfig {\n}\n\n\n（二）在 xml 中声明\n\n<cache:annotation-driven cache-manager="cacheManager"/>\n\n\n\n# spring 缓存注解 API\n\nSpring 对缓存的支持类似于对事务的支持。\n\n首先使用注解标记方法，相当于定义了切点，然后使用 Aop 技术在这个方法的调用前、调用后获取方法的入参和返回值，进而实现了缓存的逻辑。\n\n# @Cacheable\n\n@Cacheable 用于触发缓存。\n\n表明所修饰的方法是可以缓存的：当第一次调用这个方法时，它的结果会被缓存下来，在缓存的有效时间内，以后访问这个方法都直接返回缓存结果，不再执行方法中的代码段。\n\n这个注解可以用condition属性来设置条件，如果不满足条件，就不使用缓存能力，直接执行方法。\n\n可以使用key属性来指定 key 的生成规则。\n\n# @CachePut\n\n@CachePut 用于更新缓存。\n\n与@Cacheable不同，@CachePut不仅会缓存方法的结果，还会执行方法的代码段。\n\n它支持的属性和用法都与@Cacheable一致。\n\n# @CacheEvict\n\n@CacheEvict 用于清除缓存。\n\n与@Cacheable功能相反，@CacheEvict表明所修饰的方法是用来删除失效或无用的缓存数据。\n\n下面是@Cacheable、@CacheEvict和@CachePut基本使用方法的一个集中展示：\n\n@Service\npublic class UserService {\n    // @Cacheable可以设置多个缓存，形式如：@Cacheable({"books", "isbns"})\n    @Cacheable(value={"users"}, key="#user.id")\n    public User findUser(User user) {\n        return findUserInDB(user.getId());\n    }\n\n    @Cacheable(value = "users", condition = "#user.getId() <= 2")\n    public User findUserInLimit(User user) {\n        return findUserInDB(user.getId());\n    }\n\n    @CachePut(value = "users", key = "#user.getId()")\n    public void updateUser(User user) {\n        updateUserInDB(user);\n    }\n\n    @CacheEvict(value = "users")\n    public void removeUser(User user) {\n        removeUserInDB(user.getId());\n    }\n\n    @CacheEvict(value = "users", allEntries = true)\n    public void clear() {\n        removeAllInDB();\n    }\n}\n\n\n# @Caching\n\n@Caching 用于组合定义多种缓存功能。\n\n如果需要使用同一个缓存注解（@Cacheable、@CacheEvict或@CachePut）多次修饰一个方法，就需要用到@Caching。\n\n@Caching(evict = { @CacheEvict("primary"), @CacheEvict(cacheNames="secondary", key="#p0") })\npublic Book importBooks(String deposit, Date date)\n\n\n# @CacheConfig\n\n@CacheConfig 用于定义公共缓存配置。\n\n与前面的缓存注解不同，这是一个类级别的注解。\n\n如果类的所有操作都是缓存操作，你可以使用@CacheConfig来指定类，省去一些配置。\n\n@CacheConfig("books")\npublic class BookRepositoryImpl implements BookRepository {\n @Cacheable\n public Book findBook(ISBN isbn) {...}\n}\n\n\n\n# 三、Spring Boot Cache\n\n> 详见：Spring Boot Cache 特性官方文档\n\nSpring Boot Cache 是在 Spring Cache 的基础上做了封装，使得使用更为便捷。\n\n\n# Spring Boot Cache 快速入门\n\n（1）引入依赖\n\n<dependency>\n  <groupId>org.springframework.boot</groupId>\n  <artifactId>spring-boot-starter-cache</artifactId>\n</dependency>\n\n\x3c!-- 按序引入需要的缓存库 --\x3e\n<dependency>\n  <groupId>org.springframework.boot</groupId>\n  <artifactId>spring-boot-starter-data-redis</artifactId>\n</dependency>\n\n\n（2）缓存配置\n\n例如，选用缓存为 redis，则需要配置 redis 相关的配置项（如：数据源、连接池等配置信息）\n\n# 缓存类型，支持类型：GENERIC、JCACHE、EHCACHE、HAZELCAST、INFINISPAN、COUCHBASE、REDIS、CAFFEINE、SIMPLE\nspring.cache.type = redis\n# 全局缓存时间\nspring.cache.redis.time-to-live = 60s\n\n# Redis 配置\nspring.redis.database = 0\nspring.redis.host = localhost\nspring.redis.port = 6379\nspring.redis.password =\n\n\n（3）使用 @EnableCaching 开启缓存\n\n@EnableCaching\n@SpringBootApplication\npublic class Application {\n    // ...\n}\n\n\n（4）缓存注解（@Cacheable、@CachePut、@CacheEvit 等）使用方式与 Spring Cache 完全一样\n\n\n# 四、JetCache\n\n> JetCache 是一个基于 Java 的缓存系统封装，提供统一的 API 和注解来简化缓存的使用。 JetCache 提供了比 SpringCache 更加强大的注解，可以原生的支持 TTL、两级缓存、分布式自动刷新，还提供了Cache接口用于手工缓存操作。 当前有四个实现，RedisCache、TairCache（此部分未在 github 开源）、CaffeineCache(in memory)和一个简易的LinkedHashMapCache(in memory)，要添加新的实现也是非常简单的。\n> \n> 详见：jetcache Github\n\n\n# jetcache 快速入门\n\n如果使用 Spring Boot，可以按如下的方式配置（这里使用了 jedis 客户端连接 redis，如果需要集群、读写分离、异步等特性支持请使用lettuce客户端）。\n\n（1）引入 POM\n\n<dependency>\n    <groupId>com.alicp.jetcache</groupId>\n    <artifactId>jetcache-starter-redis</artifactId>\n    <version>2.5.14</version>\n</dependency>\n\n\n（2）配置\n\n配置一个 spring boot 风格的 application.yml 文件，把他放到资源目录中\n\njetcache:\n  statIntervalMinutes: 15\n  areaInCacheName: false\n  local:\n    default:\n      type: linkedhashmap\n      keyConvertor: fastjson\n  remote:\n    default:\n      type: redis\n      keyConvertor: fastjson\n      valueEncoder: java\n      valueDecoder: java\n      poolConfig:\n        minIdle: 5\n        maxIdle: 20\n        maxTotal: 50\n      host: 127.0.0.1\n      port: 6379\n\n\n（3）开启缓存\n\n然后创建一个 App 类放在业务包的根下，EnableMethodCache，EnableCreateCacheAnnotation 这两个注解分别激活 Cached 和 CreateCache 注解，其他和标准的 Spring Boot 程序是一样的。这个类可以直接 main 方法运行。\n\npackage com.company.mypackage;\n\nimport com.alicp.jetcache.anno.config.EnableCreateCacheAnnotation;\nimport com.alicp.jetcache.anno.config.EnableMethodCache;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\n@EnableMethodCache(basePackages = "com.company.mypackage")\n@EnableCreateCacheAnnotation\npublic class MySpringBootApp {\n    public static void main(String[] args) {\n        SpringApplication.run(MySpringBootApp.class);\n    }\n}\n\n\n（4）API 基本使用\n\n创建缓存实例\n\n通过 @CreateCache 注解创建一个缓存实例，默认超时时间是 100 秒\n\n@CreateCache(expire = 100)\nprivate Cache<Long, UserDO> userCache;\n\n\n用起来就像 map 一样\n\nUserDO user = userCache.get(123L);\nuserCache.put(123L, user);\nuserCache.remove(123L);\n\n\n创建一个两级（内存+远程）的缓存，内存中的元素个数限制在 50 个。\n\n@CreateCache(name = "UserService.userCache", expire = 100, cacheType = CacheType.BOTH, localLimit = 50)\nprivate Cache<Long, UserDO> userCache;\n\n\nname 属性不是必须的，但是起个名字是个好习惯，展示统计数据的使用，会使用这个名字。如果同一个 area 两个 @CreateCache 的 name 配置一样，它们生成的 Cache 将指向同一个实例。\n\n创建方法缓存\n\n使用 @Cached 方法可以为一个方法添加上缓存。JetCache 通过 Spring AOP 生成代理，来支持缓存功能。注解可以加在接口方法上也可以加在类方法上，但需要保证是个 Spring bean。\n\npublic interface UserService {\n    @Cached(name="UserService.getUserById", expire = 3600)\n    User getUserById(long userId);\n}\n\n\n\n# 五、j2cache\n\n\n# 六、总结\n\n使用缓存框架，使得开发缓存功能非常便捷。\n\n如果你的系统只需要使用一种缓存，那么推荐使用 Spring Boot Cache。Spring Boot Cache 在 Spring Cache 基础上做了封装，使用更简单、方便。\n\n如果你的系统需要使用多级缓存，那么推荐使用 jetcache。\n\n\n# 参考资料\n\n * JSR107\n * Spring Cache 官方文档\n * Spring Boot Cache 特性官方文档\n * J2Cache Gitee\n * jetcache Github\n * jetcache wiki',normalizedContent:'# java 缓存中间件\n\n> 关键词：spring cache、j2cache、jetcache\n\n\n# 一 、jsr 107\n\njsr107 中制订了 java 缓存的规范。\n\n因此，在很多缓存框架、缓存库中，其 api 都参考了 jsr 107 规范。\n\n\n\njava caching 定义了 5 个核心接口\n\n * cachingprovider - 定义了创建、配置、获取、管理和控制多个 cachemanager。一个应用可以在运行期访问多个 cachingprovider。\n * cachemanager - 定义了创建、配置、获取、管理和控制多个唯一命名的 cache，这些 cache 存在于 cachemanager 的上下文中。一个 cachemanager 仅被一个 cachingprovider 所拥有。\n * cache - 是一个类似 map 的数据结构并临时存储以 key 为索引的值。一个 cache 仅被一个 cachemanager 所拥有。\n * entry - 是一个存储在 cache 中的 key-value 对。\n * expiry - 每一个存储在 cache 中的条目有一个定义的有效期，即 expiry duration。一旦超过这个时间，条目为过期的状态。一旦过期，条目将不可访问、更新和删除。缓存有效期可以通过 expirypolicy 设置。\n\n\n# 二、spring cache\n\n> 详见：spring cache 官方文档\n\nspring 作为 java 开发最著名的框架，也提供了缓存功能的框架—— spring cache。\n\nspring 支持基于注释（annotation）的缓存（cache）技术，它本质上不是一个具体的缓存实现方案（例如：ehcache 或 oscache），而是一个对缓存使用的抽象，通过在既有代码中添加少量它定义的各种 annotation，即能够达到缓存方法的返回对象的效果。\n\nspring cache 的特点：\n\n * 通过缓存注解即可支持缓存功能\n * 支持 spring el 表达式\n * 支持 aspectj\n * 支持自定义 key 和缓存管理\n\n\n# 开启缓存注解\n\nspring 为缓存功能提供了注解功能，但是你必须启动注解。\n\n有两种方式：\n\n（一）使用标记注解 @enablecaching\n\n这种方式对于 spring 或 spring boot 项目都适用。\n\n@configuration\n@enablecaching\npublic class appconfig {\n}\n\n\n（二）在 xml 中声明\n\n<cache:annotation-driven cache-manager="cachemanager"/>\n\n\n\n# spring 缓存注解 api\n\nspring 对缓存的支持类似于对事务的支持。\n\n首先使用注解标记方法，相当于定义了切点，然后使用 aop 技术在这个方法的调用前、调用后获取方法的入参和返回值，进而实现了缓存的逻辑。\n\n# @cacheable\n\n@cacheable 用于触发缓存。\n\n表明所修饰的方法是可以缓存的：当第一次调用这个方法时，它的结果会被缓存下来，在缓存的有效时间内，以后访问这个方法都直接返回缓存结果，不再执行方法中的代码段。\n\n这个注解可以用condition属性来设置条件，如果不满足条件，就不使用缓存能力，直接执行方法。\n\n可以使用key属性来指定 key 的生成规则。\n\n# @cacheput\n\n@cacheput 用于更新缓存。\n\n与@cacheable不同，@cacheput不仅会缓存方法的结果，还会执行方法的代码段。\n\n它支持的属性和用法都与@cacheable一致。\n\n# @cacheevict\n\n@cacheevict 用于清除缓存。\n\n与@cacheable功能相反，@cacheevict表明所修饰的方法是用来删除失效或无用的缓存数据。\n\n下面是@cacheable、@cacheevict和@cacheput基本使用方法的一个集中展示：\n\n@service\npublic class userservice {\n    // @cacheable可以设置多个缓存，形式如：@cacheable({"books", "isbns"})\n    @cacheable(value={"users"}, key="#user.id")\n    public user finduser(user user) {\n        return finduserindb(user.getid());\n    }\n\n    @cacheable(value = "users", condition = "#user.getid() <= 2")\n    public user finduserinlimit(user user) {\n        return finduserindb(user.getid());\n    }\n\n    @cacheput(value = "users", key = "#user.getid()")\n    public void updateuser(user user) {\n        updateuserindb(user);\n    }\n\n    @cacheevict(value = "users")\n    public void removeuser(user user) {\n        removeuserindb(user.getid());\n    }\n\n    @cacheevict(value = "users", allentries = true)\n    public void clear() {\n        removeallindb();\n    }\n}\n\n\n# @caching\n\n@caching 用于组合定义多种缓存功能。\n\n如果需要使用同一个缓存注解（@cacheable、@cacheevict或@cacheput）多次修饰一个方法，就需要用到@caching。\n\n@caching(evict = { @cacheevict("primary"), @cacheevict(cachenames="secondary", key="#p0") })\npublic book importbooks(string deposit, date date)\n\n\n# @cacheconfig\n\n@cacheconfig 用于定义公共缓存配置。\n\n与前面的缓存注解不同，这是一个类级别的注解。\n\n如果类的所有操作都是缓存操作，你可以使用@cacheconfig来指定类，省去一些配置。\n\n@cacheconfig("books")\npublic class bookrepositoryimpl implements bookrepository {\n @cacheable\n public book findbook(isbn isbn) {...}\n}\n\n\n\n# 三、spring boot cache\n\n> 详见：spring boot cache 特性官方文档\n\nspring boot cache 是在 spring cache 的基础上做了封装，使得使用更为便捷。\n\n\n# spring boot cache 快速入门\n\n（1）引入依赖\n\n<dependency>\n  <groupid>org.springframework.boot</groupid>\n  <artifactid>spring-boot-starter-cache</artifactid>\n</dependency>\n\n\x3c!-- 按序引入需要的缓存库 --\x3e\n<dependency>\n  <groupid>org.springframework.boot</groupid>\n  <artifactid>spring-boot-starter-data-redis</artifactid>\n</dependency>\n\n\n（2）缓存配置\n\n例如，选用缓存为 redis，则需要配置 redis 相关的配置项（如：数据源、连接池等配置信息）\n\n# 缓存类型，支持类型：generic、jcache、ehcache、hazelcast、infinispan、couchbase、redis、caffeine、simple\nspring.cache.type = redis\n# 全局缓存时间\nspring.cache.redis.time-to-live = 60s\n\n# redis 配置\nspring.redis.database = 0\nspring.redis.host = localhost\nspring.redis.port = 6379\nspring.redis.password =\n\n\n（3）使用 @enablecaching 开启缓存\n\n@enablecaching\n@springbootapplication\npublic class application {\n    // ...\n}\n\n\n（4）缓存注解（@cacheable、@cacheput、@cacheevit 等）使用方式与 spring cache 完全一样\n\n\n# 四、jetcache\n\n> jetcache 是一个基于 java 的缓存系统封装，提供统一的 api 和注解来简化缓存的使用。 jetcache 提供了比 springcache 更加强大的注解，可以原生的支持 ttl、两级缓存、分布式自动刷新，还提供了cache接口用于手工缓存操作。 当前有四个实现，rediscache、taircache（此部分未在 github 开源）、caffeinecache(in memory)和一个简易的linkedhashmapcache(in memory)，要添加新的实现也是非常简单的。\n> \n> 详见：jetcache github\n\n\n# jetcache 快速入门\n\n如果使用 spring boot，可以按如下的方式配置（这里使用了 jedis 客户端连接 redis，如果需要集群、读写分离、异步等特性支持请使用lettuce客户端）。\n\n（1）引入 pom\n\n<dependency>\n    <groupid>com.alicp.jetcache</groupid>\n    <artifactid>jetcache-starter-redis</artifactid>\n    <version>2.5.14</version>\n</dependency>\n\n\n（2）配置\n\n配置一个 spring boot 风格的 application.yml 文件，把他放到资源目录中\n\njetcache:\n  statintervalminutes: 15\n  areaincachename: false\n  local:\n    default:\n      type: linkedhashmap\n      keyconvertor: fastjson\n  remote:\n    default:\n      type: redis\n      keyconvertor: fastjson\n      valueencoder: java\n      valuedecoder: java\n      poolconfig:\n        minidle: 5\n        maxidle: 20\n        maxtotal: 50\n      host: 127.0.0.1\n      port: 6379\n\n\n（3）开启缓存\n\n然后创建一个 app 类放在业务包的根下，enablemethodcache，enablecreatecacheannotation 这两个注解分别激活 cached 和 createcache 注解，其他和标准的 spring boot 程序是一样的。这个类可以直接 main 方法运行。\n\npackage com.company.mypackage;\n\nimport com.alicp.jetcache.anno.config.enablecreatecacheannotation;\nimport com.alicp.jetcache.anno.config.enablemethodcache;\nimport org.springframework.boot.springapplication;\nimport org.springframework.boot.autoconfigure.springbootapplication;\n\n@springbootapplication\n@enablemethodcache(basepackages = "com.company.mypackage")\n@enablecreatecacheannotation\npublic class myspringbootapp {\n    public static void main(string[] args) {\n        springapplication.run(myspringbootapp.class);\n    }\n}\n\n\n（4）api 基本使用\n\n创建缓存实例\n\n通过 @createcache 注解创建一个缓存实例，默认超时时间是 100 秒\n\n@createcache(expire = 100)\nprivate cache<long, userdo> usercache;\n\n\n用起来就像 map 一样\n\nuserdo user = usercache.get(123l);\nusercache.put(123l, user);\nusercache.remove(123l);\n\n\n创建一个两级（内存+远程）的缓存，内存中的元素个数限制在 50 个。\n\n@createcache(name = "userservice.usercache", expire = 100, cachetype = cachetype.both, locallimit = 50)\nprivate cache<long, userdo> usercache;\n\n\nname 属性不是必须的，但是起个名字是个好习惯，展示统计数据的使用，会使用这个名字。如果同一个 area 两个 @createcache 的 name 配置一样，它们生成的 cache 将指向同一个实例。\n\n创建方法缓存\n\n使用 @cached 方法可以为一个方法添加上缓存。jetcache 通过 spring aop 生成代理，来支持缓存功能。注解可以加在接口方法上也可以加在类方法上，但需要保证是个 spring bean。\n\npublic interface userservice {\n    @cached(name="userservice.getuserbyid", expire = 3600)\n    user getuserbyid(long userid);\n}\n\n\n\n# 五、j2cache\n\n\n# 六、总结\n\n使用缓存框架，使得开发缓存功能非常便捷。\n\n如果你的系统只需要使用一种缓存，那么推荐使用 spring boot cache。spring boot cache 在 spring cache 基础上做了封装，使用更简单、方便。\n\n如果你的系统需要使用多级缓存，那么推荐使用 jetcache。\n\n\n# 参考资料\n\n * jsr107\n * spring cache 官方文档\n * spring boot cache 特性官方文档\n * j2cache gitee\n * jetcache github\n * jetcache wiki',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Memcached 快速入门",frontmatter:{title:"Memcached 快速入门",categories:["编程","Java","中间件","缓存"],tags:["Java","中间件","缓存","面试"],abbrlink:"2e7f2a78",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/25a710/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/02.%E7%BC%93%E5%AD%98/03.Memcached.html",relativePath:"14.中间件/02.缓存/03.Memcached.md",key:"v-d302b38c",path:"/pages/25a710/",headers:[{level:2,title:"一、Memcached 简介",slug:"一、memcached-简介",normalizedTitle:"一、memcached 简介",charIndex:21},{level:3,title:"Memcached 特性",slug:"memcached-特性",normalizedTitle:"memcached 特性",charIndex:261},{level:2,title:"二、Memcached 命令",slug:"二、memcached-命令",normalizedTitle:"二、memcached 命令",charIndex:379},{level:2,title:"三、Java 连接 Memcached",slug:"三、java-连接-memcached",normalizedTitle:"三、java 连接 memcached",charIndex:1080},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:1779}],headersStr:"一、Memcached 简介 Memcached 特性 二、Memcached 命令 三、Java 连接 Memcached 参考资料",content:'# Memcached 快速入门\n\n\n# 一、Memcached 简介\n\nMemcached 是一个自由开源的，高性能，分布式内存对象缓存系统。\n\nMemcached 是一种基于内存的 key-value 存储，用来存储小块的任意数据（字符串、对象）。这些数据可以是数据库调用、API 调用或者是页面渲染的结果。\n\nMemcached 简洁而强大。它的简洁设计便于快速开发，减轻开发难度，解决了大数据量缓存的很多问题。它的 API 兼容大部分流行的开发语言。本质上，它是一个简洁的 key-value 存储系统。\n\n\n# Memcached 特性\n\nmemcached 作为高速运行的分布式缓存服务器，具有以下的特点。\n\n * 协议简单\n * 基于 libevent 的事件处理\n * 内置内存存储方式\n * memcached 不互相通信的分布式\n\n\n# 二、Memcached 命令\n\n可以通过 telnet 命令并指定主机 ip 和端口来连接 Memcached 服务。\n\ntelnet 127.0.0.1 11211\n\nTrying 127.0.0.1...\nConnected to 127.0.0.1.\nEscape character is \'^]\'.\nset foo 0 0 3                                                   保存命令\nbar                                                             数据\nSTORED                                                          结果\nget foo                                                         取得命令\nVALUE foo 0 3                                                   数据\nbar                                                             数据\nEND                                                             结束行\nquit                                                            退出\n\n\n\n# 三、Java 连接 Memcached\n\n使用 Java 程序连接 Memcached，需要在你的 classpath 中添加 Memcached jar 包。\n\n本站 jar 包下载地址：spymemcached-2.10.3.jar。\n\nGoogle Code jar 包下载地址：spymemcached-2.10.3.jar（需要科学上网）。\n\n以下程序假定 Memcached 服务的主机为 127.0.0.1，端口为 11211。\n\nimport net.spy.memcached.MemcachedClient;\nimport java.net.*;\n\n\npublic class MemcachedJava {\n   public static void main(String[] args) {\n      try{\n         // 本地连接 Memcached 服务\n         MemcachedClient mcc = new MemcachedClient(new InetSocketAddress("127.0.0.1", 11211));\n         System.out.println("Connection to server sucessful.");\n\n         // 关闭连接\n         mcc.shutdown();\n\n      }catch(Exception ex){\n         System.out.println( ex.getMessage() );\n      }\n   }\n}\n\n\n\n# 参考资料\n\n * Memcached 官网\n * Memcached Github\n * Memcached 教程',normalizedContent:'# memcached 快速入门\n\n\n# 一、memcached 简介\n\nmemcached 是一个自由开源的，高性能，分布式内存对象缓存系统。\n\nmemcached 是一种基于内存的 key-value 存储，用来存储小块的任意数据（字符串、对象）。这些数据可以是数据库调用、api 调用或者是页面渲染的结果。\n\nmemcached 简洁而强大。它的简洁设计便于快速开发，减轻开发难度，解决了大数据量缓存的很多问题。它的 api 兼容大部分流行的开发语言。本质上，它是一个简洁的 key-value 存储系统。\n\n\n# memcached 特性\n\nmemcached 作为高速运行的分布式缓存服务器，具有以下的特点。\n\n * 协议简单\n * 基于 libevent 的事件处理\n * 内置内存存储方式\n * memcached 不互相通信的分布式\n\n\n# 二、memcached 命令\n\n可以通过 telnet 命令并指定主机 ip 和端口来连接 memcached 服务。\n\ntelnet 127.0.0.1 11211\n\ntrying 127.0.0.1...\nconnected to 127.0.0.1.\nescape character is \'^]\'.\nset foo 0 0 3                                                   保存命令\nbar                                                             数据\nstored                                                          结果\nget foo                                                         取得命令\nvalue foo 0 3                                                   数据\nbar                                                             数据\nend                                                             结束行\nquit                                                            退出\n\n\n\n# 三、java 连接 memcached\n\n使用 java 程序连接 memcached，需要在你的 classpath 中添加 memcached jar 包。\n\n本站 jar 包下载地址：spymemcached-2.10.3.jar。\n\ngoogle code jar 包下载地址：spymemcached-2.10.3.jar（需要科学上网）。\n\n以下程序假定 memcached 服务的主机为 127.0.0.1，端口为 11211。\n\nimport net.spy.memcached.memcachedclient;\nimport java.net.*;\n\n\npublic class memcachedjava {\n   public static void main(string[] args) {\n      try{\n         // 本地连接 memcached 服务\n         memcachedclient mcc = new memcachedclient(new inetsocketaddress("127.0.0.1", 11211));\n         system.out.println("connection to server sucessful.");\n\n         // 关闭连接\n         mcc.shutdown();\n\n      }catch(exception ex){\n         system.out.println( ex.getmessage() );\n      }\n   }\n}\n\n\n\n# 参考资料\n\n * memcached 官网\n * memcached github\n * memcached 教程',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Ehcache 快速入门",frontmatter:{title:"Ehcache 快速入门",categories:["编程","Java","中间件","缓存"],tags:["Java","中间件","缓存","Ehcache"],abbrlink:"2720adf1",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/c4647d/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/02.%E7%BC%93%E5%AD%98/04.Ehcache.html",relativePath:"14.中间件/02.缓存/04.Ehcache.md",key:"v-16f33bda",path:"/pages/c4647d/",headers:[{level:2,title:"一、简介",slug:"一、简介",normalizedTitle:"一、简介",charIndex:94},{level:3,title:"Ehcache 特性",slug:"ehcache-特性",normalizedTitle:"ehcache 特性",charIndex:157},{level:3,title:"Ehcache 集群",slug:"ehcache-集群",normalizedTitle:"ehcache 集群",charIndex:450},{level:4,title:"RMI",slug:"rmi",normalizedTitle:"rmi",charIndex:271},{level:4,title:"JMS",slug:"jms",normalizedTitle:"jms",charIndex:493},{level:4,title:"Cache Server",slug:"cache-server",normalizedTitle:"cache server",charIndex:676},{level:2,title:"二、快速入门",slug:"二、快速入门",normalizedTitle:"二、快速入门",charIndex:695},{level:3,title:"引入 Ehcache",slug:"引入-ehcache",normalizedTitle:"引入 ehcache",charIndex:706},{level:3,title:"添加配置文件",slug:"添加配置文件",normalizedTitle:"添加配置文件",charIndex:1254},{level:3,title:"Ehcache 工作示例",slug:"ehcache-工作示例",normalizedTitle:"ehcache 工作示例",charIndex:2120},{level:2,title:"三、Ehcache API",slug:"三、ehcache-api",normalizedTitle:"三、ehcache api",charIndex:3136},{level:3,title:"创建 CacheManager",slug:"创建-cachemanager",normalizedTitle:"创建 cachemanager",charIndex:3405},{level:3,title:"添加缓存",slug:"添加缓存",normalizedTitle:"添加缓存",charIndex:4557},{level:3,title:"删除缓存",slug:"删除缓存",normalizedTitle:"删除缓存",charIndex:5716},{level:3,title:"基本缓存操作",slug:"基本缓存操作",normalizedTitle:"基本缓存操作",charIndex:5868},{level:2,title:"四、Ehcache 配置",slug:"四、ehcache-配置",normalizedTitle:"四、ehcache 配置",charIndex:7607},{level:3,title:"xml 配置方式",slug:"xml-配置方式",normalizedTitle:"xml 配置方式",charIndex:7692},{level:3,title:"API 配置方式",slug:"api-配置方式",normalizedTitle:"api 配置方式",charIndex:8641},{level:2,title:"五、Spring 集成 Ehcache",slug:"五、spring-集成-ehcache",normalizedTitle:"五、spring 集成 ehcache",charIndex:9106},{level:3,title:"绑定 Ehcache",slug:"绑定-ehcache",normalizedTitle:"绑定 ehcache",charIndex:9304},{level:3,title:"使用 Spring 的缓存注解",slug:"使用-spring-的缓存注解",normalizedTitle:"使用 spring 的缓存注解",charIndex:10476},{level:4,title:"开启注解",slug:"开启注解",normalizedTitle:"开启注解",charIndex:10495},{level:3,title:"注解基本使用方法",slug:"注解基本使用方法",normalizedTitle:"注解基本使用方法",charIndex:10785},{level:4,title:"@Cacheable",slug:"cacheable",normalizedTitle:"@cacheable",charIndex:10904},{level:4,title:"@CachePut",slug:"cacheput",normalizedTitle:"@cacheput",charIndex:11071},{level:4,title:"@CacheEvict",slug:"cacheevict",normalizedTitle:"@cacheevict",charIndex:11156},{level:4,title:"@Caching",slug:"caching",normalizedTitle:"@caching",charIndex:12030},{level:4,title:"@CacheConfig",slug:"cacheconfig",normalizedTitle:"@cacheconfig",charIndex:12260},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:12483}],headersStr:"一、简介 Ehcache 特性 Ehcache 集群 RMI JMS Cache Server 二、快速入门 引入 Ehcache 添加配置文件 Ehcache 工作示例 三、Ehcache API 创建 CacheManager 添加缓存 删除缓存 基本缓存操作 四、Ehcache 配置 xml 配置方式 API 配置方式 五、Spring 集成 Ehcache 绑定 Ehcache 使用 Spring 的缓存注解 开启注解 注解基本使用方法 @Cacheable @CachePut @CacheEvict @Caching @CacheConfig 参考资料",content:'# Ehcache 快速入门\n\n> EhCache 是一个纯 Java 的进程内缓存框架，具有快速、精干等特点，是 Hibernate 中默认的 CacheProvider。\n\n\n\n\n# 一、简介\n\n> Ehcache 虽然也支持分布式模式，但是分布式方案不是很好好，建议只将其作为单机的进程内缓存使用。\n\n\n# Ehcache 特性\n\n优点\n\n * 快速、简单\n * 支持多种缓存策略：LRU、LFU、FIFO 淘汰算法\n * 缓存数据有两级：内存和磁盘，因此无需担心容量问题\n * 缓存数据会在虚拟机重启的过程中写入磁盘\n * 可以通过 RMI、可插入 API 等方式进行分布式缓存\n * 具有缓存和缓存管理器的侦听接口\n * 支持多缓存管理器实例，以及一个实例的多个缓存区域\n * 提供 Hibernate 的缓存实现\n\n缺点\n\n * 使用磁盘 Cache 的时候非常占用磁盘空间\n * 不保证数据的安全\n * 虽然支持分布式缓存，但效率不高（通过组播方式，在不同节点之间同步数据）。\n\n\n# Ehcache 集群\n\nEhcache 目前支持五种集群方式：\n\n * RMI\n * JMS\n * JGroup\n * Terracotta\n * Ehcache Server\n\n# RMI\n\n使用组播方式通知所有节点同步数据。\n\n如果网络有问题，或某台服务宕机，则存在数据无法同步的可能，导致数据不一致。\n\n\n\n# JMS\n\nJMS 类似 MQ，所有节点订阅消息，当某节点缓存发生变化，就向 JMS 发消息，其他节点感知变化后，同步数据。\n\n\n\n# Cache Server\n\n\n\n\n# 二、快速入门\n\n\n# 引入 Ehcache\n\n如果你的项目使用 maven 管理，添加以下依赖到你的 pom.xml 中。\n\n<dependency>\n  <groupId>net.sf.ehcache</groupId>\n  <artifactId>ehcache</artifactId>\n  <version>2.10.2</version>\n  <type>pom</type>\n</dependency>\n\n\n如果你的项目不使用 maven 管理，请在 Ehcache 官网下载地址 下载 jar 包。\n\nSpring 提供了对于 Ehcache 接口的封装，可以更简便的使用其功能。接入方式如下：\n\n如果你的项目使用 maven 管理，添加以下依赖到你的pom.xml中。\n\nspring-context-support这个 jar 包中含有 Spring 对于缓存功能的抽象封装接口。\n\n<dependency>\n  <groupId>org.springframework</groupId>\n  <artifactId>spring-context-support</artifactId>\n  <version>4.1.4.RELEASE</version>\n</dependency>\n\n\n\n# 添加配置文件\n\n（1）在 classpath 下添加 ehcache.xml 添加一个名为 helloworld 的缓存。\n\n<?xml version="1.0" encoding="UTF-8"?>\n<ehcache xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n         xsi:noNamespaceSchemaLocation="http://ehcache.org/ehcache.xsd">\n\n  \x3c!-- 磁盘缓存位置 --\x3e\n  <diskStore path="java.io.tmpdir/ehcache"/>\n\n  \x3c!-- 默认缓存 --\x3e\n  <defaultCache\n          maxEntriesLocalHeap="10000"\n          eternal="false"\n          timeToIdleSeconds="120"\n          timeToLiveSeconds="120"\n          maxEntriesLocalDisk="10000000"\n          diskExpiryThreadIntervalSeconds="120"\n          memoryStoreEvictionPolicy="LRU"/>\n\n  \x3c!-- helloworld缓存 --\x3e\n  <cache name="helloworld"\n         maxElementsInMemory="1000"\n         eternal="false"\n         timeToIdleSeconds="5"\n         timeToLiveSeconds="5"\n         overflowToDisk="false"\n         memoryStoreEvictionPolicy="LRU"/>\n</ehcache>\n\n\n\n# Ehcache 工作示例\n\nEhcache 会自动加载 classpath 根目录下名为 ehcache.xml 文件。\n\nEhcacheDemo 的工作步骤如下：\n\n 1. 在 EhcacheDemo 中，我们引用 ehcache.xml 声明的名为 helloworld 的缓存来创建Cache对象；\n 2. 然后我们用一个键值对来实例化Element对象；\n 3. 将Element对象添加到Cache；\n 4. 然后用Cache的 get 方法获取Element对象。\n\npublic class EhcacheDemo {\n    public static void main(String[] args) throws Exception {\n        // Create a cache manager\n        final CacheManager cacheManager = new CacheManager();\n\n        // create the cache called "helloworld"\n        final Cache cache = cacheManager.getCache("helloworld");\n\n        // create a key to map the data to\n        final String key = "greeting";\n\n        // Create a data element\n        final Element putGreeting = new Element(key, "Hello, World!");\n\n        // Put the element into the data store\n        cache.put(putGreeting);\n\n        // Retrieve the data element\n        final Element getGreeting = cache.get(key);\n\n        // Print the value\n        System.out.println(getGreeting.getObjectValue());\n    }\n}\n\n\n输出\n\nHello, World!\n\n\n\n# 三、Ehcache API\n\nElement、Cache、CacheManager是 Ehcache 最重要的 API。\n\n * Element - 缓存的元素，它维护着一个键值对。\n * Cache - 它是 Ehcache 的核心类，它有多个Element，并被CacheManager管理。它实现了对缓存的逻辑行为。\n * CacheManager - Cache的容器对象，并管理着Cache的生命周期。CacheManager 支持两种创建模式：单例（Singleton mode）和实例（InstanceMode）。\n\n\n# 创建 CacheManager\n\n下面的代码列举了创建 CacheManager 的五种方式。\n\n使用静态方法create()会以默认配置来创建单例的CacheManager实例。\n\nnewInstance()方法是一个工厂方法，以默认配置创建一个新的CacheManager实例。\n\n此外，newInstance()还有几个重载函数，分别可以通过传入String、URL、InputStream参数来加载配置文件，然后创建CacheManager实例。\n\n// 使用Ehcache默认配置获取单例的CacheManager实例\nCacheManager.create();\nString[] cacheNames = CacheManager.getInstance().getCacheNames();\n\n// 使用Ehcache默认配置新建一个CacheManager实例\nCacheManager.newInstance();\nString[] cacheNames = manager.getCacheNames();\n\n// 使用不同的配置文件分别创建一个CacheManager实例\nCacheManager manager1 = CacheManager.newInstance("src/config/ehcache1.xml");\nCacheManager manager2 = CacheManager.newInstance("src/config/ehcache2.xml");\nString[] cacheNamesForManager1 = manager1.getCacheNames();\nString[] cacheNamesForManager2 = manager2.getCacheNames();\n\n// 基于classpath下的配置文件创建CacheManager实例\nURL url = getClass().getResource("/anotherconfigurationname.xml");\nCacheManager manager = CacheManager.newInstance(url);\n\n// 基于文件流得到配置文件，并创建CacheManager实例\nInputStream fis = new FileInputStream(new File\n("src/config/ehcache.xml").getAbsolutePath());\ntry {\n CacheManager manager = CacheManager.newInstance(fis);\n} finally {\n fis.close();\n}\n\n\n\n# 添加缓存\n\n需要强调一点，Cache对象在用addCache方法添加到CacheManager之前，是无效的。\n\n使用 CacheManager 的 addCache 方法可以根据缓存名将 ehcache.xml 中声明的 cache 添加到容器中；它也可以直接将 Cache 对象添加到缓存容器中。\n\nCache有多个构造函数，提供了不同方式去加载缓存的配置参数。\n\n有时候，你可能需要使用 API 来动态的添加缓存，下面的例子就提供了这样的范例。\n\n// 除了可以使用xml文件中配置的缓存，你也可以使用API动态增删缓存\n// 添加缓存\nmanager.addCache(cacheName);\n\n// 使用默认配置添加缓存\nCacheManager singletonManager = CacheManager.create();\nsingletonManager.addCache("testCache");\nCache test = singletonManager.getCache("testCache");\n\n// 使用自定义配置添加缓存，注意缓存未添加进CacheManager之前并不可用\nCacheManager singletonManager = CacheManager.create();\nCache memoryOnlyCache = new Cache("testCache", 5000, false, false, 5, 2);\nsingletonManager.addCache(memoryOnlyCache);\nCache test = singletonManager.getCache("testCache");\n\n// 使用特定的配置添加缓存\nCacheManager manager = CacheManager.create();\nCache testCache = new Cache(\n new CacheConfiguration("testCache", maxEntriesLocalHeap)\n .memoryStoreEvictionPolicy(MemoryStoreEvictionPolicy.LFU)\n .eternal(false)\n .timeToLiveSeconds(60)\n .timeToIdleSeconds(30)\n .diskExpiryThreadIntervalSeconds(0)\n .persistence(new PersistenceConfiguration().strategy(Strategy.LOCALTEMPSWAP)));\n manager.addCache(testCache);\n\n\n\n# 删除缓存\n\n删除缓存比较简单，你只需要将指定的缓存名传入removeCache方法即可。\n\nCacheManager singletonManager = CacheManager.create();\nsingletonManager.removeCache("sampleCache1");\n\n\n\n# 基本缓存操作\n\nCache 最重要的两个方法就是 put 和 get，分别用来添加 Element 和获取 Element。\n\nCache 还提供了一系列的 get、set 方法来设置或获取缓存参数，这里不一一列举，更多 API 操作可参考官方 API 开发手册。\n\n/**\n * 测试：使用默认配置或使用指定配置来创建CacheManager\n *\n * @author Zhang Peng\n */\npublic class CacheOperationTest {\n    private final Logger log = LoggerFactory.getLogger(CacheOperationTest.class);\n\n    /**\n     * 使用Ehcache默认配置(classpath下的ehcache.xml)获取单例的CacheManager实例\n     */\n    @Test\n    public void operation() {\n        CacheManager manager = CacheManager.newInstance("src/test/resources/ehcache/ehcache.xml");\n\n        // 获得Cache的引用\n        Cache cache = manager.getCache("userCache");\n\n        // 将一个Element添加到Cache\n        cache.put(new Element("key1", "value1"));\n\n        // 获取Element，Element类支持序列化，所以下面两种方法都可以用\n        Element element1 = cache.get("key1");\n        // 获取非序列化的值\n        log.debug("key:{}, value:{}", element1.getObjectKey(), element1.getObjectValue());\n        // 获取序列化的值\n        log.debug("key:{}, value:{}", element1.getKey(), element1.getValue());\n\n        // 更新Cache中的Element\n        cache.put(new Element("key1", "value2"));\n        Element element2 = cache.get("key1");\n        log.debug("key:{}, value:{}", element2.getObjectKey(), element2.getObjectValue());\n\n        // 获取Cache的元素数\n        log.debug("cache size:{}", cache.getSize());\n\n        // 获取MemoryStore的元素数\n        log.debug("MemoryStoreSize:{}", cache.getMemoryStoreSize());\n\n        // 获取DiskStore的元素数\n        log.debug("DiskStoreSize:{}", cache.getDiskStoreSize());\n\n        // 移除Element\n        cache.remove("key1");\n        log.debug("cache size:{}", cache.getSize());\n\n        // 关闭当前CacheManager对象\n        manager.shutdown();\n\n        // 关闭CacheManager单例实例\n        CacheManager.getInstance().shutdown();\n    }\n}\n\n\n\n# 四、Ehcache 配置\n\n> Ehcache 支持通过 xml 文件和 API 两种方式进行配置。\n> \n> 详情参考：Ehcache 官方 XML 配置手册\n\n\n# xml 配置方式\n\nEhcache 的CacheManager构造函数或工厂方法被调用时，会默认加载 classpath 下名为ehcache.xml的配置文件。如果加载失败，会加载 Ehcache jar 包中的ehcache-failsafe.xml文件，这个文件中含有简单的默认配置。 ehcache.xml 配置参数说明：\n\n * name：缓存名称。\n * maxElementsInMemory：缓存最大个数。\n * eternal：缓存中对象是否为永久的，如果是，超时设置将被忽略，对象从不过期。\n * timeToIdleSeconds：置对象在失效前的允许闲置时间（单位：秒）。仅当 eternal=false 对象不是永久有效时使用，可选属性，默认值是 0，也就是可闲置时间无穷大。\n * timeToLiveSeconds：缓存数据的生存时间（TTL），也就是一个元素从构建到消亡的最大时间间隔值，这只能在元素不是永久驻留时有效，如果该值是 0 就意味着元素可以停顿无穷长的时间。\n * maxEntriesLocalDisk：当内存中对象数量达到 maxElementsInMemory 时，Ehcache 将会对象写到磁盘中。\n * overflowToDisk：内存不足时，是否启用磁盘缓存。\n * diskSpoolBufferSizeMB：这个参数设置 DiskStore（磁盘缓存）的缓存区大小。默认是 30MB。每个 Cache 都应该有自己的一个缓冲区。\n * maxElementsOnDisk：硬盘最大缓存个数。\n * diskPersistent：是否在 VM 重启时存储硬盘的缓存数据。默认值是 false。\n * diskExpiryThreadIntervalSeconds：磁盘失效线程运行时间间隔，默认是 120 秒。\n * memoryStoreEvictionPolicy：当达到 maxElementsInMemory 限制时，Ehcache 将会根据指定的策略去清理内存。默认策略是 LRU（最近最少使用）。你可以设置为 FIFO（先进先出）或是 LFU（较少使用）。\n * clearOnFlush：内存数量最大时是否清除。\n\n\n# API 配置方式\n\nxml 配置的参数也可以直接通过编程方式来动态的进行配置（dynamicConfig 没有设为 false）。\n\nCache cache = manager.getCache("sampleCache");\nCacheConfiguration config = cache.getCacheConfiguration();\nconfig.setTimeToIdleSeconds(60);\nconfig.setTimeToLiveSeconds(120);\nconfig.setmaxEntriesLocalHeap(10000);\nconfig.setmaxEntriesLocalDisk(1000000);\n\n\n也可以通过disableDynamicFeatures()方式关闭动态配置开关。配置以后你将无法再以编程方式配置参数。\n\nCache cache = manager.getCache("sampleCache");\ncache.disableDynamicFeatures();\n\n\n\n# 五、Spring 集成 Ehcache\n\nSpring3.1 开始添加了对缓存的支持。和事务功能的支持方式类似，缓存抽象允许底层使用不同的缓存解决方案来进行整合。\n\nSpring4.1 开始支持 JSR-107 注解。\n\n> 注：我本人使用的 Spring 版本为 4.1.4.RELEASE，目前 Spring 版本仅支持 Ehcache2.5 以上版本，但不支持 Ehcache3。\n\n\n# 绑定 Ehcache\n\norg.springframework.cache.ehcache.EhCacheManagerFactoryBean这个类的作用是加载 Ehcache 配置文件。 org.springframework.cache.ehcache.EhCacheCacheManager这个类的作用是支持 net.sf.ehcache.CacheManager。\n\nspring-ehcache.xml的配置\n\n<?xml version="1.0" encoding="UTF-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n       xmlns:cache="http://www.springframework.org/schema/cache"\n       xsi:schemaLocation="http://www.springframework.org/schema/beans\n        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd\n        http://www.springframework.org/schema/cache\n        http://www.springframework.org/schema/cache/spring-cache-3.2.xsd">\n\n  <description>ehcache缓存配置管理文件</description>\n\n  <bean id="ehcache" class="org.springframework.cache.ehcache.EhCacheManagerFactoryBean">\n    <property name="configLocation" value="classpath:ehcache/ehcache.xml"/>\n  </bean>\n\n  <bean id="cacheManager" class="org.springframework.cache.ehcache.EhCacheCacheManager">\n    <property name="cacheManager" ref="ehcache"/>\n  </bean>\n\n  \x3c!-- 启用缓存注解开关 --\x3e\n  <cache:annotation-driven cache-manager="cacheManager"/>\n</beans>\n\n\n\n# 使用 Spring 的缓存注解\n\n# 开启注解\n\nSpring 为缓存功能提供了注解功能，但是你必须启动注解。 你有两个选择： (1) 在 xml 中声明 像上一节 spring-ehcache.xml 中的做法一样，使用<cache:annotation-driven/>\n\n<cache:annotation-driven cache-manager="cacheManager"/>\n\n\n(2) 使用标记注解 你也可以通过对一个类进行注解修饰的方式在这个类中使用缓存注解。 范例如下：\n\n@Configuration\n@EnableCaching\npublic class AppConfig {\n}\n\n\n\n# 注解基本使用方法\n\nSpring 对缓存的支持类似于对事务的支持。 首先使用注解标记方法，相当于定义了切点，然后使用 Aop 技术在这个方法的调用前、调用后获取方法的入参和返回值，进而实现了缓存的逻辑。 下面三个注解都是方法级别：\n\n# @Cacheable\n\n表明所修饰的方法是可以缓存的：当第一次调用这个方法时，它的结果会被缓存下来，在缓存的有效时间内，以后访问这个方法都直接返回缓存结果，不再执行方法中的代码段。 这个注解可以用condition属性来设置条件，如果不满足条件，就不使用缓存能力，直接执行方法。 可以使用key属性来指定 key 的生成规则。\n\n# @CachePut\n\n与@Cacheable不同，@CachePut不仅会缓存方法的结果，还会执行方法的代码段。 它支持的属性和用法都与@Cacheable一致。\n\n# @CacheEvict\n\n与@Cacheable功能相反，@CacheEvict表明所修饰的方法是用来删除失效或无用的缓存数据。 下面是@Cacheable、@CacheEvict和@CachePut基本使用方法的一个集中展示：\n\n@Service\npublic class UserService {\n    // @Cacheable可以设置多个缓存，形式如：@Cacheable({"books", "isbns"})\n    @Cacheable(value={"users"}, key="#user.id")\n    public User findUser(User user) {\n        return findUserInDB(user.getId());\n    }\n\n    @Cacheable(value = "users", condition = "#user.getId() <= 2")\n    public User findUserInLimit(User user) {\n        return findUserInDB(user.getId());\n    }\n\n    @CachePut(value = "users", key = "#user.getId()")\n    public void updateUser(User user) {\n        updateUserInDB(user);\n    }\n\n    @CacheEvict(value = "users")\n    public void removeUser(User user) {\n        removeUserInDB(user.getId());\n    }\n\n    @CacheEvict(value = "users", allEntries = true)\n    public void clear() {\n        removeAllInDB();\n    }\n}\n\n\n# @Caching\n\n如果需要使用同一个缓存注解（@Cacheable、@CacheEvict或@CachePut）多次修饰一个方法，就需要用到@Caching。\n\n@Caching(evict = { @CacheEvict("primary"), @CacheEvict(cacheNames="secondary", key="#p0") })\npublic Book importBooks(String deposit, Date date)\n\n\n# @CacheConfig\n\n与前面的缓存注解不同，这是一个类级别的注解。 如果类的所有操作都是缓存操作，你可以使用@CacheConfig来指定类，省去一些配置。\n\n@CacheConfig("books")\npublic class BookRepositoryImpl implements BookRepository {\n @Cacheable\n public Book findBook(ISBN isbn) {...}\n}\n\n\n\n# 参考资料\n\n * 官方\n   * Ehcache 官网\n   * Ehcache Github\n * 文章\n   * Ehcache 优缺点以及分布式详解\n   * Ehcache 详细解读\n   * 注释驱动的 Spring cache 缓存介绍\n   * Spring 官方文档第 36 章缓存抽象',normalizedContent:'# ehcache 快速入门\n\n> ehcache 是一个纯 java 的进程内缓存框架，具有快速、精干等特点，是 hibernate 中默认的 cacheprovider。\n\n\n\n\n# 一、简介\n\n> ehcache 虽然也支持分布式模式，但是分布式方案不是很好好，建议只将其作为单机的进程内缓存使用。\n\n\n# ehcache 特性\n\n优点\n\n * 快速、简单\n * 支持多种缓存策略：lru、lfu、fifo 淘汰算法\n * 缓存数据有两级：内存和磁盘，因此无需担心容量问题\n * 缓存数据会在虚拟机重启的过程中写入磁盘\n * 可以通过 rmi、可插入 api 等方式进行分布式缓存\n * 具有缓存和缓存管理器的侦听接口\n * 支持多缓存管理器实例，以及一个实例的多个缓存区域\n * 提供 hibernate 的缓存实现\n\n缺点\n\n * 使用磁盘 cache 的时候非常占用磁盘空间\n * 不保证数据的安全\n * 虽然支持分布式缓存，但效率不高（通过组播方式，在不同节点之间同步数据）。\n\n\n# ehcache 集群\n\nehcache 目前支持五种集群方式：\n\n * rmi\n * jms\n * jgroup\n * terracotta\n * ehcache server\n\n# rmi\n\n使用组播方式通知所有节点同步数据。\n\n如果网络有问题，或某台服务宕机，则存在数据无法同步的可能，导致数据不一致。\n\n\n\n# jms\n\njms 类似 mq，所有节点订阅消息，当某节点缓存发生变化，就向 jms 发消息，其他节点感知变化后，同步数据。\n\n\n\n# cache server\n\n\n\n\n# 二、快速入门\n\n\n# 引入 ehcache\n\n如果你的项目使用 maven 管理，添加以下依赖到你的 pom.xml 中。\n\n<dependency>\n  <groupid>net.sf.ehcache</groupid>\n  <artifactid>ehcache</artifactid>\n  <version>2.10.2</version>\n  <type>pom</type>\n</dependency>\n\n\n如果你的项目不使用 maven 管理，请在 ehcache 官网下载地址 下载 jar 包。\n\nspring 提供了对于 ehcache 接口的封装，可以更简便的使用其功能。接入方式如下：\n\n如果你的项目使用 maven 管理，添加以下依赖到你的pom.xml中。\n\nspring-context-support这个 jar 包中含有 spring 对于缓存功能的抽象封装接口。\n\n<dependency>\n  <groupid>org.springframework</groupid>\n  <artifactid>spring-context-support</artifactid>\n  <version>4.1.4.release</version>\n</dependency>\n\n\n\n# 添加配置文件\n\n（1）在 classpath 下添加 ehcache.xml 添加一个名为 helloworld 的缓存。\n\n<?xml version="1.0" encoding="utf-8"?>\n<ehcache xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n         xsi:nonamespaceschemalocation="http://ehcache.org/ehcache.xsd">\n\n  \x3c!-- 磁盘缓存位置 --\x3e\n  <diskstore path="java.io.tmpdir/ehcache"/>\n\n  \x3c!-- 默认缓存 --\x3e\n  <defaultcache\n          maxentrieslocalheap="10000"\n          eternal="false"\n          timetoidleseconds="120"\n          timetoliveseconds="120"\n          maxentrieslocaldisk="10000000"\n          diskexpirythreadintervalseconds="120"\n          memorystoreevictionpolicy="lru"/>\n\n  \x3c!-- helloworld缓存 --\x3e\n  <cache name="helloworld"\n         maxelementsinmemory="1000"\n         eternal="false"\n         timetoidleseconds="5"\n         timetoliveseconds="5"\n         overflowtodisk="false"\n         memorystoreevictionpolicy="lru"/>\n</ehcache>\n\n\n\n# ehcache 工作示例\n\nehcache 会自动加载 classpath 根目录下名为 ehcache.xml 文件。\n\nehcachedemo 的工作步骤如下：\n\n 1. 在 ehcachedemo 中，我们引用 ehcache.xml 声明的名为 helloworld 的缓存来创建cache对象；\n 2. 然后我们用一个键值对来实例化element对象；\n 3. 将element对象添加到cache；\n 4. 然后用cache的 get 方法获取element对象。\n\npublic class ehcachedemo {\n    public static void main(string[] args) throws exception {\n        // create a cache manager\n        final cachemanager cachemanager = new cachemanager();\n\n        // create the cache called "helloworld"\n        final cache cache = cachemanager.getcache("helloworld");\n\n        // create a key to map the data to\n        final string key = "greeting";\n\n        // create a data element\n        final element putgreeting = new element(key, "hello, world!");\n\n        // put the element into the data store\n        cache.put(putgreeting);\n\n        // retrieve the data element\n        final element getgreeting = cache.get(key);\n\n        // print the value\n        system.out.println(getgreeting.getobjectvalue());\n    }\n}\n\n\n输出\n\nhello, world!\n\n\n\n# 三、ehcache api\n\nelement、cache、cachemanager是 ehcache 最重要的 api。\n\n * element - 缓存的元素，它维护着一个键值对。\n * cache - 它是 ehcache 的核心类，它有多个element，并被cachemanager管理。它实现了对缓存的逻辑行为。\n * cachemanager - cache的容器对象，并管理着cache的生命周期。cachemanager 支持两种创建模式：单例（singleton mode）和实例（instancemode）。\n\n\n# 创建 cachemanager\n\n下面的代码列举了创建 cachemanager 的五种方式。\n\n使用静态方法create()会以默认配置来创建单例的cachemanager实例。\n\nnewinstance()方法是一个工厂方法，以默认配置创建一个新的cachemanager实例。\n\n此外，newinstance()还有几个重载函数，分别可以通过传入string、url、inputstream参数来加载配置文件，然后创建cachemanager实例。\n\n// 使用ehcache默认配置获取单例的cachemanager实例\ncachemanager.create();\nstring[] cachenames = cachemanager.getinstance().getcachenames();\n\n// 使用ehcache默认配置新建一个cachemanager实例\ncachemanager.newinstance();\nstring[] cachenames = manager.getcachenames();\n\n// 使用不同的配置文件分别创建一个cachemanager实例\ncachemanager manager1 = cachemanager.newinstance("src/config/ehcache1.xml");\ncachemanager manager2 = cachemanager.newinstance("src/config/ehcache2.xml");\nstring[] cachenamesformanager1 = manager1.getcachenames();\nstring[] cachenamesformanager2 = manager2.getcachenames();\n\n// 基于classpath下的配置文件创建cachemanager实例\nurl url = getclass().getresource("/anotherconfigurationname.xml");\ncachemanager manager = cachemanager.newinstance(url);\n\n// 基于文件流得到配置文件，并创建cachemanager实例\ninputstream fis = new fileinputstream(new file\n("src/config/ehcache.xml").getabsolutepath());\ntry {\n cachemanager manager = cachemanager.newinstance(fis);\n} finally {\n fis.close();\n}\n\n\n\n# 添加缓存\n\n需要强调一点，cache对象在用addcache方法添加到cachemanager之前，是无效的。\n\n使用 cachemanager 的 addcache 方法可以根据缓存名将 ehcache.xml 中声明的 cache 添加到容器中；它也可以直接将 cache 对象添加到缓存容器中。\n\ncache有多个构造函数，提供了不同方式去加载缓存的配置参数。\n\n有时候，你可能需要使用 api 来动态的添加缓存，下面的例子就提供了这样的范例。\n\n// 除了可以使用xml文件中配置的缓存，你也可以使用api动态增删缓存\n// 添加缓存\nmanager.addcache(cachename);\n\n// 使用默认配置添加缓存\ncachemanager singletonmanager = cachemanager.create();\nsingletonmanager.addcache("testcache");\ncache test = singletonmanager.getcache("testcache");\n\n// 使用自定义配置添加缓存，注意缓存未添加进cachemanager之前并不可用\ncachemanager singletonmanager = cachemanager.create();\ncache memoryonlycache = new cache("testcache", 5000, false, false, 5, 2);\nsingletonmanager.addcache(memoryonlycache);\ncache test = singletonmanager.getcache("testcache");\n\n// 使用特定的配置添加缓存\ncachemanager manager = cachemanager.create();\ncache testcache = new cache(\n new cacheconfiguration("testcache", maxentrieslocalheap)\n .memorystoreevictionpolicy(memorystoreevictionpolicy.lfu)\n .eternal(false)\n .timetoliveseconds(60)\n .timetoidleseconds(30)\n .diskexpirythreadintervalseconds(0)\n .persistence(new persistenceconfiguration().strategy(strategy.localtempswap)));\n manager.addcache(testcache);\n\n\n\n# 删除缓存\n\n删除缓存比较简单，你只需要将指定的缓存名传入removecache方法即可。\n\ncachemanager singletonmanager = cachemanager.create();\nsingletonmanager.removecache("samplecache1");\n\n\n\n# 基本缓存操作\n\ncache 最重要的两个方法就是 put 和 get，分别用来添加 element 和获取 element。\n\ncache 还提供了一系列的 get、set 方法来设置或获取缓存参数，这里不一一列举，更多 api 操作可参考官方 api 开发手册。\n\n/**\n * 测试：使用默认配置或使用指定配置来创建cachemanager\n *\n * @author zhang peng\n */\npublic class cacheoperationtest {\n    private final logger log = loggerfactory.getlogger(cacheoperationtest.class);\n\n    /**\n     * 使用ehcache默认配置(classpath下的ehcache.xml)获取单例的cachemanager实例\n     */\n    @test\n    public void operation() {\n        cachemanager manager = cachemanager.newinstance("src/test/resources/ehcache/ehcache.xml");\n\n        // 获得cache的引用\n        cache cache = manager.getcache("usercache");\n\n        // 将一个element添加到cache\n        cache.put(new element("key1", "value1"));\n\n        // 获取element，element类支持序列化，所以下面两种方法都可以用\n        element element1 = cache.get("key1");\n        // 获取非序列化的值\n        log.debug("key:{}, value:{}", element1.getobjectkey(), element1.getobjectvalue());\n        // 获取序列化的值\n        log.debug("key:{}, value:{}", element1.getkey(), element1.getvalue());\n\n        // 更新cache中的element\n        cache.put(new element("key1", "value2"));\n        element element2 = cache.get("key1");\n        log.debug("key:{}, value:{}", element2.getobjectkey(), element2.getobjectvalue());\n\n        // 获取cache的元素数\n        log.debug("cache size:{}", cache.getsize());\n\n        // 获取memorystore的元素数\n        log.debug("memorystoresize:{}", cache.getmemorystoresize());\n\n        // 获取diskstore的元素数\n        log.debug("diskstoresize:{}", cache.getdiskstoresize());\n\n        // 移除element\n        cache.remove("key1");\n        log.debug("cache size:{}", cache.getsize());\n\n        // 关闭当前cachemanager对象\n        manager.shutdown();\n\n        // 关闭cachemanager单例实例\n        cachemanager.getinstance().shutdown();\n    }\n}\n\n\n\n# 四、ehcache 配置\n\n> ehcache 支持通过 xml 文件和 api 两种方式进行配置。\n> \n> 详情参考：ehcache 官方 xml 配置手册\n\n\n# xml 配置方式\n\nehcache 的cachemanager构造函数或工厂方法被调用时，会默认加载 classpath 下名为ehcache.xml的配置文件。如果加载失败，会加载 ehcache jar 包中的ehcache-failsafe.xml文件，这个文件中含有简单的默认配置。 ehcache.xml 配置参数说明：\n\n * name：缓存名称。\n * maxelementsinmemory：缓存最大个数。\n * eternal：缓存中对象是否为永久的，如果是，超时设置将被忽略，对象从不过期。\n * timetoidleseconds：置对象在失效前的允许闲置时间（单位：秒）。仅当 eternal=false 对象不是永久有效时使用，可选属性，默认值是 0，也就是可闲置时间无穷大。\n * timetoliveseconds：缓存数据的生存时间（ttl），也就是一个元素从构建到消亡的最大时间间隔值，这只能在元素不是永久驻留时有效，如果该值是 0 就意味着元素可以停顿无穷长的时间。\n * maxentrieslocaldisk：当内存中对象数量达到 maxelementsinmemory 时，ehcache 将会对象写到磁盘中。\n * overflowtodisk：内存不足时，是否启用磁盘缓存。\n * diskspoolbuffersizemb：这个参数设置 diskstore（磁盘缓存）的缓存区大小。默认是 30mb。每个 cache 都应该有自己的一个缓冲区。\n * maxelementsondisk：硬盘最大缓存个数。\n * diskpersistent：是否在 vm 重启时存储硬盘的缓存数据。默认值是 false。\n * diskexpirythreadintervalseconds：磁盘失效线程运行时间间隔，默认是 120 秒。\n * memorystoreevictionpolicy：当达到 maxelementsinmemory 限制时，ehcache 将会根据指定的策略去清理内存。默认策略是 lru（最近最少使用）。你可以设置为 fifo（先进先出）或是 lfu（较少使用）。\n * clearonflush：内存数量最大时是否清除。\n\n\n# api 配置方式\n\nxml 配置的参数也可以直接通过编程方式来动态的进行配置（dynamicconfig 没有设为 false）。\n\ncache cache = manager.getcache("samplecache");\ncacheconfiguration config = cache.getcacheconfiguration();\nconfig.settimetoidleseconds(60);\nconfig.settimetoliveseconds(120);\nconfig.setmaxentrieslocalheap(10000);\nconfig.setmaxentrieslocaldisk(1000000);\n\n\n也可以通过disabledynamicfeatures()方式关闭动态配置开关。配置以后你将无法再以编程方式配置参数。\n\ncache cache = manager.getcache("samplecache");\ncache.disabledynamicfeatures();\n\n\n\n# 五、spring 集成 ehcache\n\nspring3.1 开始添加了对缓存的支持。和事务功能的支持方式类似，缓存抽象允许底层使用不同的缓存解决方案来进行整合。\n\nspring4.1 开始支持 jsr-107 注解。\n\n> 注：我本人使用的 spring 版本为 4.1.4.release，目前 spring 版本仅支持 ehcache2.5 以上版本，但不支持 ehcache3。\n\n\n# 绑定 ehcache\n\norg.springframework.cache.ehcache.ehcachemanagerfactorybean这个类的作用是加载 ehcache 配置文件。 org.springframework.cache.ehcache.ehcachecachemanager这个类的作用是支持 net.sf.ehcache.cachemanager。\n\nspring-ehcache.xml的配置\n\n<?xml version="1.0" encoding="utf-8"?>\n<beans xmlns="http://www.springframework.org/schema/beans"\n       xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n       xmlns:cache="http://www.springframework.org/schema/cache"\n       xsi:schemalocation="http://www.springframework.org/schema/beans\n        http://www.springframework.org/schema/beans/spring-beans-3.0.xsd\n        http://www.springframework.org/schema/cache\n        http://www.springframework.org/schema/cache/spring-cache-3.2.xsd">\n\n  <description>ehcache缓存配置管理文件</description>\n\n  <bean id="ehcache" class="org.springframework.cache.ehcache.ehcachemanagerfactorybean">\n    <property name="configlocation" value="classpath:ehcache/ehcache.xml"/>\n  </bean>\n\n  <bean id="cachemanager" class="org.springframework.cache.ehcache.ehcachecachemanager">\n    <property name="cachemanager" ref="ehcache"/>\n  </bean>\n\n  \x3c!-- 启用缓存注解开关 --\x3e\n  <cache:annotation-driven cache-manager="cachemanager"/>\n</beans>\n\n\n\n# 使用 spring 的缓存注解\n\n# 开启注解\n\nspring 为缓存功能提供了注解功能，但是你必须启动注解。 你有两个选择： (1) 在 xml 中声明 像上一节 spring-ehcache.xml 中的做法一样，使用<cache:annotation-driven/>\n\n<cache:annotation-driven cache-manager="cachemanager"/>\n\n\n(2) 使用标记注解 你也可以通过对一个类进行注解修饰的方式在这个类中使用缓存注解。 范例如下：\n\n@configuration\n@enablecaching\npublic class appconfig {\n}\n\n\n\n# 注解基本使用方法\n\nspring 对缓存的支持类似于对事务的支持。 首先使用注解标记方法，相当于定义了切点，然后使用 aop 技术在这个方法的调用前、调用后获取方法的入参和返回值，进而实现了缓存的逻辑。 下面三个注解都是方法级别：\n\n# @cacheable\n\n表明所修饰的方法是可以缓存的：当第一次调用这个方法时，它的结果会被缓存下来，在缓存的有效时间内，以后访问这个方法都直接返回缓存结果，不再执行方法中的代码段。 这个注解可以用condition属性来设置条件，如果不满足条件，就不使用缓存能力，直接执行方法。 可以使用key属性来指定 key 的生成规则。\n\n# @cacheput\n\n与@cacheable不同，@cacheput不仅会缓存方法的结果，还会执行方法的代码段。 它支持的属性和用法都与@cacheable一致。\n\n# @cacheevict\n\n与@cacheable功能相反，@cacheevict表明所修饰的方法是用来删除失效或无用的缓存数据。 下面是@cacheable、@cacheevict和@cacheput基本使用方法的一个集中展示：\n\n@service\npublic class userservice {\n    // @cacheable可以设置多个缓存，形式如：@cacheable({"books", "isbns"})\n    @cacheable(value={"users"}, key="#user.id")\n    public user finduser(user user) {\n        return finduserindb(user.getid());\n    }\n\n    @cacheable(value = "users", condition = "#user.getid() <= 2")\n    public user finduserinlimit(user user) {\n        return finduserindb(user.getid());\n    }\n\n    @cacheput(value = "users", key = "#user.getid()")\n    public void updateuser(user user) {\n        updateuserindb(user);\n    }\n\n    @cacheevict(value = "users")\n    public void removeuser(user user) {\n        removeuserindb(user.getid());\n    }\n\n    @cacheevict(value = "users", allentries = true)\n    public void clear() {\n        removeallindb();\n    }\n}\n\n\n# @caching\n\n如果需要使用同一个缓存注解（@cacheable、@cacheevict或@cacheput）多次修饰一个方法，就需要用到@caching。\n\n@caching(evict = { @cacheevict("primary"), @cacheevict(cachenames="secondary", key="#p0") })\npublic book importbooks(string deposit, date date)\n\n\n# @cacheconfig\n\n与前面的缓存注解不同，这是一个类级别的注解。 如果类的所有操作都是缓存操作，你可以使用@cacheconfig来指定类，省去一些配置。\n\n@cacheconfig("books")\npublic class bookrepositoryimpl implements bookrepository {\n @cacheable\n public book findbook(isbn isbn) {...}\n}\n\n\n\n# 参考资料\n\n * 官方\n   * ehcache 官网\n   * ehcache github\n * 文章\n   * ehcache 优缺点以及分布式详解\n   * ehcache 详细解读\n   * 注释驱动的 spring cache 缓存介绍\n   * spring 官方文档第 36 章缓存抽象',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 进程内缓存",frontmatter:{title:"Java 进程内缓存",categories:["编程","Java","中间件","缓存"],tags:["Java","中间件","缓存"],abbrlink:"bd2603d3",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/9632fd/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/02.%E7%BC%93%E5%AD%98/05.Java%E8%BF%9B%E7%A8%8B%E5%86%85%E7%BC%93%E5%AD%98.html",relativePath:"14.中间件/02.缓存/05.Java进程内缓存.md",key:"v-1f77f9ec",path:"/pages/9632fd/",headers:[{level:2,title:"一、ConcurrentHashMap",slug:"一、concurrenthashmap",normalizedTitle:"一、concurrenthashmap",charIndex:82},{level:2,title:"二、LRUHashMap",slug:"二、lruhashmap",normalizedTitle:"二、lruhashmap",charIndex:203},{level:2,title:"三、Guava Cache",slug:"三、guava-cache",normalizedTitle:"三、guava cache",charIndex:1310},{level:3,title:"Guava Cache 缓存回收",slug:"guava-cache-缓存回收",normalizedTitle:"guava cache 缓存回收",charIndex:1735},{level:3,title:"基于容量回收",slug:"基于容量回收",normalizedTitle:"基于容量回收",charIndex:1785},{level:3,title:"基于定时回收",slug:"基于定时回收",normalizedTitle:"基于定时回收",charIndex:1836},{level:3,title:"基于引用回收",slug:"基于引用回收",normalizedTitle:"基于引用回收",charIndex:1415},{level:3,title:"Guava Cache 核心 API",slug:"guava-cache-核心-api",normalizedTitle:"guava cache 核心 api",charIndex:2274},{level:4,title:"CacheBuilder",slug:"cachebuilder",normalizedTitle:"cachebuilder",charIndex:1455},{level:4,title:"LocalManualCache",slug:"localmanualcache",normalizedTitle:"localmanualcache",charIndex:2475},{level:4,title:"LocalLoadingCache",slug:"localloadingcache",normalizedTitle:"localloadingcache",charIndex:2581},{level:4,title:"LocalCache",slug:"localcache",normalizedTitle:"localcache",charIndex:1497},{level:2,title:"四、Caffeine",slug:"四、caffeine",normalizedTitle:"四、caffeine",charIndex:2876},{level:2,title:"五、Ehcache",slug:"五、ehcache",normalizedTitle:"五、ehcache",charIndex:3030},{level:2,title:"六、进程内缓存对比",slug:"六、进程内缓存对比",normalizedTitle:"六、进程内缓存对比",charIndex:3058},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:4513}],headersStr:"一、ConcurrentHashMap 二、LRUHashMap 三、Guava Cache Guava Cache 缓存回收 基于容量回收 基于定时回收 基于引用回收 Guava Cache 核心 API CacheBuilder LocalManualCache LocalLoadingCache LocalCache 四、Caffeine 五、Ehcache 六、进程内缓存对比 参考资料",content:"# Java 进程内缓存\n\n> 关键词：ConcurrentHashMap、LRUHashMap、Guava Cache、Caffeine、Ehcache\n\n\n# 一、ConcurrentHashMap\n\n最简单的进程内缓存可以通过 JDK 自带的 HashMap 或 ConcurrentHashMap 实现。\n\n适用场景：不需要淘汰的缓存数据。\n\n缺点：无法进行缓存淘汰，内存会无限制的增长。\n\n\n# 二、LRUHashMap\n\n可以通过继承 LinkedHashMap 来实现一个简单的 LRUHashMap，即可完成一个简单的 **LRU （最近最少使用）**算法。\n\n缺点：\n\n * 锁竞争严重，性能比较低。\n * 不支持过期时间\n * 不支持自动刷新\n\n【示例】LRUHashMap 的简单实现\n\nclass LRUCache extends LinkedHashMap {\n\n    private final int max;\n    private Object lock;\n\n    public LRUCache(int max) {\n        //无需扩容\n        super((int) (max * 1.4f), 0.75f, true);\n        this.max = max;\n        this.lock = new Object();\n    }\n\n    /**\n     * 重写LinkedHashMap的removeEldestEntry方法即可 在Put的时候判断，如果为true，就会删除最老的\n     *\n     * @param eldest\n     * @return\n     */\n    @Override\n    protected boolean removeEldestEntry(Map.Entry eldest) {\n        return size() > max;\n    }\n\n    public Object getValue(Object key) {\n        synchronized (lock) {\n            return get(key);\n        }\n    }\n\n    public void putValue(Object key, Object value) {\n        synchronized (lock) {\n            put(key, value);\n        }\n    }\n\n    public boolean removeValue(Object key) {\n        synchronized (lock) {\n            return remove(key) != null;\n        }\n    }\n\n    public boolean removeAll() {\n        clear();\n        return true;\n    }\n\n}\n\n\n\n# 三、Guava Cache\n\nGuava Cache 解决了 LRUHashMap 中的几个缺点。\n\nGuava Cache 提供了基于容量，时间和引用的缓存回收方式。基于容量的方式内部实现采用 LRU 算法，基于引用回收很好的利用了 Java 虚拟机的垃圾回收机制。\n\n其中的缓存构造器 CacheBuilder 采用构建者模式提供了设置好各种参数的缓存对象。缓存核心类 LocalCache 里面的内部类 Segment 与 jdk1.7 及以前的 ConcurrentHashMap 非常相似，分段加锁，减少锁竞争，并且都继承于 ReetrantLock，还有六个队列，以实现丰富的本地缓存方案。Guava Cache 对于过期的 Entry 并没有马上过期(也就是并没有后台线程一直在扫)，而是通过进行读写操作的时候进行过期处理，这样做的好处是避免后台线程扫描的时候进行全局加锁。\n\n直接通过查询，判断其是否满足刷新条件，进行刷新。\n\n\n# Guava Cache 缓存回收\n\nGuava Cache 提供了三种基本的缓存回收方式。\n\n\n# 基于容量回收\n\nmaximumSize(long)：当缓存中的元素数量超过指定值时触发回收。\n\n\n# 基于定时回收\n\n * expireAfterAccess(long, TimeUnit)：缓存项在给定时间内没有被读/写访问，则回收。请注意这种缓存的回收顺序和基于大小回收一样。\n * expireAfterWrite(long, TimeUnit)：缓存项在给定时间内没有被写访问（创建或覆盖），则回收。如果认为缓存数据总是在固定时候后变得陈旧不可用，这种回收方式是可取的。\n\n如下文所讨论，定时回收周期性地在写操作中执行，偶尔在读操作中执行。\n\n\n# 基于引用回收\n\n * CacheBuilder.weakKeys()：使用弱引用存储键。当键没有其它（强或软）引用时，缓存项可以被垃圾回收。\n * CacheBuilder.weakValues()：使用弱引用存储值。当值没有其它（强或软）引用时，缓存项可以被垃圾回收。\n * CacheBuilder.softValues()：使用软引用存储值。软引用只有在响应内存需要时，才按照全局最近最少使用的顺序回收。\n\n\n# Guava Cache 核心 API\n\n# CacheBuilder\n\n缓存构建器。构建缓存的入口，指定缓存配置参数并初始化本地缓存。 主要采用 builder 的模式，CacheBuilder 的每一个方法都返回这个 CacheBuilder 知道 build 方法的调用。 注意 build 方法有重载，带有参数的为构建一个具有数据加载功能的缓存，不带参数的构建一个没有数据加载功能的缓存。\n\n# LocalManualCache\n\n作为 LocalCache 的一个内部类，在构造方法里面会把 LocalCache 类型的变量传入，并且调用方法时都直接或者间接调用 LocalCache 里面的方法。\n\n# LocalLoadingCache\n\n可以看到该类继承了 LocalManualCache 并实现接口 LoadingCache。 覆盖了 get，getUnchecked 等方法。\n\n# LocalCache\n\nGuava Cache 中的核心类，重点了解。\n\nLocalCache 的数据结构与 ConcurrentHashMap 很相似，都由多个 segment 组成，且各 segment 相对独立，互不影响，所以能支持并行操作。每个 segment 由一个 table 和若干队列组成。缓存数据存储在 table 中，其类型为 AtomicReferenceArray。\n\n\n# 四、Caffeine\n\n> caffeine 是一个使用 JDK8 改进 Guava 缓存的高性能缓存库。\n\nCaffeine 实现了 W-TinyLFU(LFU + LRU 算法的变种)，其命中率和读写吞吐量大大优于 Guava Cache。\n\n其实现原理较复杂，可以参考你应该知道的缓存进化史。\n\n\n# 五、Ehcache\n\n> 参考：Ehcache\n\n\n# 六、进程内缓存对比\n\n常用进程内缓存技术对比：\n\n比较项      CONCURRENTHASHMAP   LRUMAP                EHCACHE                 GUAVA CACHE             CAFFEINE\n读写性能     很好，分段锁              一般，全局加锁               好                       好，需要做淘汰操作               很好\n淘汰算法     无                   LRU，一般                支持多种淘汰算法,LRU,LFU,FIFO   LRU，一般                  W-TinyLFU, 很好\n功能丰富程度   功能比较简单              功能比较单一                功能很丰富                   功能很丰富，支持刷新和虚引用等         功能和 Guava Cache 类似\n工具大小     jdk 自带类，很小          基于 LinkedHashMap，较小   很大，最新版本 1.4MB           是 Guava 工具类中的一个小部分，较小   一般，最新版本 644KB\n是否持久化    否                   否                     是                       否                       否\n是否支持集群   否                   否                     是                       否                       否\n\n * ConcurrentHashMap - 比较适合缓存比较固定不变的元素，且缓存的数量较小的。虽然从上面表格中比起来有点逊色，但是其由于是 JDK 自带的类，在各种框架中依然有大量的使用，比如我们可以用来缓存我们反射的 Method，Field 等等；也可以缓存一些链接，防止其重复建立。在 Caffeine 中也是使用的 ConcurrentHashMap 来存储元素。\n * LRUMap - 如果不想引入第三方包，又想使用淘汰算法淘汰数据，可以使用这个。\n * Ehcache - 由于其 jar 包很大，较重量级。对于需要持久化和集群的一些功能的，可以选择 Ehcache。需要注意的是，虽然 Ehcache 也支持分布式缓存，但是由于其节点间通信方式为 rmi，表现不如 Redis，所以一般不建议用它来作为分布式缓存。\n * Guava Cache - Guava 这个 jar 包在很多 Java 应用程序中都有大量的引入，所以很多时候其实是直接用就好了，并且其本身是轻量级的而且功能较为丰富，在不了解 Caffeine 的情况下可以选择 Guava Cache。\n * Caffeine - 其在命中率，读写性能上都比 Guava Cache 好很多，并且其 API 和 Guava cache 基本一致，甚至会多一点。在真实环境中使用 Caffeine，取得过不错的效果。\n\n总结一下：如果不需要淘汰算法则选择 ConcurrentHashMap，如果需要淘汰算法和一些丰富的 API，推荐选择 Caffeine。\n\n\n# 参考资料\n\n * caffeine github\n * 深入解密来自未来的缓存-Caffeine\n * Caffeine 缓存\n * Google Guava 官方教程（中文版）\n * Google Guava Cache 全解析\n * 注释驱动的 Spring cache 缓存介绍",normalizedContent:"# java 进程内缓存\n\n> 关键词：concurrenthashmap、lruhashmap、guava cache、caffeine、ehcache\n\n\n# 一、concurrenthashmap\n\n最简单的进程内缓存可以通过 jdk 自带的 hashmap 或 concurrenthashmap 实现。\n\n适用场景：不需要淘汰的缓存数据。\n\n缺点：无法进行缓存淘汰，内存会无限制的增长。\n\n\n# 二、lruhashmap\n\n可以通过继承 linkedhashmap 来实现一个简单的 lruhashmap，即可完成一个简单的 **lru （最近最少使用）**算法。\n\n缺点：\n\n * 锁竞争严重，性能比较低。\n * 不支持过期时间\n * 不支持自动刷新\n\n【示例】lruhashmap 的简单实现\n\nclass lrucache extends linkedhashmap {\n\n    private final int max;\n    private object lock;\n\n    public lrucache(int max) {\n        //无需扩容\n        super((int) (max * 1.4f), 0.75f, true);\n        this.max = max;\n        this.lock = new object();\n    }\n\n    /**\n     * 重写linkedhashmap的removeeldestentry方法即可 在put的时候判断，如果为true，就会删除最老的\n     *\n     * @param eldest\n     * @return\n     */\n    @override\n    protected boolean removeeldestentry(map.entry eldest) {\n        return size() > max;\n    }\n\n    public object getvalue(object key) {\n        synchronized (lock) {\n            return get(key);\n        }\n    }\n\n    public void putvalue(object key, object value) {\n        synchronized (lock) {\n            put(key, value);\n        }\n    }\n\n    public boolean removevalue(object key) {\n        synchronized (lock) {\n            return remove(key) != null;\n        }\n    }\n\n    public boolean removeall() {\n        clear();\n        return true;\n    }\n\n}\n\n\n\n# 三、guava cache\n\nguava cache 解决了 lruhashmap 中的几个缺点。\n\nguava cache 提供了基于容量，时间和引用的缓存回收方式。基于容量的方式内部实现采用 lru 算法，基于引用回收很好的利用了 java 虚拟机的垃圾回收机制。\n\n其中的缓存构造器 cachebuilder 采用构建者模式提供了设置好各种参数的缓存对象。缓存核心类 localcache 里面的内部类 segment 与 jdk1.7 及以前的 concurrenthashmap 非常相似，分段加锁，减少锁竞争，并且都继承于 reetrantlock，还有六个队列，以实现丰富的本地缓存方案。guava cache 对于过期的 entry 并没有马上过期(也就是并没有后台线程一直在扫)，而是通过进行读写操作的时候进行过期处理，这样做的好处是避免后台线程扫描的时候进行全局加锁。\n\n直接通过查询，判断其是否满足刷新条件，进行刷新。\n\n\n# guava cache 缓存回收\n\nguava cache 提供了三种基本的缓存回收方式。\n\n\n# 基于容量回收\n\nmaximumsize(long)：当缓存中的元素数量超过指定值时触发回收。\n\n\n# 基于定时回收\n\n * expireafteraccess(long, timeunit)：缓存项在给定时间内没有被读/写访问，则回收。请注意这种缓存的回收顺序和基于大小回收一样。\n * expireafterwrite(long, timeunit)：缓存项在给定时间内没有被写访问（创建或覆盖），则回收。如果认为缓存数据总是在固定时候后变得陈旧不可用，这种回收方式是可取的。\n\n如下文所讨论，定时回收周期性地在写操作中执行，偶尔在读操作中执行。\n\n\n# 基于引用回收\n\n * cachebuilder.weakkeys()：使用弱引用存储键。当键没有其它（强或软）引用时，缓存项可以被垃圾回收。\n * cachebuilder.weakvalues()：使用弱引用存储值。当值没有其它（强或软）引用时，缓存项可以被垃圾回收。\n * cachebuilder.softvalues()：使用软引用存储值。软引用只有在响应内存需要时，才按照全局最近最少使用的顺序回收。\n\n\n# guava cache 核心 api\n\n# cachebuilder\n\n缓存构建器。构建缓存的入口，指定缓存配置参数并初始化本地缓存。 主要采用 builder 的模式，cachebuilder 的每一个方法都返回这个 cachebuilder 知道 build 方法的调用。 注意 build 方法有重载，带有参数的为构建一个具有数据加载功能的缓存，不带参数的构建一个没有数据加载功能的缓存。\n\n# localmanualcache\n\n作为 localcache 的一个内部类，在构造方法里面会把 localcache 类型的变量传入，并且调用方法时都直接或者间接调用 localcache 里面的方法。\n\n# localloadingcache\n\n可以看到该类继承了 localmanualcache 并实现接口 loadingcache。 覆盖了 get，getunchecked 等方法。\n\n# localcache\n\nguava cache 中的核心类，重点了解。\n\nlocalcache 的数据结构与 concurrenthashmap 很相似，都由多个 segment 组成，且各 segment 相对独立，互不影响，所以能支持并行操作。每个 segment 由一个 table 和若干队列组成。缓存数据存储在 table 中，其类型为 atomicreferencearray。\n\n\n# 四、caffeine\n\n> caffeine 是一个使用 jdk8 改进 guava 缓存的高性能缓存库。\n\ncaffeine 实现了 w-tinylfu(lfu + lru 算法的变种)，其命中率和读写吞吐量大大优于 guava cache。\n\n其实现原理较复杂，可以参考你应该知道的缓存进化史。\n\n\n# 五、ehcache\n\n> 参考：ehcache\n\n\n# 六、进程内缓存对比\n\n常用进程内缓存技术对比：\n\n比较项      concurrenthashmap   lrumap                ehcache                 guava cache             caffeine\n读写性能     很好，分段锁              一般，全局加锁               好                       好，需要做淘汰操作               很好\n淘汰算法     无                   lru，一般                支持多种淘汰算法,lru,lfu,fifo   lru，一般                  w-tinylfu, 很好\n功能丰富程度   功能比较简单              功能比较单一                功能很丰富                   功能很丰富，支持刷新和虚引用等         功能和 guava cache 类似\n工具大小     jdk 自带类，很小          基于 linkedhashmap，较小   很大，最新版本 1.4mb           是 guava 工具类中的一个小部分，较小   一般，最新版本 644kb\n是否持久化    否                   否                     是                       否                       否\n是否支持集群   否                   否                     是                       否                       否\n\n * concurrenthashmap - 比较适合缓存比较固定不变的元素，且缓存的数量较小的。虽然从上面表格中比起来有点逊色，但是其由于是 jdk 自带的类，在各种框架中依然有大量的使用，比如我们可以用来缓存我们反射的 method，field 等等；也可以缓存一些链接，防止其重复建立。在 caffeine 中也是使用的 concurrenthashmap 来存储元素。\n * lrumap - 如果不想引入第三方包，又想使用淘汰算法淘汰数据，可以使用这个。\n * ehcache - 由于其 jar 包很大，较重量级。对于需要持久化和集群的一些功能的，可以选择 ehcache。需要注意的是，虽然 ehcache 也支持分布式缓存，但是由于其节点间通信方式为 rmi，表现不如 redis，所以一般不建议用它来作为分布式缓存。\n * guava cache - guava 这个 jar 包在很多 java 应用程序中都有大量的引入，所以很多时候其实是直接用就好了，并且其本身是轻量级的而且功能较为丰富，在不了解 caffeine 的情况下可以选择 guava cache。\n * caffeine - 其在命中率，读写性能上都比 guava cache 好很多，并且其 api 和 guava cache 基本一致，甚至会多一点。在真实环境中使用 caffeine，取得过不错的效果。\n\n总结一下：如果不需要淘汰算法则选择 concurrenthashmap，如果需要淘汰算法和一些丰富的 api，推荐选择 caffeine。\n\n\n# 参考资料\n\n * caffeine github\n * 深入解密来自未来的缓存-caffeine\n * caffeine 缓存\n * google guava 官方教程（中文版）\n * google guava cache 全解析\n * 注释驱动的 spring cache 缓存介绍",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"http-cache",frontmatter:{title:"http-cache",categories:["编程","Java","中间件","缓存"],tags:["缓存","Http"],abbrlink:"74d07b78",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/c09100/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/02.%E7%BC%93%E5%AD%98/06.Http%E7%BC%93%E5%AD%98.html",relativePath:"14.中间件/02.缓存/06.Http缓存.md",key:"v-94737480",path:"/pages/c09100/",headers:[{level:2,title:"Http 强缓存",slug:"http-强缓存",normalizedTitle:"http 强缓存",charIndex:85},{level:3,title:"Expires",slug:"expires",normalizedTitle:"expires",charIndex:240},{level:3,title:"Cache-Control",slug:"cache-control",normalizedTitle:"cache-control",charIndex:248},{level:3,title:"Pragma",slug:"pragma",normalizedTitle:"pragma",charIndex:264},{level:2,title:"协商缓存",slug:"协商缓存",normalizedTitle:"协商缓存",charIndex:36},{level:3,title:"ETag/If-None-Match",slug:"etag-if-none-match",normalizedTitle:"etag/if-none-match",charIndex:1066},{level:3,title:"Last-Modified/If-Modified-Since",slug:"last-modified-if-modified-since",normalizedTitle:"last-modified/if-modified-since",charIndex:1411},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:2076}],headersStr:"Http 强缓存 Expires Cache-Control Pragma 协商缓存 ETag/If-None-Match Last-Modified/If-Modified-Since 参考资料",content:"# Http 缓存\n\nHTTP 缓存分为 2 种，一种是强缓存，另一种是协商缓存。主要作用是可以加快资源获取速度，提升用户体验，减少网络传输，缓解服务端的压力。\n\n\n# Http 强缓存\n\n不需要发送请求到服务端，直接读取浏览器本地缓存，在 Chrome 的 Network 中显示的 HTTP 状态码是 200 ，在 Chrome 中，强缓存又分为 Disk Cache (存放在硬盘中)和 Memory Cache (存放在内存中)，存放的位置是由浏览器控制的。是否强缓存由 Expires、Cache-Control 和 Pragma 3 个 Header 属性共同来控制。\n\n\n# Expires\n\nExpires 的值是一个 HTTP 日期，在浏览器发起请求时，会根据系统时间和 Expires 的值进行比较，如果系统时间超过了 Expires 的值，缓存失效。由于和系统时间进行比较，所以当系统时间和服务器时间不一致的时候，会有缓存有效期不准的问题。Expires 的优先级在三个 Header 属性中是最低的。\n\n\n# Cache-Control\n\nCache-Control 是 HTTP/1.1 中新增的属性，在请求头和响应头中都可以使用，常用的属性值如有：\n\n * max-age：单位是秒，缓存时间计算的方式是距离发起的时间的秒数，超过间隔的秒数缓存失效\n * no-cache：不使用强缓存，需要与服务器验证缓存是否新鲜\n * no-store：禁止使用缓存（包括协商缓存），每次都向服务器请求最新的资源\n * private：专用于个人的缓存，中间代理、CDN 等不能缓存此响应\n * public：响应可以被中间代理、CDN 等缓存\n * must-revalidate：在缓存过期前可以使用，过期后必须向服务器验证\n\n\n# Pragma\n\nPragma 只有一个属性值，就是 no-cache ，效果和 Cache-Control 中的 no-cache 一致，不使用强缓存，需要与服务器验证缓存是否新鲜，在 3 个头部属性中的优先级最高。\n\n\n# 协商缓存\n\n当浏览器的强缓存失效的时候或者请求头中设置了不走强缓存，并且在请求头中设置了 If-Modified-Since 或者 If-None-Match 的时候，会将这两个属性值到服务端去验证是否命中协商缓存，如果命中了协商缓存，会返回 304 状态，加载浏览器缓存，并且响应头会设置 Last-Modified 或者 ETag 属性。\n\n\n# ETag/If-None-Match\n\nEtag： 服务器响应请求时，通过此字段告诉浏览器当前资源在服务器生成的唯一标识（生成规则由服务器决定）\n\nIf-None-Match： 再次请求服务器时，浏览器的请求报文头部会包含此字段，后面的值为在缓存中获取的标识。服务器接收到次报文后发现 If-None-Match 则与被请求资源的唯一标识进行对比。\n\n 1. 不同，说明资源被改动过，则响应整个资源内容，返回状态码 200。\n 2. 相同，说明资源无心修改，则响应 header，浏览器直接从缓存中获取数据信息。返回状态码 304.\n\n但是实际应用中由于 Etag 的计算是使用算法来得出的，而算法会占用服务端计算的资源，所有服务端的资源都是宝贵的，所以就很少使用 Etag 了。\n\n\n# Last-Modified/If-Modified-Since\n\nLast-Modified： 服务器在响应请求时，会告诉浏览器资源的最后修改时间。\n\nif-Modified-Since: 浏览器再次请求服务器的时候，请求头会包含此字段，后面跟着在缓存中获得的最后修改时间。服务端收到此请求头发现有 if-Modified-Since，则与被请求资源的最后修改时间进行对比，如果一致则返回 304 和响应报文头，浏览器只需要从缓存中获取信息即可。 从字面上看，就是说：从某个时间节点算起，是否文件被修改了\n\n 1. 如果真的被修改：那么开始传输响应一个整体，服务器返回：200 OK\n 2. 如果没有被修改：那么只需传输响应 header，服务器返回：304 Not Modified\n\nif-Unmodified-Since: 从字面上看, 就是说: 从某个时间点算起, 是否文件没有被修改\n\n 1. 如果没有被修改:则开始`继续'传送文件: 服务器返回: 200 OK\n 2. 如果文件被修改:则不传输,服务器返回: 412 Precondition failed (预处理错误)\n\n这两个的区别是一个是修改了才下载一个是没修改才下载。 Last-Modified 说好却也不是特别好，因为如果在服务器上，一个资源被修改了，但其实际内容根本没发生改变，会因为 Last-Modified 时间匹配不上而返回了整个实体给客户端（即使客户端缓存里有个一模一样的资源）。为了解决这个问题，HTTP1.1 推出了 Etag。\n\n\n# 参考资料\n\n * 图解 HTTP 缓存\n * HTTP----HTTP 缓存机制\n * 缓存详解",normalizedContent:"# http 缓存\n\nhttp 缓存分为 2 种，一种是强缓存，另一种是协商缓存。主要作用是可以加快资源获取速度，提升用户体验，减少网络传输，缓解服务端的压力。\n\n\n# http 强缓存\n\n不需要发送请求到服务端，直接读取浏览器本地缓存，在 chrome 的 network 中显示的 http 状态码是 200 ，在 chrome 中，强缓存又分为 disk cache (存放在硬盘中)和 memory cache (存放在内存中)，存放的位置是由浏览器控制的。是否强缓存由 expires、cache-control 和 pragma 3 个 header 属性共同来控制。\n\n\n# expires\n\nexpires 的值是一个 http 日期，在浏览器发起请求时，会根据系统时间和 expires 的值进行比较，如果系统时间超过了 expires 的值，缓存失效。由于和系统时间进行比较，所以当系统时间和服务器时间不一致的时候，会有缓存有效期不准的问题。expires 的优先级在三个 header 属性中是最低的。\n\n\n# cache-control\n\ncache-control 是 http/1.1 中新增的属性，在请求头和响应头中都可以使用，常用的属性值如有：\n\n * max-age：单位是秒，缓存时间计算的方式是距离发起的时间的秒数，超过间隔的秒数缓存失效\n * no-cache：不使用强缓存，需要与服务器验证缓存是否新鲜\n * no-store：禁止使用缓存（包括协商缓存），每次都向服务器请求最新的资源\n * private：专用于个人的缓存，中间代理、cdn 等不能缓存此响应\n * public：响应可以被中间代理、cdn 等缓存\n * must-revalidate：在缓存过期前可以使用，过期后必须向服务器验证\n\n\n# pragma\n\npragma 只有一个属性值，就是 no-cache ，效果和 cache-control 中的 no-cache 一致，不使用强缓存，需要与服务器验证缓存是否新鲜，在 3 个头部属性中的优先级最高。\n\n\n# 协商缓存\n\n当浏览器的强缓存失效的时候或者请求头中设置了不走强缓存，并且在请求头中设置了 if-modified-since 或者 if-none-match 的时候，会将这两个属性值到服务端去验证是否命中协商缓存，如果命中了协商缓存，会返回 304 状态，加载浏览器缓存，并且响应头会设置 last-modified 或者 etag 属性。\n\n\n# etag/if-none-match\n\netag： 服务器响应请求时，通过此字段告诉浏览器当前资源在服务器生成的唯一标识（生成规则由服务器决定）\n\nif-none-match： 再次请求服务器时，浏览器的请求报文头部会包含此字段，后面的值为在缓存中获取的标识。服务器接收到次报文后发现 if-none-match 则与被请求资源的唯一标识进行对比。\n\n 1. 不同，说明资源被改动过，则响应整个资源内容，返回状态码 200。\n 2. 相同，说明资源无心修改，则响应 header，浏览器直接从缓存中获取数据信息。返回状态码 304.\n\n但是实际应用中由于 etag 的计算是使用算法来得出的，而算法会占用服务端计算的资源，所有服务端的资源都是宝贵的，所以就很少使用 etag 了。\n\n\n# last-modified/if-modified-since\n\nlast-modified： 服务器在响应请求时，会告诉浏览器资源的最后修改时间。\n\nif-modified-since: 浏览器再次请求服务器的时候，请求头会包含此字段，后面跟着在缓存中获得的最后修改时间。服务端收到此请求头发现有 if-modified-since，则与被请求资源的最后修改时间进行对比，如果一致则返回 304 和响应报文头，浏览器只需要从缓存中获取信息即可。 从字面上看，就是说：从某个时间节点算起，是否文件被修改了\n\n 1. 如果真的被修改：那么开始传输响应一个整体，服务器返回：200 ok\n 2. 如果没有被修改：那么只需传输响应 header，服务器返回：304 not modified\n\nif-unmodified-since: 从字面上看, 就是说: 从某个时间点算起, 是否文件没有被修改\n\n 1. 如果没有被修改:则开始`继续'传送文件: 服务器返回: 200 ok\n 2. 如果文件被修改:则不传输,服务器返回: 412 precondition failed (预处理错误)\n\n这两个的区别是一个是修改了才下载一个是没修改才下载。 last-modified 说好却也不是特别好，因为如果在服务器上，一个资源被修改了，但其实际内容根本没发生改变，会因为 last-modified 时间匹配不上而返回了整个实体给客户端（即使客户端缓存里有个一模一样的资源）。为了解决这个问题，http1.1 推出了 etag。\n\n\n# 参考资料\n\n * 图解 http 缓存\n * http----http 缓存机制\n * 缓存详解",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 缓存",frontmatter:{title:"Java 缓存",categories:["编程","Java","中间件","缓存"],tags:["Java","中间件","缓存"],abbrlink:"ad7f7d3",date:"2022-02-17T22:34:30.000Z",hidden:!0,permalink:"/pages/71104f/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/02.%E7%BC%93%E5%AD%98/",relativePath:"14.中间件/02.缓存/README.md",key:"v-c4a07c5e",path:"/pages/71104f/",headers:[{level:2,title:"📖 内容",slug:"📖-内容",normalizedTitle:"📖 内容",charIndex:113},{level:2,title:"📚 资料",slug:"📚-资料",normalizedTitle:"📚 资料",charIndex:203},{level:2,title:"🚪 传送",slug:"🚪-传送",normalizedTitle:"🚪 传送",charIndex:407}],headersStr:"📖 内容 📚 资料 🚪 传送",content:"# Java 缓存\n\n> 缓存可以说是优化系统性能的第一手段，在各种技术中都会有缓存的应用。\n> \n> 如果想深入学习缓存，建议先了解一下 缓存基本原理，有助于理解缓存的特性、原理，使用缓存常见的问题及解决方案。\n\n\n\n\n# 📖 内容\n\n * 缓存面试题\n * Java 缓存框架\n * Memcached 快速入门\n * Ehcache 快速入门\n * Java 缓存库\n * Http 缓存\n\n\n# 📚 资料\n\n * JSR107\n * Spring Cache 官方文档\n * Spring Boot Cache 特性官方文档\n * J2Cache Gitee\n * JetCache Github\n * JetCache wiki\n * Memcached 官网\n * Memcached Github\n * Redis 官网\n * Redis github\n * Redis 官方文档中文版\n\n\n# 🚪 传送\n\n◾ 🏠 JAVA-TUTORIAL 首页 ◾ 🎯 我的博客 ◾",normalizedContent:"# java 缓存\n\n> 缓存可以说是优化系统性能的第一手段，在各种技术中都会有缓存的应用。\n> \n> 如果想深入学习缓存，建议先了解一下 缓存基本原理，有助于理解缓存的特性、原理，使用缓存常见的问题及解决方案。\n\n\n\n\n# 📖 内容\n\n * 缓存面试题\n * java 缓存框架\n * memcached 快速入门\n * ehcache 快速入门\n * java 缓存库\n * http 缓存\n\n\n# 📚 资料\n\n * jsr107\n * spring cache 官方文档\n * spring boot cache 特性官方文档\n * j2cache gitee\n * jetcache github\n * jetcache wiki\n * memcached 官网\n * memcached github\n * redis 官网\n * redis github\n * redis 官方文档中文版\n\n\n# 🚪 传送\n\n◾ 🏠 java-tutorial 首页 ◾ 🎯 我的博客 ◾",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Hystrix 快速入门",frontmatter:{title:"Hystrix 快速入门",categories:["编程","Java","中间件","流量控制"],tags:["Java","中间件","流量控制","Hystrix"],abbrlink:"eea3b9ff",date:"2022-02-17T22:34:30.000Z",permalink:"/pages/f2ebed/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/01.Hystrix.html",relativePath:"14.中间件/03.流量控制/01.Hystrix.md",key:"v-a9382712",path:"/pages/f2ebed/",headers:[{level:2,title:"一、Hystrix 简介",slug:"一、hystrix-简介",normalizedTitle:"一、hystrix 简介",charIndex:19},{level:3,title:"Hystrix 是什么",slug:"hystrix-是什么",normalizedTitle:"hystrix 是什么",charIndex:36},{level:3,title:"为什么需要 Hystrix",slug:"为什么需要-hystrix",normalizedTitle:"为什么需要 hystrix",charIndex:172},{level:3,title:"Hystrix 的功能",slug:"hystrix-的功能",normalizedTitle:"hystrix 的功能",charIndex:730},{level:2,title:"Hystrix 核心概念",slug:"hystrix-核心概念",normalizedTitle:"hystrix 核心概念",charIndex:1202},{level:2,title:"二、Hystrix 工作流程",slug:"二、hystrix-工作流程",normalizedTitle:"二、hystrix 工作流程",charIndex:1219},{level:3,title:"（一）包装命令",slug:"一-包装命令",normalizedTitle:"（一）包装命令",charIndex:1274},{level:3,title:"（二）执行命令",slug:"二-执行命令",normalizedTitle:"（二）执行命令",charIndex:1858},{level:3,title:"（三）是否缓存",slug:"三-是否缓存",normalizedTitle:"（三）是否缓存",charIndex:2978},{level:3,title:"（四）是否开启断路器",slug:"四-是否开启断路器",normalizedTitle:"（四）是否开启断路器",charIndex:3066},{level:3,title:"（五）信号量、线程池是否拒绝",slug:"五-信号量、线程池是否拒绝",normalizedTitle:"（五）信号量、线程池是否拒绝",charIndex:3224},{level:3,title:"（六）construct() 或 run()",slug:"六-construct-或-run",normalizedTitle:"（六）construct() 或 run()",charIndex:3374},{level:3,title:"（七）健康检查",slug:"七-健康检查",normalizedTitle:"（七）健康检查",charIndex:4388},{level:3,title:"（八）获取 Fallback",slug:"八-获取-fallback",normalizedTitle:"（八）获取 fallback",charIndex:4591},{level:3,title:"（九）返回结果",slug:"九-返回结果",normalizedTitle:"（九）返回结果",charIndex:4743},{level:2,title:"三、断路器工作原理",slug:"三、断路器工作原理",normalizedTitle:"三、断路器工作原理",charIndex:5151},{level:3,title:"系统指标",slug:"系统指标",normalizedTitle:"系统指标",charIndex:7335},{level:2,title:"四、资源隔离技术",slug:"四、资源隔离技术",normalizedTitle:"四、资源隔离技术",charIndex:7635},{level:3,title:"线程池隔离",slug:"线程池隔离",normalizedTitle:"线程池隔离",charIndex:87},{level:3,title:"信号量隔离",slug:"信号量隔离",normalizedTitle:"信号量隔离",charIndex:93},{level:2,title:"五、Hystrix 应用",slug:"五、hystrix-应用",normalizedTitle:"五、hystrix 应用",charIndex:11064},{level:3,title:"Spring Cloud + Hystrix",slug:"spring-cloud-hystrix",normalizedTitle:"spring cloud + hystrix",charIndex:11081},{level:2,title:"Hystrix 配置",slug:"hystrix-配置",normalizedTitle:"hystrix 配置",charIndex:11108},{level:3,title:"执行配置",slug:"执行配置",normalizedTitle:"执行配置",charIndex:12225},{level:3,title:"断路配置",slug:"断路配置",normalizedTitle:"断路配置",charIndex:12639},{level:3,title:"指标配置",slug:"指标配置",normalizedTitle:"指标配置",charIndex:13154},{level:3,title:"线程池配置",slug:"线程池配置",normalizedTitle:"线程池配置",charIndex:14025},{level:2,title:"六、其他限流技术",slug:"六、其他限流技术",normalizedTitle:"六、其他限流技术",charIndex:14863},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:15608}],headersStr:"一、Hystrix 简介 Hystrix 是什么 为什么需要 Hystrix Hystrix 的功能 Hystrix 核心概念 二、Hystrix 工作流程 （一）包装命令 （二）执行命令 （三）是否缓存 （四）是否开启断路器 （五）信号量、线程池是否拒绝 （六）construct() 或 run() （七）健康检查 （八）获取 Fallback （九）返回结果 三、断路器工作原理 系统指标 四、资源隔离技术 线程池隔离 信号量隔离 五、Hystrix 应用 Spring Cloud + Hystrix Hystrix 配置 执行配置 断路配置 指标配置 线程池配置 六、其他限流技术 参考资料",content:'# Hystrix 快速入门\n\n\n# 一、Hystrix 简介\n\n\n# Hystrix 是什么\n\nHystrix 是 Netflix 开源的一款容错框架，包含常用的容错方法：线程池隔离、信号量隔离、熔断、降级。\n\nHystrix 官方宣布不再发布新版本。\n\n但是 Hystrix 的客户端熔断保护，断路器设计理念，有非常高的学习价值。\n\n\n# 为什么需要 Hystrix\n\n复杂的分布式系统架构中的应用程序往往具有数十个依赖项，每个依赖项都会不可避免地在某个时刻失败。 如果主机应用程序未与这些外部故障隔离开来，则可能会被波及。\n\n例如，对于依赖于 30 个服务的应用程序，假设每个服务的正常运行时间为 99.99％，则可以期望：\n\n> 99.9930 = 99.7％ 的正常运行时间\n> \n> 10 亿个请求中的 0.3％= 3,000,000 个失败\n> \n> 即使所有依赖项都具有出色的正常运行时间，每月也会有 2 个小时以上的停机时间。\n> \n> 然而，现实情况一般比这种估量情况更糟糕。\n\n----------------------------------------\n\n当一切正常时，整体系统如下所示：\n\n\n\n在高并发场景，这些依赖的稳定性与否对系统的影响非常大，但是依赖有很多不可控问题：如网络连接、资源繁忙、服务宕机等。例如：下图中有一个 QPS 为 50 的依赖 I 出现不可用，但是其他依赖服务是可用的。\n\n\n\n但是，在高并发场景下，当依赖 I 阻塞时，大多数服务器的线程池就出现阻塞(BLOCK)。当这种级联故障愈演愈烈，就可能造成整个线上服务不可用的雪崩效应，如下图：\n\n\n\nHystrix 就是为了解决这类问题而应运而生。\n\n\n# Hystrix 的功能\n\nHystrix 具有以下功能：\n\n * 避免资源耗尽：阻止任何一个依赖服务耗尽所有的资源，比如 tomcat 中的所有线程资源。\n * 避免请求排队和积压：采用限流和 fail fast 来控制故障。\n * 支持降级：提供 fallback 降级机制来应对故障。\n * 资源隔离：比如 bulkhead（舱壁隔离技术）、swimlane（泳道技术）、circuit breaker（断路技术）来限制任何一个依赖服务的故障的影响。\n * 统计/监控/报警：通过近实时的统计/监控/报警功能，来提高故障发现的速度。\n * 通过近实时的属性和配置热修改功能，来提高故障处理和恢复的速度。\n * 保护依赖服务调用的所有故障情况，而不仅仅只是网络故障情况。\n\n如果使用 Hystrix 对每个基础依赖服务进行过载保护，则整个系统架构将会类似下图所示，每个依赖项彼此隔离，受到延迟时发生饱和的资源的被限制访问，并包含 fallback 逻辑（用于降级处理），该逻辑决定了在依赖项中发生任何类型的故障时做出对应的处理。\n\n\n\n\n# Hystrix 核心概念\n\n\n# 二、Hystrix 工作流程\n\n如下图所示，Hystrix 的工作流程大致可以分为 9 个步骤。\n\n\n\n\n# （一）包装命令\n\nx 支持资源隔离。\n\n资源隔离，就是说，你如果要把对某一个依赖服务的所有调用请求，全部隔离在同一份资源池内，不会去用其它资源了，这就叫资源隔离。哪怕对这个依赖服务，比如说商品服务，现在同时发起的调用量已经到了 1000，但是分配给商品服务线程池内就 10 个线程，最多就只会用这 10 个线程去执行。不会因为对商品服务调用的延迟，将 Tomcat 内部所有的线程资源全部耗尽。\n\nHystrix 进行资源隔离，其实是提供了一个抽象，叫做命令模式。这也是 Hystrix 最最基本的资源隔离技术。\n\n在使用 Hystrix 的过程中，会对依赖服务的调用请求封装成命令对象，Hystrix 对 命令对象抽象了两个抽象类：HystrixCommand 和HystrixObservableCommand 。\n\n * HystrixCommand 表示的命令对象会返回一个唯一返回值。\n * HystrixObservableCommand 表示的命令对象 会返回多个返回值。\n\nHystrixCommand command = new HystrixCommand(arg1, arg2);\nHystrixObservableCommand command = new HystrixObservableCommand(arg1, arg2);\n\n\n\n# （二）执行命令\n\nHystrix 中共有 4 种方式执行命令，如下所示：\n\n执行方式           说明                                               可用对象\nexecute()      阻塞式同步执行，返回依赖服务的单一返回结果(或者抛出异常)                    HystrixCommand\nqueue()        基于 Future 的异步方式执行，返回依赖服务的单一返回结果(或者抛出异常)          HystrixCommand\nobserve()      基于 Rxjava 的 Observable 方式，返回通过 Observable        HystrixObservableCommand\n               表示的依赖服务返回结果,代调用代码先执行(Hot Obserable)\ntoObvsevable   基于 Rxjava 的 Observable 方式，返回通过 Observable        HystrixObservableCommand\n               表示的依赖服务返回结果,执行代码等到真正订阅的时候才会执行(cold observable)\n\n这四种命令中，exeucte()、queue()、observe()的表示也是通过toObservable()实现的，其转换关系如下图所示：\n\n\n\nHystrixCommand 执行方式\n\nK value   = command.execute();\n// 等价语句：\nK value = command.execute().queue().get();\n\n\nFuture<K> fValue  = command.queue();\n//等价语句：\nFuture<K> fValue = command.toObservable().toBlocking().toFuture();\n\n\nObservable<K> ohValue = command.observe(); //hot observable，立刻订阅，命令立刻执行\n//等价语句：\nObservable<K> ohValue = command.toObservable().subscribe(subject);\n\n// 上述执行最终实现还是基于 toObservable()\nObservable<K> ocValue = command.toObservable(); //cold observable，延后订阅，订阅发生后，执行才真正执行\n\n\n\n# （三）是否缓存\n\n如果当前命令对象配置了允许从结果缓存中取返回结果，并且在结果缓存中已经缓存了请求结果，则缓存的请求结果会立刻通过 Observable 的格式返回。\n\n\n# （四）是否开启断路器\n\n如果第三步没有缓存没有命中，则判断一下当前断路器的断路状态是否打开。如果断路器状态为打开状态，则 Hystrix 将不会执行此 Command 命令，直接执行步骤 8 调用 Fallback；\n\n如果断路器状态是关闭，则执行 步骤 5 检查是否有足够的资源运行 Command 命令\n\n\n# （五）信号量、线程池是否拒绝\n\n如果当前要执行的 Command 命令 先关连的线程池 和队列(或者信号量)资源已经满了，Hystrix 将不会运行 Command 命令，直接执行 步骤 8的 Fallback 降级处理；如果未满，表示有剩余的资源执行 Command 命令，则执行步骤 6\n\n\n# （六）construct() 或 run()\n\n当经过步骤 5 判断，有足够的资源执行 Command 命令时，本步骤将调用 Command 命令运行方法，基于不同类型的 Command，有如下两种两种运行方式：\n\n运行方式                                   说明\nHystrixCommand.run()                   返回一个处理结果或者抛出一个异常\nHystrixObservableCommand.construct()   返回一个 Observable 表示的结果(可能多个)，或者 基于onError的错误通知\n\n如果run() 或者construct()方法 的真实执行时间超过了 Command 设置的超时时间阈值, 则当前则执行线程（或者是独立的定时器线程）将会抛出TimeoutException。抛出超时异常 TimeoutException，后，将执行步骤 8的 Fallback 降级处理。即使run()或者construct()执行没有被取消或中断，最终能够处理返回结果，但在降级处理逻辑中，将会抛弃run()或construct()方法的返回结果，而返回 Fallback 降级处理结果。\n\n> 注意事项 需要注意的是，Hystrix 无法强制 将正在运行的线程停止掉--Hystrix 能够做的最好的方式就是在 JVM 中抛出一个InterruptedException。如果 Hystrix 包装的工作不抛出中断异常InterruptedException, 则在 Hystrix 线程池中的线程将会继续执行，尽管调用的客户端已经接收到了TimeoutException。这种方式会使 Hystrix 的线程池处于饱和状态。大部分的 Java Http Client 开源库并不会解析 InterruptedException。所以确认 HTTP client 相关的连接和读/写相关的超时时间设置。 如果 Command 命令没有抛出任何异常，并且有返回结果，则 Hystrix 将会在做完日志记录和统计之后会将结果返回。 如果是通过run()方式运行，则返回一个Obserable对象，包含一个唯一值，并且发送一个onCompleted通知；如果是通过consturct()方式运行 ，则返回一个Observable对象。\n\n\n# （七）健康检查\n\nHystrix 会统计 Command 命令执行执行过程中的成功数、失败数、拒绝数和超时数,将这些信息记录到断路器(Circuit Breaker)中。断路器将上述统计按照时间窗的形式记录到一个定长数组中。断路器根据时间窗内的统计数据去判定请求什么时候可以被熔断，熔断后，在接下来一段恢复周期内，相同的请求过来后会直接被熔断。当再次校验，如果健康监测通过后，熔断开关将会被关闭。\n\n\n# （八）获取 Fallback\n\n当以下场景出现后，Hystrix 将会尝试触发 Fallback:\n\n>  * 步骤 6 Command 执行时抛出了任何异常；\n>  * 步骤 4 断路器已经被打开\n>  * 步骤 5 执行命令的线程池、队列或者信号量资源已满\n>  * 命令执行的时间超过阈值\n\n\n# （九）返回结果\n\n如果 Hystrix 命令对象执行成功，将会返回结果，或者以Observable形式包装的结果。根据步骤 2的 command 调用方式，返回的Observable 会按照如下图说是的转换关系进行返回：\n\n\n\n * execute() — 用和 .queue() 相同的方式获取 Future，然后调用 Future 的 get() 以获取 Observable 的单个值。\n * queue() —将 Observable 转换为 BlockingObservable，以便可以将其转换为 Future 并返回。\n * watch() —订阅 Observable 并开始执行命令的流程； 返回一个 Observable，当订阅该 Observable 时，它会重新通知。\n * toObservable() —返回不变的 Observable； 必须订阅它才能真正开始执行命令的流程。\n\n\n# 三、断路器工作原理\n\n\n\n 1. 断路器时间窗内的请求数 是否超过了请求数断路器生效阈值circuitBreaker.requestVolumeThreshold,如果超过了阈值，则将会触发断路，断路状态为开启 例如，如果当前阈值设置的是20,则当时间窗内统计的请求数共计 19 个，即使 19 个全部失败了，都不会触发断路器。\n 2. 并且请求错误率超过了请求错误率阈值errorThresholdPercentage\n 3. 如果两个都满足，则将断路器由关闭迁移到开启\n 4. 如果断路器开启，则后续的所有相同请求将会被断路掉；\n 5. 直到过了沉睡时间窗sleepWindowInMilliseconds后，再发起请求时，允许其通过（此时的状态为半开起状态）。如果请求失败了，则保持断路器状态为开启状态，并更新沉睡时间窗。如果请求成功了，则将断路器状态改为关闭状态；\n\n核心的逻辑如下：\n\n @Override\n                        public void onNext(HealthCounts hc) {\n                            // check if we are past the statisticalWindowVolumeThreshold\n                            if (hc.getTotalRequests() < properties.circuitBreakerRequestVolumeThreshold().get()) {\n                                // we are not past the minimum volume threshold for the stat window,\n                                // so no change to circuit status.\n                                // if it was CLOSED, it stays CLOSED\n                                // if it was half-open, we need to wait for a successful command execution\n                                // if it was open, we need to wait for sleep window to elapse\n                            } else {\n                                if (hc.getErrorPercentage() < properties.circuitBreakerErrorThresholdPercentage().get()) {\n                                    //we are not past the minimum error threshold for the stat window,\n                                    // so no change to circuit status.\n                                    // if it was CLOSED, it stays CLOSED\n                                    // if it was half-open, we need to wait for a successful command execution\n                                    // if it was open, we need to wait for sleep window to elapse\n                                } else {\n                                    // our failure rate is too high, we need to set the state to OPEN\n                                    if (status.compareAndSet(Status.CLOSED, Status.OPEN)) {\n                                        circuitOpened.set(System.currentTimeMillis());\n                                    }\n                                }\n                            }\n                        }\n\n\n\n# 系统指标\n\nHystrix 对系统指标的统计是基于时间窗模式的：\n\n> 时间窗：最近的一个时间区间内，比如前一小时到现在，那么时间窗的长度就是1小时； 桶：桶是在特定的时间窗内，等分的指标收集的统计集合；比如时间窗的长度为1小时，而桶的数量为10,那么每个桶在时间轴上依次排开，时间由远及近，每个桶统计的时间分片为 1h / 10 = 6 min 6 分钟。一个桶中，包含了成功数、失败数、超时数、拒绝数 四个指标。\n\n在系统内，时间窗会随着系统的运行逐渐向前移动，而时间窗的长度和桶的数量是固定不变的，那么随着时间的移动，会出现较久的过期的桶被移除出去，新的桶被添加进来，如下图所示：\n\n\n\n\n# 四、资源隔离技术\n\n\n# 线程池隔离\n\n如下图所示，由于计算机系统的基本执行单位就是线程，线程具备独立的执行能力，所以，为了做到资源保护，需要对系统的线程池进行划分，对于外部调用方\n\nUser Request\n\n\n的请求，调用各个线程池的服务，各个线程池独立完成调用，然后将结果返回\n\n调用方\n\n\n。在调用服务的过程中，如果\n\n服务提供方\n\n\n执行时间过长，则\n\n调用方\n\n\n可以直接以超时的方式直接返回，快速失败。\n\n\n\n线程池隔离的几点好处\n\n>  1. 使用超时返回的机制，避免同步调用服务时，调用时间过长，无法释放，导致资源耗尽的情况\n>  2. 服务方可以控制请求数量，请求过多，可以直接拒绝,达到快速失败的目的；\n>  3. 请求排队，线程池可以维护执行队列，将请求压到队列中处理\n\n举个例子，如下代码段，模拟了同步调用服务的过程：\n\n        //服务提供方，执行服务的时候模拟2分钟的耗时\n        Callable<String> callableService  = ()->{\n            long start = System.currentTimeMillis();\n            while(System.currentTimeMillis()-start> 1000 * 60 *2){\n               //模拟服务执行时间过长的情况\n            }\n            return "OK";\n        };\n\n        //模拟10个客户端调用服务\n        ExecutorService clients = Executors.newFixedThreadPool(10);\n        //模拟给10个客户端提交处理请求\n        for (int i = 0; i < 20; i++) {\n            clients.execute(()->{\n                //同步调用\n                try {\n                    String result = callableService.call();\n                    System.out.println("当前客户端："+Thread.currentThread().getName()+"调用服务完成，得到结果："+result);\n                } catch (Exception e) {\n                    e.printStackTrace();\n                }\n            });\n        }\n\n\n在此环节中，客户端 clients必须等待服务方返回结果之后，才能接收新的请求。如果用吞吐量来衡量系统的话，会发现系统的处理能力比较低。为了提高相应时间，可以借助线程池的方式，设置超时时间，这样的话，客户端就不需要必须等待服务方返回，如果时间过长，可以提前返回,改造后的代码如下所示：\n\n //服务提供方，执行服务的时候模拟2分钟的耗时\n        Callable<String> callableService  = ()->{\n            long start = System.currentTimeMillis();\n            while(System.currentTimeMillis()-start> 1000 * 60 *2){\n               //模拟服务执行时间过长的情况\n            }\n            return "OK";\n        };\n\n        //创建线程池作为服务方\n        ExecutorService executorService = Executors.newFixedThreadPool(30);\n\n\n        //模拟10个客户端调用服务\n        ExecutorService clients = Executors.newFixedThreadPool(10);\n        for (int i = 0; i < 10; i++) {\n            clients.execute(()->{\n                //同步调用\n                    //将请求提交给线程池执行，Callable 和 Runnable在某种意义上，也是Command对象\n                    Future<String> future = executorService.submit(callableService::call);\n                    //在指定的时间内获取结果，如果超时，调用方可以直接返回\n                    try {\n                        String result = future.get(1000, TimeUnit.SECONDS);\n                        //客户端等待时间之后，快速返回\n                        System.out.println("当前客户端："+Thread.currentThread().getName()+"调用服务完成，得到结果："+result);\n                    }catch (TimeoutException timeoutException){\n                        System.out.println("服务调用超时，返回处理");\n                    } catch (InterruptedException e) {\n\n                    } catch (ExecutionException e) {\n                    }\n            });\n        }\n\n\n如果我们将服务方的线程池设置为：\n\nThreadPoolExecutor executorService = new ThreadPoolExecutor(10,1000,TimeUnit.SECONDS,\nnew ArrayBlockingQueue<>(100),\nnew ThreadPoolExecutor.DiscardPolicy() // 提交请求过多时，可以丢弃请求，避免死等阻塞的情况。\n)\n\n\n线程池隔离模式的弊端\n\n> 线程池隔离模式，会根据服务划分出独立的线程池，系统资源的线程并发数是有限的，当线程数过多，系统话费大量的 CPU 时间来做线程上下文切换的无用操作，反而降低系统性能；如果线程池隔离的过多，会导致真正用于接收用户请求的线程就相应地减少，系统吞吐量反而下降； 在实践上，应当对像远程方法调用，网络资源请求这种服务时间不太可控的场景下使用线程池隔离模式处理 如下图所示，是线程池隔离模式的三种场景：\n\n\n\n\n# 信号量隔离\n\n由于基于线程池隔离的模式占用系统线程池资源，Hystrix 还提供了另外一个隔离技术：基于信号量的隔离。\n\n基于信号量的隔离方式非常地简单，其核心就是使用共用变量\n\nsemaphore\n\n\n进行原子操作，控制线程的并发量，当并发量达到一定量级时，服务禁止调用。如下图所示：信号量本身不会消耗多余的线程资源，所以就非常轻量。\n\n\n\n基于信号量隔离的利弊\n\n> 利：基于信号量的隔离，利用 JVM 的原子性 CAS 操作，避免了资源锁的竞争，省去了线程池开销，效率非常高； 弊：本质上基于信号量的隔离是同步行为，所以无法做到超时熔断，所以服务方自身要控制住执行时间，避免超时。 应用场景：业务服务上，有并发上限限制时，可以考虑此方式 > Alibaba Sentinel开源框架，就是基于信号量的熔断和断路器框架。\n\n\n# 五、Hystrix 应用\n\n\n# Spring Cloud + Hystrix\n\n * Hystrix 配置无法动态调节生效。Hystrix 框架本身是使用的Archaius框架完成的配置加载和刷新，但是集成自 Spring Cloud 下，无法有效地根据实时监控结果，动态调整熔断和系统参数\n * 线程池和 Command 之间的配置比较复杂,在 Spring Cloud 在做 feigin-hystrix 集成的时候，还有些 BUG，对 command 的默认配置没有处理好，导致所有 command 占用公共的 command 线程池，没有细粒度控制，还需要做框架适配调整\n\npublic interface SetterFactory {\n\n  /**\n   * Returns a hystrix setter appropriate for the given target and method\n   */\n  HystrixCommand.Setter create(Target<?> target, Method method);\n\n  /**\n   * Default behavior is to derive the group key from {@link Target#name()} and the command key from\n   * {@link Feign#configKey(Class, Method)}.\n   */\n  final class Default implements SetterFactory {\n\n    @Override\n    public HystrixCommand.Setter create(Target<?> target, Method method) {\n      String groupKey = target.name();\n      String commandKey = Feign.configKey(target.type(), method);\n      return HystrixCommand.Setter\n          .withGroupKey(HystrixCommandGroupKey.Factory.asKey(groupKey))\n          .andCommandKey(HystrixCommandKey.Factory.asKey(commandKey));\n          //没有处理好default配置项的加载\n    }\n  }\n}\n\n\n\n# Hystrix 配置\n\n> 详细配置可以参考 Hystrix 官方配置手册，这里仅介绍比较核心的配置\n\n\n# 执行配置\n\n以下配置用于控制 HystrixCommand.run() 如何执行。\n\n配置项                                                   说明                              默认值\nexecution.isolation.strategy                          线程隔离（THREAD）或信号量隔离（SEMAPHORE）   THREAD\nexecution.isolation.thread.timeoutInMilliseconds      方法执行超时时间                        1000(ms)\nexecution.isolation.semaphore.maxConcurrentRequests   信号量隔离最大并发数                      10\n\n\n# 断路配置\n\n以下配置用于控制 HystrixCircuitBreaker 的断路处理。\n\n配置项                                        说明                默认值\ncircuitBreaker.enabled                     是否开启断路器           true\ncircuitBreaker.requestVolumeThreshold      断路器启用请求数阈值        20\ncircuitBreaker.sleepWindowInMilliseconds   断路器启用后的休眠时间       5000(ms)\ncircuitBreaker.errorThresholdPercentage    断路器启用失败率阈值        50(%)\ncircuitBreaker.forceOpen                   是否强制将断路器设置成开启状态   false\ncircuitBreaker.forceClosed                 是否强制将断路器设置成关闭状态   false\n\n\n# 指标配置\n\n以下配置用于从 HystrixCommand 和 HystrixObservableCommand 执行中捕获相关指标。\n\n配置项                                             说明                                            默认值\nmetrics.rollingStats.timeInMilliseconds         时间窗的长度                                        10000(ms)\nmetrics.rollingStats.numBuckets                 桶的数量，需要保证timeInMilliseconds % numBuckets =0   10\nmetrics.rollingPercentile.enabled               是否统计运行延迟的占比                                   true\nmetrics.rollingPercentile.timeInMilliseconds    运行延迟占比统计的时间窗                                  60000(ms)\nmetrics.rollingPercentile.numBuckets            运行延迟占比统计的桶数                                   6\nmetrics.rollingPercentile.bucketSize            百分比统计桶的容量，桶内最多保存的运行时间统计                       100\nmetrics.healthSnapshot.intervalInMilliseconds   统计快照刷新间隔                                      500 (ms)\n\n\n# 线程池配置\n\n以下配置用于控制 Hystrix Command 执行所使用的线程池。\n\n配置项                                     说明                                                           默认值\ncoreSize                                线程池核心线程数                                                     10\nmaximumSize                             线程池最大线程数                                                     10\nmaxQueueSize                            最大 LinkedBlockingQueue 的大小，-1 表示用 SynchronousQueue           -1\nqueueSizeRejectionThreshold             队列大小阈值，超过则拒绝                                                 5\nallowMaximumSizeToDivergeFromCoreSize   此属性允许 maximumSize 的配置生效。该值可以等于或大于 coreSize。设置 coreSize       false\n                                        <maximumSize 使得线程池可以维持 maximumSize 并发性，但是会在相对空闲时将线程回收。（取决于\n                                        keepAliveTimeInMinutes）\n\n\n# 六、其他限流技术\n\n * resilience4j Hystrix 虽然官方宣布不再维护，其推荐另外一个框架：resilience4j, 这个框架是是为 Java 8 和 函数式编程设计的一个轻量级的容错框架，该框架充分利用函数式编程的概念，为函数式接口、lamda表达式、方法引用高阶函数进行包装，(本质上是装饰者模式的概念)，通过包装实现断路、限流、重试、舱壁功能。 这个框架整体而言比较轻量，没有控制台，不太好做系统级监控；\n\n * Alibaba Sentinel\n   \n   Sentinel\n   \n   \n   是 阿里巴巴开源的轻量级的流量控制、熔断降级 Java 库，该库的核心是使用的是信号量隔离的方式做流量控制和熔断，其优点是其集成性和易用性，几乎能和当前主流的 Spring Cloud, dubbo ,grpc ,nacos, zookeeper 做集成，如下图所示：\n   \n   \n   \n   sentinel-features-overview-en.png\n   \n   Sentinel\n   \n   \n   的目标生态圈：\n   \n   \n   \n   sentinel\n   \n   \n   一个强大的功能，就是它有一个流控管理控制台，你可以实时地监控每个服务的流控情况，并且可以实时编辑各种流控、熔断规则，有效地保证了服务保护的及时性。下图是内部试用的 sentinel 控制台：\n   \n   另外，\n   \n   sentinel\n   \n   \n   还可以和\n   \n   ctrip apollo\n   \n   \n   分布式配置系统进行集成，将流控规降级等各种规则先配置在 apollo 中，然后服务启动自动加载流控规则。\n\n\n# 参考资料\n\n * Hystrix Github\n * Spring Cloud Hystrix 设计原理\n * Hystrix 都停更了，我为什么还要学？',normalizedContent:'# hystrix 快速入门\n\n\n# 一、hystrix 简介\n\n\n# hystrix 是什么\n\nhystrix 是 netflix 开源的一款容错框架，包含常用的容错方法：线程池隔离、信号量隔离、熔断、降级。\n\nhystrix 官方宣布不再发布新版本。\n\n但是 hystrix 的客户端熔断保护，断路器设计理念，有非常高的学习价值。\n\n\n# 为什么需要 hystrix\n\n复杂的分布式系统架构中的应用程序往往具有数十个依赖项，每个依赖项都会不可避免地在某个时刻失败。 如果主机应用程序未与这些外部故障隔离开来，则可能会被波及。\n\n例如，对于依赖于 30 个服务的应用程序，假设每个服务的正常运行时间为 99.99％，则可以期望：\n\n> 99.9930 = 99.7％ 的正常运行时间\n> \n> 10 亿个请求中的 0.3％= 3,000,000 个失败\n> \n> 即使所有依赖项都具有出色的正常运行时间，每月也会有 2 个小时以上的停机时间。\n> \n> 然而，现实情况一般比这种估量情况更糟糕。\n\n----------------------------------------\n\n当一切正常时，整体系统如下所示：\n\n\n\n在高并发场景，这些依赖的稳定性与否对系统的影响非常大，但是依赖有很多不可控问题：如网络连接、资源繁忙、服务宕机等。例如：下图中有一个 qps 为 50 的依赖 i 出现不可用，但是其他依赖服务是可用的。\n\n\n\n但是，在高并发场景下，当依赖 i 阻塞时，大多数服务器的线程池就出现阻塞(block)。当这种级联故障愈演愈烈，就可能造成整个线上服务不可用的雪崩效应，如下图：\n\n\n\nhystrix 就是为了解决这类问题而应运而生。\n\n\n# hystrix 的功能\n\nhystrix 具有以下功能：\n\n * 避免资源耗尽：阻止任何一个依赖服务耗尽所有的资源，比如 tomcat 中的所有线程资源。\n * 避免请求排队和积压：采用限流和 fail fast 来控制故障。\n * 支持降级：提供 fallback 降级机制来应对故障。\n * 资源隔离：比如 bulkhead（舱壁隔离技术）、swimlane（泳道技术）、circuit breaker（断路技术）来限制任何一个依赖服务的故障的影响。\n * 统计/监控/报警：通过近实时的统计/监控/报警功能，来提高故障发现的速度。\n * 通过近实时的属性和配置热修改功能，来提高故障处理和恢复的速度。\n * 保护依赖服务调用的所有故障情况，而不仅仅只是网络故障情况。\n\n如果使用 hystrix 对每个基础依赖服务进行过载保护，则整个系统架构将会类似下图所示，每个依赖项彼此隔离，受到延迟时发生饱和的资源的被限制访问，并包含 fallback 逻辑（用于降级处理），该逻辑决定了在依赖项中发生任何类型的故障时做出对应的处理。\n\n\n\n\n# hystrix 核心概念\n\n\n# 二、hystrix 工作流程\n\n如下图所示，hystrix 的工作流程大致可以分为 9 个步骤。\n\n\n\n\n# （一）包装命令\n\nx 支持资源隔离。\n\n资源隔离，就是说，你如果要把对某一个依赖服务的所有调用请求，全部隔离在同一份资源池内，不会去用其它资源了，这就叫资源隔离。哪怕对这个依赖服务，比如说商品服务，现在同时发起的调用量已经到了 1000，但是分配给商品服务线程池内就 10 个线程，最多就只会用这 10 个线程去执行。不会因为对商品服务调用的延迟，将 tomcat 内部所有的线程资源全部耗尽。\n\nhystrix 进行资源隔离，其实是提供了一个抽象，叫做命令模式。这也是 hystrix 最最基本的资源隔离技术。\n\n在使用 hystrix 的过程中，会对依赖服务的调用请求封装成命令对象，hystrix 对 命令对象抽象了两个抽象类：hystrixcommand 和hystrixobservablecommand 。\n\n * hystrixcommand 表示的命令对象会返回一个唯一返回值。\n * hystrixobservablecommand 表示的命令对象 会返回多个返回值。\n\nhystrixcommand command = new hystrixcommand(arg1, arg2);\nhystrixobservablecommand command = new hystrixobservablecommand(arg1, arg2);\n\n\n\n# （二）执行命令\n\nhystrix 中共有 4 种方式执行命令，如下所示：\n\n执行方式           说明                                               可用对象\nexecute()      阻塞式同步执行，返回依赖服务的单一返回结果(或者抛出异常)                    hystrixcommand\nqueue()        基于 future 的异步方式执行，返回依赖服务的单一返回结果(或者抛出异常)          hystrixcommand\nobserve()      基于 rxjava 的 observable 方式，返回通过 observable        hystrixobservablecommand\n               表示的依赖服务返回结果,代调用代码先执行(hot obserable)\ntoobvsevable   基于 rxjava 的 observable 方式，返回通过 observable        hystrixobservablecommand\n               表示的依赖服务返回结果,执行代码等到真正订阅的时候才会执行(cold observable)\n\n这四种命令中，exeucte()、queue()、observe()的表示也是通过toobservable()实现的，其转换关系如下图所示：\n\n\n\nhystrixcommand 执行方式\n\nk value   = command.execute();\n// 等价语句：\nk value = command.execute().queue().get();\n\n\nfuture<k> fvalue  = command.queue();\n//等价语句：\nfuture<k> fvalue = command.toobservable().toblocking().tofuture();\n\n\nobservable<k> ohvalue = command.observe(); //hot observable，立刻订阅，命令立刻执行\n//等价语句：\nobservable<k> ohvalue = command.toobservable().subscribe(subject);\n\n// 上述执行最终实现还是基于 toobservable()\nobservable<k> ocvalue = command.toobservable(); //cold observable，延后订阅，订阅发生后，执行才真正执行\n\n\n\n# （三）是否缓存\n\n如果当前命令对象配置了允许从结果缓存中取返回结果，并且在结果缓存中已经缓存了请求结果，则缓存的请求结果会立刻通过 observable 的格式返回。\n\n\n# （四）是否开启断路器\n\n如果第三步没有缓存没有命中，则判断一下当前断路器的断路状态是否打开。如果断路器状态为打开状态，则 hystrix 将不会执行此 command 命令，直接执行步骤 8 调用 fallback；\n\n如果断路器状态是关闭，则执行 步骤 5 检查是否有足够的资源运行 command 命令\n\n\n# （五）信号量、线程池是否拒绝\n\n如果当前要执行的 command 命令 先关连的线程池 和队列(或者信号量)资源已经满了，hystrix 将不会运行 command 命令，直接执行 步骤 8的 fallback 降级处理；如果未满，表示有剩余的资源执行 command 命令，则执行步骤 6\n\n\n# （六）construct() 或 run()\n\n当经过步骤 5 判断，有足够的资源执行 command 命令时，本步骤将调用 command 命令运行方法，基于不同类型的 command，有如下两种两种运行方式：\n\n运行方式                                   说明\nhystrixcommand.run()                   返回一个处理结果或者抛出一个异常\nhystrixobservablecommand.construct()   返回一个 observable 表示的结果(可能多个)，或者 基于onerror的错误通知\n\n如果run() 或者construct()方法 的真实执行时间超过了 command 设置的超时时间阈值, 则当前则执行线程（或者是独立的定时器线程）将会抛出timeoutexception。抛出超时异常 timeoutexception，后，将执行步骤 8的 fallback 降级处理。即使run()或者construct()执行没有被取消或中断，最终能够处理返回结果，但在降级处理逻辑中，将会抛弃run()或construct()方法的返回结果，而返回 fallback 降级处理结果。\n\n> 注意事项 需要注意的是，hystrix 无法强制 将正在运行的线程停止掉--hystrix 能够做的最好的方式就是在 jvm 中抛出一个interruptedexception。如果 hystrix 包装的工作不抛出中断异常interruptedexception, 则在 hystrix 线程池中的线程将会继续执行，尽管调用的客户端已经接收到了timeoutexception。这种方式会使 hystrix 的线程池处于饱和状态。大部分的 java http client 开源库并不会解析 interruptedexception。所以确认 http client 相关的连接和读/写相关的超时时间设置。 如果 command 命令没有抛出任何异常，并且有返回结果，则 hystrix 将会在做完日志记录和统计之后会将结果返回。 如果是通过run()方式运行，则返回一个obserable对象，包含一个唯一值，并且发送一个oncompleted通知；如果是通过consturct()方式运行 ，则返回一个observable对象。\n\n\n# （七）健康检查\n\nhystrix 会统计 command 命令执行执行过程中的成功数、失败数、拒绝数和超时数,将这些信息记录到断路器(circuit breaker)中。断路器将上述统计按照时间窗的形式记录到一个定长数组中。断路器根据时间窗内的统计数据去判定请求什么时候可以被熔断，熔断后，在接下来一段恢复周期内，相同的请求过来后会直接被熔断。当再次校验，如果健康监测通过后，熔断开关将会被关闭。\n\n\n# （八）获取 fallback\n\n当以下场景出现后，hystrix 将会尝试触发 fallback:\n\n>  * 步骤 6 command 执行时抛出了任何异常；\n>  * 步骤 4 断路器已经被打开\n>  * 步骤 5 执行命令的线程池、队列或者信号量资源已满\n>  * 命令执行的时间超过阈值\n\n\n# （九）返回结果\n\n如果 hystrix 命令对象执行成功，将会返回结果，或者以observable形式包装的结果。根据步骤 2的 command 调用方式，返回的observable 会按照如下图说是的转换关系进行返回：\n\n\n\n * execute() — 用和 .queue() 相同的方式获取 future，然后调用 future 的 get() 以获取 observable 的单个值。\n * queue() —将 observable 转换为 blockingobservable，以便可以将其转换为 future 并返回。\n * watch() —订阅 observable 并开始执行命令的流程； 返回一个 observable，当订阅该 observable 时，它会重新通知。\n * toobservable() —返回不变的 observable； 必须订阅它才能真正开始执行命令的流程。\n\n\n# 三、断路器工作原理\n\n\n\n 1. 断路器时间窗内的请求数 是否超过了请求数断路器生效阈值circuitbreaker.requestvolumethreshold,如果超过了阈值，则将会触发断路，断路状态为开启 例如，如果当前阈值设置的是20,则当时间窗内统计的请求数共计 19 个，即使 19 个全部失败了，都不会触发断路器。\n 2. 并且请求错误率超过了请求错误率阈值errorthresholdpercentage\n 3. 如果两个都满足，则将断路器由关闭迁移到开启\n 4. 如果断路器开启，则后续的所有相同请求将会被断路掉；\n 5. 直到过了沉睡时间窗sleepwindowinmilliseconds后，再发起请求时，允许其通过（此时的状态为半开起状态）。如果请求失败了，则保持断路器状态为开启状态，并更新沉睡时间窗。如果请求成功了，则将断路器状态改为关闭状态；\n\n核心的逻辑如下：\n\n @override\n                        public void onnext(healthcounts hc) {\n                            // check if we are past the statisticalwindowvolumethreshold\n                            if (hc.gettotalrequests() < properties.circuitbreakerrequestvolumethreshold().get()) {\n                                // we are not past the minimum volume threshold for the stat window,\n                                // so no change to circuit status.\n                                // if it was closed, it stays closed\n                                // if it was half-open, we need to wait for a successful command execution\n                                // if it was open, we need to wait for sleep window to elapse\n                            } else {\n                                if (hc.geterrorpercentage() < properties.circuitbreakererrorthresholdpercentage().get()) {\n                                    //we are not past the minimum error threshold for the stat window,\n                                    // so no change to circuit status.\n                                    // if it was closed, it stays closed\n                                    // if it was half-open, we need to wait for a successful command execution\n                                    // if it was open, we need to wait for sleep window to elapse\n                                } else {\n                                    // our failure rate is too high, we need to set the state to open\n                                    if (status.compareandset(status.closed, status.open)) {\n                                        circuitopened.set(system.currenttimemillis());\n                                    }\n                                }\n                            }\n                        }\n\n\n\n# 系统指标\n\nhystrix 对系统指标的统计是基于时间窗模式的：\n\n> 时间窗：最近的一个时间区间内，比如前一小时到现在，那么时间窗的长度就是1小时； 桶：桶是在特定的时间窗内，等分的指标收集的统计集合；比如时间窗的长度为1小时，而桶的数量为10,那么每个桶在时间轴上依次排开，时间由远及近，每个桶统计的时间分片为 1h / 10 = 6 min 6 分钟。一个桶中，包含了成功数、失败数、超时数、拒绝数 四个指标。\n\n在系统内，时间窗会随着系统的运行逐渐向前移动，而时间窗的长度和桶的数量是固定不变的，那么随着时间的移动，会出现较久的过期的桶被移除出去，新的桶被添加进来，如下图所示：\n\n\n\n\n# 四、资源隔离技术\n\n\n# 线程池隔离\n\n如下图所示，由于计算机系统的基本执行单位就是线程，线程具备独立的执行能力，所以，为了做到资源保护，需要对系统的线程池进行划分，对于外部调用方\n\nuser request\n\n\n的请求，调用各个线程池的服务，各个线程池独立完成调用，然后将结果返回\n\n调用方\n\n\n。在调用服务的过程中，如果\n\n服务提供方\n\n\n执行时间过长，则\n\n调用方\n\n\n可以直接以超时的方式直接返回，快速失败。\n\n\n\n线程池隔离的几点好处\n\n>  1. 使用超时返回的机制，避免同步调用服务时，调用时间过长，无法释放，导致资源耗尽的情况\n>  2. 服务方可以控制请求数量，请求过多，可以直接拒绝,达到快速失败的目的；\n>  3. 请求排队，线程池可以维护执行队列，将请求压到队列中处理\n\n举个例子，如下代码段，模拟了同步调用服务的过程：\n\n        //服务提供方，执行服务的时候模拟2分钟的耗时\n        callable<string> callableservice  = ()->{\n            long start = system.currenttimemillis();\n            while(system.currenttimemillis()-start> 1000 * 60 *2){\n               //模拟服务执行时间过长的情况\n            }\n            return "ok";\n        };\n\n        //模拟10个客户端调用服务\n        executorservice clients = executors.newfixedthreadpool(10);\n        //模拟给10个客户端提交处理请求\n        for (int i = 0; i < 20; i++) {\n            clients.execute(()->{\n                //同步调用\n                try {\n                    string result = callableservice.call();\n                    system.out.println("当前客户端："+thread.currentthread().getname()+"调用服务完成，得到结果："+result);\n                } catch (exception e) {\n                    e.printstacktrace();\n                }\n            });\n        }\n\n\n在此环节中，客户端 clients必须等待服务方返回结果之后，才能接收新的请求。如果用吞吐量来衡量系统的话，会发现系统的处理能力比较低。为了提高相应时间，可以借助线程池的方式，设置超时时间，这样的话，客户端就不需要必须等待服务方返回，如果时间过长，可以提前返回,改造后的代码如下所示：\n\n //服务提供方，执行服务的时候模拟2分钟的耗时\n        callable<string> callableservice  = ()->{\n            long start = system.currenttimemillis();\n            while(system.currenttimemillis()-start> 1000 * 60 *2){\n               //模拟服务执行时间过长的情况\n            }\n            return "ok";\n        };\n\n        //创建线程池作为服务方\n        executorservice executorservice = executors.newfixedthreadpool(30);\n\n\n        //模拟10个客户端调用服务\n        executorservice clients = executors.newfixedthreadpool(10);\n        for (int i = 0; i < 10; i++) {\n            clients.execute(()->{\n                //同步调用\n                    //将请求提交给线程池执行，callable 和 runnable在某种意义上，也是command对象\n                    future<string> future = executorservice.submit(callableservice::call);\n                    //在指定的时间内获取结果，如果超时，调用方可以直接返回\n                    try {\n                        string result = future.get(1000, timeunit.seconds);\n                        //客户端等待时间之后，快速返回\n                        system.out.println("当前客户端："+thread.currentthread().getname()+"调用服务完成，得到结果："+result);\n                    }catch (timeoutexception timeoutexception){\n                        system.out.println("服务调用超时，返回处理");\n                    } catch (interruptedexception e) {\n\n                    } catch (executionexception e) {\n                    }\n            });\n        }\n\n\n如果我们将服务方的线程池设置为：\n\nthreadpoolexecutor executorservice = new threadpoolexecutor(10,1000,timeunit.seconds,\nnew arrayblockingqueue<>(100),\nnew threadpoolexecutor.discardpolicy() // 提交请求过多时，可以丢弃请求，避免死等阻塞的情况。\n)\n\n\n线程池隔离模式的弊端\n\n> 线程池隔离模式，会根据服务划分出独立的线程池，系统资源的线程并发数是有限的，当线程数过多，系统话费大量的 cpu 时间来做线程上下文切换的无用操作，反而降低系统性能；如果线程池隔离的过多，会导致真正用于接收用户请求的线程就相应地减少，系统吞吐量反而下降； 在实践上，应当对像远程方法调用，网络资源请求这种服务时间不太可控的场景下使用线程池隔离模式处理 如下图所示，是线程池隔离模式的三种场景：\n\n\n\n\n# 信号量隔离\n\n由于基于线程池隔离的模式占用系统线程池资源，hystrix 还提供了另外一个隔离技术：基于信号量的隔离。\n\n基于信号量的隔离方式非常地简单，其核心就是使用共用变量\n\nsemaphore\n\n\n进行原子操作，控制线程的并发量，当并发量达到一定量级时，服务禁止调用。如下图所示：信号量本身不会消耗多余的线程资源，所以就非常轻量。\n\n\n\n基于信号量隔离的利弊\n\n> 利：基于信号量的隔离，利用 jvm 的原子性 cas 操作，避免了资源锁的竞争，省去了线程池开销，效率非常高； 弊：本质上基于信号量的隔离是同步行为，所以无法做到超时熔断，所以服务方自身要控制住执行时间，避免超时。 应用场景：业务服务上，有并发上限限制时，可以考虑此方式 > alibaba sentinel开源框架，就是基于信号量的熔断和断路器框架。\n\n\n# 五、hystrix 应用\n\n\n# spring cloud + hystrix\n\n * hystrix 配置无法动态调节生效。hystrix 框架本身是使用的archaius框架完成的配置加载和刷新，但是集成自 spring cloud 下，无法有效地根据实时监控结果，动态调整熔断和系统参数\n * 线程池和 command 之间的配置比较复杂,在 spring cloud 在做 feigin-hystrix 集成的时候，还有些 bug，对 command 的默认配置没有处理好，导致所有 command 占用公共的 command 线程池，没有细粒度控制，还需要做框架适配调整\n\npublic interface setterfactory {\n\n  /**\n   * returns a hystrix setter appropriate for the given target and method\n   */\n  hystrixcommand.setter create(target<?> target, method method);\n\n  /**\n   * default behavior is to derive the group key from {@link target#name()} and the command key from\n   * {@link feign#configkey(class, method)}.\n   */\n  final class default implements setterfactory {\n\n    @override\n    public hystrixcommand.setter create(target<?> target, method method) {\n      string groupkey = target.name();\n      string commandkey = feign.configkey(target.type(), method);\n      return hystrixcommand.setter\n          .withgroupkey(hystrixcommandgroupkey.factory.askey(groupkey))\n          .andcommandkey(hystrixcommandkey.factory.askey(commandkey));\n          //没有处理好default配置项的加载\n    }\n  }\n}\n\n\n\n# hystrix 配置\n\n> 详细配置可以参考 hystrix 官方配置手册，这里仅介绍比较核心的配置\n\n\n# 执行配置\n\n以下配置用于控制 hystrixcommand.run() 如何执行。\n\n配置项                                                   说明                              默认值\nexecution.isolation.strategy                          线程隔离（thread）或信号量隔离（semaphore）   thread\nexecution.isolation.thread.timeoutinmilliseconds      方法执行超时时间                        1000(ms)\nexecution.isolation.semaphore.maxconcurrentrequests   信号量隔离最大并发数                      10\n\n\n# 断路配置\n\n以下配置用于控制 hystrixcircuitbreaker 的断路处理。\n\n配置项                                        说明                默认值\ncircuitbreaker.enabled                     是否开启断路器           true\ncircuitbreaker.requestvolumethreshold      断路器启用请求数阈值        20\ncircuitbreaker.sleepwindowinmilliseconds   断路器启用后的休眠时间       5000(ms)\ncircuitbreaker.errorthresholdpercentage    断路器启用失败率阈值        50(%)\ncircuitbreaker.forceopen                   是否强制将断路器设置成开启状态   false\ncircuitbreaker.forceclosed                 是否强制将断路器设置成关闭状态   false\n\n\n# 指标配置\n\n以下配置用于从 hystrixcommand 和 hystrixobservablecommand 执行中捕获相关指标。\n\n配置项                                             说明                                            默认值\nmetrics.rollingstats.timeinmilliseconds         时间窗的长度                                        10000(ms)\nmetrics.rollingstats.numbuckets                 桶的数量，需要保证timeinmilliseconds % numbuckets =0   10\nmetrics.rollingpercentile.enabled               是否统计运行延迟的占比                                   true\nmetrics.rollingpercentile.timeinmilliseconds    运行延迟占比统计的时间窗                                  60000(ms)\nmetrics.rollingpercentile.numbuckets            运行延迟占比统计的桶数                                   6\nmetrics.rollingpercentile.bucketsize            百分比统计桶的容量，桶内最多保存的运行时间统计                       100\nmetrics.healthsnapshot.intervalinmilliseconds   统计快照刷新间隔                                      500 (ms)\n\n\n# 线程池配置\n\n以下配置用于控制 hystrix command 执行所使用的线程池。\n\n配置项                                     说明                                                           默认值\ncoresize                                线程池核心线程数                                                     10\nmaximumsize                             线程池最大线程数                                                     10\nmaxqueuesize                            最大 linkedblockingqueue 的大小，-1 表示用 synchronousqueue           -1\nqueuesizerejectionthreshold             队列大小阈值，超过则拒绝                                                 5\nallowmaximumsizetodivergefromcoresize   此属性允许 maximumsize 的配置生效。该值可以等于或大于 coresize。设置 coresize       false\n                                        <maximumsize 使得线程池可以维持 maximumsize 并发性，但是会在相对空闲时将线程回收。（取决于\n                                        keepalivetimeinminutes）\n\n\n# 六、其他限流技术\n\n * resilience4j hystrix 虽然官方宣布不再维护，其推荐另外一个框架：resilience4j, 这个框架是是为 java 8 和 函数式编程设计的一个轻量级的容错框架，该框架充分利用函数式编程的概念，为函数式接口、lamda表达式、方法引用高阶函数进行包装，(本质上是装饰者模式的概念)，通过包装实现断路、限流、重试、舱壁功能。 这个框架整体而言比较轻量，没有控制台，不太好做系统级监控；\n\n * alibaba sentinel\n   \n   sentinel\n   \n   \n   是 阿里巴巴开源的轻量级的流量控制、熔断降级 java 库，该库的核心是使用的是信号量隔离的方式做流量控制和熔断，其优点是其集成性和易用性，几乎能和当前主流的 spring cloud, dubbo ,grpc ,nacos, zookeeper 做集成，如下图所示：\n   \n   \n   \n   sentinel-features-overview-en.png\n   \n   sentinel\n   \n   \n   的目标生态圈：\n   \n   \n   \n   sentinel\n   \n   \n   一个强大的功能，就是它有一个流控管理控制台，你可以实时地监控每个服务的流控情况，并且可以实时编辑各种流控、熔断规则，有效地保证了服务保护的及时性。下图是内部试用的 sentinel 控制台：\n   \n   另外，\n   \n   sentinel\n   \n   \n   还可以和\n   \n   ctrip apollo\n   \n   \n   分布式配置系统进行集成，将流控规降级等各种规则先配置在 apollo 中，然后服务启动自动加载流控规则。\n\n\n# 参考资料\n\n * hystrix github\n * spring cloud hystrix 设计原理\n * hystrix 都停更了，我为什么还要学？',charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Java 中间件",frontmatter:{title:"Java 中间件",categories:["编程","Java","中间件"],tags:["编程","Java","中间件"],abbrlink:"8b30e720",date:"2022-04-09T15:11:37.000Z",permalink:"/pages/3cbcff/"},regularPath:"/14.%E4%B8%AD%E9%97%B4%E4%BB%B6/",relativePath:"14.中间件/README.md",key:"v-9e9dd666",path:"/pages/3cbcff/",headers:[{level:2,title:"📖 内容",slug:"📖-内容",normalizedTitle:"📖 内容",charIndex:15},{level:4,title:"消息队列",slug:"消息队列",normalizedTitle:"消息队列",charIndex:24},{level:4,title:"缓存",slug:"缓存",normalizedTitle:"缓存",charIndex:258},{level:4,title:"流量控制",slug:"流量控制",normalizedTitle:"流量控制",charIndex:443},{level:2,title:"📚 资料",slug:"📚-资料",normalizedTitle:"📚 资料",charIndex:464},{level:2,title:"🚪 传送",slug:"🚪-传送",normalizedTitle:"🚪 传送",charIndex:762}],headersStr:"📖 内容 消息队列 缓存 流量控制 📚 资料 🚪 传送",content:"# Java 中间件\n\n\n# 📖 内容\n\n# 消息队列\n\n> 消息队列（Message Queue，简称 MQ）技术是分布式应用间交换信息的一种技术。\n> \n> 消息队列主要解决应用耦合，异步消息，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。\n> \n> 如果想深入学习各种消息队列产品，建议先了解一下 消息队列基本原理 ，有助于理解消息队列特性的实现和设计思路。\n\n * 消息队列面试\n * 消息队列基本原理\n * RocketMQ\n * ActiveMQ\n\n# 缓存\n\n> 缓存可以说是优化系统性能的第一手段，在各种技术中都会有缓存的应用。\n> \n> 如果想深入学习缓存，建议先了解一下 缓存基本原理，有助于理解缓存的特性、原理，使用缓存常见的问题及解决方案。\n\n * 缓存面试题\n * Java 缓存框架\n * Memcached 快速入门\n * Ehcache 快速入门\n * Java 进程内缓存\n * Http 缓存\n\n# 流量控制\n\n * Hystrix\n\n\n# 📚 资料\n\n * Mybatis\n   * Mybatis Github\n   * Mybatis 官网\n   * MyBatis 官方代码生成（mybatis-generator）\n   * MyBatis 官方集成 Spring（mybatis-spring）\n   * Mybatis 官方集成 Spring Boot（mybatis-spring-boot）\n   * MyBatis-Plus - CRUD 扩展插件、代码生成器、分页器等多功能\n   * Mapper - CRUD 扩展插件\n   * Mybatis-PageHelper - Mybatis 通用分页插件\n\n\n# 🚪 传送\n\n◾ 🏠 JAVA-TUTORIAL 首页 ◾ 🎯 我的博客 ◾",normalizedContent:"# java 中间件\n\n\n# 📖 内容\n\n# 消息队列\n\n> 消息队列（message queue，简称 mq）技术是分布式应用间交换信息的一种技术。\n> \n> 消息队列主要解决应用耦合，异步消息，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。\n> \n> 如果想深入学习各种消息队列产品，建议先了解一下 消息队列基本原理 ，有助于理解消息队列特性的实现和设计思路。\n\n * 消息队列面试\n * 消息队列基本原理\n * rocketmq\n * activemq\n\n# 缓存\n\n> 缓存可以说是优化系统性能的第一手段，在各种技术中都会有缓存的应用。\n> \n> 如果想深入学习缓存，建议先了解一下 缓存基本原理，有助于理解缓存的特性、原理，使用缓存常见的问题及解决方案。\n\n * 缓存面试题\n * java 缓存框架\n * memcached 快速入门\n * ehcache 快速入门\n * java 进程内缓存\n * http 缓存\n\n# 流量控制\n\n * hystrix\n\n\n# 📚 资料\n\n * mybatis\n   * mybatis github\n   * mybatis 官网\n   * mybatis 官方代码生成（mybatis-generator）\n   * mybatis 官方集成 spring（mybatis-spring）\n   * mybatis 官方集成 spring boot（mybatis-spring-boot）\n   * mybatis-plus - crud 扩展插件、代码生成器、分页器等多功能\n   * mapper - crud 扩展插件\n   * mybatis-pagehelper - mybatis 通用分页插件\n\n\n# 🚪 传送\n\n◾ 🏠 java-tutorial 首页 ◾ 🎯 我的博客 ◾",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"归档",frontmatter:{archivesPage:!0,title:"归档",permalink:"/archives/",article:!1},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-04cda89e",path:"/archives/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"分类",frontmatter:{categoriesPage:!0,title:"分类",permalink:"/categories/",article:!1},regularPath:"/@pages/categoriesPage.html",relativePath:"@pages/categoriesPage.md",key:"v-5d493111",path:"/categories/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"标签",frontmatter:{tagsPage:!0,title:"标签",permalink:"/tags/",article:!1},regularPath:"/@pages/tagsPage.html",relativePath:"@pages/tagsPage.md",key:"v-26877d31",path:"/tags/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3},{title:"Home",frontmatter:{home:!0,heroImage:"img/bg.gif",heroText:"JAVA-TUTORIAL",tagline:"☕ java-tutorial 是一个 Java 教程，汇集一个老司机在 Java 领域的十年积累。",bannerBg:"none",postList:"none",footer:"CC-BY-SA-4.0 Licensed | Copyright © 2018-Now Dunwu"},regularPath:"/",relativePath:"README.md",key:"v-10d1fe8a",path:"/",headers:[{level:2,title:"📖 内容",slug:"📖-内容",normalizedTitle:"📖 内容",charIndex:221},{level:3,title:"JavaSE",slug:"javase",normalizedTitle:"javase",charIndex:231},{level:3,title:"JavaEE",slug:"javaee",normalizedTitle:"javaee",charIndex:321},{level:4,title:"JavaWeb",slug:"javaweb",normalizedTitle:"javaweb",charIndex:331},{level:4,title:"Java 服务器",slug:"java-服务器",normalizedTitle:"java 服务器",charIndex:462},{level:3,title:"Java 软件",slug:"java-软件",normalizedTitle:"java 软件",charIndex:633},{level:4,title:"Java 构建",slug:"java-构建",normalizedTitle:"java 构建",charIndex:644},{level:4,title:"Java IDE",slug:"java-ide",normalizedTitle:"java ide",charIndex:1054},{level:4,title:"Java 监控诊断",slug:"java-监控诊断",normalizedTitle:"java 监控诊断",charIndex:1339},{level:3,title:"Java 工具",slug:"java-工具",normalizedTitle:"java 工具",charIndex:1478},{level:4,title:"Java IO",slug:"java-io",normalizedTitle:"java io",charIndex:306},{level:4,title:"JavaBean 工具",slug:"javabean-工具",normalizedTitle:"javabean 工具",charIndex:1582},{level:4,title:"Java 模板引擎",slug:"java-模板引擎",normalizedTitle:"java 模板引擎",charIndex:1617},{level:4,title:"Java 测试工具",slug:"java-测试工具",normalizedTitle:"java 测试工具",charIndex:1668},{level:4,title:"其他",slug:"其他",normalizedTitle:"其他",charIndex:1719},{level:3,title:"Java 框架",slug:"java-框架",normalizedTitle:"java 框架",charIndex:1812},{level:4,title:"ORM",slug:"orm",normalizedTitle:"orm",charIndex:1823},{level:4,title:"Spring",slug:"spring",normalizedTitle:"spring",charIndex:1861},{level:4,title:"Spring Boot",slug:"spring-boot",normalizedTitle:"spring boot",charIndex:1908},{level:4,title:"安全",slug:"安全",normalizedTitle:"安全",charIndex:1964},{level:4,title:"IO",slug:"io",normalizedTitle:"io",charIndex:311},{level:4,title:"微服务",slug:"微服务",normalizedTitle:"微服务",charIndex:2215},{level:3,title:"Java 中间件",slug:"java-中间件",normalizedTitle:"java 中间件",charIndex:2233},{level:4,title:"MQ",slug:"mq",normalizedTitle:"mq",charIndex:2245},{level:4,title:"缓存",slug:"缓存",normalizedTitle:"缓存",charIndex:2477},{level:4,title:"流量控制",slug:"流量控制",normalizedTitle:"流量控制",charIndex:2663},{level:3,title:"大数据",slug:"大数据",normalizedTitle:"大数据",charIndex:2684},{level:2,title:"📚 资料",slug:"📚-资料",normalizedTitle:"📚 资料",charIndex:2834},{level:2,title:"🚪 传送",slug:"🚪-传送",normalizedTitle:"🚪 传送",charIndex:3756}],headersStr:"📖 内容 JavaSE JavaEE JavaWeb Java 服务器 Java 软件 Java 构建 Java IDE Java 监控诊断 Java 工具 Java IO JavaBean 工具 Java 模板引擎 Java 测试工具 其他 Java 框架 ORM Spring Spring Boot 安全 IO 微服务 Java 中间件 MQ 缓存 流量控制 大数据 📚 资料 🚪 传送",content:"> ☕ java-tutorial 是一个 Java 教程，汇集一个老司机在 Java 领域的十年积累。\n> \n>  * 🔁 项目同步维护：Github | Gitee\n>  * 📖 电子书阅读：Github Pages | Gitee Pages\n> \n> 说明：\n> \n>  * 下面的内容清单中，凡是有 📚 标记的技术，都已整理成详细的教程。\n>  * 部分技术因为可以应用于不同领域，所以可能会同时出现在不同的类别下。\n\n\n# 📖 内容\n\n\n# JavaSE\n\n> 📚 javacore 是一个 Java 核心技术教程。内容包含：Java 基础特性、Java 高级特性、Java 并发、JVM、Java IO 等。\n\n\n# JavaEE\n\n# JavaWeb\n\n * JavaWeb 面经\n * JavaWeb 之 Servlet 指南\n * JavaWeb 之 Jsp 指南\n * JavaWeb 之 Filter 和 Listener\n * JavaWeb 之 Cookie 和 Session\n\n# Java 服务器\n\n> Tomcat 和 Jetty 都是 Java 比较流行的轻量级服务器。\n> \n> Nginx 是目前最流行的反向代理服务器，也常用于负载均衡。\n\n * Tomcat 快速入门\n * Tomcat 连接器\n * Tomcat 容器\n * Tomcat 优化\n * Tomcat 和 Jetty\n * Jetty\n\n\n# Java 软件\n\n# Java 构建\n\n> Java 项目需要通过 构建工具 来管理项目依赖，完成编译、打包、发布、生成 JavaDoc 等任务。\n> \n>  * 目前最主流的构建工具是 Maven，它的功能非常强大。\n>  * Gradle 号称是要替代 Maven 等构件工具，它的版本管理确实简洁，但是需要学习 Groovy，学习成本比 Maven 高。\n>  * Ant 功能比 Maven 和 Gradle 要弱，现代 Java 项目基本不用了，但也有一些传统的 Java 项目还在使用。\n\n * Maven 📚\n   * Maven 快速入门\n   * Maven 教程之 pom.xml 详解\n   * Maven 教程之 settings.xml 详解\n   * Maven 实战问题和最佳实践\n   * Maven 教程之发布 jar 到私服或中央仓库\n   * Maven 插件之代码检查\n * Ant 简易教程\n\n# Java IDE\n\n> 自从有了 IDE，写代码从此就告别了刀耕火种的蛮荒时代。\n> \n>  * Eclipse 是久负盛名的开源 Java IDE，我的学生时代一直使用它写 Java。\n>  * 曾经抗拒从转 Intellij Idea ，但后来发现真香，不得不说，确实是目前最优秀的 Java IDE。\n>  * 你可以在 vscode 中写各种语言，只要安装相应插件即可。如果你的项目中使用了很多种编程语言，又懒得在多个 IDE 之间切换，那么就用 vscode 来一网打尽吧。\n\n * Intellij Idea\n * Eclipse\n * vscode\n\n# Java 监控诊断\n\n> 监控/诊断 工具主要用于 Java 应用的运维。通过采集、分析、存储、可视化应用的有效数据，帮助开发者、使用者快速定位问题，找到性能瓶颈。\n\n * 监控工具对比\n * CAT\n * Zipkin\n * SkyWalking\n * Arthas\n\n\n# Java 工具\n\n# Java IO\n\n * JSON 序列化 - fastjson、Jackson、Gson\n * 二进制序列化 - Protobuf、Thrift、Hessian、Kryo、FST\n\n# JavaBean 工具\n\n * Lombok\n * Dozer\n\n# Java 模板引擎\n\n * Freemark\n * Velocity\n * Thymeleaf\n\n# Java 测试工具\n\n * Junit\n * Mockito\n * Jmeter\n * JMH\n\n# 其他\n\n * Java 日志\n * Java 工具包\n * Reflections\n * JavaMail\n * Jsoup\n * Thumbnailator\n * Zxing\n\n\n# Java 框架\n\n# ORM\n\n * Mybatis 快速入门\n * Mybatis 原理\n\n# Spring\n\n📚 spring-tutorial 是一个 Spring 实战教程。\n\n# Spring Boot\n\n📚 Spring Boot 教程 是一个 Spring Boot 实战教程。\n\n# 安全\n\n> Java 领域比较流行的安全框架就是 shiro 和 spring-security。\n> \n> shiro 更为简单、轻便，容易理解，能满足大多数基本安全场景下的需要。\n> \n> spring-security 功能更丰富，也比 shiro 更复杂。值得一提的是由于 spring-security 是 spring 团队开发，所以集成 spring 和 spring-boot 框架更容易。\n\n * Shiro\n * SpringSecurity\n\n# IO\n\n * Shiro\n\n# 微服务\n\n * Dubbo\n\n\n# Java 中间件\n\n# MQ\n\n> 消息队列（Message Queue，简称 MQ）技术是分布式应用间交换信息的一种技术。\n> \n> 消息队列主要解决应用耦合，异步消息，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。\n> \n> 如果想深入学习各种消息队列产品，建议先了解一下 消息队列基本原理 ，有助于理解消息队列特性的实现和设计思路。\n\n * 消息队列面试\n * 消息队列基本原理\n * RocketMQ\n * ActiveMQ\n\n# 缓存\n\n> 缓存可以说是优化系统性能的第一手段，在各种技术中都会有缓存的应用。\n> \n> 如果想深入学习缓存，建议先了解一下 缓存基本原理，有助于理解缓存的特性、原理，使用缓存常见的问题及解决方案。\n\n * 缓存面试题\n * Java 缓存中间件\n * Memcached 快速入门\n * Ehcache 快速入门\n * Java 进程内缓存\n * Http 缓存\n\n# 流量控制\n\n * Hystrix\n\n\n# 大数据\n\n> 大数据技术点以归档在：bigdata-tutorial\n\n * Hdfs 📚\n * Hbase 📚\n * Hive 📚\n * MapReduce\n * Yarn\n * ZooKeeper 📚\n * Kafka 📚\n * Spark\n * Storm\n * Flink\n\n\n# 📚 资料\n\n * Java 经典书籍\n   * 《Effective Java 中文版》 - 本书介绍了在 Java 编程中 78 条极具实用价值的经验规则，这些经验规则涵盖了大多数开发人员每天所面临的问题的解决方案。同推荐《重构 : 改善既有代码的设计》、《代码整洁之道》、《代码大全》，有一定的内容重叠。\n   * 《Java 并发编程实战》 - 本书深入浅出地介绍了 Java 线程和并发，是一本完美的 Java 并发参考手册。\n   * 《深入理解 Java 虚拟机》 - 不去了解 JVM 的工程师，和咸鱼有什么区\n   * 《Maven 实战》 - 国内最权威的 Maven 专家的力作，唯一一本哦！\n * 其他领域书籍\n   * 《Redis 设计与实现》 - 系统而全面地描述了 Redis 内部运行机制。图示丰富，描述清晰，并给出大量参考信息，是 NoSQL 数据库开发人员案头必备。\n   * 《鸟哥的 Linux 私房菜 （基础学习篇）》 - 本书是最具知名度的 Linux 入门书《鸟哥的 Linux 私房菜基础学习篇》的最新版，全面而详细地介绍了 Linux 操作系统。内容非常全面，建议挑选和自己实际工作相关度较高的，其他部分有需要再阅读。\n   * 《Head First 设计模式》 - 《Head First 设计模式》(中文版)共有 14 章，每章都介绍了几个设计模式，完整地涵盖了四人组版本全部 23 个设计模式。\n   * 《HTTP 权威指南》 - 本书尝试着将 HTTP 中一些互相关联且常被误解的规则梳理清楚，并编写了一系列基于各种主题的章节，对 HTTP 各方面的特性进行了介绍。纵观全书，对 HTTP“为什么”这样做进行了详细的解释，而不仅仅停留在它是“怎么做”的。\n   * 《TCP/IP 详解 系列》 - 完整而详细的 TCP/IP 协议指南。针对任何希望理解 TCP/IP 协议是如何实现的读者设计。\n   * 《剑指 Offer：名企面试官精讲典型编程题》 - 剖析了 80 个典型的编程面试题，系统整理基础知识、代码质量、解题思路、优化效率和综合能力这 5 个面试要点。\n\n\n# 🚪 传送\n\n◾ 🏠 JAVA-TUTORIAL 首页 ◾ 🎯 我的博客 ◾\n\n> 你可能会感兴趣：\n\n * Java 教程 📚\n * JavaCore 教程 📚\n * Spring 教程 📚\n * Spring Boot 教程 📚\n * 数据库教程 📚\n * 数据结构和算法教程 📚\n * Linux 教程 📚\n * Nginx 教程 📚",normalizedContent:"> ☕ java-tutorial 是一个 java 教程，汇集一个老司机在 java 领域的十年积累。\n> \n>  * 🔁 项目同步维护：github | gitee\n>  * 📖 电子书阅读：github pages | gitee pages\n> \n> 说明：\n> \n>  * 下面的内容清单中，凡是有 📚 标记的技术，都已整理成详细的教程。\n>  * 部分技术因为可以应用于不同领域，所以可能会同时出现在不同的类别下。\n\n\n# 📖 内容\n\n\n# javase\n\n> 📚 javacore 是一个 java 核心技术教程。内容包含：java 基础特性、java 高级特性、java 并发、jvm、java io 等。\n\n\n# javaee\n\n# javaweb\n\n * javaweb 面经\n * javaweb 之 servlet 指南\n * javaweb 之 jsp 指南\n * javaweb 之 filter 和 listener\n * javaweb 之 cookie 和 session\n\n# java 服务器\n\n> tomcat 和 jetty 都是 java 比较流行的轻量级服务器。\n> \n> nginx 是目前最流行的反向代理服务器，也常用于负载均衡。\n\n * tomcat 快速入门\n * tomcat 连接器\n * tomcat 容器\n * tomcat 优化\n * tomcat 和 jetty\n * jetty\n\n\n# java 软件\n\n# java 构建\n\n> java 项目需要通过 构建工具 来管理项目依赖，完成编译、打包、发布、生成 javadoc 等任务。\n> \n>  * 目前最主流的构建工具是 maven，它的功能非常强大。\n>  * gradle 号称是要替代 maven 等构件工具，它的版本管理确实简洁，但是需要学习 groovy，学习成本比 maven 高。\n>  * ant 功能比 maven 和 gradle 要弱，现代 java 项目基本不用了，但也有一些传统的 java 项目还在使用。\n\n * maven 📚\n   * maven 快速入门\n   * maven 教程之 pom.xml 详解\n   * maven 教程之 settings.xml 详解\n   * maven 实战问题和最佳实践\n   * maven 教程之发布 jar 到私服或中央仓库\n   * maven 插件之代码检查\n * ant 简易教程\n\n# java ide\n\n> 自从有了 ide，写代码从此就告别了刀耕火种的蛮荒时代。\n> \n>  * eclipse 是久负盛名的开源 java ide，我的学生时代一直使用它写 java。\n>  * 曾经抗拒从转 intellij idea ，但后来发现真香，不得不说，确实是目前最优秀的 java ide。\n>  * 你可以在 vscode 中写各种语言，只要安装相应插件即可。如果你的项目中使用了很多种编程语言，又懒得在多个 ide 之间切换，那么就用 vscode 来一网打尽吧。\n\n * intellij idea\n * eclipse\n * vscode\n\n# java 监控诊断\n\n> 监控/诊断 工具主要用于 java 应用的运维。通过采集、分析、存储、可视化应用的有效数据，帮助开发者、使用者快速定位问题，找到性能瓶颈。\n\n * 监控工具对比\n * cat\n * zipkin\n * skywalking\n * arthas\n\n\n# java 工具\n\n# java io\n\n * json 序列化 - fastjson、jackson、gson\n * 二进制序列化 - protobuf、thrift、hessian、kryo、fst\n\n# javabean 工具\n\n * lombok\n * dozer\n\n# java 模板引擎\n\n * freemark\n * velocity\n * thymeleaf\n\n# java 测试工具\n\n * junit\n * mockito\n * jmeter\n * jmh\n\n# 其他\n\n * java 日志\n * java 工具包\n * reflections\n * javamail\n * jsoup\n * thumbnailator\n * zxing\n\n\n# java 框架\n\n# orm\n\n * mybatis 快速入门\n * mybatis 原理\n\n# spring\n\n📚 spring-tutorial 是一个 spring 实战教程。\n\n# spring boot\n\n📚 spring boot 教程 是一个 spring boot 实战教程。\n\n# 安全\n\n> java 领域比较流行的安全框架就是 shiro 和 spring-security。\n> \n> shiro 更为简单、轻便，容易理解，能满足大多数基本安全场景下的需要。\n> \n> spring-security 功能更丰富，也比 shiro 更复杂。值得一提的是由于 spring-security 是 spring 团队开发，所以集成 spring 和 spring-boot 框架更容易。\n\n * shiro\n * springsecurity\n\n# io\n\n * shiro\n\n# 微服务\n\n * dubbo\n\n\n# java 中间件\n\n# mq\n\n> 消息队列（message queue，简称 mq）技术是分布式应用间交换信息的一种技术。\n> \n> 消息队列主要解决应用耦合，异步消息，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。\n> \n> 如果想深入学习各种消息队列产品，建议先了解一下 消息队列基本原理 ，有助于理解消息队列特性的实现和设计思路。\n\n * 消息队列面试\n * 消息队列基本原理\n * rocketmq\n * activemq\n\n# 缓存\n\n> 缓存可以说是优化系统性能的第一手段，在各种技术中都会有缓存的应用。\n> \n> 如果想深入学习缓存，建议先了解一下 缓存基本原理，有助于理解缓存的特性、原理，使用缓存常见的问题及解决方案。\n\n * 缓存面试题\n * java 缓存中间件\n * memcached 快速入门\n * ehcache 快速入门\n * java 进程内缓存\n * http 缓存\n\n# 流量控制\n\n * hystrix\n\n\n# 大数据\n\n> 大数据技术点以归档在：bigdata-tutorial\n\n * hdfs 📚\n * hbase 📚\n * hive 📚\n * mapreduce\n * yarn\n * zookeeper 📚\n * kafka 📚\n * spark\n * storm\n * flink\n\n\n# 📚 资料\n\n * java 经典书籍\n   * 《effective java 中文版》 - 本书介绍了在 java 编程中 78 条极具实用价值的经验规则，这些经验规则涵盖了大多数开发人员每天所面临的问题的解决方案。同推荐《重构 : 改善既有代码的设计》、《代码整洁之道》、《代码大全》，有一定的内容重叠。\n   * 《java 并发编程实战》 - 本书深入浅出地介绍了 java 线程和并发，是一本完美的 java 并发参考手册。\n   * 《深入理解 java 虚拟机》 - 不去了解 jvm 的工程师，和咸鱼有什么区\n   * 《maven 实战》 - 国内最权威的 maven 专家的力作，唯一一本哦！\n * 其他领域书籍\n   * 《redis 设计与实现》 - 系统而全面地描述了 redis 内部运行机制。图示丰富，描述清晰，并给出大量参考信息，是 nosql 数据库开发人员案头必备。\n   * 《鸟哥的 linux 私房菜 （基础学习篇）》 - 本书是最具知名度的 linux 入门书《鸟哥的 linux 私房菜基础学习篇》的最新版，全面而详细地介绍了 linux 操作系统。内容非常全面，建议挑选和自己实际工作相关度较高的，其他部分有需要再阅读。\n   * 《head first 设计模式》 - 《head first 设计模式》(中文版)共有 14 章，每章都介绍了几个设计模式，完整地涵盖了四人组版本全部 23 个设计模式。\n   * 《http 权威指南》 - 本书尝试着将 http 中一些互相关联且常被误解的规则梳理清楚，并编写了一系列基于各种主题的章节，对 http 各方面的特性进行了介绍。纵观全书，对 http“为什么”这样做进行了详细的解释，而不仅仅停留在它是“怎么做”的。\n   * 《tcp/ip 详解 系列》 - 完整而详细的 tcp/ip 协议指南。针对任何希望理解 tcp/ip 协议是如何实现的读者设计。\n   * 《剑指 offer：名企面试官精讲典型编程题》 - 剖析了 80 个典型的编程面试题，系统整理基础知识、代码质量、解题思路、优化效率和综合能力这 5 个面试要点。\n\n\n# 🚪 传送\n\n◾ 🏠 java-tutorial 首页 ◾ 🎯 我的博客 ◾\n\n> 你可能会感兴趣：\n\n * java 教程 📚\n * javacore 教程 📚\n * spring 教程 📚\n * spring boot 教程 📚\n * 数据库教程 📚\n * 数据结构和算法教程 📚\n * linux 教程 📚\n * nginx 教程 📚",charsets:{cjk:!0},lastUpdated:"2022/07/08, 19:00:16",lastUpdatedTimestamp:1657278016e3}],themeConfig:{nav:[{text:"JavaEE",items:[{text:"JavaWeb",link:"/02.JavaEE/01.JavaWeb/"},{text:"服务器",link:"/02.JavaEE/02.服务器/"}]},{text:"Java软件",link:"/11.软件/",items:[{text:"Java构建",link:"/11.软件/01.构建/"},{text:"Java IDE",link:"/11.软件/02.IDE/"},{text:"Java监控诊断",link:"/11.软件/03.监控诊断/"}]},{text:"Java工具",link:"/12.工具/"},{text:"Java框架",link:"/13.框架/"},{text:"Java中间件",link:"/14.中间件/"},{text:"✨ Java系列",ariaLabel:"Java",items:[{text:"Java 教程 📚",link:"https://dunwu.github.io/java-tutorial/",target:"_blank"},{text:"JavaCore 教程 📚",link:"https://dunwu.github.io/javacore/",target:"_blank"}]}],sidebarDepth:2,logo:"https://raw.githubusercontent.com/dunwu/images/dev/common/dunwu-logo.png",repo:"dunwu/java-tutorial",searchMaxSuggestions:10,lastUpdated:"上次更新",docsDir:"docs",editLinks:!0,editLinkText:"📝 帮助改善此页面！",sidebar:{"/02.JavaEE/":[{title:"JavaWeb",collapsable:!1,children:[["01.JavaWeb/01.JavaWeb之Servlet指南.md","JavaWeb 之 Servlet 指南","/pages/be093b/"],["01.JavaWeb/02.JavaWeb之Jsp指南.md","JavaWeb 之 Jsp 指南","/pages/6bbb16/"],["01.JavaWeb/03.JavaWeb之Filter和Listener.md","JavaWeb 之 Filter 和 Listener","/pages/5ecb29/"],["01.JavaWeb/04.JavaWeb之Cookie和Session.md","JavaWeb 之 Cookie 和 Session","/pages/e61883/"],["01.JavaWeb/99.JavaWeb面经.md","JavaWeb 面经","/pages/1933b3/"]]},{title:"服务器",collapsable:!1,children:[{title:"Tomcat",collapsable:!1,children:[["02.服务器/01.Tomcat/01.Tomcat快速入门.md","Tomcat 快速入门","/pages/c50d2b/"],["02.服务器/01.Tomcat/02.Tomcat连接器.md","Tomcat连接器","/pages/3c954b/"],["02.服务器/01.Tomcat/03.Tomcat容器.md","Tomcat容器","/pages/2fea08/"],["02.服务器/01.Tomcat/04.Tomcat优化.md","Tomcat优化","/pages/6c22f4/"],["02.服务器/01.Tomcat/05.Tomcat和Jetty.md","Tomcat 和 Jetty","/pages/f1bba6/"]]},["02.服务器/02.Jetty.md","Jetty 快速入门","/pages/9ecdc1/"]]}],catalogue:{},"/11.软件/":[{title:"构建",collapsable:!1,children:[{title:"Maven",collapsable:!1,children:[["01.构建/01.Maven/01.Maven快速入门.md","Maven 快速入门","/pages/6b8149/"],["01.构建/01.Maven/02.Maven教程之pom.xml详解.md","Maven 教程之 pom.xml 详解","/pages/f594fa/"],["01.构建/01.Maven/03.Maven教程之settings.xml详解.md","Maven 教程之 settings.xml 详解","/pages/d05c38/"],["01.构建/01.Maven/04.Maven实战问题和最佳实践.md","Maven 实战问题和最佳实践","/pages/7908f2/"],["01.构建/01.Maven/05.Maven教程之发布jar到私服或中央仓库.md","Maven 教程之发布 jar 到私服或中央仓库","/pages/2ddf04/"],["01.构建/01.Maven/06.Maven插件之代码检查.md","Maven 插件之代码检查","/pages/149013/"]]},["01.构建/02.Ant.md","Ant 简易教程","/pages/e2af3a/"]]},{title:"IDE",collapsable:!1,children:[["02.IDE/01.Intellij.md","Intellij IDEA 快速入门","/pages/ea83ee/"],["02.IDE/02.Eclipse.md","Eclipse 快速入门","/pages/a897a9/"],["02.IDE/03.VsCode.md","Vscode 快速入门","/pages/a537c7/"]]},{title:"监控诊断",collapsable:!1,children:[["03.监控诊断/01.监控工具对比.md","监控工具对比","/pages/c7c5ec/"],["03.监控诊断/02.CAT.md","CAT 快速入门","/pages/83e684/"],["03.监控诊断/03.Zipkin.md","Zipkin 快速入门","/pages/82c168/"],["03.监控诊断/04.Skywalking.md","SkyWalking 快速入门","/pages/d82d3c/"],["03.监控诊断/05.Arthas.md","Arthas 快速入门","/pages/b6a542/"]]}],"/12.工具/":[{title:"IO",collapsable:!1,children:[["01.IO/01.JSON序列化.md","Java 和 JSON 序列化","/pages/a14952/"],["01.IO/02.二进制序列化.md","Java 二进制序列化","/pages/95f25b/"]]},{title:"JavaBean",collapsable:!1,children:[["02.JavaBean/01.Lombok.md","Lombok 快速入门","/pages/0d31cd/"],["02.JavaBean/02.Dozer.md","Dozer 快速入门","/pages/596174/"]]},{title:"模板引擎",collapsable:!1,children:[["03.模板引擎/01.Freemark.md","Freemark 快速入门","/pages/34ec25/"],["03.模板引擎/02.Thymeleaf.md","Thymeleaf 快速入门","/pages/2263fb/"],["03.模板引擎/03.Velocity.md","Velocity 快速入门","/pages/7ecb81/"]]},{title:"测试",collapsable:!1,children:[["04.测试/01.Junit.md","JUnit5 快速入门","/pages/06533c/"],["04.测试/02.Mockito.md","Mockito 快速入门","/pages/ab18ad/"],["04.测试/03.Jmeter.md","JMeter 快速入门","/pages/d99171/"],["04.测试/04.JMH.md","JMH 快速入门","/pages/747d3e/"]]},{title:"其他",collapsable:!1,children:[["99.其他/01.Java日志.md","javalib-log","/pages/337701/"],["99.其他/02.Java工具包.md","javalib-util","/pages/14e432/"],["99.其他/03.Reflections.md","Reflections 快速入门","/pages/ea4914/"],["99.其他/04.JavaMail.md","JavaMail 快速入门","/pages/da3f07/"],["99.其他/05.Jsoup.md","Jsoup 快速入门","/pages/c516cc/"],["99.其他/06.Thumbnailator.md","Thumbnailator 快速入门","/pages/aa9f61/"],["99.其他/07.Zxing.md","ZXing 快速入门","/pages/cc8ce5/"]]}],"/13.框架/":[{title:"ORM",collapsable:!1,children:[["11.ORM/01.Mybatis快速入门.md","Mybatis快速入门","/pages/538358/"],["11.ORM/02.Mybatis原理.md","Mybatis原理","/pages/3f3dba/"]]},{title:"安全",collapsable:!1,children:[["12.安全/01.Shiro.md","Shiro 快速入门","/pages/cd25bf/"],["12.安全/02.SpringSecurity.md","Spring Security 快速入门","/pages/a6cc5f/"]]},{title:"IO",collapsable:!1,children:[["13.IO/01.Netty.md","Netty 快速入门","/pages/520c52/"]]},{title:"微服务",collapsable:!1,children:[["14.微服务/01.Dubbo.md","Dubbo 快速入门","/pages/e79b77/"]]}],"/14.中间件/":[{title:"MQ",collapsable:!1,children:[["01.MQ/01.消息队列面试.md","消息队列面试","/pages/5a6cf3/"],["01.MQ/02.消息队列基本原理.md","消息队列基本原理","/pages/055069/"],["01.MQ/03.RocketMQ.md","RocketMQ 快速入门","/pages/f56a96/"],["01.MQ/04.ActiveMQ.md","ActiveMQ 快速入门","/pages/3f7c49/"]]},{title:"缓存",collapsable:!1,children:[["02.缓存/01.缓存面试题.md","缓存夺命连环问","/pages/eb30d6/"],["02.缓存/02.Java缓存中间件.md","Java 缓存中间件","/pages/970fa6/"],["02.缓存/03.Memcached.md","Memcached 快速入门","/pages/25a710/"],["02.缓存/04.Ehcache.md","Ehcache 快速入门","/pages/c4647d/"],["02.缓存/05.Java进程内缓存.md","Java 进程内缓存","/pages/9632fd/"],["02.缓存/06.Http缓存.md","http-cache","/pages/c09100/"]]},{title:"流量控制",collapsable:!1,children:[["03.流量控制/01.Hystrix.md","Hystrix 快速入门","/pages/f2ebed/"]]}]},updateBar:{showToArticle:!0},category:!0,tag:!0,archive:!0,author:{name:"dunwu",href:"https://github.com/dunwu"},social:{icons:[{iconClass:"icon-youjian",title:"发邮件",link:"mailto:forbreak@163.com"},{iconClass:"icon-github",title:"GitHub",link:"https://github.com/dunwu"}]},footer:{createYear:2019,copyrightInfo:"钝悟（dunwu） | CC-BY-SA-4.0"},htmlModules:{pageB:'\n  <div class="wwads-cn wwads-horizontal pageB" data-id="136" style="width:100%;max-height:80px;min-height:auto;"></div>\n  <style>\n    .pageB img{width:80px!important;}\n    .wwads-horizontal .wwads-text, .wwads-content .wwads-text{line-height:1;}\n  </style>\n  ',windowRB:'\n    <div class="wwads-cn wwads-vertical windowRB" data-id="136" style="max-width:160px;\n    min-width: auto;min-height:auto;"></div>\n    <style>\n      .windowRB{ padding: 0;}\n      .windowRB .wwads-img{margin-top: 10px;}\n      .windowRB .wwads-content{margin: 0 10px 10px 10px;}\n      .custom-html-window-rb .close-but{\n        display: none;\n      }\n    </style>\n  '}}};function fl(n){const e=document.createElement("link");e.href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css",e.rel="stylesheet",document.body.appendChild(e);const t=document.createElement("script");function a(n){let e=document.getElementById("gitalk-container");e||(e=document.createElement("div"),e.id="gitalk-container",e.classList.add("content"));const t=document.querySelector(".page");t&&(t.appendChild(e),"undefined"!=typeof Gitalk&&Gitalk instanceof Function&&function(n){console.info(n);new Gitalk({clientID:"1ba9606d18aec7c070d4",clientSecret:"57c7e5e3611840efe117ccbad4d87fb60cb364cc",repo:"java-tutorial",owner:"dunwu",admin:["dunwu"],id:"comment",distractionFreeMode:!1,language:"zh-CN"}).render("gitalk-container")}(n.fullPath))}t.src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js",document.body.appendChild(t),n.afterEach(n=>{t.onload?a(n):t.onload=()=>{a(n)}})}var yl=t(92),xl=t(93),kl=t(11);var jl={computed:{$filterPosts(){return this.$site.pages.filter(n=>{const{frontmatter:{pageComponent:e,article:t,home:a}}=n;return!(e||!1===t||!0===a)})},$sortPosts(){return(n=this.$filterPosts).sort((n,e)=>{const t=n.frontmatter.sticky,a=e.frontmatter.sticky;return t&&a?t==a?Object(kl.a)(n,e):t-a:t&&!a?-1:!t&&a?1:Object(kl.a)(n,e)}),n;var n},$sortPostsByDate(){return(n=this.$filterPosts).sort((n,e)=>Object(kl.a)(n,e)),n;var n},$groupPosts(){return function(n){const e={},t={};for(let a=0,r=n.length;a<r;a++){const{frontmatter:{categories:r,tags:i}}=n[a];"array"===Object(kl.n)(r)&&r.forEach(t=>{t&&(e[t]||(e[t]=[]),e[t].push(n[a]))}),"array"===Object(kl.n)(i)&&i.forEach(e=>{e&&(t[e]||(t[e]=[]),t[e].push(n[a]))})}return{categories:e,tags:t}}(this.$sortPosts)},$categoriesAndTags(){return function(n){const e=[],t=[];for(let t in n.categories)e.push({key:t,length:n.categories[t].length});for(let e in n.tags)t.push({key:e,length:n.tags[e].length});return{categories:e,tags:t}}(this.$groupPosts)}}};Nt.component(yl.default),Nt.component(xl.default);function Sl(n){return n.toString().padStart(2,"0")}t(235);Nt.component("Badge",()=>Promise.all([t.e(0),t.e(3)]).then(t.bind(null,403))),Nt.component("CodeBlock",()=>Promise.resolve().then(t.bind(null,92))),Nt.component("CodeGroup",()=>Promise.resolve().then(t.bind(null,93)));t(236);var wl=[({Vue:n,options:e,router:t,siteData:a,isServer:r})=>{r||t.afterEach(()=>{var n;n=function(){},"complete"===document.readyState||"interactive"===document.readyState?setTimeout(n,1):document.addEventListener("DOMContentLoaded",n),setTimeout(()=>{const n=document.querySelector(".pageB");if(!n)return;const e=n.querySelector(".wwads-hide");e&&(e.onclick=()=>{n.style.display="none"}),n.style.display="flex",fl(t)},0)});try{document&&fl(t)}catch(n){console.error(n.message)}},({Vue:n,options:e,router:t,siteData:a})=>{a.pages.map(n=>{const{frontmatter:{date:e,author:t}}=n;"string"==typeof e&&"Z"===e.charAt(e.length-1)&&(n.frontmatter.date=function(n){n instanceof Date||(n=new Date(n));return`${n.getUTCFullYear()}-${Sl(n.getUTCMonth()+1)}-${Sl(n.getUTCDate())} ${Sl(n.getUTCHours())}:${Sl(n.getUTCMinutes())}:${Sl(n.getUTCSeconds())}`}(e)),t?n.author=t:a.themeConfig.author&&(n.author=a.themeConfig.author)}),n.mixin(jl)},{},({Vue:n})=>{n.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},{},()=>{"undefined"!=typeof window&&function(n,e,t){function a(n){var t=e.createElement("div");t.className="heart",r.push({el:t,x:n.clientX-5,y:n.clientY-5,scale:1,alpha:1,color:"#11a8cd"}),e.body.appendChild(t)}var r=[];n.requestAnimationFrame=n.requestAnimationFrame||n.webkitRequestAnimationFrame||n.mozRequestAnimationFrame||n.oRequestAnimationFrame||n.msRequestAnimationFrame||function(n){setTimeout(n,1e3/60)},function(n){var t=e.createElement("style");t.type="text/css";try{t.appendChild(e.createTextNode(n))}catch(e){t.styleSheet.cssText=n}e.getElementsByTagName("head")[0].appendChild(t)}(".heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}"),function(){var e="function"==typeof n.onclick&&n.onclick;n.onclick=function(n){let t=!0;n.path&&n.path.forEach(n=>{1===n.nodeType&&"string"==typeof n.className&&n.className.indexOf("theme-vdoing-content")>-1&&(t=!1)}),t&&(e&&e(),a(n))}}(),function n(){for(var t=0;t<r.length;t++)r[t].alpha<=0?(e.body.removeChild(r[t].el),r.splice(t,1)):(r[t].y--,r[t].scale+=.004,r[t].alpha-=.013,r[t].el.style.cssText="left:"+r[t].x+"px;top:"+r[t].y+"px;opacity:"+r[t].alpha+";transform:scale("+r[t].scale+","+r[t].scale+") rotate(45deg);background:"+r[t].color+";z-index:99999");requestAnimationFrame(n)}()}(window,document)}],Tl=[];class Il extends class{constructor(){this.store=new Nt({data:{state:{}}})}$get(n){return this.store.state[n]}$set(n,e){Nt.set(this.store.state,n,e)}$emit(...n){this.store.$emit(...n)}$on(...n){this.store.$on(...n)}}{}Object.assign(Il.prototype,{getPageAsyncComponent:as,getLayoutAsyncComponent:rs,getAsyncComponent:is,getVueComponent:os});var Cl={install(n){const e=new Il;n.$vuepress=e,n.prototype.$vuepress=e}};function Ml(n,e){const t=e.toLowerCase();return n.options.routes.some(n=>n.path.toLowerCase()===t)}var El={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(n){const e=this.pageKey||this.$parent.$page.key;return ls("pageKey",e),Nt.component(e)||Nt.component(e,as(e)),Nt.component(e)?n(e):n("")}},Pl={functional:!0,props:{slotKey:String,required:!0},render:(n,{props:e,slots:t})=>n("div",{class:["content__"+e.slotKey]},t()[e.slotKey])},zl={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Al=(t(237),t(238),Object(hl.a)(zl,(function(){var n=this._self._c;return n("span",[n("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[n("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),n("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),n("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),ql={functional:!0,render(n,{parent:e,children:t}){if(e._isMounted)return t;e.$once("hook:mounted",()=>{e.$forceUpdate()})}};Nt.config.productionTip=!1,Nt.use(Fo),Nt.use(Cl),Nt.mixin(function(n,e,t=Nt){!function(n){n.locales&&Object.keys(n.locales).forEach(e=>{n.locales[e].path=e});Object.freeze(n)}(e),t.$vuepress.$set("siteData",e);const a=new(n(t.$vuepress.$get("siteData"))),r=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(a)),i={};return Object.keys(r).reduce((n,e)=>(e.startsWith("$")&&(n[e]=r[e].get),n),i),{computed:i}}(n=>class{setPage(n){this.__page=n}get $site(){return n}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:n={}}=this.$site;let e,t;for(const a in n)"/"===a?t=n[a]:0===this.$page.path.indexOf(a)&&(e=n[a]);return e||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:n}=this.$page.frontmatter;return"string"==typeof n&&n}get $title(){const n=this.$page,{metaTitle:e}=this.$page.frontmatter;if("string"==typeof e)return e;const t=this.$siteTitle,a=n.frontmatter.home?null:n.frontmatter.title||n.title;return t?a?a+" | "+t:t:a||"VuePress"}get $description(){const n=function(n){if(n){const e=n.filter(n=>"description"===n.name)[0];if(e)return e.content}}(this.$page.frontmatter.meta);return n||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(n,e){for(let t=0;t<n.length;t++){const a=n[t];if(a.path.toLowerCase()===e.toLowerCase())return a}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},bl)),Nt.component("Content",El),Nt.component("ContentSlotsDistributor",Pl),Nt.component("OutboundLink",Al),Nt.component("ClientOnly",ql),Nt.component("Layout",rs("Layout")),Nt.component("NotFound",rs("NotFound")),Nt.prototype.$withBase=function(n){const e=this.$site.base;return"/"===n.charAt(0)?e+n.slice(1):n},window.__VUEPRESS__={version:"1.9.2",hash:"68388af"},async function(n){const e="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:bl.routerBase||bl.base,t=new Fo({base:e,mode:"history",fallback:!1,routes:vl,scrollBehavior:(n,e,t)=>t||(n.hash?!Nt.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(n.hash)}:{x:0,y:0})});!function(n){n.beforeEach((e,t,a)=>{if(Ml(n,e.path))a();else if(/(\/|\.html)$/.test(e.path))if(/\/$/.test(e.path)){const t=e.path.replace(/\/$/,"")+".html";Ml(n,t)?a(t):a()}else a();else{const t=e.path+"/",r=e.path+".html";Ml(n,r)?a(r):Ml(n,t)?a(t):a()}})}(t);const a={};try{await Promise.all(wl.filter(n=>"function"==typeof n).map(e=>e({Vue:Nt,options:a,router:t,siteData:bl,isServer:n})))}catch(n){console.error(n)}return{app:new Nt(Object.assign(a,{router:t,render:n=>n("div",{attrs:{id:"app"}},[n("RouterView",{ref:"layout"}),n("div",{class:"global-ui"},Tl.map(e=>n(e)))])})),router:t}}(!1).then(({app:n,router:e})=>{e.onReady(()=>{n.$mount("#app")})})}]);